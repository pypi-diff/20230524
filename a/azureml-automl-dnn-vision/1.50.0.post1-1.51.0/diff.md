# Comparing `tmp/azureml_automl_dnn_vision-1.50.0.post1-py3-none-any.whl.zip` & `tmp/azureml_automl_dnn_vision-1.51.0-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,194 +1,194 @@
-Zip file size: 435144 bytes, number of entries: 192
--rw-rw-rw-  2.0 fat      299 b- defN 23-Apr-27 14:30 azureml/__init__.py
--rw-rw-rw-  2.0 fat      311 b- defN 23-Apr-27 14:31 azureml/automl/__init__.py
--rw-rw-rw-  2.0 fat      315 b- defN 23-Apr-27 14:32 azureml/automl/dnn/__init__.py
--rw-rw-rw-  2.0 fat      682 b- defN 23-Apr-27 14:34 azureml/automl/dnn/vision/__init__.py
--rw-rw-rw-  2.0 fat      226 b- defN 23-Apr-27 14:36 azureml/automl/dnn/vision/classification/__init__.py
--rw-rw-rw-  2.0 fat    14072 b- defN 23-Apr-27 14:36 azureml/automl/dnn/vision/classification/runner.py
--rw-rw-rw-  2.0 fat      229 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/classification/common/__init__.py
--rw-rw-rw-  2.0 fat    26968 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/classification/common/classification_utils.py
--rw-rw-rw-  2.0 fat     7587 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/classification/common/constants.py
--rw-rw-rw-  2.0 fat     2573 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/classification/common/transforms.py
--rw-rw-rw-  2.0 fat      208 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/classification/inference/__init__.py
--rw-rw-rw-  2.0 fat    23903 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/classification/inference/score.py
--rw-rw-rw-  2.0 fat      210 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/classification/io/__init__.py
--rw-rw-rw-  2.0 fat      398 b- defN 23-Apr-27 14:38 azureml/automl/dnn/vision/classification/io/read/__init__.py
--rw-rw-rw-  2.0 fat     4919 b- defN 23-Apr-27 14:38 azureml/automl/dnn/vision/classification/io/read/dataloader.py
--rw-rw-rw-  2.0 fat    22399 b- defN 23-Apr-27 14:38 azureml/automl/dnn/vision/classification/io/read/dataset_wrappers.py
--rw-rw-rw-  2.0 fat     5541 b- defN 23-Apr-27 14:38 azureml/automl/dnn/vision/classification/io/read/utils.py
--rw-rw-rw-  2.0 fat      237 b- defN 23-Apr-27 14:38 azureml/automl/dnn/vision/classification/io/write/__init__.py
--rw-rw-rw-  2.0 fat     2613 b- defN 23-Apr-27 14:38 azureml/automl/dnn/vision/classification/io/write/featurize_script.py
--rw-rw-rw-  2.0 fat     6433 b- defN 23-Apr-27 14:38 azureml/automl/dnn/vision/classification/io/write/score_script.py
--rw-rw-rw-  2.0 fat      973 b- defN 23-Apr-27 14:38 azureml/automl/dnn/vision/classification/io/write/score_script_utils.py
--rw-rw-rw-  2.0 fat      429 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/classification/models/__init__.py
--rw-rw-rw-  2.0 fat    11491 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/classification/models/base_model_wrapper.py
--rw-rw-rw-  2.0 fat    30503 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/classification/models/classification_model_wrappers.py
--rw-rw-rw-  2.0 fat      221 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/classification/trainer/__init__.py
--rw-rw-rw-  2.0 fat     1203 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/classification/trainer/criterion.py
--rw-rw-rw-  2.0 fat    38271 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/classification/trainer/train.py
--rw-rw-rw-  2.0 fat    85645 b- defN 23-Apr-27 14:36 azureml/automl/dnn/vision/common/NOTICE
--rw-rw-rw-  2.0 fat      263 b- defN 23-Apr-27 14:36 azureml/automl/dnn/vision/common/__init__.py
--rw-rw-rw-  2.0 fat     1903 b- defN 23-Apr-27 14:36 azureml/automl/dnn/vision/common/aml_dataset_base_wrapper.py
--rw-rw-rw-  2.0 fat    18726 b- defN 23-Apr-27 14:36 azureml/automl/dnn/vision/common/artifacts_utils.py
--rw-rw-rw-  2.0 fat     2025 b- defN 23-Apr-27 14:36 azureml/automl/dnn/vision/common/average_meter.py
--rw-rw-rw-  2.0 fat     2162 b- defN 23-Apr-27 14:36 azureml/automl/dnn/vision/common/base_model_factory.py
--rw-rw-rw-  2.0 fat     1231 b- defN 23-Apr-27 14:36 azureml/automl/dnn/vision/common/base_model_settings.py
--rw-rw-rw-  2.0 fat    22576 b- defN 23-Apr-27 14:36 azureml/automl/dnn/vision/common/constants.py
--rw-rw-rw-  2.0 fat     2826 b- defN 23-Apr-27 14:36 azureml/automl/dnn/vision/common/data_utils.py
--rw-rw-rw-  2.0 fat     3184 b- defN 23-Apr-27 14:36 azureml/automl/dnn/vision/common/dataloaders.py
--rw-rw-rw-  2.0 fat    18976 b- defN 23-Apr-27 14:36 azureml/automl/dnn/vision/common/dataset_helper.py
--rw-rw-rw-  2.0 fat    21108 b- defN 23-Apr-27 14:36 azureml/automl/dnn/vision/common/distributed_utils.py
--rw-rw-rw-  2.0 fat      672 b- defN 23-Apr-27 14:36 azureml/automl/dnn/vision/common/errors.py
--rw-rw-rw-  2.0 fat     2379 b- defN 23-Apr-27 14:36 azureml/automl/dnn/vision/common/exceptions.py
--rw-rw-rw-  2.0 fat     2528 b- defN 23-Apr-27 14:36 azureml/automl/dnn/vision/common/logging_utils.py
--rw-rw-rw-  2.0 fat    25971 b- defN 23-Apr-27 14:36 azureml/automl/dnn/vision/common/model_export_utils.py
--rw-rw-rw-  2.0 fat    14736 b- defN 23-Apr-27 14:36 azureml/automl/dnn/vision/common/parameters.py
--rw-rw-rw-  2.0 fat    10208 b- defN 23-Apr-27 14:36 azureml/automl/dnn/vision/common/prediction_dataset.py
--rw-rw-rw-  2.0 fat    37171 b- defN 23-Apr-27 14:36 azureml/automl/dnn/vision/common/pretrained_model_utilities.py
--rw-rw-rw-  2.0 fat     3200 b- defN 23-Apr-27 14:36 azureml/automl/dnn/vision/common/sku_validation.py
--rw-rw-rw-  2.0 fat     9887 b- defN 23-Apr-27 14:36 azureml/automl/dnn/vision/common/system_meter.py
--rw-rw-rw-  2.0 fat     5490 b- defN 23-Apr-27 14:36 azureml/automl/dnn/vision/common/tiling_dataset_element.py
--rw-rw-rw-  2.0 fat     6434 b- defN 23-Apr-27 14:36 azureml/automl/dnn/vision/common/tiling_utils.py
--rw-rw-rw-  2.0 fat     1039 b- defN 23-Apr-27 14:36 azureml/automl/dnn/vision/common/torch_utils.py
--rw-rw-rw-  2.0 fat     2994 b- defN 23-Apr-27 14:36 azureml/automl/dnn/vision/common/training_state.py
--rw-rw-rw-  2.0 fat    70131 b- defN 23-Apr-27 14:36 azureml/automl/dnn/vision/common/utils.py
--rw-rw-rw-  2.0 fat      237 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/common/mlflow/__init__.py
--rw-rw-rw-  2.0 fat     6364 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/common/mlflow/mlflow_model_wrapper.py
--rw-rw-rw-  2.0 fat      272 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/common/trainer/__init__.py
--rw-rw-rw-  2.0 fat     7720 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/common/trainer/lrschedule.py
--rw-rw-rw-  2.0 fat     3336 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/common/trainer/lrschedule_parameters.py
--rw-rw-rw-  2.0 fat     9241 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/common/trainer/optimize.py
--rw-rw-rw-  2.0 fat     4337 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/common/trainer/optimize_parameters.py
--rw-rw-rw-  2.0 fat      229 b- defN 23-Apr-27 14:36 azureml/automl/dnn/vision/explainability/__init__.py
--rw-rw-rw-  2.0 fat     2638 b- defN 23-Apr-27 14:36 azureml/automl/dnn/vision/explainability/constants.py
--rw-rw-rw-  2.0 fat    16285 b- defN 23-Apr-27 14:36 azureml/automl/dnn/vision/explainability/methods.py
--rw-rw-rw-  2.0 fat     8627 b- defN 23-Apr-27 14:36 azureml/automl/dnn/vision/explainability/utils.py
--rw-rw-rw-  2.0 fat     6437 b- defN 23-Apr-27 14:36 azureml/automl/dnn/vision/explainability/xrai_utils.py
--rw-rw-rw-  2.0 fat      321 b- defN 23-Apr-27 14:36 azureml/automl/dnn/vision/metrics/__init__.py
--rw-rw-rw-  2.0 fat     6643 b- defN 23-Apr-27 14:36 azureml/automl/dnn/vision/metrics/automl_classification_metrics.py
--rw-rw-rw-  2.0 fat     4480 b- defN 23-Apr-27 14:36 azureml/automl/dnn/vision/metrics/classification_metrics.py
--rw-rw-rw-  2.0 fat      240 b- defN 23-Apr-27 14:36 azureml/automl/dnn/vision/object_detection/__init__.py
--rw-rw-rw-  2.0 fat    20822 b- defN 23-Apr-27 14:36 azureml/automl/dnn/vision/object_detection/runner.py
--rw-rw-rw-  2.0 fat      243 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/object_detection/common/__init__.py
--rw-rw-rw-  2.0 fat     9636 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/object_detection/common/augmentations.py
--rw-rw-rw-  2.0 fat     7356 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/object_detection/common/boundingbox.py
--rw-rw-rw-  2.0 fat     3009 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/object_detection/common/coco_eval_box_converter.py
--rw-rw-rw-  2.0 fat    11089 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/object_detection/common/constants.py
--rw-rw-rw-  2.0 fat    11945 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/object_detection/common/masktools.py
--rw-rw-rw-  2.0 fat    27385 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/object_detection/common/object_detection_utils.py
--rw-rw-rw-  2.0 fat     1632 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/object_detection/common/od_training_state.py
--rw-rw-rw-  2.0 fat     4891 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/object_detection/common/parameters.py
--rw-rw-rw-  2.0 fat    25960 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/object_detection/common/tiling_helper.py
--rw-rw-rw-  2.0 fat      238 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/object_detection/data/__init__.py
--rw-rw-rw-  2.0 fat     4886 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/object_detection/data/dataset_wrappers.py
--rw-rw-rw-  2.0 fat    40147 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/object_detection/data/datasets.py
--rw-rw-rw-  2.0 fat     6110 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/object_detection/data/loaders.py
--rw-rw-rw-  2.0 fat    12574 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/object_detection/data/object_annotation.py
--rw-rw-rw-  2.0 fat     4985 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/object_detection/data/tiling_distributed_sampler.py
--rw-rw-rw-  2.0 fat    11277 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/object_detection/data/utils.py
--rw-rw-rw-  2.0 fat      240 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/object_detection/eval/__init__.py
--rw-rw-rw-  2.0 fat     8380 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/object_detection/eval/cocotools.py
--rw-rw-rw-  2.0 fat    21272 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/object_detection/eval/incremental_voc_evaluator.py
--rw-rw-rw-  2.0 fat    17354 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/object_detection/eval/metric_computation_utils.py
--rw-rw-rw-  2.0 fat    14609 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/object_detection/eval/object_detection_instance_segmentation_evaluator.py
--rw-rw-rw-  2.0 fat     5220 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/object_detection/eval/utils.py
--rw-rw-rw-  2.0 fat      239 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/object_detection/models/__init__.py
--rw-rw-rw-  2.0 fat    14422 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/object_detection/models/base_model_wrapper.py
--rw-rw-rw-  2.0 fat     5102 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/object_detection/models/detection.py
--rw-rw-rw-  2.0 fat    14240 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/object_detection/models/instance_segmentation_model_wrappers.py
--rw-rw-rw-  2.0 fat    28844 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/object_detection/models/object_detection_model_wrappers.py
--rw-rw-rw-  2.0 fat      238 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/object_detection/trainer/__init__.py
--rw-rw-rw-  2.0 fat     3651 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/object_detection/trainer/criterion.py
--rw-rw-rw-  2.0 fat    25255 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/object_detection/trainer/train.py
--rw-rw-rw-  2.0 fat      257 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/object_detection/writers/__init__.py
--rw-rw-rw-  2.0 fat    15885 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/object_detection/writers/score.py
--rw-rw-rw-  2.0 fat     5041 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/object_detection/writers/score_script.py
--rw-rw-rw-  2.0 fat     1411 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/object_detection/writers/score_script_utils.py
--rw-rw-rw-  2.0 fat      241 b- defN 23-Apr-27 14:36 azureml/automl/dnn/vision/object_detection_yolo/__init__.py
--rw-rw-rw-  2.0 fat    14496 b- defN 23-Apr-27 14:36 azureml/automl/dnn/vision/object_detection_yolo/runner.py
--rw-rw-rw-  2.0 fat      243 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/object_detection_yolo/common/__init__.py
--rw-rw-rw-  2.0 fat     7128 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/object_detection_yolo/common/constants.py
--rw-rw-rw-  2.0 fat     1382 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/object_detection_yolo/common/od_yolo_training_state.py
--rw-rw-rw-  2.0 fat      254 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/object_detection_yolo/data/__init__.py
--rw-rw-rw-  2.0 fat    12848 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/object_detection_yolo/data/datasets.py
--rw-rw-rw-  2.0 fat     9783 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/object_detection_yolo/data/utils.py
--rw-rw-rw-  2.0 fat      245 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/object_detection_yolo/eval/__init__.py
--rw-rw-rw-  2.0 fat     4430 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/object_detection_yolo/eval/yolo_evaluator.py
--rw-rw-rw-  2.0 fat      239 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/object_detection_yolo/models/__init__.py
--rw-rw-rw-  2.0 fat     6097 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/object_detection_yolo/models/common.py
--rw-rw-rw-  2.0 fat     9858 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/object_detection_yolo/models/yolo.py
--rw-rw-rw-  2.0 fat    11041 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/object_detection_yolo/models/yolo_wrapper.py
--rw-rw-rw-  2.0 fat     1501 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/object_detection_yolo/models/yolov5.3.0l.yaml
--rw-rw-rw-  2.0 fat     1503 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/object_detection_yolo/models/yolov5.3.0m.yaml
--rw-rw-rw-  2.0 fat     1503 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/object_detection_yolo/models/yolov5.3.0s.yaml
--rw-rw-rw-  2.0 fat     1503 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/object_detection_yolo/models/yolov5.3.0x.yaml
--rw-rw-rw-  2.0 fat      238 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/object_detection_yolo/trainer/__init__.py
--rw-rw-rw-  2.0 fat    28280 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/object_detection_yolo/trainer/train.py
--rw-rw-rw-  2.0 fat      242 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/object_detection_yolo/utils/__init__.py
--rw-rw-rw-  2.0 fat     3060 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/object_detection_yolo/utils/ema.py
--rw-rw-rw-  2.0 fat     3799 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/object_detection_yolo/utils/torch_utils.py
--rw-rw-rw-  2.0 fat    41566 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/object_detection_yolo/utils/utils.py
--rw-rw-rw-  2.0 fat      257 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/object_detection_yolo/writers/__init__.py
--rw-rw-rw-  2.0 fat    14388 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/object_detection_yolo/writers/score.py
--rw-rw-rw-  2.0 fat     3292 b- defN 23-Apr-27 14:37 azureml/automl/dnn/vision/object_detection_yolo/writers/score_script.py
--rw-rw-rw-  2.0 fat      183 b- defN 23-Apr-27 14:30 tests/__init__.py
--rw-rw-rw-  2.0 fat      183 b- defN 23-Apr-27 14:31 tests/classification_tests/__init__.py
--rw-rw-rw-  2.0 fat      426 b- defN 23-Apr-27 14:31 tests/classification_tests/aml_dataset_mock.py
--rw-rw-rw-  2.0 fat      915 b- defN 23-Apr-27 14:31 tests/classification_tests/conftest.py
--rw-rw-rw-  2.0 fat    14353 b- defN 23-Apr-27 14:31 tests/classification_tests/test_classification_local_run.py
--rw-rw-rw-  2.0 fat     5320 b- defN 23-Apr-27 14:31 tests/classification_tests/test_classification_resume_local_run.py
--rw-rw-rw-  2.0 fat     3457 b- defN 23-Apr-27 14:31 tests/classification_tests/test_classification_trainer.py
--rw-rw-rw-  2.0 fat      906 b- defN 23-Apr-27 14:31 tests/classification_tests/test_classification_utils.py
--rw-rw-rw-  2.0 fat    11342 b- defN 23-Apr-27 14:31 tests/classification_tests/test_classification_xai_methods.py
--rw-rw-rw-  2.0 fat     2169 b- defN 23-Apr-27 14:31 tests/classification_tests/test_dataloaders.py
--rw-rw-rw-  2.0 fat    19599 b- defN 23-Apr-27 14:31 tests/classification_tests/test_dataset_wrappers.py
--rw-rw-rw-  2.0 fat    13726 b- defN 23-Apr-27 14:31 tests/classification_tests/test_inference_model_wrapper.py
--rw-rw-rw-  2.0 fat    19780 b- defN 23-Apr-27 14:31 tests/classification_tests/test_model_wrappers.py
--rw-rw-rw-  2.0 fat    11694 b- defN 23-Apr-27 14:31 tests/classification_tests/test_prediction_dataset.py
--rw-rw-rw-  2.0 fat     3067 b- defN 23-Apr-27 14:31 tests/classification_tests/test_pretrained_model_factory.py
--rw-rw-rw-  2.0 fat      183 b- defN 23-Apr-27 14:31 tests/common/__init__.py
--rw-rw-rw-  2.0 fat     1237 b- defN 23-Apr-27 14:31 tests/common/aml_dataset_mock.py
--rw-rw-rw-  2.0 fat     5116 b- defN 23-Apr-27 14:31 tests/common/run_mock.py
--rw-rw-rw-  2.0 fat    10438 b- defN 23-Apr-27 14:31 tests/common/test_aml_dataset_helper.py
--rw-rw-rw-  2.0 fat    12795 b- defN 23-Apr-27 14:31 tests/common/test_artifacts_utils.py
--rw-rw-rw-  2.0 fat    56044 b- defN 23-Apr-27 14:31 tests/common/test_common_methods.py
--rw-rw-rw-  2.0 fat    16927 b- defN 23-Apr-27 14:31 tests/common/test_distributed_utils.py
--rw-rw-rw-  2.0 fat    10683 b- defN 23-Apr-27 14:31 tests/common/test_model_export_utils.py
--rw-rw-rw-  2.0 fat     6720 b- defN 23-Apr-27 14:31 tests/common/test_pretrained_model_utilities.py
--rw-rw-rw-  2.0 fat     6606 b- defN 23-Apr-27 14:31 tests/common/test_runner_default_args.py
--rw-rw-rw-  2.0 fat     5624 b- defN 23-Apr-27 14:31 tests/common/test_training_state.py
--rw-rw-rw-  2.0 fat     6315 b- defN 23-Apr-27 14:31 tests/common/utils.py
--rw-rw-rw-  2.0 fat      183 b- defN 23-Apr-27 14:31 tests/object_detection_tests/__init__.py
--rw-rw-rw-  2.0 fat      430 b- defN 23-Apr-27 14:31 tests/object_detection_tests/aml_dataset_mock.py
--rw-rw-rw-  2.0 fat      711 b- defN 23-Apr-27 14:31 tests/object_detection_tests/conftest.py
--rw-rw-rw-  2.0 fat     5755 b- defN 23-Apr-27 14:31 tests/object_detection_tests/test_augmentations.py
--rw-rw-rw-  2.0 fat     4323 b- defN 23-Apr-27 14:31 tests/object_detection_tests/test_coco_eval_box_converter.py
--rw-rw-rw-  2.0 fat     1604 b- defN 23-Apr-27 14:31 tests/object_detection_tests/test_cocotools.py
--rw-rw-rw-  2.0 fat     9815 b- defN 23-Apr-27 14:31 tests/object_detection_tests/test_dataset_wrappers.py
--rw-rw-rw-  2.0 fat    73108 b- defN 23-Apr-27 14:31 tests/object_detection_tests/test_datasets.py
--rw-rw-rw-  2.0 fat    76835 b- defN 23-Apr-27 14:31 tests/object_detection_tests/test_incremental_voc_evaluator.py
--rw-rw-rw-  2.0 fat     6193 b- defN 23-Apr-27 14:31 tests/object_detection_tests/test_maskutils.py
--rw-rw-rw-  2.0 fat    21122 b- defN 23-Apr-27 14:31 tests/object_detection_tests/test_metric_computation_utils.py
--rw-rw-rw-  2.0 fat    15744 b- defN 23-Apr-27 14:31 tests/object_detection_tests/test_model_wrappers.py
--rw-rw-rw-  2.0 fat    14068 b- defN 23-Apr-27 14:31 tests/object_detection_tests/test_object_annotation.py
--rw-rw-rw-  2.0 fat    18676 b- defN 23-Apr-27 14:31 tests/object_detection_tests/test_object_detection_instance_segmentation_evaluator.py
--rw-rw-rw-  2.0 fat     4296 b- defN 23-Apr-27 14:31 tests/object_detection_tests/test_object_detection_local_run.py
--rw-rw-rw-  2.0 fat    21358 b- defN 23-Apr-27 14:31 tests/object_detection_tests/test_object_detection_utils.py
--rw-rw-rw-  2.0 fat     2728 b- defN 23-Apr-27 14:31 tests/object_detection_tests/test_pretrained_model_factory.py
--rw-rw-rw-  2.0 fat     5550 b- defN 23-Apr-27 14:31 tests/object_detection_tests/test_scoring.py
--rw-rw-rw-  2.0 fat     5677 b- defN 23-Apr-27 14:31 tests/object_detection_tests/test_secondary_model_wrappers.py
--rw-rw-rw-  2.0 fat     5050 b- defN 23-Apr-27 14:31 tests/object_detection_tests/test_tiling_distributed_sampler.py
--rw-rw-rw-  2.0 fat    49608 b- defN 23-Apr-27 14:31 tests/object_detection_tests/test_tiling_helper.py
--rw-rw-rw-  2.0 fat     9531 b- defN 23-Apr-27 14:31 tests/object_detection_tests/test_tiling_utils.py
--rw-rw-rw-  2.0 fat     1280 b- defN 23-Apr-27 14:31 tests/object_detection_tests/test_trainer_criterion.py
--rw-rw-rw-  2.0 fat     4133 b- defN 23-Apr-27 14:31 tests/object_detection_tests/test_yolo_trainer_train.py
--rw-rw-rw-  2.0 fat     3710 b- defN 23-Apr-27 14:31 tests/object_detection_tests/test_yolo_utils.py
--rw-rw-rw-  2.0 fat      773 b- defN 23-Apr-27 14:31 tests/object_detection_tests/test_yolo_wrapper.py
--rw-rw-rw-  2.0 fat     1088 b- defN 23-Apr-27 14:31 tests/object_detection_tests/utils.py
--rw-rw-rw-  2.0 fat     1021 b- defN 23-Apr-27 14:42 azureml_automl_dnn_vision-1.50.0.post1.dist-info/LICENSE.txt
--rw-rw-rw-  2.0 fat     1938 b- defN 23-Apr-27 14:42 azureml_automl_dnn_vision-1.50.0.post1.dist-info/METADATA
--rw-rw-rw-  2.0 fat       97 b- defN 23-Apr-27 14:42 azureml_automl_dnn_vision-1.50.0.post1.dist-info/WHEEL
--rw-rw-rw-  2.0 fat        1 b- defN 23-Apr-27 14:42 azureml_automl_dnn_vision-1.50.0.post1.dist-info/namespace_packages.txt
--rw-rw-rw-  2.0 fat       14 b- defN 23-Apr-27 14:42 azureml_automl_dnn_vision-1.50.0.post1.dist-info/top_level.txt
-?rw-rw-r--  2.0 fat    21746 b- defN 23-Apr-27 14:42 azureml_automl_dnn_vision-1.50.0.post1.dist-info/RECORD
-192 files, 1853322 bytes uncompressed, 398834 bytes compressed:  78.5%
+Zip file size: 435572 bytes, number of entries: 192
+-rw-rw-rw-  2.0 fat      299 b- defN 23-May-24 03:26 azureml/__init__.py
+-rw-rw-rw-  2.0 fat      311 b- defN 23-May-24 03:26 azureml/automl/__init__.py
+-rw-rw-rw-  2.0 fat      315 b- defN 23-May-24 03:26 azureml/automl/dnn/__init__.py
+-rw-rw-rw-  2.0 fat      682 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/__init__.py
+-rw-rw-rw-  2.0 fat      226 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/classification/__init__.py
+-rw-rw-rw-  2.0 fat    14072 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/classification/runner.py
+-rw-rw-rw-  2.0 fat      229 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/classification/common/__init__.py
+-rw-rw-rw-  2.0 fat    27028 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/classification/common/classification_utils.py
+-rw-rw-rw-  2.0 fat     7587 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/classification/common/constants.py
+-rw-rw-rw-  2.0 fat     2573 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/classification/common/transforms.py
+-rw-rw-rw-  2.0 fat      208 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/classification/inference/__init__.py
+-rw-rw-rw-  2.0 fat    23903 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/classification/inference/score.py
+-rw-rw-rw-  2.0 fat      210 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/classification/io/__init__.py
+-rw-rw-rw-  2.0 fat      398 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/classification/io/read/__init__.py
+-rw-rw-rw-  2.0 fat     4919 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/classification/io/read/dataloader.py
+-rw-rw-rw-  2.0 fat    22399 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/classification/io/read/dataset_wrappers.py
+-rw-rw-rw-  2.0 fat     5507 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/classification/io/read/utils.py
+-rw-rw-rw-  2.0 fat      237 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/classification/io/write/__init__.py
+-rw-rw-rw-  2.0 fat     2613 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/classification/io/write/featurize_script.py
+-rw-rw-rw-  2.0 fat     6433 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/classification/io/write/score_script.py
+-rw-rw-rw-  2.0 fat      973 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/classification/io/write/score_script_utils.py
+-rw-rw-rw-  2.0 fat      429 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/classification/models/__init__.py
+-rw-rw-rw-  2.0 fat    11491 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/classification/models/base_model_wrapper.py
+-rw-rw-rw-  2.0 fat    30503 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/classification/models/classification_model_wrappers.py
+-rw-rw-rw-  2.0 fat      221 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/classification/trainer/__init__.py
+-rw-rw-rw-  2.0 fat     1203 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/classification/trainer/criterion.py
+-rw-rw-rw-  2.0 fat    38271 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/classification/trainer/train.py
+-rw-rw-rw-  2.0 fat    85645 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/common/NOTICE
+-rw-rw-rw-  2.0 fat      263 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/common/__init__.py
+-rw-rw-rw-  2.0 fat     1903 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/common/aml_dataset_base_wrapper.py
+-rw-rw-rw-  2.0 fat    18726 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/common/artifacts_utils.py
+-rw-rw-rw-  2.0 fat     2025 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/common/average_meter.py
+-rw-rw-rw-  2.0 fat     2162 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/common/base_model_factory.py
+-rw-rw-rw-  2.0 fat     1231 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/common/base_model_settings.py
+-rw-rw-rw-  2.0 fat    22576 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/common/constants.py
+-rw-rw-rw-  2.0 fat     2826 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/common/data_utils.py
+-rw-rw-rw-  2.0 fat     3184 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/common/dataloaders.py
+-rw-rw-rw-  2.0 fat    18976 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/common/dataset_helper.py
+-rw-rw-rw-  2.0 fat    21108 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/common/distributed_utils.py
+-rw-rw-rw-  2.0 fat      672 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/common/errors.py
+-rw-rw-rw-  2.0 fat     2379 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/common/exceptions.py
+-rw-rw-rw-  2.0 fat     2528 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/common/logging_utils.py
+-rw-rw-rw-  2.0 fat    25968 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/common/model_export_utils.py
+-rw-rw-rw-  2.0 fat    14730 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/common/parameters.py
+-rw-rw-rw-  2.0 fat    10208 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/common/prediction_dataset.py
+-rw-rw-rw-  2.0 fat    37122 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/common/pretrained_model_utilities.py
+-rw-rw-rw-  2.0 fat     3200 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/common/sku_validation.py
+-rw-rw-rw-  2.0 fat     9887 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/common/system_meter.py
+-rw-rw-rw-  2.0 fat     5477 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/common/tiling_dataset_element.py
+-rw-rw-rw-  2.0 fat     6399 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/common/tiling_utils.py
+-rw-rw-rw-  2.0 fat     1039 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/common/torch_utils.py
+-rw-rw-rw-  2.0 fat     2994 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/common/training_state.py
+-rw-rw-rw-  2.0 fat    70480 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/common/utils.py
+-rw-rw-rw-  2.0 fat      237 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/common/mlflow/__init__.py
+-rw-rw-rw-  2.0 fat     6364 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/common/mlflow/mlflow_model_wrapper.py
+-rw-rw-rw-  2.0 fat      272 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/common/trainer/__init__.py
+-rw-rw-rw-  2.0 fat     7720 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/common/trainer/lrschedule.py
+-rw-rw-rw-  2.0 fat     3336 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/common/trainer/lrschedule_parameters.py
+-rw-rw-rw-  2.0 fat     9241 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/common/trainer/optimize.py
+-rw-rw-rw-  2.0 fat     4337 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/common/trainer/optimize_parameters.py
+-rw-rw-rw-  2.0 fat      229 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/explainability/__init__.py
+-rw-rw-rw-  2.0 fat     2638 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/explainability/constants.py
+-rw-rw-rw-  2.0 fat    16285 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/explainability/methods.py
+-rw-rw-rw-  2.0 fat     8627 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/explainability/utils.py
+-rw-rw-rw-  2.0 fat     6437 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/explainability/xrai_utils.py
+-rw-rw-rw-  2.0 fat      321 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/metrics/__init__.py
+-rw-rw-rw-  2.0 fat     6643 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/metrics/automl_classification_metrics.py
+-rw-rw-rw-  2.0 fat     4480 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/metrics/classification_metrics.py
+-rw-rw-rw-  2.0 fat      240 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/object_detection/__init__.py
+-rw-rw-rw-  2.0 fat    20822 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/object_detection/runner.py
+-rw-rw-rw-  2.0 fat      243 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/object_detection/common/__init__.py
+-rw-rw-rw-  2.0 fat     9636 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/object_detection/common/augmentations.py
+-rw-rw-rw-  2.0 fat     7356 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/object_detection/common/boundingbox.py
+-rw-rw-rw-  2.0 fat     3009 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/object_detection/common/coco_eval_box_converter.py
+-rw-rw-rw-  2.0 fat    11089 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/object_detection/common/constants.py
+-rw-rw-rw-  2.0 fat    11945 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/object_detection/common/masktools.py
+-rw-rw-rw-  2.0 fat    27385 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/object_detection/common/object_detection_utils.py
+-rw-rw-rw-  2.0 fat     1632 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/object_detection/common/od_training_state.py
+-rw-rw-rw-  2.0 fat     4891 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/object_detection/common/parameters.py
+-rw-rw-rw-  2.0 fat    26057 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/object_detection/common/tiling_helper.py
+-rw-rw-rw-  2.0 fat      238 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/object_detection/data/__init__.py
+-rw-rw-rw-  2.0 fat     4605 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/object_detection/data/dataset_wrappers.py
+-rw-rw-rw-  2.0 fat    40467 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/object_detection/data/datasets.py
+-rw-rw-rw-  2.0 fat     6110 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/object_detection/data/loaders.py
+-rw-rw-rw-  2.0 fat    12574 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/object_detection/data/object_annotation.py
+-rw-rw-rw-  2.0 fat     4985 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/object_detection/data/tiling_distributed_sampler.py
+-rw-rw-rw-  2.0 fat    11231 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/object_detection/data/utils.py
+-rw-rw-rw-  2.0 fat      240 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/object_detection/eval/__init__.py
+-rw-rw-rw-  2.0 fat     8380 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/object_detection/eval/cocotools.py
+-rw-rw-rw-  2.0 fat    21506 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/object_detection/eval/incremental_voc_evaluator.py
+-rw-rw-rw-  2.0 fat    17354 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/object_detection/eval/metric_computation_utils.py
+-rw-rw-rw-  2.0 fat    14609 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/object_detection/eval/object_detection_instance_segmentation_evaluator.py
+-rw-rw-rw-  2.0 fat     5220 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/object_detection/eval/utils.py
+-rw-rw-rw-  2.0 fat      239 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/object_detection/models/__init__.py
+-rw-rw-rw-  2.0 fat    14422 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/object_detection/models/base_model_wrapper.py
+-rw-rw-rw-  2.0 fat     5102 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/object_detection/models/detection.py
+-rw-rw-rw-  2.0 fat    14240 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/object_detection/models/instance_segmentation_model_wrappers.py
+-rw-rw-rw-  2.0 fat    28844 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/object_detection/models/object_detection_model_wrappers.py
+-rw-rw-rw-  2.0 fat      238 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/object_detection/trainer/__init__.py
+-rw-rw-rw-  2.0 fat     3651 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/object_detection/trainer/criterion.py
+-rw-rw-rw-  2.0 fat    25255 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/object_detection/trainer/train.py
+-rw-rw-rw-  2.0 fat      257 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/object_detection/writers/__init__.py
+-rw-rw-rw-  2.0 fat    15885 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/object_detection/writers/score.py
+-rw-rw-rw-  2.0 fat     5041 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/object_detection/writers/score_script.py
+-rw-rw-rw-  2.0 fat     1411 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/object_detection/writers/score_script_utils.py
+-rw-rw-rw-  2.0 fat      241 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/object_detection_yolo/__init__.py
+-rw-rw-rw-  2.0 fat    14496 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/object_detection_yolo/runner.py
+-rw-rw-rw-  2.0 fat      243 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/object_detection_yolo/common/__init__.py
+-rw-rw-rw-  2.0 fat     7128 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/object_detection_yolo/common/constants.py
+-rw-rw-rw-  2.0 fat     1382 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/object_detection_yolo/common/od_yolo_training_state.py
+-rw-rw-rw-  2.0 fat      254 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/object_detection_yolo/data/__init__.py
+-rw-rw-rw-  2.0 fat    12848 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/object_detection_yolo/data/datasets.py
+-rw-rw-rw-  2.0 fat     9783 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/object_detection_yolo/data/utils.py
+-rw-rw-rw-  2.0 fat      245 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/object_detection_yolo/eval/__init__.py
+-rw-rw-rw-  2.0 fat     4430 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/object_detection_yolo/eval/yolo_evaluator.py
+-rw-rw-rw-  2.0 fat      239 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/object_detection_yolo/models/__init__.py
+-rw-rw-rw-  2.0 fat     6097 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/object_detection_yolo/models/common.py
+-rw-rw-rw-  2.0 fat     9858 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/object_detection_yolo/models/yolo.py
+-rw-rw-rw-  2.0 fat    11041 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/object_detection_yolo/models/yolo_wrapper.py
+-rw-rw-rw-  2.0 fat     1501 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/object_detection_yolo/models/yolov5.3.0l.yaml
+-rw-rw-rw-  2.0 fat     1503 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/object_detection_yolo/models/yolov5.3.0m.yaml
+-rw-rw-rw-  2.0 fat     1503 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/object_detection_yolo/models/yolov5.3.0s.yaml
+-rw-rw-rw-  2.0 fat     1503 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/object_detection_yolo/models/yolov5.3.0x.yaml
+-rw-rw-rw-  2.0 fat      238 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/object_detection_yolo/trainer/__init__.py
+-rw-rw-rw-  2.0 fat    28280 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/object_detection_yolo/trainer/train.py
+-rw-rw-rw-  2.0 fat      242 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/object_detection_yolo/utils/__init__.py
+-rw-rw-rw-  2.0 fat     3060 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/object_detection_yolo/utils/ema.py
+-rw-rw-rw-  2.0 fat     3799 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/object_detection_yolo/utils/torch_utils.py
+-rw-rw-rw-  2.0 fat    41566 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/object_detection_yolo/utils/utils.py
+-rw-rw-rw-  2.0 fat      257 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/object_detection_yolo/writers/__init__.py
+-rw-rw-rw-  2.0 fat    14388 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/object_detection_yolo/writers/score.py
+-rw-rw-rw-  2.0 fat     3292 b- defN 23-May-24 03:26 azureml/automl/dnn/vision/object_detection_yolo/writers/score_script.py
+-rw-rw-rw-  2.0 fat      183 b- defN 23-May-24 03:26 tests/__init__.py
+-rw-rw-rw-  2.0 fat      183 b- defN 23-May-24 03:26 tests/classification_tests/__init__.py
+-rw-rw-rw-  2.0 fat      426 b- defN 23-May-24 03:26 tests/classification_tests/aml_dataset_mock.py
+-rw-rw-rw-  2.0 fat      915 b- defN 23-May-24 03:26 tests/classification_tests/conftest.py
+-rw-rw-rw-  2.0 fat    14353 b- defN 23-May-24 03:26 tests/classification_tests/test_classification_local_run.py
+-rw-rw-rw-  2.0 fat     5320 b- defN 23-May-24 03:26 tests/classification_tests/test_classification_resume_local_run.py
+-rw-rw-rw-  2.0 fat     3457 b- defN 23-May-24 03:26 tests/classification_tests/test_classification_trainer.py
+-rw-rw-rw-  2.0 fat      906 b- defN 23-May-24 03:26 tests/classification_tests/test_classification_utils.py
+-rw-rw-rw-  2.0 fat    11342 b- defN 23-May-24 03:26 tests/classification_tests/test_classification_xai_methods.py
+-rw-rw-rw-  2.0 fat     2169 b- defN 23-May-24 03:26 tests/classification_tests/test_dataloaders.py
+-rw-rw-rw-  2.0 fat    19599 b- defN 23-May-24 03:26 tests/classification_tests/test_dataset_wrappers.py
+-rw-rw-rw-  2.0 fat    13726 b- defN 23-May-24 03:26 tests/classification_tests/test_inference_model_wrapper.py
+-rw-rw-rw-  2.0 fat    19780 b- defN 23-May-24 03:26 tests/classification_tests/test_model_wrappers.py
+-rw-rw-rw-  2.0 fat    11694 b- defN 23-May-24 03:26 tests/classification_tests/test_prediction_dataset.py
+-rw-rw-rw-  2.0 fat     3067 b- defN 23-May-24 03:26 tests/classification_tests/test_pretrained_model_factory.py
+-rw-rw-rw-  2.0 fat      183 b- defN 23-May-24 03:26 tests/common/__init__.py
+-rw-rw-rw-  2.0 fat     1237 b- defN 23-May-24 03:26 tests/common/aml_dataset_mock.py
+-rw-rw-rw-  2.0 fat     5116 b- defN 23-May-24 03:26 tests/common/run_mock.py
+-rw-rw-rw-  2.0 fat    10438 b- defN 23-May-24 03:26 tests/common/test_aml_dataset_helper.py
+-rw-rw-rw-  2.0 fat    12795 b- defN 23-May-24 03:26 tests/common/test_artifacts_utils.py
+-rw-rw-rw-  2.0 fat    57289 b- defN 23-May-24 03:26 tests/common/test_common_methods.py
+-rw-rw-rw-  2.0 fat    16927 b- defN 23-May-24 03:26 tests/common/test_distributed_utils.py
+-rw-rw-rw-  2.0 fat    10683 b- defN 23-May-24 03:26 tests/common/test_model_export_utils.py
+-rw-rw-rw-  2.0 fat     6720 b- defN 23-May-24 03:26 tests/common/test_pretrained_model_utilities.py
+-rw-rw-rw-  2.0 fat     6606 b- defN 23-May-24 03:26 tests/common/test_runner_default_args.py
+-rw-rw-rw-  2.0 fat     5624 b- defN 23-May-24 03:26 tests/common/test_training_state.py
+-rw-rw-rw-  2.0 fat     6315 b- defN 23-May-24 03:26 tests/common/utils.py
+-rw-rw-rw-  2.0 fat      183 b- defN 23-May-24 03:26 tests/object_detection_tests/__init__.py
+-rw-rw-rw-  2.0 fat      430 b- defN 23-May-24 03:26 tests/object_detection_tests/aml_dataset_mock.py
+-rw-rw-rw-  2.0 fat      711 b- defN 23-May-24 03:26 tests/object_detection_tests/conftest.py
+-rw-rw-rw-  2.0 fat     5755 b- defN 23-May-24 03:26 tests/object_detection_tests/test_augmentations.py
+-rw-rw-rw-  2.0 fat     4323 b- defN 23-May-24 03:26 tests/object_detection_tests/test_coco_eval_box_converter.py
+-rw-rw-rw-  2.0 fat     1604 b- defN 23-May-24 03:26 tests/object_detection_tests/test_cocotools.py
+-rw-rw-rw-  2.0 fat     9815 b- defN 23-May-24 03:26 tests/object_detection_tests/test_dataset_wrappers.py
+-rw-rw-rw-  2.0 fat    73835 b- defN 23-May-24 03:26 tests/object_detection_tests/test_datasets.py
+-rw-rw-rw-  2.0 fat    78443 b- defN 23-May-24 03:26 tests/object_detection_tests/test_incremental_voc_evaluator.py
+-rw-rw-rw-  2.0 fat     6193 b- defN 23-May-24 03:26 tests/object_detection_tests/test_maskutils.py
+-rw-rw-rw-  2.0 fat    21122 b- defN 23-May-24 03:26 tests/object_detection_tests/test_metric_computation_utils.py
+-rw-rw-rw-  2.0 fat    15744 b- defN 23-May-24 03:26 tests/object_detection_tests/test_model_wrappers.py
+-rw-rw-rw-  2.0 fat    14068 b- defN 23-May-24 03:26 tests/object_detection_tests/test_object_annotation.py
+-rw-rw-rw-  2.0 fat    18676 b- defN 23-May-24 03:26 tests/object_detection_tests/test_object_detection_instance_segmentation_evaluator.py
+-rw-rw-rw-  2.0 fat     4296 b- defN 23-May-24 03:26 tests/object_detection_tests/test_object_detection_local_run.py
+-rw-rw-rw-  2.0 fat    21358 b- defN 23-May-24 03:26 tests/object_detection_tests/test_object_detection_utils.py
+-rw-rw-rw-  2.0 fat     2728 b- defN 23-May-24 03:26 tests/object_detection_tests/test_pretrained_model_factory.py
+-rw-rw-rw-  2.0 fat     5550 b- defN 23-May-24 03:26 tests/object_detection_tests/test_scoring.py
+-rw-rw-rw-  2.0 fat     5677 b- defN 23-May-24 03:26 tests/object_detection_tests/test_secondary_model_wrappers.py
+-rw-rw-rw-  2.0 fat     5050 b- defN 23-May-24 03:26 tests/object_detection_tests/test_tiling_distributed_sampler.py
+-rw-rw-rw-  2.0 fat    49608 b- defN 23-May-24 03:26 tests/object_detection_tests/test_tiling_helper.py
+-rw-rw-rw-  2.0 fat     9531 b- defN 23-May-24 03:26 tests/object_detection_tests/test_tiling_utils.py
+-rw-rw-rw-  2.0 fat     1280 b- defN 23-May-24 03:26 tests/object_detection_tests/test_trainer_criterion.py
+-rw-rw-rw-  2.0 fat     4133 b- defN 23-May-24 03:26 tests/object_detection_tests/test_yolo_trainer_train.py
+-rw-rw-rw-  2.0 fat     3710 b- defN 23-May-24 03:26 tests/object_detection_tests/test_yolo_utils.py
+-rw-rw-rw-  2.0 fat      773 b- defN 23-May-24 03:26 tests/object_detection_tests/test_yolo_wrapper.py
+-rw-rw-rw-  2.0 fat     1088 b- defN 23-May-24 03:26 tests/object_detection_tests/utils.py
+-rw-rw-rw-  2.0 fat     1021 b- defN 23-May-24 03:33 azureml_automl_dnn_vision-1.51.0.dist-info/LICENSE.txt
+-rw-rw-rw-  2.0 fat     1932 b- defN 23-May-24 03:33 azureml_automl_dnn_vision-1.51.0.dist-info/METADATA
+-rw-rw-rw-  2.0 fat       97 b- defN 23-May-24 03:33 azureml_automl_dnn_vision-1.51.0.dist-info/WHEEL
+-rw-rw-rw-  2.0 fat        1 b- defN 23-May-24 03:33 azureml_automl_dnn_vision-1.51.0.dist-info/namespace_packages.txt
+-rw-rw-rw-  2.0 fat       14 b- defN 23-May-24 03:33 azureml_automl_dnn_vision-1.51.0.dist-info/top_level.txt
+?rw-rw-r--  2.0 fat    21710 b- defN 23-May-24 03:33 azureml_automl_dnn_vision-1.51.0.dist-info/RECORD
+192 files, 1857453 bytes uncompressed, 399334 bytes compressed:  78.5%
```

## zipnote {}

```diff
@@ -552,26 +552,26 @@
 
 Filename: tests/object_detection_tests/test_yolo_wrapper.py
 Comment: 
 
 Filename: tests/object_detection_tests/utils.py
 Comment: 
 
-Filename: azureml_automl_dnn_vision-1.50.0.post1.dist-info/LICENSE.txt
+Filename: azureml_automl_dnn_vision-1.51.0.dist-info/LICENSE.txt
 Comment: 
 
-Filename: azureml_automl_dnn_vision-1.50.0.post1.dist-info/METADATA
+Filename: azureml_automl_dnn_vision-1.51.0.dist-info/METADATA
 Comment: 
 
-Filename: azureml_automl_dnn_vision-1.50.0.post1.dist-info/WHEEL
+Filename: azureml_automl_dnn_vision-1.51.0.dist-info/WHEEL
 Comment: 
 
-Filename: azureml_automl_dnn_vision-1.50.0.post1.dist-info/namespace_packages.txt
+Filename: azureml_automl_dnn_vision-1.51.0.dist-info/namespace_packages.txt
 Comment: 
 
-Filename: azureml_automl_dnn_vision-1.50.0.post1.dist-info/top_level.txt
+Filename: azureml_automl_dnn_vision-1.51.0.dist-info/top_level.txt
 Comment: 
 
-Filename: azureml_automl_dnn_vision-1.50.0.post1.dist-info/RECORD
+Filename: azureml_automl_dnn_vision-1.51.0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## azureml/automl/dnn/vision/classification/common/classification_utils.py

```diff
@@ -8,21 +8,17 @@
 
 import numpy as np
 import pkg_resources
 import torch
 from sklearn.model_selection import train_test_split
 
 import azureml.automl.core.shared.constants as shared_constants
-from azureml.automl.runtime.shared.score._metric_base import NonScalarMetric
-from azureml.automl.runtime.shared.score import constants as scoring_constants
 from azureml.automl.dnn.vision.classification.common.constants import PackageInfo, ModelLiterals, \
     vit_batch_size_defaults, vit_mc_lrs, vit_ml_lrs
-from azureml.automl.dnn.vision.classification.models import ModelFactory
 from azureml.automl.dnn.vision.classification.models.base_model_wrapper import BaseModelWrapper
-from azureml.automl.dnn.vision.common.artifacts_utils import _download_model_from_artifacts
 from azureml.automl.dnn.vision.common.constants import ArtifactLiterals, MetricsLiterals, SettingsLiterals, \
     TrainingCommonSettings, TrainingLiterals as CommonTrainingLiterals
 from azureml.automl.dnn.vision.common.data_utils import get_labels_files_paths_from_settings
 from azureml.automl.dnn.vision.common.exceptions import AutoMLVisionValidationException, AutoMLVisionTrainingException
 from azureml.automl.dnn.vision.common.dataset_helper import AmlDatasetHelper
 from azureml.automl.dnn.vision.common.logging_utils import get_logger
 from azureml.core.conda_dependencies import CondaDependencies
@@ -187,14 +183,18 @@
     :param local_rank: local rank of the process in distributed mode
     :type local_rank: int
     :param model_settings: Optional argument to update model settings
     :type model_settings: Dictionary
     :return: Model Wrapper object
     :rtype: classification.models.base_model_wrapper.BaseModelWrapper
     """
+    from azureml.automl.dnn.vision.common.artifacts_utils import (
+        _download_model_from_artifacts,
+    )
+
     _download_model_from_artifacts(run_id=run_id, experiment_name=experiment_name)
 
     return _load_model_wrapper(shared_constants.PT_MODEL_FILENAME, distributed, local_rank, device, model_settings)
 
 
 def _load_model_wrapper(torch_model_file, distributed, local_rank, device, model_settings={}) -> BaseModelWrapper:
 
@@ -211,14 +211,18 @@
     }
     for key in model_settings:
         if key in image_size_key_mapping and image_size_key_mapping[key] in settings:
             settings[image_size_key_mapping[key]] = model_settings[key]
         elif key in settings:
             settings[key] = model_settings[key]
 
+    from azureml.automl.dnn.vision.classification.models import (
+        ModelFactory,
+    )
+
     model_wrapper: BaseModelWrapper = ModelFactory().get_model_wrapper(model_name=model_name,
                                                                        num_classes=number_of_classes,
                                                                        multilabel=specs['multilabel'],
                                                                        distributed=distributed,
                                                                        local_rank=local_rank,
                                                                        device=device,
                                                                        model_state=model_state,
@@ -310,14 +314,17 @@
     :param final_epoch: Flag indicating the final epoch.
     :type final_epoch: bool
     :param best_model_metrics: Dictionary with metrics and respective values to be logged
         to Run History corresponding to the best model.
     :type best_model_metrics: dict
 
     """
+    from azureml.automl.runtime.shared.score._metric_base import NonScalarMetric
+    from azureml.automl.runtime.shared.score import constants as scoring_constants
+
     if azureml_run is None:
         raise AutoMLVisionTrainingException("Cannot log metrics to Run History \
             since azureml_run is None", has_pii=False)
 
     logger.info("Logging metrics in Run History.")
 
     if isinstance(azureml_run, _OfflineRun):
```

## azureml/automl/dnn/vision/classification/io/read/utils.py

```diff
@@ -6,15 +6,14 @@
 
 from azureml.automl.dnn.vision.classification.common.classification_utils import \
     _get_train_valid_sub_file_paths
 from azureml.automl.dnn.vision.classification.io.read.dataset_wrappers import \
     AmlDatasetWrapper, ImageFolderLabelFileDatasetWrapper
 from azureml.automl.dnn.vision.common import utils
 from azureml.automl.dnn.vision.common.constants import SettingsLiterals
-from azureml.core.run import Run
 
 
 def read_aml_dataset(dataset, validation_dataset, validation_size, multilabel, output_dir, master_process,
                      label_column_name, ignore_data_errors, stream_image_files):
     """Read the training and validation datasets from AML datasets.
 
     :param dataset: Training dataset
```

## azureml/automl/dnn/vision/common/model_export_utils.py

```diff
@@ -198,15 +198,15 @@
     file should be updated in the vendor.
 
     :param run: The current azureml run object
     :type run: azureml.core.run
     :return: Conda dependencies as string
     :rtype: str
     """
-    all_pip_dependencies, all_conda_dependencies, _, channels = \
+    all_pip_dependencies, all_conda_dependencies, channels = \
         package_utilities._get_curated_environment_conda_list_packages()
 
     python_version = platform.python_version()
     conda_deps = CondaDependencies.create(conda_packages=all_conda_dependencies,
                                           python_version=python_version,
                                           pip_packages=all_pip_dependencies,
                                           pin_sdk_version=False)
```

## azureml/automl/dnn/vision/common/parameters.py

```diff
@@ -1,15 +1,15 @@
 # ---------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # ---------------------------------------------------------
 
 """Parameters that apply to model training/scoring"""
 
 from argparse import ArgumentParser
-from typing import Any, Dict, List
+from typing import Any, Dict
 
 from azureml.automl.dnn.vision.common import utils
 from azureml.automl.dnn.vision.common.constants import LrSchedulerType, OptimizerType, ScoringLiterals, \
     SettingsLiterals, TrainingLiterals, supported_model_layer_info, DistributedLiterals
 
 
 def add_task_agnostic_train_parameters(parser: ArgumentParser, default_values: Dict[str, Any]) -> None:
```

## azureml/automl/dnn/vision/common/pretrained_model_utilities.py

```diff
@@ -11,15 +11,14 @@
 import torch
 import torch.nn
 from pretrainedmodels.models.senet import SENet, SEResNeXtBottleneck, pretrained_settings
 from resnest.torch import resnest50, resnest101
 
 from timm import create_model
 from timm.models.vision_transformer import VisionTransformer
-from timm.models.helpers import load_pretrained
 from timm.models.vision_transformer import checkpoint_filter_fn
 
 from torchvision.models.detection.backbone_utils import BackboneWithFPN
 from torchvision.models.detection.faster_rcnn import FasterRCNN
 from torchvision.models.detection.mask_rcnn import MaskRCNN
 from torchvision.models.detection.retinanet import RetinaNet
 from torchvision.models.mobilenet import MobileNetV2
```

## azureml/automl/dnn/vision/common/tiling_dataset_element.py

```diff
@@ -1,14 +1,13 @@
 # ---------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # ---------------------------------------------------------
 
 """Class to process the images in a dataset with tiling."""
 
-import time
 from typing import Any, cast, Optional, Tuple
 
 from azureml.automl.dnn.vision.common.logging_utils import get_logger
 
 logger = get_logger(__name__)
```

## azureml/automl/dnn/vision/common/tiling_utils.py

```diff
@@ -2,19 +2,19 @@
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # ---------------------------------------------------------
 
 """Helper utiities for image tiling."""
 
 import ast
 import re
-from typing import Any, List, Optional, Tuple, cast
+from typing import Any, Optional, Tuple, cast
 
 import torch
 from azureml.automl.dnn.vision.common.exceptions import (
-    AutoMLVisionSystemException, AutoMLVisionValidationException)
+    AutoMLVisionValidationException)
 from azureml.automl.dnn.vision.common.logging_utils import get_logger
 from azureml.automl.dnn.vision.common.tiling_dataset_element import Tile
 from azureml.automl.dnn.vision.object_detection.common.constants import \
     TilingParameters
 
 logger = get_logger(__name__)
```

## azureml/automl/dnn/vision/common/utils.py

```diff
@@ -766,28 +766,36 @@
 
         if metric_name_stem == MetricsLiterals.CONFUSION_MATRICES_PER_SCORE_THRESHOLD:
             confusion_matrices_per_score_threshold = metrics[metric_name]
 
             # Go through sorted score thresholds and log the corresponding confusion matrices.
             sorted_score_thresholds = sorted(confusion_matrices_per_score_threshold.keys())
             for st in sorted_score_thresholds:
+                # Skip empty confusion matrices.
+                cm = confusion_matrices_per_score_threshold[st]
+                if len(cm) == 0:
+                    continue
+
                 # Format the confusion matrix in scikit format, ie append a row to make it square and add a class. The
                 # matrix ends up being (C+1)x(C+1), with the last class called 'Missed'.
-                cm = confusion_matrices_per_score_threshold[st]
                 fcm = {
                     "schema_type": "confusion_matrix",
                     "schema_version": "1.0.0",
                     "data": {
                         "class_labels": class_names + [MISSED_CLASS_NAME],
                         "matrix": cm + [[NO_VALUE for _ in range(len(cm[0]))]]
                     }
                 }
 
-                # Log confusion matrix, mentioning the score threshold in the metric name.
-                azureml_run.log_confusion_matrix("confusion_matrix_score_threshold_{}".format(st), fcm)
+                # Log confusion matrix under a name that includes a. the _train suffix if present in the original
+                # metric name and b. the score threshold.
+                logged_metric_name = "confusion_matrix{}_score_threshold_{}".format(
+                    "_train" if metric_name.endswith("_train") else "", st
+                )
+                azureml_run.log_confusion_matrix(logged_metric_name, fcm)
 
 
 def log_verbose_metrics_to_rh(train_time: float, epoch_time: AverageMeter,
                               train_sys_meter: SystemMeter, valid_sys_meter: SystemMeter,
                               azureml_run: Run) -> None:
     """Logs verbose metrics to run history at the end of training.
```

## azureml/automl/dnn/vision/object_detection/common/tiling_helper.py

```diff
@@ -1,14 +1,13 @@
 # ---------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # ---------------------------------------------------------
 
 """Helper utilities for image tiling for object detection."""
 
-import itertools
 import numpy as np
 import time
 import torch
 
 from pycocotools import mask as pycoco_mask
 from torch import Tensor
 from typing import Any, Callable, cast, Dict, List, Optional, Tuple
@@ -36,14 +35,19 @@
     :param tile_overlap_ratio: Overlap ratio between adjacent tiles in each dimension.
     :type tile_overlap_ratio: float
     :param image_size: Tuple indicating width and height of the image.
     :type image_size: Tuple[int, int]
     :return: Annotations for each tile. Each Key in the dictionary is a tile.
     :rtype: Dict[Tile, List[Dict]]
     """
+
+    # Check if background image (does not have annotations)
+    if len(annotations) == 0:
+        return {}
+
     # Tile pixel co-ordinates.
     tiles_list = get_tiles(tile_grid_size, tile_overlap_ratio, image_size)
     tiles = torch.tensor([tile.as_tuple() for tile in tiles_list], device="cpu")
 
     # Annotation box percentage co-ordinates
     annotation_boxes = torch.tensor(
         [[annotation._x0_percentage, annotation._y0_percentage,
```

## azureml/automl/dnn/vision/object_detection/data/dataset_wrappers.py

```diff
@@ -1,29 +1,20 @@
 # ---------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # ---------------------------------------------------------
 
 """Classes and functions to ingest data for object detection."""
-import copy
-import json
-import os
-import numpy as np
-import time
-import torch
 from typing import Dict, List
 
-
 from abc import ABC, abstractmethod
 from enum import Enum
 from torch.utils.data import Dataset
 
 from azureml.automl.dnn.vision.common.exceptions import AutoMLVisionSystemException
-from azureml.automl.dnn.vision.object_detection.common.masktools import decode_rle_masks_as_binary_mask
 from azureml.automl.dnn.vision.object_detection.data.datasets import CommonObjectDetectionDataset
-from azureml.automl.dnn.vision.common.tiling_dataset_element import TilingDatasetElement
 from typing import TypeVar
 
 T_co = TypeVar('T_co', covariant=True)
 
 
 class ObjectDetectionDatasetBaseWrapper(ABC, Dataset[T_co]):
     """Class the establishes interface for object detection datasets"""
```

## azureml/automl/dnn/vision/object_detection/data/datasets.py

```diff
@@ -810,14 +810,20 @@
             image_elements.add(image_element)
             self._annotations[image_element].extend(cur_img_object_infos)
             object_classes.update(cur_object_classes)
 
         if not image_elements:
             raise AutoMLVisionDataException("All annotations provided are ill-formed.", has_pii=False)
 
+        # Check that at least an image in the dataset has at least an object.
+        if num_background_images == len(image_elements):
+            raise AutoMLVisionDataException(
+                "No objects in dataset. Please ensure that at least one image has one or more objects.", has_pii=False
+            )
+
         # Check that class data is of one type only.
         if len(object_classes) > 0:
             first_type = type(next(iter(object_classes)))
             if not all([isinstance(c, first_type) for c in object_classes]):
                 raise AutoMLVisionDataException(
                     "More than one type found for the class field. Please ensure that all classes are of the same "
                     "type, e.g. string.", has_pii=False
```

## azureml/automl/dnn/vision/object_detection/data/utils.py

```diff
@@ -1,24 +1,21 @@
 # ---------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # ---------------------------------------------------------
 
 """Helper classes and functions for creating operating with datasets and dataloaders."""
 
-import torch
-
 from typing import Optional, Tuple
 
 from azureml.automl.dnn.vision.common.exceptions import AutoMLVisionDataException
 from azureml.automl.dnn.vision.common.utils import _save_image_df, _save_image_lf
 from azureml.automl.dnn.vision.common.logging_utils import get_logger
 from azureml.automl.dnn.vision.object_detection.data import datasets
 from azureml.automl.dnn.vision.object_detection.data.dataset_wrappers import \
     CommonObjectDetectionDatasetWrapper, DatasetProcessingType
-from azureml.core import Run
 
 logger = get_logger(__name__)
 
 
 def read_aml_dataset(dataset, validation_dataset, validation_size, ignore_data_errors, output_dir,
                      master_process, use_bg_label, dataset_class=datasets.AmlDatasetObjectDetection,
                      settings=None, masks_required=False,
```

## azureml/automl/dnn/vision/object_detection/eval/incremental_voc_evaluator.py

```diff
@@ -221,23 +221,28 @@
 
         if self._task_is_detection:
             # Image level metrics and confusion matrices for object detection.
 
             # Calculate the image level metrics.
             image_level_metrics = {
                 MetricsLiterals.IMAGE_LEVEL_BINARY_CLASSIFIER_METRICS: calculate_pr_metrics(
-                    self._num_images_with_gt_objects, np.concatenate(all_tp_fp_labels), np.concatenate(all_scores),
-                    np.concatenate(all_image_indexes), False, self.UNDEFINED_METRIC_VALUE
+                    self._num_images_with_gt_objects,
+                    np.concatenate([np.zeros((0,), dtype=np.uint8)] + all_tp_fp_labels),
+                    np.concatenate([np.zeros((0,))] + all_scores),
+                    np.concatenate([np.zeros((0,), dtype=np.uint32)] + all_image_indexes),
+                    False,
+                    self.UNDEFINED_METRIC_VALUE
                 )
             }
 
             # Calculate the confusion matrices at representative scores.
             confusion_matrix_metrics = {
                 MetricsLiterals.CONFUSION_MATRICES_PER_SCORE_THRESHOLD: calculate_confusion_matrices(
-                    self._num_gt_objects_per_class, np.concatenate(self._all_matched_classes_and_scores)
+                    self._num_gt_objects_per_class,
+                    np.concatenate([np.zeros((0, 3), dtype=np.float32)] + self._all_matched_classes_and_scores)
                 )
             }
 
         else:
             # No image level metrics or confusion matrices for instance segmentation.
             image_level_metrics = {}
             confusion_matrix_metrics = {}
```

## tests/common/test_common_methods.py

```diff
@@ -1097,37 +1097,37 @@
             call(
                 MetricsLiterals.IMAGE_LEVEL_BINARY_CLASSIFIER_METRICS + "_train",
                 precision=0.6, recall=0.7, average_precision=0.8
             )
         ]
         confusion_matrix_calls += [
             call(
-                "confusion_matrix_score_threshold_0.1",
+                "confusion_matrix_train_score_threshold_0.1",
                 {
                     "schema_type": "confusion_matrix",
                     "schema_version": "1.0.0",
                     "data": {
                         "class_labels": ["dog", "cat", "axolotl", "Missed"],
                         "matrix": [[4, 3, 4, 3], [5, 4, 5, 4], [6, 5, 6, 5], ["N/A", "N/A", "N/A", "N/A"]]
                     }
                 }
             ),
             call(
-                "confusion_matrix_score_threshold_0.2",
+                "confusion_matrix_train_score_threshold_0.2",
                 {
                     "schema_type": "confusion_matrix",
                     "schema_version": "1.0.0",
                     "data": {
                         "class_labels": ["dog", "cat", "axolotl", "Missed"],
                         "matrix": [[3, 3, 4, 4], [4, 4, 5, 5], [5, 5, 6, 6], ["N/A", "N/A", "N/A", "N/A"]]
                     }
                 }
             ),
             call(
-                "confusion_matrix_score_threshold_0.3",
+                "confusion_matrix_train_score_threshold_0.3",
                 {
                     "schema_type": "confusion_matrix",
                     "schema_version": "1.0.0",
                     "data": {
                         "class_labels": ["dog", "cat", "axolotl", "Missed"],
                         "matrix": [[2, 3, 4, 5], [3, 4, 5, 6], [4, 5, 6, 7], ["N/A", "N/A", "N/A", "N/A"]]
                     }
@@ -1135,14 +1135,48 @@
             )
         ]
 
     mock_log_row.assert_has_calls(per_label_calls + image_level_calls, any_order=True)
     mock_log_confusion_matrix.assert_has_calls(confusion_matrix_calls, any_order=True)
 
 
+@mock.patch("azureml.core.run.Run.log_confusion_matrix")
+@mock.patch("azureml.core.run.Run.log_row")
+@mock.patch("azureml.core.run.Run")
+def test_detailed_object_detection_metrics_zero_classes(mock_run, mock_log_row, mock_log_confusion_matrix):
+    mock_run.return_value = None
+    mock_log_row.return_value = None
+
+    metrics = {
+        MetricsLiterals.PRECISION: 0.0,
+        MetricsLiterals.RECALL: 0.0,
+        MetricsLiterals.MEAN_AVERAGE_PRECISION: 0.0,
+        MetricsLiterals.PER_LABEL_METRICS: {},
+        MetricsLiterals.IMAGE_LEVEL_BINARY_CLASSIFIER_METRICS: {
+            "precision": -1.0, "recall": -1.0, "average_precision": -1.0
+        },
+        MetricsLiterals.CONFUSION_MATRICES_PER_SCORE_THRESHOLD: {
+            -1.0: []
+        }
+    }
+
+    utils.log_detailed_object_detection_metrics(metrics, mock_run, [])
+
+    image_level_calls = [
+        call(
+            MetricsLiterals.IMAGE_LEVEL_BINARY_CLASSIFIER_METRICS, precision=-1.0, recall=-1.0, average_precision=-1.0
+        )
+    ]
+
+    mock_log_row.assert_has_calls(image_level_calls, any_order=True)
+    assert mock_log_row.call_count == len(image_level_calls)
+
+    mock_log_confusion_matrix.assert_not_called()
+
+
 @patch("torch.cuda.is_available", return_value=True)
 @patch("azureml.automl.dnn.vision.common.distributed_utils.master_process", return_value=True)
 @patch("pynvml.nvmlInit")
 @patch("pynvml.nvmlDeviceGetCount", return_value=1)
 @patch("pynvml.nvmlDeviceGetName", return_value='test_gpu_device')
 @patch("pynvml.nvmlDeviceGetHandleByIndex")
 @patch("pynvml.nvmlShutdown")
```

## tests/object_detection_tests/test_datasets.py

```diff
@@ -263,16 +263,19 @@
 
     test_files_full_path = [os.path.join(AmlDatasetHelper.get_data_dir(),
                                          test_file) for test_file in test_files]
     test_labels = []
     for file_bbox_list in bbox_list:
         file_labels = []
         for bbox in file_bbox_list:
-            file_labels.append({'label': '1', 'topX': bbox[0], 'topY': bbox[1],
-                                'bottomX': bbox[2], 'bottomY': bbox[3]})
+            if len(bbox) == 0:
+                file_labels.append([])
+            else:
+                file_labels.append({'label': '1', 'topX': bbox[0], 'topY': bbox[1],
+                                    'bottomX': bbox[2], 'bottomY': bbox[3]})
         test_labels.append(file_labels)
     mockworkspace, mockdataset = _get_mockworkspace(test_files, test_labels, test_files_full_path, test_dataset_id)
     return mockworkspace, mockdataset, test_files_full_path, test_labels
 
 
 @pytest.mark.usefixtures('new_clean_dir')
 class TestAmlDatasetObjectDetection:
@@ -457,14 +460,22 @@
                 for image, target, info in dataset_wrapper:
                     assert image is not None
                     assert target is not None
                     assert info is not None
 
                 for test_file in test_files_full_path:
                     assert os.path.exists(test_file)
+
+            except AutoMLVisionDataException as e:
+                error_str = "No objects in dataset. Please ensure that at least one image has one or more objects."
+                if error_str in e.message:
+                    assert all([n == 0 for n in num_valid_boxes_per_image])
+                else:
+                    raise
+
             finally:
                 for test_file in test_files_full_path:
                     os.remove(test_file)
 
         # Valid and invalid box definitions.
         valid_bbox = [0.0, 0.0, 0.5, 0.5]
         invalid_bbox = [-0.1, 0.0, 0.5, 0.5]
@@ -478,14 +489,18 @@
         _test(bbox_list, 1, [0])
 
         # An image with a valid box, two background images, an image with an invalid box, and an image with a valid and
         # invalid box. The image with the invalid box and nothing else is skipped.
         bbox_list = [[valid_bbox], [], [], [invalid_bbox], [invalid_bbox, valid_bbox]]
         _test(bbox_list, 4, [1, 0, 0, 1])
 
+        # Two background images.
+        bbox_list = [[], []]
+        _test(bbox_list, 2, [0, 0])
+
     def test_aml_dataset_object_detection_invalid_bboxes(self):
 
         def _test_loop(bbox_list, valid, num_valid_boxes):
             mockworkspace, mockdataset, test_files_full_path, test_labels \
                 = _build_aml_dataset_object_detection_with_bbox_list(bbox_list)
             try:
                 AmlDatasetObjectDetection.download_image_files(mockdataset)
@@ -687,30 +702,33 @@
         tile_overlap_ratio = 0.0  # Using overlap_ratio of 0 for easier test case construction
         tiles = get_tiles(tile_grid_size, tile_overlap_ratio, image_size)
 
         bbox_list = [[[0.0, 0.0, 0.25, 0.25],  # box in tile 0
                       [0.0, 0.25, 0.25, 0.75],  # box in tile 0 and tile 1
                       [0.0, 0.75, 0.25, 1.0],  # box in tile 1
                       [0.75, 0.0, 1.0, 0.25],  # box in tile 2
-                      [0.25, 0.0, 0.75, 0.25]  # box in tile 0 and tile 2
-                      ]]
+                      [0.25, 0.0, 0.75, 0.25]],  # box in tile 0 and tile 2
+                     []]  # background image with no annotations
         # Expected bounding boxes in each tile with co-ordinates relative to tile dimensions
         # the comment against each line indicates what box in bbox_list it corresponds to.
         expected_tile_bbox_list = [[] for _ in tiles]
         expected_tile_bbox_list[0] = [[0.0, 0.0, 0.5, 0.5],  # bbox_list[0]
                                       [0.0, 0.5, 0.5, 1.0],  # bbox_list[1]
                                       [0.5, 0.0, 1.0, 0.5]  # bbox_list[4]
                                       ]
         expected_tile_bbox_list[1] = [[0.0, 0.0, 0.5, 0.5],  # bbox_list[1]
                                       [0.0, 0.5, 0.5, 1.0]  # bbox_list[2]
                                       ]
         expected_tile_bbox_list[2] = [[0.5, 0.0, 1.0, 0.5],  # bbox_list[3]
                                       [0.0, 0.0, 0.5, 0.5]  # bbox_list[4]
                                       ]
-        _test(bbox_list, tile_grid_size, tile_overlap_ratio, True, [tiles[:3]], [expected_tile_bbox_list[:3]])
+        background_tiles = []
+        background_expected_tile_bbox = []
+        _test(bbox_list, tile_grid_size, tile_overlap_ratio, True, [tiles[:3], background_tiles],
+              [expected_tile_bbox_list[:3], background_expected_tile_bbox])
 
     @pytest.mark.parametrize("yolo", [False, True])
     @pytest.mark.parametrize("train", [True, False])
     def test_aml_dataset_object_detection_get_image_label_info(self, yolo, train):
 
         def _test(bbox_list, tile_grid_size, tile_overlap_ratio, valid, expected_num_boxes):
             mockworkspace, mockdataset, test_files_full_path, test_labels \
```

## tests/object_detection_tests/test_incremental_voc_evaluator.py

```diff
@@ -1607,14 +1607,56 @@
 
         _check_metrics_keys(metrics)
 
         assert metrics[IMAGE_LEVEL_BINARY_CLASSIFIER_METRICS] == {
             AVERAGE_PRECISION: approx(1.0 / 6.0), PRECISION: approx(0.5), RECALL: approx(1.0 / 3.0)
         }
 
+    @pytest.mark.parametrize("num_classes", [0, 1])
+    def test_three_images_no_gt_no_pred(self, num_classes):
+        ive = IncrementalVocEvaluator(True, num_classes, 0.5)
+
+        meta_info_per_image = [
+            {"width": 640, "height": 480, "iscrowd": np.array([], dtype=bool)}
+            for _ in range(3)
+        ]
+        gt_objects_per_image = [
+            {"boxes": np.zeros((0, 4)), "masks": None, "classes": np.zeros((0,))}
+            for _ in range(3)
+        ]
+        predicted_objects_per_image = [
+            {"boxes": np.zeros((0, 4)), "masks": None, "classes": np.zeros((0,)), "scores": np.zeros((0,))}
+            for _ in range(3)
+        ]
+        ive.evaluate_batch(gt_objects_per_image, predicted_objects_per_image, meta_info_per_image)
+
+        metrics = ive.compute_metrics()
+
+        _check_metrics_keys(metrics)
+
+        if num_classes == 0:
+            assert metrics[PER_LABEL_METRICS] == {}
+        else:
+            assert metrics[PER_LABEL_METRICS] == {
+                i: {AVERAGE_PRECISION: -1.0, PRECISION: -1.0, RECALL: -1.0}
+                for i in range(num_classes)
+            }
+
+        assert metrics[MEAN_AVERAGE_PRECISION] == approx(0.0)
+        assert metrics[PRECISION] == approx(0.0)
+        assert metrics[RECALL] == approx(0.0)
+
+        assert metrics[IMAGE_LEVEL_BINARY_CLASSIFIER_METRICS] == {
+            AVERAGE_PRECISION: -1.0, PRECISION: -1.0, RECALL: -1.0
+        }
+
+        assert metrics[CONFUSION_MATRICES_PER_SCORE_THRESHOLD] == {
+            -1.0: [] if num_classes == 0 else [[0, 0]]
+        }
+
     def test_hundred_images_multi_gt_multi_pred_image_level(self):
         ive = IncrementalVocEvaluator(True, 3, 0.5)
 
         meta_info_per_image = [
             {"width": 640, "height": 480, "iscrowd": np.array([])} for _ in range(98)
         ] + [
             {"width": 640, "height": 480, "iscrowd": np.array([False])}
```

## Comparing `azureml_automl_dnn_vision-1.50.0.post1.dist-info/LICENSE.txt` & `azureml_automl_dnn_vision-1.51.0.dist-info/LICENSE.txt`

 * *Files identical despite different names*

## Comparing `azureml_automl_dnn_vision-1.50.0.post1.dist-info/METADATA` & `azureml_automl_dnn_vision-1.51.0.dist-info/METADATA`

 * *Files 4% similar despite different names*

```diff
@@ -1,29 +1,29 @@
 Metadata-Version: 2.1
 Name: azureml-automl-dnn-vision
-Version: 1.50.0.post1
+Version: 1.51.0
 Summary: AutoML DNN Vision Models
 Home-page: https://docs.microsoft.com/python/api/overview/azure/ml/?view=azure-ml-py
 Author: Microsoft Corp
 License: Proprietary https://aka.ms/azureml-preview-sdk-license 
 Platform: UNKNOWN
 Classifier: Intended Audience :: Developers
 Classifier: Intended Audience :: Science/Research
 Classifier: Programming Language :: Python :: 3.7
 Classifier: Programming Language :: Python :: 3.8
 Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
 Requires-Python: >=3.7,<3.9
 Description-Content-Type: text/x-rst
-Requires-Dist: azureml-automl-core (~=1.50.0)
-Requires-Dist: azureml-dataset-runtime (~=1.50.0)
-Requires-Dist: azureml-core (~=1.50.0)
-Requires-Dist: azureml-telemetry (~=1.50.0)
-Requires-Dist: azureml-train-automl-client (~=1.50.0)
-Requires-Dist: azureml-train-automl-runtime (~=1.50.0)
-Requires-Dist: azureml-automl-runtime (~=1.50.0)
+Requires-Dist: azureml-automl-core (~=1.51.0)
+Requires-Dist: azureml-dataset-runtime (~=1.51.0)
+Requires-Dist: azureml-core (~=1.51.0)
+Requires-Dist: azureml-telemetry (~=1.51.0)
+Requires-Dist: azureml-train-automl-client (~=1.51.0)
+Requires-Dist: azureml-train-automl-runtime (~=1.51.0)
+Requires-Dist: azureml-automl-runtime (~=1.51.0)
 Requires-Dist: numpy (<=1.22.3,>=1.18.5)
 Requires-Dist: opencv-python-headless (==4.3.0.38)
 Requires-Dist: pillow (==9.0.1)
 Requires-Dist: pretrainedmodels (==0.7.4)
 Requires-Dist: psutil (==5.8.0)
 Requires-Dist: pycocotools (==2.0.4)
 Requires-Dist: pynvml (==8.0.4)
```

## Comparing `azureml_automl_dnn_vision-1.50.0.post1.dist-info/RECORD` & `azureml_automl_dnn_vision-1.51.0.dist-info/RECORD`

 * *Files 2% similar despite different names*

```diff
@@ -1,24 +1,24 @@
 azureml/__init__.py,sha256=syS7y5bp6eMiVYpVIzGmuu1WtWHwIws3npeumrfqkA8,299
 azureml/automl/__init__.py,sha256=q5jlC1Fx4e1goVOr_j-I9L16IDBZq69NLgk99rptAYQ,311
 azureml/automl/dnn/__init__.py,sha256=rHQXZlQEH51poK7_axVb9slFY0BxEBs91KAGrtt7Tz0,315
 azureml/automl/dnn/vision/__init__.py,sha256=oEb9hgzRORMpw_-xjShfR-ObPYapVJ64_PG7OXomQCE,682
 azureml/automl/dnn/vision/classification/__init__.py,sha256=2FxDNknSOoU7OD6sC0_LHT0srW0oo2Rfstx7O-mOAl4,226
 azureml/automl/dnn/vision/classification/runner.py,sha256=4jTySWDAwby88yQSJpsE8WgsCyQCEfzdV2xZoL5Ub34,14072
 azureml/automl/dnn/vision/classification/common/__init__.py,sha256=esfc7Hus3rOZPaKVVPui2GI7l1XvrU608oHiKv3rBAo,229
-azureml/automl/dnn/vision/classification/common/classification_utils.py,sha256=SkT1cCzCxidxi57bTwAIe0cH7eF_dBVlplXj7Z0lNJc,26968
+azureml/automl/dnn/vision/classification/common/classification_utils.py,sha256=YXfOWEW-I9jAsfCxvN5BqNwfSLv8ZlvTmQYBUapZEe8,27028
 azureml/automl/dnn/vision/classification/common/constants.py,sha256=-qdte2teiH9r0DTBhQGoN061ui2oy3MFJ4epZLquo5A,7587
 azureml/automl/dnn/vision/classification/common/transforms.py,sha256=W9byIr6sZpqSUgyFBztZt1Xoywjsa80V101wPdavvtY,2573
 azureml/automl/dnn/vision/classification/inference/__init__.py,sha256=RWjmRjs-4oi3OoHLKxmCt7nGikwwO5F4bTsu2myfMf0,208
 azureml/automl/dnn/vision/classification/inference/score.py,sha256=WTiEX-hyY4GNlsYKACqQQWDy9bp0_E4a53hU7W_UVeg,23903
 azureml/automl/dnn/vision/classification/io/__init__.py,sha256=S3TcgSpub-R4pTuOcXjk2afWlEfvHCtrWB2x3Uibkyo,210
 azureml/automl/dnn/vision/classification/io/read/__init__.py,sha256=NUfn3hL96D-vJo-EDp3mX0qYb6Ag8FdkEZyAAgLTYEo,398
 azureml/automl/dnn/vision/classification/io/read/dataloader.py,sha256=UNx61ifkoq9-yAcdTD87I5c6oto39hLGTwqlvrkFTQg,4919
 azureml/automl/dnn/vision/classification/io/read/dataset_wrappers.py,sha256=Qz19pXWhKo9BZA8mDkY3BMtkv_DQtiv6YHEqw0CFPi4,22399
-azureml/automl/dnn/vision/classification/io/read/utils.py,sha256=IfCUiSVcl9N_FFZ5wAeVq7H5SHdqdDwuADoK85PtQv8,5541
+azureml/automl/dnn/vision/classification/io/read/utils.py,sha256=m7PJrwPbNa3AEIdrh87pCCEYM1c6GsNMhEVBMYEDbGc,5507
 azureml/automl/dnn/vision/classification/io/write/__init__.py,sha256=mPLWFNGsKeZglM7_jw0wJCLvIbych9UwD6ddmLKoVwo,237
 azureml/automl/dnn/vision/classification/io/write/featurize_script.py,sha256=_ZDkcCqQeBpto_aB7zmNk4nLrsLCPK6r2bH5hKd3QsQ,2613
 azureml/automl/dnn/vision/classification/io/write/score_script.py,sha256=oXMIx99g9ekwIqzgiP41zdlzm9AaVE0ISQpAGiazgYk,6433
 azureml/automl/dnn/vision/classification/io/write/score_script_utils.py,sha256=KeMloeDDmmdYbXF3G0Av2NlhFgG5VaXXtNNwry5CkiU,973
 azureml/automl/dnn/vision/classification/models/__init__.py,sha256=aJJrit8a_1sLTCOlpPkw4glIgbQRiqO2O2Xrur3KyGU,429
 azureml/automl/dnn/vision/classification/models/base_model_wrapper.py,sha256=6ckuTOD5kGby51PgW6Zsf1o4UebwDJmMhhVIVRFntbU,11491
 azureml/automl/dnn/vision/classification/models/classification_model_wrappers.py,sha256=15jTGeX8vno9YEn-89kpVTKDktbcqEYIJcKqea6JHQ8,30503
@@ -36,25 +36,25 @@
 azureml/automl/dnn/vision/common/data_utils.py,sha256=qdg2SmmN-0BJkaut0XtjhNGbNm7zvhabolJcnxJbDxM,2826
 azureml/automl/dnn/vision/common/dataloaders.py,sha256=k3lTVbW_1r_9zJAamCN1as8N60yS-IuwEXY4e5v8GDc,3184
 azureml/automl/dnn/vision/common/dataset_helper.py,sha256=cwZxMPnH31tL-LpmCGFX5SbX07449x3W_UXabliIDMw,18976
 azureml/automl/dnn/vision/common/distributed_utils.py,sha256=Ut6zamPMIxCcDsS3SwT4lHyulCouy9vrshRcziGdQX4,21108
 azureml/automl/dnn/vision/common/errors.py,sha256=9knV7WI1paVWHLXGTSIa-AxYMq0s2RtrrsyEXxVbqH0,672
 azureml/automl/dnn/vision/common/exceptions.py,sha256=eDxs4p3tI7JZG4Fv60rIehayqAO751xELLPGozsWuig,2379
 azureml/automl/dnn/vision/common/logging_utils.py,sha256=LldRV06kWtaI16snaGVgyH6rpMhWAnTy2SHBex0_R6A,2528
-azureml/automl/dnn/vision/common/model_export_utils.py,sha256=8zd3bwjkGkEi-wqm2QT0nZO9KvVOy3C3dD-wCfIGzFU,25971
-azureml/automl/dnn/vision/common/parameters.py,sha256=2Aqi8Pg84RG6bi_5Mzl0nI-gek-L_72k6oxIovLXi_k,14736
+azureml/automl/dnn/vision/common/model_export_utils.py,sha256=cXcdWg7OicZpMviy4EW8bIw9srd5zIbSFpHFA0ijbQM,25968
+azureml/automl/dnn/vision/common/parameters.py,sha256=kNcFXvUD_GFMRi8TK0IQIYsZEOJuCiiv0VswSiAJU1g,14730
 azureml/automl/dnn/vision/common/prediction_dataset.py,sha256=WnVeCzap2tgFWMKOJ6vIC-opIJ0r6D2pvagijuxM3vs,10208
-azureml/automl/dnn/vision/common/pretrained_model_utilities.py,sha256=fqkREWpTA0UVk_uqaEOgNVgsu9A6OjDdfii6MGqtkdo,37171
+azureml/automl/dnn/vision/common/pretrained_model_utilities.py,sha256=64IFy7zlMVfE68VVuzJXodG99pvcL5fgwnCLShoFj_s,37122
 azureml/automl/dnn/vision/common/sku_validation.py,sha256=RW_lZFsZFqhi3U8pkP57Vr1rnl7OQquwLy4hbjTkb88,3200
 azureml/automl/dnn/vision/common/system_meter.py,sha256=yOC8fQFD7Fu7-8GI3mXUnmwnTBHaAq-uHWRD1h9Gki0,9887
-azureml/automl/dnn/vision/common/tiling_dataset_element.py,sha256=pZLM-mE6KOccUflhi3rDCucmoIeuH-PlC5CbCi3KPYM,5490
-azureml/automl/dnn/vision/common/tiling_utils.py,sha256=OYsQZ0ugsdrfqMxoq6xouYXMPF-XkSHVTVDDiCYsqdk,6434
+azureml/automl/dnn/vision/common/tiling_dataset_element.py,sha256=Nrwmqy5qq5mkOljjEOnlMLMzGtVP91YXbZiWIIf8OmA,5477
+azureml/automl/dnn/vision/common/tiling_utils.py,sha256=JxnOSZkv2yS47rBLzFXszzUwm-CPIrZX3T2o26nrQOg,6399
 azureml/automl/dnn/vision/common/torch_utils.py,sha256=LgCIEUaJLj4vvGRPLFzW71G1kj5BdDW4hh2yYZpzhGk,1039
 azureml/automl/dnn/vision/common/training_state.py,sha256=u_hcK_Gkqqr0bO8EzHkiwJ39gEs8hT3QPxL1ySkUpuU,2994
-azureml/automl/dnn/vision/common/utils.py,sha256=ep4wDSX_MAsE9rQBZdX9WRbkZlV3fTd9rplujZcdcmE,70131
+azureml/automl/dnn/vision/common/utils.py,sha256=CyAuAJSDnAvv9IAQnXb_hDTPU7eWGYFeXjqflMzDzA0,70480
 azureml/automl/dnn/vision/common/mlflow/__init__.py,sha256=TkLaDSO2l8DaHcSUqn9IeOq1sxv9QB7l-OlT_7b_-ao,237
 azureml/automl/dnn/vision/common/mlflow/mlflow_model_wrapper.py,sha256=NwC3rmXWybAiFnFrtlTKOoUVfWrs6NrQfC_6vds89Jc,6364
 azureml/automl/dnn/vision/common/trainer/__init__.py,sha256=pDiItIKTd0YnUIgh2SBUpb-biWbwdEIEg_GctE0c3MA,272
 azureml/automl/dnn/vision/common/trainer/lrschedule.py,sha256=6RKR9lJHBW4MSbLJ78MT7tvlKsU7K0I62vMSQZzaWFg,7720
 azureml/automl/dnn/vision/common/trainer/lrschedule_parameters.py,sha256=KUAaOi2O8RYulDBfW52947R_oFN0Hb0x1EEpc_5a81Q,3336
 azureml/automl/dnn/vision/common/trainer/optimize.py,sha256=I5-u1O0gIPsq-GCaHqpXTz1xdVve7-25ERL7dZbxW10,9241
 azureml/automl/dnn/vision/common/trainer/optimize_parameters.py,sha256=NPKOxN6pBqFvflPS6fc0qW_AlGasd90kuzPzsjpwqAI,4337
@@ -73,25 +73,25 @@
 azureml/automl/dnn/vision/object_detection/common/boundingbox.py,sha256=WpftxN0Nvej0_BJxHWQdPkRKUx-dCBHhUUE7vD-caGo,7356
 azureml/automl/dnn/vision/object_detection/common/coco_eval_box_converter.py,sha256=d4_qrM0zaV-gqxBlHF55QXHyYv4572a-pCs_0MACUl0,3009
 azureml/automl/dnn/vision/object_detection/common/constants.py,sha256=02XBI1JWG0jt7siuj0wk8zwHo2KuF5bcUQ-ehaH_zi8,11089
 azureml/automl/dnn/vision/object_detection/common/masktools.py,sha256=bl9jPxVuNjpG7qdUd3jkhx_xABtctk1qUqHme6CJ1m0,11945
 azureml/automl/dnn/vision/object_detection/common/object_detection_utils.py,sha256=MXfinruUNhUghnEHiUqzQMXzGTfwKhQkRhGnS5AcwT0,27385
 azureml/automl/dnn/vision/object_detection/common/od_training_state.py,sha256=E_SMar741zRj6JCzJUW_5zL3N9lUBJHbhOFtg-chX5o,1632
 azureml/automl/dnn/vision/object_detection/common/parameters.py,sha256=ylYngnLI8Q_3FEcL2xKM3ktgwAXvhkFGvqCXqOdxmh0,4891
-azureml/automl/dnn/vision/object_detection/common/tiling_helper.py,sha256=nMFtm5HBmGu955jGq1Skw9spOQN0JY-HcSuZwHX0KDY,25960
+azureml/automl/dnn/vision/object_detection/common/tiling_helper.py,sha256=DtAPW_H0u8zLckTj7sSLAMEUHc77UgQ67iPijgJI6pQ,26057
 azureml/automl/dnn/vision/object_detection/data/__init__.py,sha256=XEFSLiDC0lAhxmYq4MkWsVLzAO95Onn0fXbvXR0JTJ8,238
-azureml/automl/dnn/vision/object_detection/data/dataset_wrappers.py,sha256=6hfoLOnJpWqohXzd51_7tdeEtXgTaXn5bbYIVKZLFHQ,4886
-azureml/automl/dnn/vision/object_detection/data/datasets.py,sha256=MiV5Zk0KuNkiFsFWEw4TQnDdHKaLeulRFmkbcZe395g,40147
+azureml/automl/dnn/vision/object_detection/data/dataset_wrappers.py,sha256=ItAowpQ1vWrvFc6xFv-dETaaX2XvnQzZtdcQXI3m99o,4605
+azureml/automl/dnn/vision/object_detection/data/datasets.py,sha256=fhM2dkiknUa3s9TjxiI2ZPWrBoaRbdINbW1h6N5JEII,40467
 azureml/automl/dnn/vision/object_detection/data/loaders.py,sha256=QtV3k6QrJw82n2pMv_vH-D968ZOG9MYlM4S6_zLucDg,6110
 azureml/automl/dnn/vision/object_detection/data/object_annotation.py,sha256=hYYGIg3cms8J_3RFZSj0ifRt0vlk-B3Mqeo4U3Og0js,12574
 azureml/automl/dnn/vision/object_detection/data/tiling_distributed_sampler.py,sha256=SGlKInQQUeFt5mRlaHYXiVLvi_rBumRKUZ7Rzk8m46w,4985
-azureml/automl/dnn/vision/object_detection/data/utils.py,sha256=1EnLQPrlxL6jNmSYdGJ4zTiZy4m_fi25EgC85v6uNms,11277
+azureml/automl/dnn/vision/object_detection/data/utils.py,sha256=bj13WOkTUz2zn3LpkPlxY0w1Fa65cgHay698hfbIXwM,11231
 azureml/automl/dnn/vision/object_detection/eval/__init__.py,sha256=z1te76w-UN8eUJa5Fn0NRQne-cdDNU1jEs0_ARQBH9c,240
 azureml/automl/dnn/vision/object_detection/eval/cocotools.py,sha256=onTV6-iVpOsox9RSoPpMzMBIlqUBsatAKyrXJcaucQI,8380
-azureml/automl/dnn/vision/object_detection/eval/incremental_voc_evaluator.py,sha256=9MSZVV6NkgirHT9CtuRjYl6JH3PvWd34ph3uHQD0h1c,21272
+azureml/automl/dnn/vision/object_detection/eval/incremental_voc_evaluator.py,sha256=xTTy1bnZpPcL6nA4zDtDRJPWrmwYYFfaLl-9HD5Ftjk,21506
 azureml/automl/dnn/vision/object_detection/eval/metric_computation_utils.py,sha256=ASKw0j115uGAiMDXBdCtw8utllopAHry80PFCyOOagI,17354
 azureml/automl/dnn/vision/object_detection/eval/object_detection_instance_segmentation_evaluator.py,sha256=zxdt7ITVTxTl6rFUqss8cTMiHoM0v0tB4tDITD2r7hA,14609
 azureml/automl/dnn/vision/object_detection/eval/utils.py,sha256=WnlKSB8zSJFPGS5TPQJ3CwkAWZ1mW4_RZbrUJ-28Dxk,5220
 azureml/automl/dnn/vision/object_detection/models/__init__.py,sha256=NhNRu71Vk3XkfvXsrb0rJ7UeyJsi7O3iyqEoyOVVzpk,239
 azureml/automl/dnn/vision/object_detection/models/base_model_wrapper.py,sha256=S8mrdf5ePgwK4fo8FvLXNbk9dgYNCwNCBD1AwmTgnxc,14422
 azureml/automl/dnn/vision/object_detection/models/detection.py,sha256=8hDkCsCiL_aG0fYf9bRuQo0JhIz2xiu7K9RIrmfv7G4,5102
 azureml/automl/dnn/vision/object_detection/models/instance_segmentation_model_wrappers.py,sha256=EZyDm19W90CX3EtJOEWvH8HTAb_s5K3aXnmG9limWMo,14240
@@ -146,30 +146,30 @@
 tests/classification_tests/test_prediction_dataset.py,sha256=u0Qax67k7DxM5Yrtvgd60xXF2ytsx_UUQzXwiAUyCw0,11694
 tests/classification_tests/test_pretrained_model_factory.py,sha256=vOwVPR1gNbVZV9aMajwTGdTPW9gccn0Hq9OjMWpICwE,3067
 tests/common/__init__.py,sha256=JlCCObuOLZyNhIZlsoL51KtFxiY4xKIIzIRDBcdeu6Y,183
 tests/common/aml_dataset_mock.py,sha256=dCJETAPmt1VLTU3z8aBWz_rdMwYqc58jQS_YjQPrVkc,1237
 tests/common/run_mock.py,sha256=4m_xk_qRBI56AIntlIOlpZCOWUgF-AN-8czkH9KODRg,5116
 tests/common/test_aml_dataset_helper.py,sha256=3g1vnARqj4RURkdO_J-AlM7TWh1HOkXtjaCOcOmKGN4,10438
 tests/common/test_artifacts_utils.py,sha256=5inn9XGxp21olRe9W33s20Hr7LzB1R33mkMp_H3OE9o,12795
-tests/common/test_common_methods.py,sha256=Ei0CxOQIUkvEdsn7y3zYZhb0Bl8TbjK9SfbQdOAhc-Q,56044
+tests/common/test_common_methods.py,sha256=Cx1cUwPG_UTfPrNlGLOcL2pOS__G_0FuCO-XZBgDQ9w,57289
 tests/common/test_distributed_utils.py,sha256=cs08Um-czHe52GTLjhgHlJIbx0it6Sag83Bz30ck0Gs,16927
 tests/common/test_model_export_utils.py,sha256=7CSOjxD9suSlCIBRZgUYU8a_NMSLBc-a-dDf1Q_YHH8,10683
 tests/common/test_pretrained_model_utilities.py,sha256=9yxWrj7IGLVkxOUSCyTKeu8XEmNgIBSxxT5cS_mibCs,6720
 tests/common/test_runner_default_args.py,sha256=K9Rhnfdaz69hl_CZP27HhfOgF_IRKIzTKNV0Yo3IcaE,6606
 tests/common/test_training_state.py,sha256=efxSLfV72e0M6bZwpbIIs4F-1dzmmoGtJqXqul82bRc,5624
 tests/common/utils.py,sha256=ZZoXTNgem_jI2G8r2wTmoLjh1nVqw5F9XIoEjR6sY7Y,6315
 tests/object_detection_tests/__init__.py,sha256=JlCCObuOLZyNhIZlsoL51KtFxiY4xKIIzIRDBcdeu6Y,183
 tests/object_detection_tests/aml_dataset_mock.py,sha256=YzZ57ivEwZGO-ziZRFBDPsGy5fr1gX3nuItOFm70ffQ,430
 tests/object_detection_tests/conftest.py,sha256=1xubLF0mMfJ72UeDWyk4ShG903gHqq0lV0_zuIflALc,711
 tests/object_detection_tests/test_augmentations.py,sha256=-VAEzx5CMsDG23KXN3n3EPQcloZac-W7TbePTKoVA1I,5755
 tests/object_detection_tests/test_coco_eval_box_converter.py,sha256=fvekV1MxfGCTiJwa1LPFtFbxMtZ1EUwoNZZjsvwa4YU,4323
 tests/object_detection_tests/test_cocotools.py,sha256=3MP6QNli7XcMwTz2f2zJC9nCA_efr0mrIgS8M0xA1IE,1604
 tests/object_detection_tests/test_dataset_wrappers.py,sha256=ulH_CqDLssrbnplqC4gSQq_U2Bp8CSooaFr4LWcGJZ8,9815
-tests/object_detection_tests/test_datasets.py,sha256=z9pxvmbmDsjAMeVQtWg3ExbY2MhGr09pRXNUbeeEQhc,73108
-tests/object_detection_tests/test_incremental_voc_evaluator.py,sha256=alHxV5egtucUiNP4_GPZhB-ASU5CqrIydOXPvmMaHFA,76835
+tests/object_detection_tests/test_datasets.py,sha256=Wlu6Ui0C8K_Ypw_oc-0gLdGlp6l2bYMcM30zWjjVZrA,73835
+tests/object_detection_tests/test_incremental_voc_evaluator.py,sha256=9YjRZeGdHePLeNwWsz23fTRWEQDi-Cmy-LIbqLSyL-c,78443
 tests/object_detection_tests/test_maskutils.py,sha256=Nheu3leLh9DA4JRqjXAXsjimXAbc0DIvc_z0yclUDuA,6193
 tests/object_detection_tests/test_metric_computation_utils.py,sha256=xAEx-25IDbuNW0aNiVhJD9REg6sFa6Ys-aTDLbkpL7E,21122
 tests/object_detection_tests/test_model_wrappers.py,sha256=Qj8Lalw4Y1rcy6jfpNCrlX6Y8InVbiVREQuVl5huCtQ,15744
 tests/object_detection_tests/test_object_annotation.py,sha256=sLAmwHX48qVJR-aOqVtncGE7o_gD-sk3KmXAYTl3Dgs,14068
 tests/object_detection_tests/test_object_detection_instance_segmentation_evaluator.py,sha256=ySWdOn7-JJwgs53caYxqYvv7cVM9YjsoGRmgOYZAMDw,18676
 tests/object_detection_tests/test_object_detection_local_run.py,sha256=Z1KR2YIYrs578bvdCW8e59vvcn__-Jxx4JnuJTD5_mA,4296
 tests/object_detection_tests/test_object_detection_utils.py,sha256=o2X8gd80VZopMSdRs0eR-bHi8OeWrg435-anCWCZnO4,21358
@@ -180,13 +180,13 @@
 tests/object_detection_tests/test_tiling_helper.py,sha256=BTkNsHimEWquGlsm-CvGX196vaGp0ViR8RwICVWIluU,49608
 tests/object_detection_tests/test_tiling_utils.py,sha256=wLE0JZLO6y08JB4rpp4gH0A4MMCGXfURFgGpXtgHEvs,9531
 tests/object_detection_tests/test_trainer_criterion.py,sha256=KqsUiG5OhcJcLOQSfpXmMcnWsu3aqJZ5bx72d_fxhbA,1280
 tests/object_detection_tests/test_yolo_trainer_train.py,sha256=D4R3C--NmdYLWBO-KFVBErl5VAmM2FreIcFrt3Quet8,4133
 tests/object_detection_tests/test_yolo_utils.py,sha256=2bi7M2Ty7300-pYX6KjbcrfFEqmWhnPoVtNtTRAsez0,3710
 tests/object_detection_tests/test_yolo_wrapper.py,sha256=AnUUAoT6julWm0AT0gM2GTuktDGB16kGwv4fcCER39I,773
 tests/object_detection_tests/utils.py,sha256=k4b7GmBViQFEi_LP3JFMa9kCmfeqEtD3y8oLHa9tH6o,1088
-azureml_automl_dnn_vision-1.50.0.post1.dist-info/LICENSE.txt,sha256=FOfkEEz4uS7g278F9Rq12rqKF3lLyBUZhVpLetuZrTg,1021
-azureml_automl_dnn_vision-1.50.0.post1.dist-info/METADATA,sha256=dyg7MQWgIn7bcJ7EnUIXxTy7IF_oH9lcCecudqum_Ng,1938
-azureml_automl_dnn_vision-1.50.0.post1.dist-info/WHEEL,sha256=YUYzQ6UQdoqxXjimOitTqynltBCkwY6qlTfTh2IzqQU,97
-azureml_automl_dnn_vision-1.50.0.post1.dist-info/namespace_packages.txt,sha256=AbpHGcgLb-kRsJGnwFEktk7uzpZOCcBY74-YBdrKVGs,1
-azureml_automl_dnn_vision-1.50.0.post1.dist-info/top_level.txt,sha256=YGbVVonfOvHBwpsDBTpLWbK7KEdGg0m7LlGFY7j0SCw,14
-azureml_automl_dnn_vision-1.50.0.post1.dist-info/RECORD,,
+azureml_automl_dnn_vision-1.51.0.dist-info/LICENSE.txt,sha256=FOfkEEz4uS7g278F9Rq12rqKF3lLyBUZhVpLetuZrTg,1021
+azureml_automl_dnn_vision-1.51.0.dist-info/METADATA,sha256=XDb0xpZflaTbpPHGvwDPRfVIVxIE3oWncULRGkinnaE,1932
+azureml_automl_dnn_vision-1.51.0.dist-info/WHEEL,sha256=YUYzQ6UQdoqxXjimOitTqynltBCkwY6qlTfTh2IzqQU,97
+azureml_automl_dnn_vision-1.51.0.dist-info/namespace_packages.txt,sha256=AbpHGcgLb-kRsJGnwFEktk7uzpZOCcBY74-YBdrKVGs,1
+azureml_automl_dnn_vision-1.51.0.dist-info/top_level.txt,sha256=YGbVVonfOvHBwpsDBTpLWbK7KEdGg0m7LlGFY7j0SCw,14
+azureml_automl_dnn_vision-1.51.0.dist-info/RECORD,,
```

