# Comparing `tmp/azureml_contrib_automl_pipeline_steps-1.50.0-py3-none-any.whl.zip` & `tmp/azureml_contrib_automl_pipeline_steps-1.51.0-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,29 +1,29 @@
-Zip file size: 36689 bytes, number of entries: 27
--rw-rw-rw-  2.0 fat      251 b- defN 23-Apr-12 03:27 azureml/__init__.py
--rw-rw-rw-  2.0 fat      251 b- defN 23-Apr-12 03:27 azureml/contrib/__init__.py
--rw-rw-rw-  2.0 fat      366 b- defN 23-Apr-12 03:27 azureml/contrib/automl/__init__.py
--rw-rw-rw-  2.0 fat      368 b- defN 23-Apr-12 03:27 azureml/contrib/automl/pipeline/__init__.py
--rw-rw-rw-  2.0 fat      380 b- defN 23-Apr-12 03:27 azureml/contrib/automl/pipeline/steps/__init__.py
--rw-rw-rw-  2.0 fat    38345 b- defN 23-Apr-12 03:27 azureml/contrib/automl/pipeline/steps/_hts_pipeline_builder.py
--rw-rw-rw-  2.0 fat    24489 b- defN 23-Apr-12 03:27 azureml/contrib/automl/pipeline/steps/automl_pipeline_builder.py
--rw-rw-rw-  2.0 fat      712 b- defN 23-Apr-12 03:27 azureml/contrib/automl/pipeline/steps/exceptions.py
--rw-rw-rw-  2.0 fat     9654 b- defN 23-Apr-12 03:27 azureml/contrib/automl/pipeline/steps/utilities.py
--rw-rw-rw-  2.0 fat      302 b- defN 23-Apr-12 03:27 azureml/contrib/automl/pipeline/steps/_assets/__init__.py
--rw-rw-rw-  2.0 fat     2633 b- defN 23-Apr-12 03:27 azureml/contrib/automl/pipeline/steps/_assets/allocation_explanation_wrapper.py
--rw-rw-rw-  2.0 fat     2304 b- defN 23-Apr-12 03:27 azureml/contrib/automl/pipeline/steps/_assets/allocation_wrapper.py
--rw-rw-rw-  2.0 fat     6102 b- defN 23-Apr-12 03:27 azureml/contrib/automl/pipeline/steps/_assets/automl_forecast_wrapper.py
--rw-rw-rw-  2.0 fat     6106 b- defN 23-Apr-12 03:27 azureml/contrib/automl/pipeline/steps/_assets/automl_training_wrapper.py
--rw-rw-rw-  2.0 fat     5406 b- defN 23-Apr-12 03:27 azureml/contrib/automl/pipeline/steps/_assets/data_aggregation_and_validation_wrapper.py
--rw-rw-rw-  2.0 fat     2378 b- defN 23-Apr-12 03:27 azureml/contrib/automl/pipeline/steps/_assets/hierarchy_builder_wrapper.py
--rw-rw-rw-  2.0 fat     3241 b- defN 23-Apr-12 03:27 azureml/contrib/automl/pipeline/steps/_assets/many_models_inference_driver.py
--rw-rw-rw-  2.0 fat     3692 b- defN 23-Apr-12 03:27 azureml/contrib/automl/pipeline/steps/_assets/many_models_train_driver.py
--rw-rw-rw-  2.0 fat     2510 b- defN 23-Apr-12 03:27 azureml/contrib/automl/pipeline/steps/_assets/partition_inference_dataset_wrapper.py
--rw-rw-rw-  2.0 fat     2490 b- defN 23-Apr-12 03:27 azureml/contrib/automl/pipeline/steps/_assets/partition_training_dataset_wrapper.py
--rw-rw-rw-  2.0 fat     2489 b- defN 23-Apr-12 03:27 azureml/contrib/automl/pipeline/steps/_assets/proportions_calculation_wrapper.py
--rw-rw-rw-  2.0 fat     1021 b- defN 23-Apr-12 03:36 azureml_contrib_automl_pipeline_steps-1.50.0.dist-info/LICENSE.txt
--rw-rw-rw-  2.0 fat      941 b- defN 23-Apr-12 03:36 azureml_contrib_automl_pipeline_steps-1.50.0.dist-info/METADATA
--rw-rw-rw-  2.0 fat       97 b- defN 23-Apr-12 03:36 azureml_contrib_automl_pipeline_steps-1.50.0.dist-info/WHEEL
--rw-rw-rw-  2.0 fat        1 b- defN 23-Apr-12 03:36 azureml_contrib_automl_pipeline_steps-1.50.0.dist-info/namespace_packages.txt
--rw-rw-rw-  2.0 fat        8 b- defN 23-Apr-12 03:36 azureml_contrib_automl_pipeline_steps-1.50.0.dist-info/top_level.txt
-?rw-rw-r--  2.0 fat     3171 b- defN 23-Apr-12 03:36 azureml_contrib_automl_pipeline_steps-1.50.0.dist-info/RECORD
-27 files, 119708 bytes uncompressed, 31215 bytes compressed:  73.9%
+Zip file size: 37428 bytes, number of entries: 27
+-rw-rw-rw-  2.0 fat      251 b- defN 23-May-24 03:26 azureml/__init__.py
+-rw-rw-rw-  2.0 fat      251 b- defN 23-May-24 03:26 azureml/contrib/__init__.py
+-rw-rw-rw-  2.0 fat      366 b- defN 23-May-24 03:26 azureml/contrib/automl/__init__.py
+-rw-rw-rw-  2.0 fat      368 b- defN 23-May-24 03:26 azureml/contrib/automl/pipeline/__init__.py
+-rw-rw-rw-  2.0 fat      380 b- defN 23-May-24 03:26 azureml/contrib/automl/pipeline/steps/__init__.py
+-rw-rw-rw-  2.0 fat    41414 b- defN 23-May-24 03:26 azureml/contrib/automl/pipeline/steps/_hts_pipeline_builder.py
+-rw-rw-rw-  2.0 fat    25539 b- defN 23-May-24 03:26 azureml/contrib/automl/pipeline/steps/automl_pipeline_builder.py
+-rw-rw-rw-  2.0 fat      712 b- defN 23-May-24 03:26 azureml/contrib/automl/pipeline/steps/exceptions.py
+-rw-rw-rw-  2.0 fat     9654 b- defN 23-May-24 03:26 azureml/contrib/automl/pipeline/steps/utilities.py
+-rw-rw-rw-  2.0 fat      302 b- defN 23-May-24 03:26 azureml/contrib/automl/pipeline/steps/_assets/__init__.py
+-rw-rw-rw-  2.0 fat     2633 b- defN 23-May-24 03:26 azureml/contrib/automl/pipeline/steps/_assets/allocation_explanation_wrapper.py
+-rw-rw-rw-  2.0 fat     2304 b- defN 23-May-24 03:26 azureml/contrib/automl/pipeline/steps/_assets/allocation_wrapper.py
+-rw-rw-rw-  2.0 fat     6102 b- defN 23-May-24 03:26 azureml/contrib/automl/pipeline/steps/_assets/automl_forecast_wrapper.py
+-rw-rw-rw-  2.0 fat     6106 b- defN 23-May-24 03:26 azureml/contrib/automl/pipeline/steps/_assets/automl_training_wrapper.py
+-rw-rw-rw-  2.0 fat     5406 b- defN 23-May-24 03:26 azureml/contrib/automl/pipeline/steps/_assets/data_aggregation_and_validation_wrapper.py
+-rw-rw-rw-  2.0 fat     2378 b- defN 23-May-24 03:26 azureml/contrib/automl/pipeline/steps/_assets/hierarchy_builder_wrapper.py
+-rw-rw-rw-  2.0 fat     3241 b- defN 23-May-24 03:26 azureml/contrib/automl/pipeline/steps/_assets/many_models_inference_driver.py
+-rw-rw-rw-  2.0 fat     3692 b- defN 23-May-24 03:26 azureml/contrib/automl/pipeline/steps/_assets/many_models_train_driver.py
+-rw-rw-rw-  2.0 fat     2510 b- defN 23-May-24 03:26 azureml/contrib/automl/pipeline/steps/_assets/partition_inference_dataset_wrapper.py
+-rw-rw-rw-  2.0 fat     2490 b- defN 23-May-24 03:26 azureml/contrib/automl/pipeline/steps/_assets/partition_training_dataset_wrapper.py
+-rw-rw-rw-  2.0 fat     2489 b- defN 23-May-24 03:26 azureml/contrib/automl/pipeline/steps/_assets/proportions_calculation_wrapper.py
+-rw-rw-rw-  2.0 fat     1021 b- defN 23-May-24 03:33 azureml_contrib_automl_pipeline_steps-1.51.0.dist-info/LICENSE.txt
+-rw-rw-rw-  2.0 fat      941 b- defN 23-May-24 03:33 azureml_contrib_automl_pipeline_steps-1.51.0.dist-info/METADATA
+-rw-rw-rw-  2.0 fat       97 b- defN 23-May-24 03:33 azureml_contrib_automl_pipeline_steps-1.51.0.dist-info/WHEEL
+-rw-rw-rw-  2.0 fat        1 b- defN 23-May-24 03:33 azureml_contrib_automl_pipeline_steps-1.51.0.dist-info/namespace_packages.txt
+-rw-rw-rw-  2.0 fat        8 b- defN 23-May-24 03:33 azureml_contrib_automl_pipeline_steps-1.51.0.dist-info/top_level.txt
+?rw-rw-r--  2.0 fat     3171 b- defN 23-May-24 03:33 azureml_contrib_automl_pipeline_steps-1.51.0.dist-info/RECORD
+27 files, 123827 bytes uncompressed, 31954 bytes compressed:  74.2%
```

## zipnote {}

```diff
@@ -57,26 +57,26 @@
 
 Filename: azureml/contrib/automl/pipeline/steps/_assets/partition_training_dataset_wrapper.py
 Comment: 
 
 Filename: azureml/contrib/automl/pipeline/steps/_assets/proportions_calculation_wrapper.py
 Comment: 
 
-Filename: azureml_contrib_automl_pipeline_steps-1.50.0.dist-info/LICENSE.txt
+Filename: azureml_contrib_automl_pipeline_steps-1.51.0.dist-info/LICENSE.txt
 Comment: 
 
-Filename: azureml_contrib_automl_pipeline_steps-1.50.0.dist-info/METADATA
+Filename: azureml_contrib_automl_pipeline_steps-1.51.0.dist-info/METADATA
 Comment: 
 
-Filename: azureml_contrib_automl_pipeline_steps-1.50.0.dist-info/WHEEL
+Filename: azureml_contrib_automl_pipeline_steps-1.51.0.dist-info/WHEEL
 Comment: 
 
-Filename: azureml_contrib_automl_pipeline_steps-1.50.0.dist-info/namespace_packages.txt
+Filename: azureml_contrib_automl_pipeline_steps-1.51.0.dist-info/namespace_packages.txt
 Comment: 
 
-Filename: azureml_contrib_automl_pipeline_steps-1.50.0.dist-info/top_level.txt
+Filename: azureml_contrib_automl_pipeline_steps-1.51.0.dist-info/top_level.txt
 Comment: 
 
-Filename: azureml_contrib_automl_pipeline_steps-1.50.0.dist-info/RECORD
+Filename: azureml_contrib_automl_pipeline_steps-1.51.0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## azureml/contrib/automl/pipeline/steps/_hts_pipeline_builder.py

```diff
@@ -7,15 +7,19 @@
 from typing import Any, Dict, List, Optional, Tuple, Union
 import json
 import os
 import shutil
 import sys
 
 from azureml._common._error_definition import AzureMLError
-from azureml.automl.core.shared._diagnostics.automl_error_definitions import AllowedModelsNonExplainable
+from azureml.automl.core.shared._diagnostics.automl_error_definitions import (
+    AllowedModelsNonExplainable,
+    HTSForecastQuantilesInputExtraArguments,
+    QuantileForecastAggregationNotSupported
+)
 from azureml.automl.core.shared.constants import _NonExplainableModels
 from azureml.automl.core.shared.exceptions import ConfigException
 from azureml._common._error_definition.user_error import ArgumentBlankOrEmpty
 from azureml.automl.core.shared.reference_codes import ReferenceCodes
 
 from azureml._base_sdk_common._docstring_wrapper import experimental
 from azureml.core import ComputeTarget, Dataset, Datastore, Experiment, Run, RunConfiguration
@@ -236,18 +240,21 @@
         return steps
 
     @staticmethod
     def get_hierarchy_inference_steps(
         experiment: Experiment,
         inference_data: Union[TabularDataset, FileDataset, DatasetConsumptionConfig],
         hierarchy_forecast_level: str,
+        forecast_mode: str,
+        step: int,
         compute_target: Union[str, ComputeTarget],
         node_count: int,
         process_count_per_node: int = 2,
         run_invocation_timeout: int = 600,
+        forecast_quantiles: Optional[List[float]] = None,
         allocation_method: str = PROPORTIONS_OF_HISTORICAL_AVERAGE,
         train_experiment_name: Optional[str] = None,
         training_run_id: Optional[str] = None,
         output_datastore: Optional[Datastore] = None,
         inference_env: Optional[Environment] = None,
         arguments: Optional[List[Union[str, int]]] = None
     ) -> List[PipelineStep]:
@@ -282,14 +289,16 @@
         :param output_datastore: The datastore to be used for output. If specified any pipeline
             output will be written to that location. If unspecified the default datastore will be used.
         :param inference_env: The inference environment.
         :param arguments: The additional arguments that will be passed to each step.
         :returns: A list of steps which will preprocess data to the desired training_level (as set in
             the automl_settings) and train and register automl models.
         """
+        _HTSPipelineBuilder._validate_additional_inference_arguments(arguments)
+
         os.makedirs(_HTSPipelineBuilder._PROJECT_FOLDER, exist_ok=True)
 
         if train_experiment_name is None:
             training_experiment = experiment
             train_experiment_name = experiment.name
         else:
             training_experiment = Experiment(experiment.workspace, train_experiment_name)
@@ -313,14 +322,21 @@
         allocation_param = PipelineParameter(name="allocation_method", default_value=allocation_method)
 
         steps = []
 
         settings = json.loads(training_run.properties[HTSConstants.HTS_PROPERTIES_SETTINGS])
         _HTSPipelineBuilder._dump_settings(settings)
         partition_keys = hts_client_utilities.get_hierarchy_to_training_level(settings)
+
+        # For quantile forecasts, validate that forecast level is deeper than training level
+        # We can disaggregate quantile forecasts, but we can't aggregate them
+        _HTSPipelineBuilder._validate_forecast_quantile_settings(forecast_quantiles,
+                                                                 hierarchy_forecast_level,
+                                                                 settings)
+
         hts_input = ManyModelsInputDataset.from_input_data(inference_data, partition_keys, HTSConstants.HTS_INPUT)
 
         _HTSPipelineBuilder._copy_wrapper_files(hts_input, False)
         if hts_input.is_partition_step_needed:
             steps.append(
                 _HTSPipelineBuilder._build_dataset_partition_step(
                     compute_target, run_config, hts_input, source_directory=_HTSPipelineBuilder._PROJECT_FOLDER,
@@ -331,29 +347,34 @@
         output_forecasts = PipelineData(
             name="raw_forecasts", datastore=datastore, pipeline_output_name="raw_forecasts")
 
         steps.append(
             _HTSPipelineBuilder._build_forecast_parallel_step(
                 hts_input, inference_env, compute_target, node_count,
                 process_count_per_node,
-                run_invocation_timeout, training_run_id, output_forecasts, partition_keys))
+                run_invocation_timeout, training_run_id, output_forecasts,
+                forecast_mode, step, forecast_quantiles, partition_keys))
+
+        step_arguments = [
+            HTSConstants.TRAINING_RUN_ID, training_run_id,
+            HTSConstants.OUTPUT_PATH, output_allocations,
+            HTSConstants.ALLOCATION_METHOD, allocation_param,
+            HTSConstants.FORECAST_LEVEL, forecast_param,
+            HTSConstants.RAW_FORECASTS, output_forecasts,
+        ]
+        if forecast_quantiles is not None:
+            step_arguments.extend([HTSConstants.FORECAST_QUANTILES] + forecast_quantiles)
 
         inf_allocation = PythonScriptStep(
             name=_HTSStepConstants.HTS_ALLOCATION,
             script_name=_HTSPipelineBuilder.SCRIPT_ALLOCATION_WRAPPER.name,
             inputs=[output_forecasts.as_mount()],
             outputs=[output_allocations],
             source_directory=_HTSPipelineBuilder._PROJECT_FOLDER,
-            arguments=[
-                HTSConstants.TRAINING_RUN_ID, training_run_id,
-                HTSConstants.OUTPUT_PATH, output_allocations,
-                HTSConstants.ALLOCATION_METHOD, allocation_param,
-                HTSConstants.FORECAST_LEVEL, forecast_param,
-                HTSConstants.RAW_FORECASTS, output_forecasts,
-            ],
+            arguments=step_arguments,
             runconfig=run_config,
             compute_target=compute_target,
             allow_reuse=False
         )
         steps.append(inf_allocation)
 
         return steps
@@ -582,14 +603,17 @@
             environment: Experiment,
             compute_target: Union[str, ComputeTarget],
             node_count: int,
             process_count_per_node: PipelineParameter,
             run_invocation_timeout: int,
             training_run_id: str,
             output_forecasts: str,
+            forecast_mode: str,
+            step: int,
+            forecast_quantiles: Optional[List[float]] = None,
             partition_keys: Optional[str] = None,
             arguments: Optional[List[Union[str, int]]] = None
     ) -> ParallelRunStep:
         """Build forecast parallel step."""
         inf_prc = _HTSPipelineBuilder._get_prs_config(
             mm_input_data=hts_input,
             partition_keys=partition_keys,
@@ -607,15 +631,20 @@
         inputs = [hts_input.prs_input]
 
         step_arguments = [
             HTSConstants.TRAINING_RUN_ID, training_run_id,
             HTSConstants.OUTPUT_PATH, output_forecasts,
             HTSConstants.APPEND_HEADER_PRS, True,
             HTSConstants.NODES_COUNT, node_count,
+            HTSConstants.FORECAST_MODE, forecast_mode,
+            HTSConstants.FORECAST_STEP, step
         ]
+        if forecast_quantiles is not None:
+            step_arguments.extend([HTSConstants.FORECAST_QUANTILES] + forecast_quantiles)
+
         step_arguments.extend(_HTSPipelineBuilder._get_additional_step_arguments(
             _HTSStepConstants.HTS_FORECAST, arguments
         ))
 
         inf_prs = ParallelRunStep(
             name=_HTSStepConstants.HTS_FORECAST,
             inputs=inputs,
@@ -764,7 +793,43 @@
     def _get_run_config(env: Environment) -> RunConfiguration:
         """Get the run config for step run."""
         run_config = RunConfiguration()
         run_config.docker.use_docker = True
         run_config.environment = env
         utilities.set_environment_variables_for_run(run_config)
         return run_config
+
+    @staticmethod
+    def _validate_additional_inference_arguments(arguments: Optional[List[Union[str, int]]]) -> None:
+        """Validate additional arguments passed to the HTS inference pipeline builder."""
+        if arguments:
+            # Make sure forecast quantiles are not passed in the additional arguments
+            # This is to ensure streamlined validation of the quantile input
+            if HTSConstants.FORECAST_QUANTILES in arguments:
+                raise ConfigException._with_error(
+                    AzureMLError.create(
+                        HTSForecastQuantilesInputExtraArguments,
+                        quantile_option=HTSConstants.FORECAST_QUANTILES,
+                        class_name='HTSInferenceParameters',
+                        target='arguments'
+                    )
+                )
+
+    @staticmethod
+    def _validate_forecast_quantile_settings(
+        forecast_quantiles: Optional[List[float]],
+        forecast_level: str,
+        settings: Dict[str, Any]
+    ) -> None:
+        """Validate forecast quantile settings."""
+        if forecast_quantiles:
+            valid_levels = hts_client_utilities.get_hierarchy_valid_quantile_forecast_levels(settings)
+            if forecast_level not in valid_levels:
+                raise ConfigException._with_error(
+                    AzureMLError.create(
+                        QuantileForecastAggregationNotSupported,
+                        forecast_level_param='hierarchy_forecast_level',
+                        valid_forecast_levels=valid_levels,
+                        reference_code=ReferenceCodes._HTS_QUANTILE_FORECAST_AGGREGATION,
+                        target='hierarchy_forecast_level'
+                    )
+                )
```

## azureml/contrib/automl/pipeline/steps/automl_pipeline_builder.py

```diff
@@ -16,16 +16,19 @@
 from azureml._base_sdk_common._docstring_wrapper import experimental
 from azureml._common._core_user_error.user_error import InvalidArgumentType
 from azureml._common._error_definition import AzureMLError
 from azureml._restclient.jasmine_client import JasmineClient
 
 from azureml.automl.core.console_writer import ConsoleWriter
 from azureml.train.automl.constants import AutoMLPipelineScenario
-from azureml.automl.core.shared._diagnostics.automl_error_definitions import ExecutionFailure
-from azureml.automl.core.shared.exceptions import ValidationException
+from azureml.automl.core.shared._diagnostics.automl_error_definitions import (
+    ConflictingValueForArguments,
+    ExecutionFailure
+)
+from azureml.automl.core.shared.exceptions import ConfigException, ValidationException
 from azureml.core import ComputeTarget, Datastore, Environment, Experiment
 from azureml.data import FileDataset, TabularDataset
 from azureml.data.output_dataset_config import OutputDatasetConfig
 from azureml.data.dataset_consumption_config import DatasetConsumptionConfig
 from azureml.pipeline.core import PipelineData, PipelineParameter, PipelineStep
 from azureml.pipeline.steps import ParallelRunStep
 from azureml.train.automl.runtime._many_models.many_models_parameters import (
@@ -285,36 +288,40 @@
                 input_dataset = input_dataset.default_value
         else:
             input_dataset = inference_data
 
         if isinstance(inference_pipeline_parameters, HTSInferenceParameters):
             return _HTSPipelineBuilder.get_hierarchy_inference_steps(
                 experiment, input_dataset, inference_pipeline_parameters.hierarchy_forecast_level,
+                inference_pipeline_parameters.forecast_mode, inference_pipeline_parameters.step,
                 compute_target, node_count, process_count_per_node, run_invocation_timeout,
+                inference_pipeline_parameters.forecast_quantiles,
                 inference_pipeline_parameters.allocation_method, train_experiment_name,
                 train_run_id, output_datastore, inference_env, arguments
             )
 
         if target_column_name is not None:
             AutoMLPipelineBuilder._print_deprecate_message("target_column_names", "ManyModelsParameters")
         if time_column_name is not None:
             AutoMLPipelineBuilder._print_deprecate_message("time_column_name", "ManyModelsParameters")
         if partition_column_names is not None:
             AutoMLPipelineBuilder._print_deprecate_message("partition_column_names", "ManyModelsParameters")
 
         inference_type = None
         forecast_mode = TimeSeriesInternal.RECURSIVE
+        forecast_quantiles = None
         step = 1
         if inference_pipeline_parameters is not None:
             target_column_name = inference_pipeline_parameters.target_column_name
             partition_column_names = inference_pipeline_parameters.partition_column_names
             time_column_name = inference_pipeline_parameters.time_column_name
             inference_type = inference_pipeline_parameters.inference_type
             forecast_mode = inference_pipeline_parameters.forecast_mode
             step = inference_pipeline_parameters.step
+            forecast_quantiles = inference_pipeline_parameters.forecast_quantiles
         if inference_env is None and (train_run_id is None or train_experiment_name is None):
             raise Exception("Either pass inference_env or pass train_run_id and train_experiment_name")
 
         if inference_env is None:
             inference_env = utilities.get_default_inference_env(
                 experiment, train_run_id, train_experiment_name, MANY_MODELS_TRAIN_STEP_RUN_NAME)
 
@@ -385,14 +392,27 @@
             arguments.append(time_column_name)
         if target_column_name:
             arguments.append('--target_column_name')
             arguments.append(target_column_name)
         if inference_type:
             arguments.append('--inference_type')
             arguments.append(inference_type)
+        if forecast_quantiles:
+            # Continue to allow forecast_quantiles as an additional argument for backward compat
+            # But raise an error if they're given as an argument and through a ManyModelsInferenceParameters object
+            if '--forecast_quantiles' in arguments:
+                raise ConfigException._with_error(
+                    AzureMLError.create(
+                        ConflictingValueForArguments,
+                        arguments='forecast_quantiles',
+                        target='forecast_quantiles'
+                    )
+                )
+            arguments.append('--forecast_quantiles')
+            arguments.extend(forecast_quantiles)
         parallel_run_step = ParallelRunStep(
             name="many-models-inference",
             parallel_run_config=prs_config,
             inputs=datasets,
             output=output_dir,
             arguments=arguments,
             allow_reuse=False,)
```

## Comparing `azureml_contrib_automl_pipeline_steps-1.50.0.dist-info/LICENSE.txt` & `azureml_contrib_automl_pipeline_steps-1.51.0.dist-info/LICENSE.txt`

 * *Files identical despite different names*

## Comparing `azureml_contrib_automl_pipeline_steps-1.50.0.dist-info/METADATA` & `azureml_contrib_automl_pipeline_steps-1.51.0.dist-info/METADATA`

 * *Files 2% similar despite different names*

```diff
@@ -1,23 +1,23 @@
 Metadata-Version: 2.1
 Name: azureml-contrib-automl-pipeline-steps
-Version: 1.50.0
+Version: 1.51.0
 Summary: Helper classes, modules for creating AutoML many models train/inference steps using ParallelRunStep
 Home-page: https://docs.microsoft.com/python/api/overview/azure/ml/?view=azure-ml-py
 Author: Microsoft Corp
 License: Proprietary https://aka.ms/azureml-preview-sdk-license 
 Platform: UNKNOWN
 Classifier: Intended Audience :: Developers
 Classifier: Intended Audience :: Science/Research
 Classifier: Programming Language :: Python :: 3.7
 Classifier: Programming Language :: Python :: 3.8
 Classifier: Programming Language :: Python :: 3.9
 Classifier: Programming Language :: Python :: 3.10
 Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
 Requires-Python: >=3.7,<4.0
 Description-Content-Type: text/x-rst
-Requires-Dist: azureml-pipeline-steps (~=1.50.0)
+Requires-Dist: azureml-pipeline-steps (~=1.51.0)
 
 Represents a unit of computation in azureml-contrib-automl-pipeline-steps.
```

## Comparing `azureml_contrib_automl_pipeline_steps-1.50.0.dist-info/RECORD` & `azureml_contrib_automl_pipeline_steps-1.51.0.dist-info/RECORD`

 * *Files 10% similar despite different names*

```diff
@@ -1,27 +1,27 @@
 azureml/__init__.py,sha256=n0xtZ3iWcoVg5Qognsb7InYAUVAK8s3iaVeHB5GOaNA,251
 azureml/contrib/__init__.py,sha256=n0xtZ3iWcoVg5Qognsb7InYAUVAK8s3iaVeHB5GOaNA,251
 azureml/contrib/automl/__init__.py,sha256=AB0BmvTeeEQpN3BIgFmD1NCez6ARz7XVpzltiUElcO4,366
 azureml/contrib/automl/pipeline/__init__.py,sha256=GpgCnbGW8EuuOilYCym2U7YdFQqzlNzbCh-9UWxhqY0,368
 azureml/contrib/automl/pipeline/steps/__init__.py,sha256=SuqvxSBmsiLZYDZ3tkx4F2mEI22zHA6-vedZ3-w0z74,380
-azureml/contrib/automl/pipeline/steps/_hts_pipeline_builder.py,sha256=b818-on1P_XkcuObTKkikHFwgocZUZIJVhlyxsXnDUo,38345
-azureml/contrib/automl/pipeline/steps/automl_pipeline_builder.py,sha256=FpQxIIu6FTgMkKf-8G-tZnzGOQzYqrv-I8grKFBErq8,24489
+azureml/contrib/automl/pipeline/steps/_hts_pipeline_builder.py,sha256=OQyiUyY6Nqs887PChC7fAjruOAtlLupbo3O-ZXEoX9c,41414
+azureml/contrib/automl/pipeline/steps/automl_pipeline_builder.py,sha256=1_EjX_iTENNr9SBtifKvRYDV62jWluiLnPRkD1miDjQ,25539
 azureml/contrib/automl/pipeline/steps/exceptions.py,sha256=EbXQ9QmHmAvtX0pq_9PjMYqzofAGapCFqW9P19-j4u8,712
 azureml/contrib/automl/pipeline/steps/utilities.py,sha256=QSSt5Y1l-iq7xeT6ILTTxiMsfjNRXf4tj2lOQA_UjBg,9654
 azureml/contrib/automl/pipeline/steps/_assets/__init__.py,sha256=XwcVGBJj7FVs-96lXTXcskNuCEb5jjN3Duux-SF1xT0,302
 azureml/contrib/automl/pipeline/steps/_assets/allocation_explanation_wrapper.py,sha256=OWns5C9KFwdpMGTYdvF7J0N9tLsveBdtBeFJ9FDImII,2633
 azureml/contrib/automl/pipeline/steps/_assets/allocation_wrapper.py,sha256=zi-wuHlcNOAKHMdwGBAXH0iPJ0NYBe3YsCaXQyF0TdY,2304
 azureml/contrib/automl/pipeline/steps/_assets/automl_forecast_wrapper.py,sha256=e9bVhCTJqmSUMCVXfeyl3n_bZ-V9wBeREbdiECac8lM,6102
 azureml/contrib/automl/pipeline/steps/_assets/automl_training_wrapper.py,sha256=yQgtQ-m9jz8OuHodDSauELCpjMebM-T-Q3vEswn2FPg,6106
 azureml/contrib/automl/pipeline/steps/_assets/data_aggregation_and_validation_wrapper.py,sha256=_ZrKTckVaR7_u2W2TnR_Af46-ZULni8DFOyI5M92Rv8,5406
 azureml/contrib/automl/pipeline/steps/_assets/hierarchy_builder_wrapper.py,sha256=BDmA2auC4VwTQKzbQx7OOwztRil9P6mnuOrlG9wbnRc,2378
 azureml/contrib/automl/pipeline/steps/_assets/many_models_inference_driver.py,sha256=0gxQRexaOoi4dGbT7uQZEwir5dAZuuWM_QZE1IsNh2o,3241
 azureml/contrib/automl/pipeline/steps/_assets/many_models_train_driver.py,sha256=lSIdIYbGSUfowm3koPYRuGdxALxZxWFa4TA9woHiLMU,3692
 azureml/contrib/automl/pipeline/steps/_assets/partition_inference_dataset_wrapper.py,sha256=8zgik5_ea4OwbrAhE-NpplH2oDiVSwrrNip9Vtn3bDc,2510
 azureml/contrib/automl/pipeline/steps/_assets/partition_training_dataset_wrapper.py,sha256=7Fu1v20EW_525ftJzVmmbAnoS2IE2zPpH8hkefhr26s,2490
 azureml/contrib/automl/pipeline/steps/_assets/proportions_calculation_wrapper.py,sha256=B7vUP9RBCkFAW4wNi0xUCnCaUdiDiFVXbLdZax5e-VQ,2489
-azureml_contrib_automl_pipeline_steps-1.50.0.dist-info/LICENSE.txt,sha256=FOfkEEz4uS7g278F9Rq12rqKF3lLyBUZhVpLetuZrTg,1021
-azureml_contrib_automl_pipeline_steps-1.50.0.dist-info/METADATA,sha256=VlNbZgX1Kz6N2ldHSOyD-Neo-sTMxmlBL_DNRWNRVuQ,941
-azureml_contrib_automl_pipeline_steps-1.50.0.dist-info/WHEEL,sha256=YUYzQ6UQdoqxXjimOitTqynltBCkwY6qlTfTh2IzqQU,97
-azureml_contrib_automl_pipeline_steps-1.50.0.dist-info/namespace_packages.txt,sha256=AbpHGcgLb-kRsJGnwFEktk7uzpZOCcBY74-YBdrKVGs,1
-azureml_contrib_automl_pipeline_steps-1.50.0.dist-info/top_level.txt,sha256=ZOeEa0TAXo6i5wOjwBoqfIGEuxOcKuscGgNSpizqREY,8
-azureml_contrib_automl_pipeline_steps-1.50.0.dist-info/RECORD,,
+azureml_contrib_automl_pipeline_steps-1.51.0.dist-info/LICENSE.txt,sha256=FOfkEEz4uS7g278F9Rq12rqKF3lLyBUZhVpLetuZrTg,1021
+azureml_contrib_automl_pipeline_steps-1.51.0.dist-info/METADATA,sha256=4BicFj4k2IQbi4cYr59mqctYsoPjlisMEKIk1uyrZcM,941
+azureml_contrib_automl_pipeline_steps-1.51.0.dist-info/WHEEL,sha256=YUYzQ6UQdoqxXjimOitTqynltBCkwY6qlTfTh2IzqQU,97
+azureml_contrib_automl_pipeline_steps-1.51.0.dist-info/namespace_packages.txt,sha256=AbpHGcgLb-kRsJGnwFEktk7uzpZOCcBY74-YBdrKVGs,1
+azureml_contrib_automl_pipeline_steps-1.51.0.dist-info/top_level.txt,sha256=ZOeEa0TAXo6i5wOjwBoqfIGEuxOcKuscGgNSpizqREY,8
+azureml_contrib_automl_pipeline_steps-1.51.0.dist-info/RECORD,,
```

