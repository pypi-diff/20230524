# Comparing `tmp/alphamed-federated-0.4.7.tar.gz` & `tmp/alphamed-federated-0.4.9.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "alphamed-federated-0.4.7.tar", last modified: Wed Apr 19 06:56:20 2023, max compression
+gzip compressed data, was "alphamed-federated-0.4.9.tar", last modified: Wed May 24 11:11:02 2023, max compression
```

## Comparing `alphamed-federated-0.4.7.tar` & `alphamed-federated-0.4.9.tar`

### file list

```diff
@@ -1,220 +1,232 @@
-drwxrwxrwx   0        0        0        0 2023-04-19 06:56:20.374245 alphamed-federated-0.4.7/
--rw-rw-rw-   0        0        0    11357 2023-03-29 15:01:00.000000 alphamed-federated-0.4.7/LICENSE
--rw-rw-rw-   0        0        0    17211 2023-04-19 06:56:20.372245 alphamed-federated-0.4.7/PKG-INFO
--rw-rw-rw-   0        0        0     3447 2023-03-29 15:01:00.000000 alphamed-federated-0.4.7/README.md
--rw-rw-rw-   0        0        0      945 2023-04-19 06:55:26.000000 alphamed-federated-0.4.7/pyproject.toml
--rw-rw-rw-   0        0        0       42 2023-04-19 06:56:20.374245 alphamed-federated-0.4.7/setup.cfg
-drwxrwxrwx   0        0        0        0 2023-04-19 06:56:19.987835 alphamed-federated-0.4.7/src/
-drwxrwxrwx   0        0        0        0 2023-04-19 06:56:20.007298 alphamed-federated-0.4.7/src/alphafed/
--rw-rw-rw-   0        0        0      121 2023-03-29 15:01:28.000000 alphamed-federated-0.4.7/src/alphafed/__init__.py
-drwxrwxrwx   0        0        0        0 2023-04-19 06:56:20.016238 alphamed-federated-0.4.7/src/alphafed/auto_ml/
--rw-rw-rw-   0        0        0      180 2023-03-29 15:01:29.000000 alphamed-federated-0.4.7/src/alphafed/auto_ml/__init__.py
--rw-rw-rw-   0        0        0    14678 2023-03-29 15:01:29.000000 alphamed-federated-0.4.7/src/alphafed/auto_ml/auto_model.py
-drwxrwxrwx   0        0        0        0 2023-04-19 06:56:20.019645 alphamed-federated-0.4.7/src/alphafed/auto_ml/cvat/
--rw-rw-rw-   0        0        0        0 2023-03-29 15:01:29.000000 alphamed-federated-0.4.7/src/alphafed/auto_ml/cvat/__init__.py
--rw-rw-rw-   0        0        0     3578 2023-03-29 15:01:29.000000 alphamed-federated-0.4.7/src/alphafed/auto_ml/cvat/annotation.py
--rw-rw-rw-   0        0        0      116 2023-03-29 15:01:29.000000 alphamed-federated-0.4.7/src/alphafed/auto_ml/exceptions.py
--rw-rw-rw-   0        0        0     5758 2023-03-29 15:01:29.000000 alphamed-federated-0.4.7/src/alphafed/auto_ml/pretrained.py
-drwxrwxrwx   0        0        0        0 2023-04-19 06:56:20.028038 alphamed-federated-0.4.7/src/alphafed/contractor/
--rw-rw-rw-   0        0        0      116 2023-03-29 15:01:29.000000 alphamed-federated-0.4.7/src/alphafed/contractor/__init__.py
--rw-rw-rw-   0        0        0     4717 2023-03-29 15:01:29.000000 alphamed-federated-0.4.7/src/alphafed/contractor/common.py
--rw-rw-rw-   0        0        0     9772 2023-03-29 15:01:29.000000 alphamed-federated-0.4.7/src/alphafed/contractor/task_contractor.py
--rw-rw-rw-   0        0        0    25099 2023-04-13 03:25:38.000000 alphamed-federated-0.4.7/src/alphafed/contractor/task_message_contractor.py
-drwxrwxrwx   0        0        0        0 2023-04-19 06:56:20.040226 alphamed-federated-0.4.7/src/alphafed/data_channel/
--rw-rw-rw-   0        0        0      125 2023-03-29 15:01:29.000000 alphamed-federated-0.4.7/src/alphafed/data_channel/__init__.py
--rw-rw-rw-   0        0        0     6048 2023-03-29 15:01:29.000000 alphamed-federated-0.4.7/src/alphafed/data_channel/data_channel.py
--rw-rw-rw-   0        0        0     2105 2023-03-29 15:01:29.000000 alphamed-federated-0.4.7/src/alphafed/data_channel/data_channel_pb2.py
--rw-rw-rw-   0        0        0     2534 2023-03-29 15:01:29.000000 alphamed-federated-0.4.7/src/alphafed/data_channel/data_channel_pb2_grpc.py
--rw-rw-rw-   0        0        0    17562 2023-03-29 15:01:29.000000 alphamed-federated-0.4.7/src/alphafed/data_channel/grpc_data_channel.py
--rw-rw-rw-   0        0        0    11060 2023-03-29 15:01:29.000000 alphamed-federated-0.4.7/src/alphafed/data_channel/shared_file_data_channel.py
-drwxrwxrwx   0        0        0        0 2023-04-19 06:56:19.950163 alphamed-federated-0.4.7/src/alphafed/docs/
-drwxrwxrwx   0        0        0        0 2023-04-19 06:56:19.944162 alphamed-federated-0.4.7/src/alphafed/docs/auto_ml/
-drwxrwxrwx   0        0        0        0 2023-04-19 06:56:20.044228 alphamed-federated-0.4.7/src/alphafed/docs/auto_ml/res/
--rw-rw-rw-   0        0        0    27911 2023-03-29 15:01:29.000000 alphamed-federated-0.4.7/src/alphafed/docs/auto_ml/res/auto.py
--rw-rw-rw-   0        0        0    11996 2023-03-29 15:01:29.000000 alphamed-federated-0.4.7/src/alphafed/docs/auto_ml/res/res_net.py
-drwxrwxrwx   0        0        0        0 2023-04-19 06:56:20.052610 alphamed-federated-0.4.7/src/alphafed/docs/customized_scheduler/
--rw-rw-rw-   0        0        0     6225 2023-03-29 15:01:29.000000 alphamed-federated-0.4.7/src/alphafed/docs/customized_scheduler/contractor.py
--rw-rw-rw-   0        0        0    18538 2023-04-12 12:57:03.000000 alphamed-federated-0.4.7/src/alphafed/docs/customized_scheduler/scheduler.py
--rw-rw-rw-   0        0        0     5049 2023-03-29 15:01:29.000000 alphamed-federated-0.4.7/src/alphafed/docs/customized_scheduler/simple_task.py
-drwxrwxrwx   0        0        0        0 2023-04-19 06:56:20.055124 alphamed-federated-0.4.7/src/alphafed/docs/fed_avg/
--rw-rw-rw-   0        0        0      782 2023-03-29 15:01:29.000000 alphamed-federated-0.4.7/src/alphafed/docs/fed_avg/net.py
-drwxrwxrwx   0        0        0        0 2023-04-19 06:56:20.059124 alphamed-federated-0.4.7/src/alphafed/docs/mock/
--rw-rw-rw-   0        0        0      782 2023-03-29 15:01:30.000000 alphamed-federated-0.4.7/src/alphafed/docs/mock/net.py
--rw-rw-rw-   0        0        0     5008 2023-03-29 15:01:30.000000 alphamed-federated-0.4.7/src/alphafed/docs/mock/scheduler.py
-drwxrwxrwx   0        0        0        0 2023-04-19 06:56:19.950163 alphamed-federated-0.4.7/src/alphafed/docs/tutorial/
-drwxrwxrwx   0        0        0        0 2023-04-19 06:56:20.061761 alphamed-federated-0.4.7/src/alphafed/docs/tutorial/res/
-drwxrwxrwx   0        0        0        0 2023-04-19 06:56:20.065773 alphamed-federated-0.4.7/src/alphafed/docs/tutorial/res/auto_model_fed_avg/
--rw-rw-rw-   0        0        0    23001 2023-03-29 15:01:30.000000 alphamed-federated-0.4.7/src/alphafed/docs/tutorial/res/auto_model_fed_avg/auto_fed_avg.py
--rw-rw-rw-   0        0        0    11996 2023-03-29 15:01:30.000000 alphamed-federated-0.4.7/src/alphafed/docs/tutorial/res/auto_model_fed_avg/res_net.py
-drwxrwxrwx   0        0        0        0 2023-04-19 06:56:20.069783 alphamed-federated-0.4.7/src/alphafed/docs/tutorial/res/auto_model_local/
--rw-rw-rw-   0        0        0    21045 2023-03-29 15:01:31.000000 alphamed-federated-0.4.7/src/alphafed/docs/tutorial/res/auto_model_local/auto.py
--rw-rw-rw-   0        0        0    11996 2023-03-29 15:01:31.000000 alphamed-federated-0.4.7/src/alphafed/docs/tutorial/res/auto_model_local/res_net.py
--rw-rw-rw-   0        0        0     1481 2023-03-29 15:01:30.000000 alphamed-federated-0.4.7/src/alphafed/docs/tutorial/res/cnn_net.py
-drwxrwxrwx   0        0        0        0 2023-04-19 06:56:20.072771 alphamed-federated-0.4.7/src/alphafed/docs/tutorial/res/simple_fed_avg/
--rw-rw-rw-   0        0        0     3039 2023-03-29 15:03:24.000000 alphamed-federated-0.4.7/src/alphafed/docs/tutorial/res/simple_fed_avg/contractor.py
--rw-rw-rw-   0        0        0    12837 2023-04-12 12:49:52.000000 alphamed-federated-0.4.7/src/alphafed/docs/tutorial/res/simple_fed_avg/scheduler.py
-drwxrwxrwx   0        0        0        0 2023-04-19 06:56:20.073913 alphamed-federated-0.4.7/src/alphafed/examples/
--rw-rw-rw-   0        0        0        0 2023-03-29 15:03:24.000000 alphamed-federated-0.4.7/src/alphafed/examples/__init__.py
-drwxrwxrwx   0        0        0        0 2023-04-19 06:56:20.075923 alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/
--rw-rw-rw-   0        0        0        0 2023-03-29 15:03:24.000000 alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/__init__.py
-drwxrwxrwx   0        0        0        0 2023-04-19 06:56:20.089321 alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/breast_density_classification/
--rw-rw-rw-   0        0        0      732 2023-03-29 15:03:24.000000 alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/breast_density_classification/__init__.py
--rw-rw-rw-   0        0        0      541 2023-03-29 15:03:24.000000 alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/breast_density_classification/clean_history_msg.py
-drwxrwxrwx   0        0        0        0 2023-04-19 06:56:20.094645 alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/breast_density_classification/res_fed_avg/
--rw-rw-rw-   0        0        0    28837 2023-03-29 15:03:24.000000 alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/breast_density_classification/res_fed_avg/auto.py
--rw-rw-rw-   0        0        0    15644 2023-03-29 15:03:27.000000 alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/breast_density_classification/res_fed_avg/inception3.py
-drwxrwxrwx   0        0        0        0 2023-04-19 06:56:20.099146 alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/breast_density_classification/res_local/
--rw-rw-rw-   0        0        0    27956 2023-04-07 07:21:53.000000 alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/breast_density_classification/res_local/auto.py
--rw-rw-rw-   0        0        0    15644 2023-03-29 15:03:29.000000 alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/breast_density_classification/res_local/inception3.py
--rw-rw-rw-   0        0        0     1348 2023-03-29 15:03:24.000000 alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/breast_density_classification/run_aggregator.py
--rw-rw-rw-   0        0        0     1308 2023-03-29 15:03:24.000000 alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/breast_density_classification/run_data_owner_2.py
--rw-rw-rw-   0        0        0     1308 2023-03-29 15:03:24.000000 alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/breast_density_classification/run_data_owner_4.py
--rw-rw-rw-   0        0        0     1041 2023-03-29 15:03:24.000000 alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/breast_density_classification/run_local.py
-drwxrwxrwx   0        0        0        0 2023-04-19 06:56:20.113911 alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/endoscopic_inbody_classification/
--rw-rw-rw-   0        0        0      732 2023-03-29 15:03:29.000000 alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/endoscopic_inbody_classification/__init__.py
--rw-rw-rw-   0        0        0      533 2023-03-29 15:03:29.000000 alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/endoscopic_inbody_classification/clean_history_msg.py
-drwxrwxrwx   0        0        0        0 2023-04-19 06:56:20.115910 alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/endoscopic_inbody_classification/res_fed_avg/
--rw-rw-rw-   0        0        0    30857 2023-03-29 15:03:29.000000 alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/endoscopic_inbody_classification/res_fed_avg/auto.py
-drwxrwxrwx   0        0        0        0 2023-04-19 06:56:20.121175 alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/endoscopic_inbody_classification/res_fed_avg/senet/
--rw-rw-rw-   0        0        0       41 2023-03-29 15:03:31.000000 alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/endoscopic_inbody_classification/res_fed_avg/senet/__init__.py
--rw-rw-rw-   0        0        0    14317 2023-03-29 15:03:31.000000 alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/endoscopic_inbody_classification/res_fed_avg/senet/convolutions.py
-drwxrwxrwx   0        0        0        0 2023-04-19 06:56:20.125176 alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/endoscopic_inbody_classification/res_fed_avg/senet/cv/
--rw-rw-rw-   0        0        0        0 2023-03-29 15:03:31.000000 alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/endoscopic_inbody_classification/res_fed_avg/senet/cv/__init__.py
--rw-rw-rw-   0        0        0    22522 2023-03-29 15:03:31.000000 alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/endoscopic_inbody_classification/res_fed_avg/senet/cv/senet.py
--rw-rw-rw-   0        0        0    12274 2023-03-29 15:03:31.000000 alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/endoscopic_inbody_classification/res_fed_avg/senet/layer_factories.py
-drwxrwxrwx   0        0        0        0 2023-04-19 06:56:20.128636 alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/endoscopic_inbody_classification/res_local/
--rw-rw-rw-   0        0        0    29972 2023-03-29 15:03:31.000000 alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/endoscopic_inbody_classification/res_local/auto.py
-drwxrwxrwx   0        0        0        0 2023-04-19 06:56:20.133890 alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/endoscopic_inbody_classification/res_local/senet/
--rw-rw-rw-   0        0        0       41 2023-03-29 15:03:33.000000 alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/endoscopic_inbody_classification/res_local/senet/__init__.py
--rw-rw-rw-   0        0        0    14317 2023-03-29 15:03:33.000000 alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/endoscopic_inbody_classification/res_local/senet/convolutions.py
-drwxrwxrwx   0        0        0        0 2023-04-19 06:56:20.138495 alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/endoscopic_inbody_classification/res_local/senet/cv/
--rw-rw-rw-   0        0        0        0 2023-03-29 15:03:33.000000 alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/endoscopic_inbody_classification/res_local/senet/cv/__init__.py
--rw-rw-rw-   0        0        0    22522 2023-03-29 15:03:33.000000 alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/endoscopic_inbody_classification/res_local/senet/cv/senet.py
--rw-rw-rw-   0        0        0    12274 2023-03-29 15:03:33.000000 alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/endoscopic_inbody_classification/res_local/senet/layer_factories.py
--rw-rw-rw-   0        0        0     1354 2023-03-29 15:03:29.000000 alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/endoscopic_inbody_classification/run_aggregator.py
--rw-rw-rw-   0        0        0     1314 2023-03-29 15:03:29.000000 alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/endoscopic_inbody_classification/run_data_owner_2.py
--rw-rw-rw-   0        0        0     1314 2023-03-29 15:03:29.000000 alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/endoscopic_inbody_classification/run_data_owner_4.py
--rw-rw-rw-   0        0        0     1043 2023-03-29 15:03:29.000000 alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/endoscopic_inbody_classification/run_local.py
-drwxrwxrwx   0        0        0        0 2023-04-19 06:56:20.155338 alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/skin_lesion_diagnosis/
--rw-rw-rw-   0        0        0      732 2023-03-29 15:03:33.000000 alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/skin_lesion_diagnosis/__init__.py
--rw-rw-rw-   0        0        0      533 2023-03-29 15:03:33.000000 alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/skin_lesion_diagnosis/clean_history_msg.py
-drwxrwxrwx   0        0        0        0 2023-04-19 06:56:20.159777 alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/skin_lesion_diagnosis/res_fed_avg/
--rw-rw-rw-   0        0        0    27957 2023-03-29 15:03:33.000000 alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/skin_lesion_diagnosis/res_fed_avg/auto.py
--rw-rw-rw-   0        0        0    11996 2023-03-29 15:03:33.000000 alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/skin_lesion_diagnosis/res_fed_avg/res_net.py
-drwxrwxrwx   0        0        0        0 2023-04-19 06:56:20.163790 alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/skin_lesion_diagnosis/res_local/
--rw-rw-rw-   0        0        0    27051 2023-03-29 15:03:34.000000 alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/skin_lesion_diagnosis/res_local/auto.py
--rw-rw-rw-   0        0        0    11996 2023-03-29 15:03:34.000000 alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/skin_lesion_diagnosis/res_local/res_net.py
--rw-rw-rw-   0        0        0     1388 2023-03-29 15:03:33.000000 alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/skin_lesion_diagnosis/run_aggregator.py
--rw-rw-rw-   0        0        0     1292 2023-03-29 15:03:33.000000 alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/skin_lesion_diagnosis/run_data_owner_2.py
--rw-rw-rw-   0        0        0     1292 2023-03-29 15:03:33.000000 alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/skin_lesion_diagnosis/run_data_owner_4.py
--rw-rw-rw-   0        0        0     1096 2023-03-29 15:03:33.000000 alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/skin_lesion_diagnosis/run_local.py
-drwxrwxrwx   0        0        0        0 2023-04-19 06:56:20.173543 alphamed-federated-0.4.7/src/alphafed/examples/data_channel/
--rw-rw-rw-   0        0        0      578 2023-03-29 15:03:35.000000 alphamed-federated-0.4.7/src/alphafed/examples/data_channel/__init__.py
--rw-rw-rw-   0        0        0      497 2023-03-29 15:03:35.000000 alphamed-federated-0.4.7/src/alphafed/examples/data_channel/clean_history_msg.py
--rw-rw-rw-   0        0        0     4544 2023-03-29 15:03:35.000000 alphamed-federated-0.4.7/src/alphafed/examples/data_channel/run_receiver_2.py
--rw-rw-rw-   0        0        0     3866 2023-03-29 15:03:35.000000 alphamed-federated-0.4.7/src/alphafed/examples/data_channel/run_receiver_4.py
--rw-rw-rw-   0        0        0     6242 2023-03-29 15:03:35.000000 alphamed-federated-0.4.7/src/alphafed/examples/data_channel/run_sender.py
-drwxrwxrwx   0        0        0        0 2023-04-19 06:56:20.195758 alphamed-federated-0.4.7/src/alphafed/examples/fed_avg/
--rw-rw-rw-   0        0        0      736 2023-04-13 02:23:18.000000 alphamed-federated-0.4.7/src/alphafed/examples/fed_avg/__init__.py
--rw-rw-rw-   0        0        0      492 2023-03-29 15:03:35.000000 alphamed-federated-0.4.7/src/alphafed/examples/fed_avg/clean_history_msg.py
--rw-rw-rw-   0        0        0    23586 2023-03-29 15:03:35.000000 alphamed-federated-0.4.7/src/alphafed/examples/fed_avg/demo_FedIRM.py
--rw-rw-rw-   0        0        0    20482 2023-03-29 15:03:35.000000 alphamed-federated-0.4.7/src/alphafed/examples/fed_avg/demos.py
-drwxrwxrwx   0        0        0        0 2023-04-19 06:56:20.199766 alphamed-federated-0.4.7/src/alphafed/examples/fed_avg/model/
--rw-rw-rw-   0        0        0     5021 2023-03-29 15:03:36.000000 alphamed-federated-0.4.7/src/alphafed/examples/fed_avg/model/my_scheduler.py
--rw-rw-rw-   0        0        0      782 2023-03-29 15:03:36.000000 alphamed-federated-0.4.7/src/alphafed/examples/fed_avg/model/net.py
--rw-rw-rw-   0        0        0     1265 2023-03-29 15:03:35.000000 alphamed-federated-0.4.7/src/alphafed/examples/fed_avg/run_aggregator.py
--rw-rw-rw-   0        0        0     1030 2023-03-29 15:03:35.000000 alphamed-federated-0.4.7/src/alphafed/examples/fed_avg/run_data_owner_2.py
--rw-rw-rw-   0        0        0     1030 2023-03-29 15:03:36.000000 alphamed-federated-0.4.7/src/alphafed/examples/fed_avg/run_data_owner_3.py
--rw-rw-rw-   0        0        0     1030 2023-03-29 15:03:36.000000 alphamed-federated-0.4.7/src/alphafed/examples/fed_avg/run_data_owner_4.py
--rw-rw-rw-   0        0        0     1030 2023-03-29 15:03:36.000000 alphamed-federated-0.4.7/src/alphafed/examples/fed_avg/run_data_owner_5.py
-drwxrwxrwx   0        0        0        0 2023-04-19 06:56:20.211553 alphamed-federated-0.4.7/src/alphafed/examples/fed_md/
--rw-rw-rw-   0        0        0      736 2023-04-13 02:23:18.000000 alphamed-federated-0.4.7/src/alphafed/examples/fed_md/__init__.py
--rw-rw-rw-   0        0        0      492 2023-03-29 15:03:35.000000 alphamed-federated-0.4.7/src/alphafed/examples/fed_md/clean_history_msg.py
--rw-rw-rw-   0        0        0     7556 2023-04-13 06:17:28.000000 alphamed-federated-0.4.7/src/alphafed/examples/fed_md/demos.py
-drwxrwxrwx   0        0        0        0 2023-04-19 06:56:20.222087 alphamed-federated-0.4.7/src/alphafed/examples/fed_md/model/
--rw-rw-rw-   0        0        0    10630 2023-04-12 09:11:34.000000 alphamed-federated-0.4.7/src/alphafed/examples/fed_md/model/contractor.py
--rw-rw-rw-   0        0        0      384 2023-04-12 09:11:32.000000 alphamed-federated-0.4.7/src/alphafed/examples/fed_md/model/loss.py
--rw-rw-rw-   0        0        0     6818 2023-04-12 09:48:27.000000 alphamed-federated-0.4.7/src/alphafed/examples/fed_md/model/my_homo_fed_md_impl.py
--rw-rw-rw-   0        0        0      782 2023-04-12 09:11:31.000000 alphamed-federated-0.4.7/src/alphafed/examples/fed_md/model/net.py
--rw-rw-rw-   0        0        0    31535 2023-04-13 06:16:45.000000 alphamed-federated-0.4.7/src/alphafed/examples/fed_md/model/scheduler.py
--rw-rw-rw-   0        0        0      514 2023-04-13 06:17:45.000000 alphamed-federated-0.4.7/src/alphafed/examples/fed_md/run_aggregator.py
--rw-rw-rw-   0        0        0      499 2023-04-13 06:17:54.000000 alphamed-federated-0.4.7/src/alphafed/examples/fed_md/run_data_owner_2.py
--rw-rw-rw-   0        0        0      499 2023-04-13 06:18:22.000000 alphamed-federated-0.4.7/src/alphafed/examples/fed_md/run_data_owner_4.py
-drwxrwxrwx   0        0        0        0 2023-04-19 06:56:20.234094 alphamed-federated-0.4.7/src/alphafed/examples/fed_per/
--rw-rw-rw-   0        0        0      736 2023-04-13 02:23:18.000000 alphamed-federated-0.4.7/src/alphafed/examples/fed_per/__init__.py
--rw-rw-rw-   0        0        0      492 2023-03-29 15:03:35.000000 alphamed-federated-0.4.7/src/alphafed/examples/fed_per/clean_history_msg.py
--rw-rw-rw-   0        0        0     5747 2023-04-13 06:05:41.000000 alphamed-federated-0.4.7/src/alphafed/examples/fed_per/demos.py
-drwxrwxrwx   0        0        0        0 2023-04-19 06:56:20.243097 alphamed-federated-0.4.7/src/alphafed/examples/fed_per/model/
--rw-rw-rw-   0        0        0     1420 2023-04-11 09:28:02.000000 alphamed-federated-0.4.7/src/alphafed/examples/fed_per/model/contractor.py
--rw-rw-rw-   0        0        0     5033 2023-04-12 04:47:33.000000 alphamed-federated-0.4.7/src/alphafed/examples/fed_per/model/my_homo_fed_per_impl.py
--rw-rw-rw-   0        0        0      939 2023-04-11 09:28:02.000000 alphamed-federated-0.4.7/src/alphafed/examples/fed_per/model/net.py
--rw-rw-rw-   0        0        0    11157 2023-04-13 06:00:22.000000 alphamed-federated-0.4.7/src/alphafed/examples/fed_per/model/scheduler.py
--rw-rw-rw-   0        0        0      516 2023-04-13 05:55:12.000000 alphamed-federated-0.4.7/src/alphafed/examples/fed_per/run_aggregator.py
--rw-rw-rw-   0        0        0      501 2023-04-13 06:06:23.000000 alphamed-federated-0.4.7/src/alphafed/examples/fed_per/run_data_owner_2.py
--rw-rw-rw-   0        0        0      501 2023-04-13 06:06:34.000000 alphamed-federated-0.4.7/src/alphafed/examples/fed_per/run_data_owner_4.py
-drwxrwxrwx   0        0        0        0 2023-04-19 06:56:20.256404 alphamed-federated-0.4.7/src/alphafed/examples/fed_prox/
--rw-rw-rw-   0        0        0      736 2023-04-13 02:23:18.000000 alphamed-federated-0.4.7/src/alphafed/examples/fed_prox/__init__.py
--rw-rw-rw-   0        0        0      492 2023-03-29 15:03:35.000000 alphamed-federated-0.4.7/src/alphafed/examples/fed_prox/clean_history_msg.py
--rw-rw-rw-   0        0        0     5870 2023-04-13 05:44:09.000000 alphamed-federated-0.4.7/src/alphafed/examples/fed_prox/demos.py
-drwxrwxrwx   0        0        0        0 2023-04-19 06:56:20.262406 alphamed-federated-0.4.7/src/alphafed/examples/fed_prox/model/
--rw-rw-rw-   0        0        0     5124 2023-04-11 08:25:09.000000 alphamed-federated-0.4.7/src/alphafed/examples/fed_prox/model/my_fed_prox_impl.py
--rw-rw-rw-   0        0        0      782 2023-04-10 09:03:18.000000 alphamed-federated-0.4.7/src/alphafed/examples/fed_prox/model/net.py
--rw-rw-rw-   0        0        0     2425 2023-04-10 09:03:17.000000 alphamed-federated-0.4.7/src/alphafed/examples/fed_prox/model/scheduler.py
--rw-rw-rw-   0        0        0      518 2023-04-13 05:55:53.000000 alphamed-federated-0.4.7/src/alphafed/examples/fed_prox/run_aggregator.py
--rw-rw-rw-   0        0        0      503 2023-04-13 05:55:51.000000 alphamed-federated-0.4.7/src/alphafed/examples/fed_prox/run_data_owner_2.py
--rw-rw-rw-   0        0        0      503 2023-04-13 05:55:48.000000 alphamed-federated-0.4.7/src/alphafed/examples/fed_prox/run_data_owner_4.py
-drwxrwxrwx   0        0        0        0 2023-04-19 06:56:20.272161 alphamed-federated-0.4.7/src/alphafed/examples/hetero_nn/
--rw-rw-rw-   0        0        0      389 2023-04-13 04:20:24.000000 alphamed-federated-0.4.7/src/alphafed/examples/hetero_nn/__init__.py
--rw-rw-rw-   0        0        0      494 2023-03-29 15:03:36.000000 alphamed-federated-0.4.7/src/alphafed/examples/hetero_nn/clean_history_msg.py
--rw-rw-rw-   0        0        0    23092 2023-03-29 15:03:36.000000 alphamed-federated-0.4.7/src/alphafed/examples/hetero_nn/demos.py
-drwxrwxrwx   0        0        0        0 2023-04-19 06:56:20.281161 alphamed-federated-0.4.7/src/alphafed/examples/hetero_nn/hetero_fed_irm/
--rw-rw-rw-   0        0        0     7185 2023-04-19 06:15:52.000000 alphamed-federated-0.4.7/src/alphafed/examples/hetero_nn/hetero_fed_irm/collaborator_scheduler.py
--rw-rw-rw-   0        0        0      524 2023-04-19 05:59:20.000000 alphamed-federated-0.4.7/src/alphafed/examples/hetero_nn/hetero_fed_irm/data_checker.py
--rw-rw-rw-   0        0        0    11895 2023-04-19 06:24:40.000000 alphamed-federated-0.4.7/src/alphafed/examples/hetero_nn/hetero_fed_irm/host_scheduler.py
--rw-rw-rw-   0        0        0    11996 2023-03-29 15:03:33.000000 alphamed-federated-0.4.7/src/alphafed/examples/hetero_nn/hetero_fed_irm/res_net.py
-drwxrwxrwx   0        0        0        0 2023-04-19 06:56:20.293422 alphamed-federated-0.4.7/src/alphafed/examples/hetero_nn/psi/
--rw-rw-rw-   0        0        0      592 2023-03-29 15:03:36.000000 alphamed-federated-0.4.7/src/alphafed/examples/hetero_nn/psi/demos.py
--rw-rw-rw-   0        0        0      819 2023-03-29 15:03:36.000000 alphamed-federated-0.4.7/src/alphafed/examples/hetero_nn/psi/run_collaborator_2.py
--rw-rw-rw-   0        0        0      819 2023-03-29 15:03:36.000000 alphamed-federated-0.4.7/src/alphafed/examples/hetero_nn/psi/run_collaborator_3.py
--rw-rw-rw-   0        0        0      819 2023-03-29 15:03:36.000000 alphamed-federated-0.4.7/src/alphafed/examples/hetero_nn/psi/run_collaborator_4.py
--rw-rw-rw-   0        0        0      819 2023-03-29 15:03:36.000000 alphamed-federated-0.4.7/src/alphafed/examples/hetero_nn/psi/run_collaborator_5.py
--rw-rw-rw-   0        0        0     1046 2023-03-29 15:03:36.000000 alphamed-federated-0.4.7/src/alphafed/examples/hetero_nn/psi/run_initiator.py
--rw-rw-rw-   0        0        0     1218 2023-03-29 15:03:36.000000 alphamed-federated-0.4.7/src/alphafed/examples/hetero_nn/run_collaborater.py
--rw-rw-rw-   0        0        0     1117 2023-03-29 15:03:36.000000 alphamed-federated-0.4.7/src/alphafed/examples/hetero_nn/run_host.py
-drwxrwxrwx   0        0        0        0 2023-04-19 06:56:20.307079 alphamed-federated-0.4.7/src/alphafed/fed_avg/
--rw-rw-rw-   0        0        0      103 2023-03-29 15:03:36.000000 alphamed-federated-0.4.7/src/alphafed/fed_avg/__init__.py
--rw-rw-rw-   0        0        0     9619 2023-03-29 15:03:36.000000 alphamed-federated-0.4.7/src/alphafed/fed_avg/contractor.py
--rw-rw-rw-   0        0        0     2026 2023-03-29 15:03:36.000000 alphamed-federated-0.4.7/src/alphafed/fed_avg/dp_contractor.py
--rw-rw-rw-   0        0        0     8964 2023-03-29 15:03:36.000000 alphamed-federated-0.4.7/src/alphafed/fed_avg/dp_fed_avg.py
--rw-rw-rw-   0        0        0    33004 2023-04-12 12:58:20.000000 alphamed-federated-0.4.7/src/alphafed/fed_avg/fed_avg.py
--rw-rw-rw-   0        0        0    10441 2023-03-29 15:03:36.000000 alphamed-federated-0.4.7/src/alphafed/fed_avg/secure_contractor.py
--rw-rw-rw-   0        0        0    34059 2023-03-29 15:03:36.000000 alphamed-federated-0.4.7/src/alphafed/fed_avg/secure_fed_avg.py
--rw-rw-rw-   0        0        0     1827 2023-03-29 15:01:28.000000 alphamed-federated-0.4.7/src/alphafed/fs.py
-drwxrwxrwx   0        0        0        0 2023-04-19 06:56:20.319247 alphamed-federated-0.4.7/src/alphafed/hetero_nn/
--rw-rw-rw-   0        0        0      116 2023-03-29 15:03:36.000000 alphamed-federated-0.4.7/src/alphafed/hetero_nn/__init__.py
--rw-rw-rw-   0        0        0    12136 2023-03-29 15:03:36.000000 alphamed-federated-0.4.7/src/alphafed/hetero_nn/contractor.py
--rw-rw-rw-   0        0        0    49995 2023-04-19 06:54:23.000000 alphamed-federated-0.4.7/src/alphafed/hetero_nn/hetero_nn.py
-drwxrwxrwx   0        0        0        0 2023-04-19 06:56:20.325247 alphamed-federated-0.4.7/src/alphafed/hetero_nn/psi/
--rw-rw-rw-   0        0        0      105 2023-03-29 15:03:36.000000 alphamed-federated-0.4.7/src/alphafed/hetero_nn/psi/__init__.py
--rw-rw-rw-   0        0        0     3489 2023-03-29 15:03:36.000000 alphamed-federated-0.4.7/src/alphafed/hetero_nn/psi/psi.py
--rw-rw-rw-   0        0        0    14497 2023-03-29 15:03:36.000000 alphamed-federated-0.4.7/src/alphafed/hetero_nn/psi/rsa_intersecter.py
--rw-rw-rw-   0        0        0     3753 2023-03-29 15:03:36.000000 alphamed-federated-0.4.7/src/alphafed/hetero_nn/psi/rsa_psi_contractor.py
--rw-rw-rw-   0        0        0    14008 2023-03-29 15:03:36.000000 alphamed-federated-0.4.7/src/alphafed/hetero_nn/secure_contractor.py
--rw-rw-rw-   0        0        0    74408 2023-04-13 11:32:21.000000 alphamed-federated-0.4.7/src/alphafed/hetero_nn/secure_hetero_nn.py
--rw-rw-rw-   0        0        0      741 2023-03-29 15:01:28.000000 alphamed-federated-0.4.7/src/alphafed/loggers.py
--rw-rw-rw-   0        0        0     6428 2023-03-29 15:01:28.000000 alphamed-federated-0.4.7/src/alphafed/mock.py
--rw-rw-rw-   0        0        0     5037 2023-03-29 15:01:28.000000 alphamed-federated-0.4.7/src/alphafed/perf_bench.py
--rw-rw-rw-   0        0        0     6441 2023-03-29 15:01:28.000000 alphamed-federated-0.4.7/src/alphafed/scheduler.py
-drwxrwxrwx   0        0        0        0 2023-04-19 06:56:20.335531 alphamed-federated-0.4.7/src/alphafed/secure/
--rw-rw-rw-   0        0        0       59 2023-03-29 15:03:36.000000 alphamed-federated-0.4.7/src/alphafed/secure/__init__.py
--rw-rw-rw-   0        0        0      685 2023-03-29 15:03:36.000000 alphamed-federated-0.4.7/src/alphafed/secure/aes.py
--rw-rw-rw-   0        0        0     1242 2023-03-29 15:03:36.000000 alphamed-federated-0.4.7/src/alphafed/secure/ecdhe.py
--rw-rw-rw-   0        0        0     2602 2023-03-29 15:03:36.000000 alphamed-federated-0.4.7/src/alphafed/secure/shamir.py
--rw-rw-rw-   0        0        0      621 2023-03-29 15:03:36.000000 alphamed-federated-0.4.7/src/alphafed/secure/tools.py
--rw-rw-rw-   0        0        0     1864 2023-03-29 15:01:28.000000 alphamed-federated-0.4.7/src/alphafed/utils.py
-drwxrwxrwx   0        0        0        0 2023-04-19 06:56:20.368240 alphamed-federated-0.4.7/src/alphamed_federated.egg-info/
--rw-rw-rw-   0        0        0    17211 2023-04-19 06:56:19.000000 alphamed-federated-0.4.7/src/alphamed_federated.egg-info/PKG-INFO
--rw-rw-rw-   0        0        0     8789 2023-04-19 06:56:19.000000 alphamed-federated-0.4.7/src/alphamed_federated.egg-info/SOURCES.txt
--rw-rw-rw-   0        0        0        1 2023-04-19 06:56:19.000000 alphamed-federated-0.4.7/src/alphamed_federated.egg-info/dependency_links.txt
--rw-rw-rw-   0        0        0      208 2023-04-19 06:56:19.000000 alphamed-federated-0.4.7/src/alphamed_federated.egg-info/requires.txt
--rw-rw-rw-   0        0        0        9 2023-04-19 06:56:19.000000 alphamed-federated-0.4.7/src/alphamed_federated.egg-info/top_level.txt
+drwxrwxrwx   0        0        0        0 2023-05-24 11:11:02.513435 alphamed-federated-0.4.9/
+-rw-rw-rw-   0        0        0    11357 2023-03-29 15:01:00.000000 alphamed-federated-0.4.9/LICENSE
+-rw-rw-rw-   0        0        0    17211 2023-05-24 11:11:02.512436 alphamed-federated-0.4.9/PKG-INFO
+-rw-rw-rw-   0        0        0     3447 2023-03-29 15:01:00.000000 alphamed-federated-0.4.9/README.md
+-rw-rw-rw-   0        0        0      981 2023-05-24 11:10:12.000000 alphamed-federated-0.4.9/pyproject.toml
+-rw-rw-rw-   0        0        0       42 2023-05-24 11:11:02.514438 alphamed-federated-0.4.9/setup.cfg
+drwxrwxrwx   0        0        0        0 2023-05-24 11:11:01.939896 alphamed-federated-0.4.9/src/
+drwxrwxrwx   0        0        0        0 2023-05-24 11:11:01.953815 alphamed-federated-0.4.9/src/alphafed/
+-rw-rw-rw-   0        0        0      121 2023-03-29 15:01:28.000000 alphamed-federated-0.4.9/src/alphafed/__init__.py
+drwxrwxrwx   0        0        0        0 2023-05-24 11:11:01.961882 alphamed-federated-0.4.9/src/alphafed/auto_ml/
+-rw-rw-rw-   0        0        0      180 2023-03-29 15:01:29.000000 alphamed-federated-0.4.9/src/alphafed/auto_ml/__init__.py
+-rw-rw-rw-   0        0        0    14678 2023-03-29 15:01:29.000000 alphamed-federated-0.4.9/src/alphafed/auto_ml/auto_model.py
+drwxrwxrwx   0        0        0        0 2023-05-24 11:11:01.966882 alphamed-federated-0.4.9/src/alphafed/auto_ml/cvat/
+-rw-rw-rw-   0        0        0        0 2023-03-29 15:01:29.000000 alphamed-federated-0.4.9/src/alphafed/auto_ml/cvat/__init__.py
+-rw-rw-rw-   0        0        0     3578 2023-03-29 15:01:29.000000 alphamed-federated-0.4.9/src/alphafed/auto_ml/cvat/annotation.py
+-rw-rw-rw-   0        0        0      116 2023-03-29 15:01:29.000000 alphamed-federated-0.4.9/src/alphafed/auto_ml/exceptions.py
+-rw-rw-rw-   0        0        0     5758 2023-03-29 15:01:29.000000 alphamed-federated-0.4.9/src/alphafed/auto_ml/pretrained.py
+drwxrwxrwx   0        0        0        0 2023-05-24 11:11:01.973445 alphamed-federated-0.4.9/src/alphafed/contractor/
+-rw-rw-rw-   0        0        0      116 2023-03-29 15:01:29.000000 alphamed-federated-0.4.9/src/alphafed/contractor/__init__.py
+-rw-rw-rw-   0        0        0     4717 2023-03-29 15:01:29.000000 alphamed-federated-0.4.9/src/alphafed/contractor/common.py
+-rw-rw-rw-   0        0        0     9772 2023-03-29 15:01:29.000000 alphamed-federated-0.4.9/src/alphafed/contractor/task_contractor.py
+-rw-rw-rw-   0        0        0    25713 2023-05-16 05:47:19.000000 alphamed-federated-0.4.9/src/alphafed/contractor/task_message_contractor.py
+drwxrwxrwx   0        0        0        0 2023-05-24 11:11:01.989128 alphamed-federated-0.4.9/src/alphafed/data_channel/
+-rw-rw-rw-   0        0        0      125 2023-03-29 15:01:29.000000 alphamed-federated-0.4.9/src/alphafed/data_channel/__init__.py
+-rw-rw-rw-   0        0        0     6048 2023-03-29 15:01:29.000000 alphamed-federated-0.4.9/src/alphafed/data_channel/data_channel.py
+-rw-rw-rw-   0        0        0     2105 2023-03-29 15:01:29.000000 alphamed-federated-0.4.9/src/alphafed/data_channel/data_channel_pb2.py
+-rw-rw-rw-   0        0        0     2534 2023-03-29 15:01:29.000000 alphamed-federated-0.4.9/src/alphafed/data_channel/data_channel_pb2_grpc.py
+-rw-rw-rw-   0        0        0    17562 2023-03-29 15:01:29.000000 alphamed-federated-0.4.9/src/alphafed/data_channel/grpc_data_channel.py
+-rw-rw-rw-   0        0        0    11060 2023-03-29 15:01:29.000000 alphamed-federated-0.4.9/src/alphafed/data_channel/shared_file_data_channel.py
+drwxrwxrwx   0        0        0        0 2023-05-24 11:11:01.993085 alphamed-federated-0.4.9/src/alphafed/dataset/
+-rw-rw-rw-   0        0        0        0 2023-05-20 07:21:22.000000 alphamed-federated-0.4.9/src/alphafed/dataset/__init__.py
+-rw-rw-rw-   0        0        0     4476 2023-05-16 05:47:19.000000 alphamed-federated-0.4.9/src/alphafed/dataset/mnist.py
+drwxrwxrwx   0        0        0        0 2023-05-24 11:11:01.894752 alphamed-federated-0.4.9/src/alphafed/docs/
+drwxrwxrwx   0        0        0        0 2023-05-24 11:11:01.891306 alphamed-federated-0.4.9/src/alphafed/docs/auto_ml/
+drwxrwxrwx   0        0        0        0 2023-05-24 11:11:01.996830 alphamed-federated-0.4.9/src/alphafed/docs/auto_ml/res/
+-rw-rw-rw-   0        0        0    27911 2023-03-29 15:01:29.000000 alphamed-federated-0.4.9/src/alphafed/docs/auto_ml/res/auto.py
+-rw-rw-rw-   0        0        0    11996 2023-03-29 15:01:29.000000 alphamed-federated-0.4.9/src/alphafed/docs/auto_ml/res/res_net.py
+drwxrwxrwx   0        0        0        0 2023-05-24 11:11:02.002840 alphamed-federated-0.4.9/src/alphafed/docs/customized_scheduler/
+-rw-rw-rw-   0        0        0     6225 2023-03-29 15:01:29.000000 alphamed-federated-0.4.9/src/alphafed/docs/customized_scheduler/contractor.py
+-rw-rw-rw-   0        0        0    18998 2023-05-16 05:47:20.000000 alphamed-federated-0.4.9/src/alphafed/docs/customized_scheduler/scheduler.py
+-rw-rw-rw-   0        0        0     5049 2023-03-29 15:01:29.000000 alphamed-federated-0.4.9/src/alphafed/docs/customized_scheduler/simple_task.py
+drwxrwxrwx   0        0        0        0 2023-05-24 11:11:02.005838 alphamed-federated-0.4.9/src/alphafed/docs/fed_avg/
+-rw-rw-rw-   0        0        0      803 2023-05-16 05:47:20.000000 alphamed-federated-0.4.9/src/alphafed/docs/fed_avg/net.py
+drwxrwxrwx   0        0        0        0 2023-05-24 11:11:02.009260 alphamed-federated-0.4.9/src/alphafed/docs/mock/
+-rw-rw-rw-   0        0        0      782 2023-03-29 15:01:30.000000 alphamed-federated-0.4.9/src/alphafed/docs/mock/net.py
+-rw-rw-rw-   0        0        0     5008 2023-03-29 15:01:30.000000 alphamed-federated-0.4.9/src/alphafed/docs/mock/scheduler.py
+drwxrwxrwx   0        0        0        0 2023-05-24 11:11:01.894752 alphamed-federated-0.4.9/src/alphafed/docs/tutorial/
+drwxrwxrwx   0        0        0        0 2023-05-24 11:11:02.013221 alphamed-federated-0.4.9/src/alphafed/docs/tutorial/res/
+drwxrwxrwx   0        0        0        0 2023-05-24 11:11:02.017465 alphamed-federated-0.4.9/src/alphafed/docs/tutorial/res/auto_model_fed_avg/
+-rw-rw-rw-   0        0        0    23001 2023-03-29 15:01:30.000000 alphamed-federated-0.4.9/src/alphafed/docs/tutorial/res/auto_model_fed_avg/auto_fed_avg.py
+-rw-rw-rw-   0        0        0    11996 2023-03-29 15:01:30.000000 alphamed-federated-0.4.9/src/alphafed/docs/tutorial/res/auto_model_fed_avg/res_net.py
+drwxrwxrwx   0        0        0        0 2023-05-24 11:11:02.021464 alphamed-federated-0.4.9/src/alphafed/docs/tutorial/res/auto_model_local/
+-rw-rw-rw-   0        0        0    21045 2023-03-29 15:01:31.000000 alphamed-federated-0.4.9/src/alphafed/docs/tutorial/res/auto_model_local/auto.py
+-rw-rw-rw-   0        0        0    11996 2023-03-29 15:01:31.000000 alphamed-federated-0.4.9/src/alphafed/docs/tutorial/res/auto_model_local/res_net.py
+-rw-rw-rw-   0        0        0     1481 2023-03-29 15:01:30.000000 alphamed-federated-0.4.9/src/alphafed/docs/tutorial/res/cnn_net.py
+drwxrwxrwx   0        0        0        0 2023-05-24 11:11:02.024465 alphamed-federated-0.4.9/src/alphafed/docs/tutorial/res/simple_fed_avg/
+-rw-rw-rw-   0        0        0     3039 2023-03-29 15:03:24.000000 alphamed-federated-0.4.9/src/alphafed/docs/tutorial/res/simple_fed_avg/contractor.py
+-rw-rw-rw-   0        0        0    12837 2023-05-16 05:47:20.000000 alphamed-federated-0.4.9/src/alphafed/docs/tutorial/res/simple_fed_avg/scheduler.py
+drwxrwxrwx   0        0        0        0 2023-05-24 11:11:02.026467 alphamed-federated-0.4.9/src/alphafed/examples/
+-rw-rw-rw-   0        0        0        0 2023-03-29 15:03:24.000000 alphamed-federated-0.4.9/src/alphafed/examples/__init__.py
+drwxrwxrwx   0        0        0        0 2023-05-24 11:11:02.028464 alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/
+-rw-rw-rw-   0        0        0        0 2023-03-29 15:03:24.000000 alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/__init__.py
+drwxrwxrwx   0        0        0        0 2023-05-24 11:11:02.040070 alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/breast_density_classification/
+-rw-rw-rw-   0        0        0      732 2023-03-29 15:03:24.000000 alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/breast_density_classification/__init__.py
+-rw-rw-rw-   0        0        0      541 2023-03-29 15:03:24.000000 alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/breast_density_classification/clean_history_msg.py
+drwxrwxrwx   0        0        0        0 2023-05-24 11:11:02.060164 alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/breast_density_classification/res_fed_avg/
+-rw-rw-rw-   0        0        0    29666 2023-05-16 05:47:20.000000 alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/breast_density_classification/res_fed_avg/auto.py
+-rw-rw-rw-   0        0        0    15644 2023-03-29 15:03:27.000000 alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/breast_density_classification/res_fed_avg/inception3.py
+drwxrwxrwx   0        0        0        0 2023-05-24 11:11:02.065166 alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/breast_density_classification/res_local/
+-rw-rw-rw-   0        0        0    28774 2023-05-16 05:47:20.000000 alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/breast_density_classification/res_local/auto.py
+-rw-rw-rw-   0        0        0    15644 2023-03-29 15:03:29.000000 alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/breast_density_classification/res_local/inception3.py
+-rw-rw-rw-   0        0        0     1348 2023-03-29 15:03:24.000000 alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/breast_density_classification/run_aggregator.py
+-rw-rw-rw-   0        0        0     1308 2023-03-29 15:03:24.000000 alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/breast_density_classification/run_data_owner_2.py
+-rw-rw-rw-   0        0        0     1308 2023-03-29 15:03:24.000000 alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/breast_density_classification/run_data_owner_4.py
+-rw-rw-rw-   0        0        0     1068 2023-04-25 02:57:20.000000 alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/breast_density_classification/run_local.py
+drwxrwxrwx   0        0        0        0 2023-05-24 11:11:02.080557 alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/endoscopic_inbody_classification/
+-rw-rw-rw-   0        0        0      732 2023-03-29 15:03:29.000000 alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/endoscopic_inbody_classification/__init__.py
+-rw-rw-rw-   0        0        0      533 2023-03-29 15:03:29.000000 alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/endoscopic_inbody_classification/clean_history_msg.py
+drwxrwxrwx   0        0        0        0 2023-05-24 11:11:02.082570 alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/endoscopic_inbody_classification/res_fed_avg/
+-rw-rw-rw-   0        0        0    31729 2023-05-16 05:47:20.000000 alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/endoscopic_inbody_classification/res_fed_avg/auto.py
+drwxrwxrwx   0        0        0        0 2023-05-24 11:11:02.090066 alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/endoscopic_inbody_classification/res_fed_avg/senet/
+-rw-rw-rw-   0        0        0       41 2023-03-29 15:03:31.000000 alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/endoscopic_inbody_classification/res_fed_avg/senet/__init__.py
+-rw-rw-rw-   0        0        0    14317 2023-03-29 15:03:31.000000 alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/endoscopic_inbody_classification/res_fed_avg/senet/convolutions.py
+drwxrwxrwx   0        0        0        0 2023-05-24 11:11:02.094074 alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/endoscopic_inbody_classification/res_fed_avg/senet/cv/
+-rw-rw-rw-   0        0        0        0 2023-03-29 15:03:31.000000 alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/endoscopic_inbody_classification/res_fed_avg/senet/cv/__init__.py
+-rw-rw-rw-   0        0        0    22522 2023-03-29 15:03:31.000000 alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/endoscopic_inbody_classification/res_fed_avg/senet/cv/senet.py
+-rw-rw-rw-   0        0        0    12274 2023-03-29 15:03:31.000000 alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/endoscopic_inbody_classification/res_fed_avg/senet/layer_factories.py
+drwxrwxrwx   0        0        0        0 2023-05-24 11:11:02.096074 alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/endoscopic_inbody_classification/res_local/
+-rw-rw-rw-   0        0        0    30831 2023-05-16 05:47:20.000000 alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/endoscopic_inbody_classification/res_local/auto.py
+drwxrwxrwx   0        0        0        0 2023-05-24 11:11:02.104386 alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/endoscopic_inbody_classification/res_local/senet/
+-rw-rw-rw-   0        0        0       41 2023-03-29 15:03:33.000000 alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/endoscopic_inbody_classification/res_local/senet/__init__.py
+-rw-rw-rw-   0        0        0    14317 2023-03-29 15:03:33.000000 alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/endoscopic_inbody_classification/res_local/senet/convolutions.py
+drwxrwxrwx   0        0        0        0 2023-05-24 11:11:02.107255 alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/endoscopic_inbody_classification/res_local/senet/cv/
+-rw-rw-rw-   0        0        0        0 2023-03-29 15:03:33.000000 alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/endoscopic_inbody_classification/res_local/senet/cv/__init__.py
+-rw-rw-rw-   0        0        0    22522 2023-03-29 15:03:33.000000 alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/endoscopic_inbody_classification/res_local/senet/cv/senet.py
+-rw-rw-rw-   0        0        0    12274 2023-03-29 15:03:33.000000 alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/endoscopic_inbody_classification/res_local/senet/layer_factories.py
+-rw-rw-rw-   0        0        0     1354 2023-03-29 15:03:29.000000 alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/endoscopic_inbody_classification/run_aggregator.py
+-rw-rw-rw-   0        0        0     1314 2023-03-29 15:03:29.000000 alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/endoscopic_inbody_classification/run_data_owner_2.py
+-rw-rw-rw-   0        0        0     1314 2023-03-29 15:03:29.000000 alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/endoscopic_inbody_classification/run_data_owner_4.py
+-rw-rw-rw-   0        0        0     1043 2023-03-29 15:03:29.000000 alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/endoscopic_inbody_classification/run_local.py
+drwxrwxrwx   0        0        0        0 2023-05-24 11:11:02.120708 alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/skin_lesion_diagnosis/
+-rw-rw-rw-   0        0        0      732 2023-03-29 15:03:33.000000 alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/skin_lesion_diagnosis/__init__.py
+-rw-rw-rw-   0        0        0      533 2023-03-29 15:03:33.000000 alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/skin_lesion_diagnosis/clean_history_msg.py
+drwxrwxrwx   0        0        0        0 2023-05-24 11:11:02.125039 alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/skin_lesion_diagnosis/res_fed_avg/
+-rw-rw-rw-   0        0        0    28765 2023-05-16 05:47:20.000000 alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/skin_lesion_diagnosis/res_fed_avg/auto.py
+-rw-rw-rw-   0        0        0    11996 2023-03-29 15:03:33.000000 alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/skin_lesion_diagnosis/res_fed_avg/res_net.py
+drwxrwxrwx   0        0        0        0 2023-05-24 11:11:02.128033 alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/skin_lesion_diagnosis/res_local/
+-rw-rw-rw-   0        0        0    27846 2023-05-16 05:47:20.000000 alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/skin_lesion_diagnosis/res_local/auto.py
+-rw-rw-rw-   0        0        0    11996 2023-03-29 15:03:34.000000 alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/skin_lesion_diagnosis/res_local/res_net.py
+-rw-rw-rw-   0        0        0     1388 2023-03-29 15:03:33.000000 alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/skin_lesion_diagnosis/run_aggregator.py
+-rw-rw-rw-   0        0        0     1292 2023-03-29 15:03:33.000000 alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/skin_lesion_diagnosis/run_data_owner_2.py
+-rw-rw-rw-   0        0        0     1292 2023-03-29 15:03:33.000000 alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/skin_lesion_diagnosis/run_data_owner_4.py
+-rw-rw-rw-   0        0        0     1096 2023-03-29 15:03:33.000000 alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/skin_lesion_diagnosis/run_local.py
+drwxrwxrwx   0        0        0        0 2023-05-24 11:11:02.138345 alphamed-federated-0.4.9/src/alphafed/examples/benchmark/
+-rw-rw-rw-   0        0        0     3234 2023-05-24 08:48:55.000000 alphamed-federated-0.4.9/src/alphafed/examples/benchmark/fed_avg_schd.py
+-rw-rw-rw-   0        0        0     3667 2023-05-24 08:49:21.000000 alphamed-federated-0.4.9/src/alphafed/examples/benchmark/fed_prox_schd.py
+-rw-rw-rw-   0        0        0     3738 2023-05-24 09:04:28.000000 alphamed-federated-0.4.9/src/alphafed/examples/benchmark/train_res.py
+drwxrwxrwx   0        0        0        0 2023-05-24 11:11:02.153987 alphamed-federated-0.4.9/src/alphafed/examples/data_channel/
+-rw-rw-rw-   0        0        0      578 2023-03-29 15:03:35.000000 alphamed-federated-0.4.9/src/alphafed/examples/data_channel/__init__.py
+-rw-rw-rw-   0        0        0      497 2023-03-29 15:03:35.000000 alphamed-federated-0.4.9/src/alphafed/examples/data_channel/clean_history_msg.py
+-rw-rw-rw-   0        0        0     4544 2023-03-29 15:03:35.000000 alphamed-federated-0.4.9/src/alphafed/examples/data_channel/run_receiver_2.py
+-rw-rw-rw-   0        0        0     3866 2023-03-29 15:03:35.000000 alphamed-federated-0.4.9/src/alphafed/examples/data_channel/run_receiver_4.py
+-rw-rw-rw-   0        0        0     6242 2023-03-29 15:03:35.000000 alphamed-federated-0.4.9/src/alphafed/examples/data_channel/run_sender.py
+drwxrwxrwx   0        0        0        0 2023-05-24 11:11:02.179928 alphamed-federated-0.4.9/src/alphafed/examples/fed_avg/
+-rw-rw-rw-   0        0        0      752 2023-05-16 05:47:20.000000 alphamed-federated-0.4.9/src/alphafed/examples/fed_avg/__init__.py
+-rw-rw-rw-   0        0        0      492 2023-03-29 15:03:35.000000 alphamed-federated-0.4.9/src/alphafed/examples/fed_avg/clean_history_msg.py
+-rw-rw-rw-   0        0        0    13337 2023-05-16 05:47:20.000000 alphamed-federated-0.4.9/src/alphafed/examples/fed_avg/demo_FedIRM.py
+-rw-rw-rw-   0        0        0    20985 2023-05-19 06:40:06.000000 alphamed-federated-0.4.9/src/alphafed/examples/fed_avg/demos.py
+drwxrwxrwx   0        0        0        0 2023-05-24 11:11:02.184616 alphamed-federated-0.4.9/src/alphafed/examples/fed_avg/model/
+-rw-rw-rw-   0        0        0     5155 2023-05-16 05:47:20.000000 alphamed-federated-0.4.9/src/alphafed/examples/fed_avg/model/my_scheduler.py
+-rw-rw-rw-   0        0        0      803 2023-05-16 05:47:20.000000 alphamed-federated-0.4.9/src/alphafed/examples/fed_avg/model/net.py
+-rw-rw-rw-   0        0        0    12331 2023-05-16 05:47:20.000000 alphamed-federated-0.4.9/src/alphafed/examples/fed_avg/res_net.py
+-rw-rw-rw-   0        0        0     1265 2023-03-29 15:03:35.000000 alphamed-federated-0.4.9/src/alphafed/examples/fed_avg/run_aggregator.py
+-rw-rw-rw-   0        0        0     1030 2023-03-29 15:03:35.000000 alphamed-federated-0.4.9/src/alphafed/examples/fed_avg/run_data_owner_2.py
+-rw-rw-rw-   0        0        0     1030 2023-03-29 15:03:36.000000 alphamed-federated-0.4.9/src/alphafed/examples/fed_avg/run_data_owner_3.py
+-rw-rw-rw-   0        0        0     1030 2023-03-29 15:03:36.000000 alphamed-federated-0.4.9/src/alphafed/examples/fed_avg/run_data_owner_4.py
+-rw-rw-rw-   0        0        0     1030 2023-03-29 15:03:36.000000 alphamed-federated-0.4.9/src/alphafed/examples/fed_avg/run_data_owner_5.py
+drwxrwxrwx   0        0        0        0 2023-05-24 11:11:02.197910 alphamed-federated-0.4.9/src/alphafed/examples/fed_md/
+-rw-rw-rw-   0        0        0      752 2023-05-16 05:47:20.000000 alphamed-federated-0.4.9/src/alphafed/examples/fed_md/__init__.py
+-rw-rw-rw-   0        0        0      509 2023-05-16 05:47:20.000000 alphamed-federated-0.4.9/src/alphafed/examples/fed_md/clean_history_msg.py
+-rw-rw-rw-   0        0        0     7770 2023-05-16 05:47:20.000000 alphamed-federated-0.4.9/src/alphafed/examples/fed_md/demos.py
+drwxrwxrwx   0        0        0        0 2023-05-24 11:11:02.207970 alphamed-federated-0.4.9/src/alphafed/examples/fed_md/model/
+-rw-rw-rw-   0        0        0    10630 2023-05-16 05:47:20.000000 alphamed-federated-0.4.9/src/alphafed/examples/fed_md/model/contractor.py
+-rw-rw-rw-   0        0        0      397 2023-05-16 05:47:20.000000 alphamed-federated-0.4.9/src/alphafed/examples/fed_md/model/loss.py
+-rw-rw-rw-   0        0        0     6818 2023-05-16 05:47:20.000000 alphamed-federated-0.4.9/src/alphafed/examples/fed_md/model/my_homo_fed_md_impl.py
+-rw-rw-rw-   0        0        0      803 2023-05-16 05:47:20.000000 alphamed-federated-0.4.9/src/alphafed/examples/fed_md/model/net.py
+-rw-rw-rw-   0        0        0    31535 2023-05-16 05:47:20.000000 alphamed-federated-0.4.9/src/alphafed/examples/fed_md/model/scheduler.py
+-rw-rw-rw-   0        0        0      531 2023-05-16 05:47:20.000000 alphamed-federated-0.4.9/src/alphafed/examples/fed_md/run_aggregator.py
+-rw-rw-rw-   0        0        0      516 2023-05-16 05:47:20.000000 alphamed-federated-0.4.9/src/alphafed/examples/fed_md/run_data_owner_2.py
+-rw-rw-rw-   0        0        0      516 2023-05-16 05:47:20.000000 alphamed-federated-0.4.9/src/alphafed/examples/fed_md/run_data_owner_4.py
+drwxrwxrwx   0        0        0        0 2023-05-24 11:11:02.245518 alphamed-federated-0.4.9/src/alphafed/examples/fed_per/
+-rw-rw-rw-   0        0        0      752 2023-05-16 05:47:20.000000 alphamed-federated-0.4.9/src/alphafed/examples/fed_per/__init__.py
+-rw-rw-rw-   0        0        0      509 2023-05-16 05:47:20.000000 alphamed-federated-0.4.9/src/alphafed/examples/fed_per/clean_history_msg.py
+-rw-rw-rw-   0        0        0     5907 2023-05-16 05:47:20.000000 alphamed-federated-0.4.9/src/alphafed/examples/fed_per/demos.py
+drwxrwxrwx   0        0        0        0 2023-05-24 11:11:02.257837 alphamed-federated-0.4.9/src/alphafed/examples/fed_per/model/
+-rw-rw-rw-   0        0        0     1420 2023-05-16 05:47:20.000000 alphamed-federated-0.4.9/src/alphafed/examples/fed_per/model/contractor.py
+-rw-rw-rw-   0        0        0     5033 2023-05-16 05:47:20.000000 alphamed-federated-0.4.9/src/alphafed/examples/fed_per/model/my_homo_fed_per_impl.py
+-rw-rw-rw-   0        0        0      939 2023-05-16 05:47:20.000000 alphamed-federated-0.4.9/src/alphafed/examples/fed_per/model/net.py
+-rw-rw-rw-   0        0        0    11432 2023-05-16 05:47:20.000000 alphamed-federated-0.4.9/src/alphafed/examples/fed_per/model/scheduler.py
+-rw-rw-rw-   0        0        0      533 2023-05-16 05:47:20.000000 alphamed-federated-0.4.9/src/alphafed/examples/fed_per/run_aggregator.py
+-rw-rw-rw-   0        0        0      518 2023-05-16 05:47:20.000000 alphamed-federated-0.4.9/src/alphafed/examples/fed_per/run_data_owner_2.py
+-rw-rw-rw-   0        0        0      518 2023-05-16 05:47:20.000000 alphamed-federated-0.4.9/src/alphafed/examples/fed_per/run_data_owner_4.py
+drwxrwxrwx   0        0        0        0 2023-05-24 11:11:02.270864 alphamed-federated-0.4.9/src/alphafed/examples/fed_prox/
+-rw-rw-rw-   0        0        0      752 2023-05-16 05:47:20.000000 alphamed-federated-0.4.9/src/alphafed/examples/fed_prox/__init__.py
+-rw-rw-rw-   0        0        0      509 2023-05-16 05:47:20.000000 alphamed-federated-0.4.9/src/alphafed/examples/fed_prox/clean_history_msg.py
+-rw-rw-rw-   0        0        0     6032 2023-05-16 05:47:20.000000 alphamed-federated-0.4.9/src/alphafed/examples/fed_prox/demos.py
+drwxrwxrwx   0        0        0        0 2023-05-24 11:11:02.346001 alphamed-federated-0.4.9/src/alphafed/examples/fed_prox/model/
+-rw-rw-rw-   0        0        0     5124 2023-05-16 05:47:20.000000 alphamed-federated-0.4.9/src/alphafed/examples/fed_prox/model/my_fed_prox_impl.py
+-rw-rw-rw-   0        0        0      803 2023-05-16 05:47:20.000000 alphamed-federated-0.4.9/src/alphafed/examples/fed_prox/model/net.py
+-rw-rw-rw-   0        0        0     2485 2023-05-16 05:47:20.000000 alphamed-federated-0.4.9/src/alphafed/examples/fed_prox/model/scheduler.py
+-rw-rw-rw-   0        0        0      535 2023-05-16 05:47:20.000000 alphamed-federated-0.4.9/src/alphafed/examples/fed_prox/run_aggregator.py
+-rw-rw-rw-   0        0        0      520 2023-05-16 05:47:20.000000 alphamed-federated-0.4.9/src/alphafed/examples/fed_prox/run_data_owner_2.py
+-rw-rw-rw-   0        0        0      520 2023-05-16 05:47:20.000000 alphamed-federated-0.4.9/src/alphafed/examples/fed_prox/run_data_owner_4.py
+drwxrwxrwx   0        0        0        0 2023-05-24 11:11:02.395754 alphamed-federated-0.4.9/src/alphafed/examples/hetero_nn/
+-rw-rw-rw-   0        0        0      396 2023-05-16 05:47:20.000000 alphamed-federated-0.4.9/src/alphafed/examples/hetero_nn/__init__.py
+-rw-rw-rw-   0        0        0      494 2023-03-29 15:03:36.000000 alphamed-federated-0.4.9/src/alphafed/examples/hetero_nn/clean_history_msg.py
+-rw-rw-rw-   0        0        0    23092 2023-03-29 15:03:36.000000 alphamed-federated-0.4.9/src/alphafed/examples/hetero_nn/demos.py
+drwxrwxrwx   0        0        0        0 2023-05-24 11:11:02.403752 alphamed-federated-0.4.9/src/alphafed/examples/hetero_nn/hetero_fed_irm/
+-rw-rw-rw-   0        0        0     6802 2023-05-16 05:47:20.000000 alphamed-federated-0.4.9/src/alphafed/examples/hetero_nn/hetero_fed_irm/collaborator_scheduler.py
+-rw-rw-rw-   0        0        0      524 2023-05-16 05:47:20.000000 alphamed-federated-0.4.9/src/alphafed/examples/hetero_nn/hetero_fed_irm/data_checker.py
+-rw-rw-rw-   0        0        0    11907 2023-05-16 05:47:20.000000 alphamed-federated-0.4.9/src/alphafed/examples/hetero_nn/hetero_fed_irm/host_scheduler.py
+-rw-rw-rw-   0        0        0    12331 2023-05-16 05:47:20.000000 alphamed-federated-0.4.9/src/alphafed/examples/hetero_nn/hetero_fed_irm/res_net.py
+drwxrwxrwx   0        0        0        0 2023-05-24 11:11:02.418414 alphamed-federated-0.4.9/src/alphafed/examples/hetero_nn/psi/
+-rw-rw-rw-   0        0        0      592 2023-03-29 15:03:36.000000 alphamed-federated-0.4.9/src/alphafed/examples/hetero_nn/psi/demos.py
+-rw-rw-rw-   0        0        0      819 2023-03-29 15:03:36.000000 alphamed-federated-0.4.9/src/alphafed/examples/hetero_nn/psi/run_collaborator_2.py
+-rw-rw-rw-   0        0        0      819 2023-03-29 15:03:36.000000 alphamed-federated-0.4.9/src/alphafed/examples/hetero_nn/psi/run_collaborator_3.py
+-rw-rw-rw-   0        0        0      819 2023-03-29 15:03:36.000000 alphamed-federated-0.4.9/src/alphafed/examples/hetero_nn/psi/run_collaborator_4.py
+-rw-rw-rw-   0        0        0      819 2023-03-29 15:03:36.000000 alphamed-federated-0.4.9/src/alphafed/examples/hetero_nn/psi/run_collaborator_5.py
+-rw-rw-rw-   0        0        0     1046 2023-03-29 15:03:36.000000 alphamed-federated-0.4.9/src/alphafed/examples/hetero_nn/psi/run_initiator.py
+-rw-rw-rw-   0        0        0     1218 2023-03-29 15:03:36.000000 alphamed-federated-0.4.9/src/alphafed/examples/hetero_nn/run_collaborater.py
+-rw-rw-rw-   0        0        0     1117 2023-03-29 15:03:36.000000 alphamed-federated-0.4.9/src/alphafed/examples/hetero_nn/run_host.py
+drwxrwxrwx   0        0        0        0 2023-05-24 11:11:02.434080 alphamed-federated-0.4.9/src/alphafed/fed_avg/
+-rw-rw-rw-   0        0        0      103 2023-03-29 15:03:36.000000 alphamed-federated-0.4.9/src/alphafed/fed_avg/__init__.py
+-rw-rw-rw-   0        0        0     9619 2023-03-29 15:03:36.000000 alphamed-federated-0.4.9/src/alphafed/fed_avg/contractor.py
+-rw-rw-rw-   0        0        0     2026 2023-03-29 15:03:36.000000 alphamed-federated-0.4.9/src/alphafed/fed_avg/dp_contractor.py
+-rw-rw-rw-   0        0        0     8964 2023-03-29 15:03:36.000000 alphamed-federated-0.4.9/src/alphafed/fed_avg/dp_fed_avg.py
+-rw-rw-rw-   0        0        0    33808 2023-05-16 05:47:20.000000 alphamed-federated-0.4.9/src/alphafed/fed_avg/fed_avg.py
+-rw-rw-rw-   0        0        0    10441 2023-03-29 15:03:36.000000 alphamed-federated-0.4.9/src/alphafed/fed_avg/secure_contractor.py
+-rw-rw-rw-   0        0        0    34059 2023-03-29 15:03:36.000000 alphamed-federated-0.4.9/src/alphafed/fed_avg/secure_fed_avg.py
+drwxrwxrwx   0        0        0        0 2023-05-24 11:11:02.438330 alphamed-federated-0.4.9/src/alphafed/fed_prox/
+-rw-rw-rw-   0        0        0       34 2023-05-24 08:43:39.000000 alphamed-federated-0.4.9/src/alphafed/fed_prox/__init__.py
+-rw-rw-rw-   0        0        0     2521 2023-05-19 11:16:56.000000 alphamed-federated-0.4.9/src/alphafed/fed_prox/scheduler.py
+-rw-rw-rw-   0        0        0     1827 2023-03-29 15:01:28.000000 alphamed-federated-0.4.9/src/alphafed/fs.py
+drwxrwxrwx   0        0        0        0 2023-05-24 11:11:02.449645 alphamed-federated-0.4.9/src/alphafed/hetero_nn/
+-rw-rw-rw-   0        0        0      116 2023-03-29 15:03:36.000000 alphamed-federated-0.4.9/src/alphafed/hetero_nn/__init__.py
+-rw-rw-rw-   0        0        0    12136 2023-03-29 15:03:36.000000 alphamed-federated-0.4.9/src/alphafed/hetero_nn/contractor.py
+-rw-rw-rw-   0        0        0    51191 2023-05-16 05:47:20.000000 alphamed-federated-0.4.9/src/alphafed/hetero_nn/hetero_nn.py
+drwxrwxrwx   0        0        0        0 2023-05-24 11:11:02.458228 alphamed-federated-0.4.9/src/alphafed/hetero_nn/psi/
+-rw-rw-rw-   0        0        0      105 2023-03-29 15:03:36.000000 alphamed-federated-0.4.9/src/alphafed/hetero_nn/psi/__init__.py
+-rw-rw-rw-   0        0        0     3489 2023-03-29 15:03:36.000000 alphamed-federated-0.4.9/src/alphafed/hetero_nn/psi/psi.py
+-rw-rw-rw-   0        0        0    14497 2023-03-29 15:03:36.000000 alphamed-federated-0.4.9/src/alphafed/hetero_nn/psi/rsa_intersecter.py
+-rw-rw-rw-   0        0        0     3753 2023-03-29 15:03:36.000000 alphamed-federated-0.4.9/src/alphafed/hetero_nn/psi/rsa_psi_contractor.py
+-rw-rw-rw-   0        0        0    14008 2023-03-29 15:03:36.000000 alphamed-federated-0.4.9/src/alphafed/hetero_nn/secure_contractor.py
+-rw-rw-rw-   0        0        0    76079 2023-05-16 05:47:20.000000 alphamed-federated-0.4.9/src/alphafed/hetero_nn/secure_hetero_nn.py
+-rw-rw-rw-   0        0        0      764 2023-05-16 05:47:20.000000 alphamed-federated-0.4.9/src/alphafed/loggers.py
+-rw-rw-rw-   0        0        0     6755 2023-05-16 05:47:21.000000 alphamed-federated-0.4.9/src/alphafed/mock.py
+-rw-rw-rw-   0        0        0     5037 2023-03-29 15:01:28.000000 alphamed-federated-0.4.9/src/alphafed/perf_bench.py
+-rw-rw-rw-   0        0        0     6607 2023-05-16 06:00:34.000000 alphamed-federated-0.4.9/src/alphafed/scheduler.py
+drwxrwxrwx   0        0        0        0 2023-05-24 11:11:02.469345 alphamed-federated-0.4.9/src/alphafed/secure/
+-rw-rw-rw-   0        0        0       59 2023-03-29 15:03:36.000000 alphamed-federated-0.4.9/src/alphafed/secure/__init__.py
+-rw-rw-rw-   0        0        0      685 2023-03-29 15:03:36.000000 alphamed-federated-0.4.9/src/alphafed/secure/aes.py
+-rw-rw-rw-   0        0        0     1242 2023-03-29 15:03:36.000000 alphamed-federated-0.4.9/src/alphafed/secure/ecdhe.py
+-rw-rw-rw-   0        0        0     2602 2023-03-29 15:03:36.000000 alphamed-federated-0.4.9/src/alphafed/secure/shamir.py
+-rw-rw-rw-   0        0        0      621 2023-03-29 15:03:36.000000 alphamed-federated-0.4.9/src/alphafed/secure/tools.py
+-rw-rw-rw-   0        0        0     1864 2023-03-29 15:01:28.000000 alphamed-federated-0.4.9/src/alphafed/utils.py
+drwxrwxrwx   0        0        0        0 2023-05-24 11:11:02.510442 alphamed-federated-0.4.9/src/alphamed_federated.egg-info/
+-rw-rw-rw-   0        0        0    17211 2023-05-24 11:11:01.000000 alphamed-federated-0.4.9/src/alphamed_federated.egg-info/PKG-INFO
+-rw-rw-rw-   0        0        0     9117 2023-05-24 11:11:01.000000 alphamed-federated-0.4.9/src/alphamed_federated.egg-info/SOURCES.txt
+-rw-rw-rw-   0        0        0        1 2023-05-24 11:11:01.000000 alphamed-federated-0.4.9/src/alphamed_federated.egg-info/dependency_links.txt
+-rw-rw-rw-   0        0        0      207 2023-05-24 11:11:01.000000 alphamed-federated-0.4.9/src/alphamed_federated.egg-info/requires.txt
+-rw-rw-rw-   0        0        0       15 2023-05-24 11:11:01.000000 alphamed-federated-0.4.9/src/alphamed_federated.egg-info/top_level.txt
+-rw-rw-rw-   0        0        0      448 2023-05-16 06:47:04.000000 alphamed-federated-0.4.9/src/fcntl.py
```

### Comparing `alphamed-federated-0.4.7/LICENSE` & `alphamed-federated-0.4.9/LICENSE`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/PKG-INFO` & `alphamed-federated-0.4.9/PKG-INFO`

 * *Files 0% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: alphamed-federated
-Version: 0.4.7
+Version: 0.4.9
 Summary: AlphaMed Federated Learning Module
 Author-email: Huang Yi Chun <huangyichun@jinghang.ai>
 License:                                  Apache License
                                    Version 2.0, January 2004
                                 http://www.apache.org/licenses/
         
            TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
```

### Comparing `alphamed-federated-0.4.7/README.md` & `alphamed-federated-0.4.9/README.md`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/auto_ml/auto_model.py` & `alphamed-federated-0.4.9/src/alphafed/auto_ml/auto_model.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/auto_ml/cvat/annotation.py` & `alphamed-federated-0.4.9/src/alphafed/auto_ml/cvat/annotation.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/auto_ml/pretrained.py` & `alphamed-federated-0.4.9/src/alphafed/auto_ml/pretrained.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/contractor/common.py` & `alphamed-federated-0.4.9/src/alphafed/contractor/common.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/contractor/task_contractor.py` & `alphamed-federated-0.4.9/src/alphafed/contractor/task_contractor.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/contractor/task_message_contractor.py` & `alphamed-federated-0.4.9/src/alphafed/contractor/task_message_contractor.py`

 * *Ordering differences only*

 * *Files 18% similar despite different names*

```diff
@@ -1,614 +1,614 @@
-"""公共合约."""
-
-import base64
-import json
-import os
-import secrets
-import time
-from abc import ABCMeta
-from dataclasses import dataclass
-from datetime import datetime
-from io import IOBase
-from typing import Dict, List, Optional, Union, overload
-
-import requests
-from requests import Response
-
-from .. import is_mock_mode, logger, mock_node_id, mock_nodes
-from ..mock import _get_mock_contract, _put_mock_contract
-from ..utils import retry
-from .common import (ContractEvent, ContractEventFactory, ContractException,
-                     Contractor)
-from .task_contractor import AutoTaskContractor, TaskContractor
-
-__all__ = [
-    'ApplySendingDataEvent',
-    'ApplyGRPCSendingDataEvent',
-    'ApplySharedFileSendingDataEvent',
-    'DenySendingDataEvent',
-    'AcceptSendingDataEvent',
-    'AcceptGRPCSendingDataEvent',
-    'AcceptSharedFileSendingDataEvent',
-    'TaskMessageEventFactory',
-    'TaskMessageContractor',
-    'AutoTaskMessageContractor'
-]
-
-
-@dataclass
-class ApplySendingDataEvent(ContractEvent, metaclass=ABCMeta):
-    """An event of requesting sending data."""
-
-    session_id: str
-    source: str
-    target: Union[str, List[str]]
-
-
-@dataclass
-class ApplyGRPCSendingDataEvent(ApplySendingDataEvent):
-    """An event of requesting sending data by GRPC."""
-
-    TYPE = 'apply_grpc_sending_data'
-
-    public_key: bytes
-
-    @classmethod
-    def contract_to_event(cls, contract: dict) -> 'ApplyGRPCSendingDataEvent':
-        event_type = contract.get('type')
-        session_id = contract.get('session_id')
-        source = contract.get('source')
-        target = contract.get('target')
-        base64_key = contract.get('public_key')
-        assert event_type == cls.TYPE, f'合约类型错误: {event_type}'
-        assert session_id and isinstance(session_id, str), f'invalid session_id: {session_id}'
-        assert source and isinstance(source, str), f'invalid source: {source}'
-        assert target and isinstance(session_id, str), f'invalid target: {target}'
-        assert base64_key and isinstance(base64_key, str), f'invalid public_key: {base64_key}'
-        public_key = base64.b64decode(base64_key.encode())
-        return ApplyGRPCSendingDataEvent(session_id=session_id,
-                                         source=source,
-                                         target=target,
-                                         public_key=public_key)
-
-
-@dataclass
-class ApplySharedFileSendingDataEvent(ApplySendingDataEvent):
-    """An event of requesting sending data by shared file."""
-
-    TYPE = 'apply_sf_sending_data'
-
-    file_url: str
-
-    @classmethod
-    def contract_to_event(cls, contract: dict) -> 'ApplySharedFileSendingDataEvent':
-        event_type = contract.get('type')
-        session_id = contract.get('session_id')
-        source = contract.get('source')
-        target = contract.get('target')
-        file_url = contract.get('file_url')
-        assert event_type == cls.TYPE, f'合约类型错误: {event_type}'
-        assert session_id and isinstance(session_id, str), f'invalid session_id: {session_id}'
-        assert source and isinstance(source, str), f'invalid source: {source}'
-        assert (
-            target and isinstance(target, list) and all(isinstance(_id, str) for _id in target)
-        ), f'invalid target: {target}'
-        assert file_url and isinstance(file_url, str), f'invalid public_key: {file_url}'
-        return ApplySharedFileSendingDataEvent(session_id=session_id,
-                                               source=source,
-                                               target=target,
-                                               file_url=file_url)
-
-
-@dataclass
-class DenySendingDataEvent(ContractEvent):
-    """An event of denying sending data."""
-
-    TYPE = 'deny_sending_data'
-
-    session_id: str
-    rejecter: str
-    cause: str = None
-
-    @classmethod
-    def contract_to_event(cls, contract: dict) -> 'DenySendingDataEvent':
-        event_type = contract.get('type')
-        session_id = contract.get('session_id')
-        rejecter = contract.get('rejecter')
-        cause = contract.get('cause')
-        assert event_type == cls.TYPE, f'合约类型错误: {event_type}'
-        assert session_id and isinstance(session_id, str), f'invalid session_id: {session_id}'
-        assert rejecter and isinstance(rejecter, str), f'invalid rejecter: {rejecter}'
-        assert not cause or isinstance(cause, str), f'invalid cause: {cause}'
-        return DenySendingDataEvent(session_id=session_id, rejecter=rejecter, cause=cause)
-
-
-@dataclass
-class AcceptSendingDataEvent(ContractEvent, metaclass=ABCMeta):
-    """A event of accepting receiving data."""
-
-    session_id: str
-
-
-@dataclass
-class AcceptGRPCSendingDataEvent(AcceptSendingDataEvent):
-    """A event of accepting receiving data by GRPC."""
-
-    TYPE = 'accept_grpc_sending_data'
-
-    public_key: bytes
-    port: bytes
-
-    @classmethod
-    def contract_to_event(cls, contract: dict) -> 'AcceptGRPCSendingDataEvent':
-        event_type = contract.get('type')
-        session_id = contract.get('session_id')
-        base64_key = contract.get('public_key')
-        base64_port = contract.get('port')
-        assert event_type == cls.TYPE, f'合约类型错误: {event_type}'
-        assert session_id and isinstance(session_id, str), f'invalid session_id: {session_id}'
-        assert base64_key and isinstance(base64_key, str), f'invalid public_key: {base64_key}'
-        assert base64_port and isinstance(base64_port, str), f'invalid port: {base64_port}'
-        public_key = base64.b64decode(base64_key.encode())
-        port = base64.b64decode(base64_port.encode())
-        return AcceptGRPCSendingDataEvent(session_id=session_id,
-                                          public_key=public_key,
-                                          port=port)
-
-
-@dataclass
-class AcceptSharedFileSendingDataEvent(AcceptSendingDataEvent):
-    """A event of accepting receiving data by shared file."""
-
-    TYPE = 'accept_sf_sending_data'
-
-    receiver: str
-
-    @classmethod
-    def contract_to_event(cls, contract: dict) -> 'AcceptSharedFileSendingDataEvent':
-        event_type = contract.get('type')
-        session_id = contract.get('session_id')
-        receiver = contract.get('receiver')
-        assert event_type == cls.TYPE, f'合约类型错误: {event_type}'
-        assert session_id and isinstance(session_id, str), f'invalid session_id: {session_id}'
-        assert receiver and isinstance(receiver, str), f'invalid receiver: {receiver}'
-        return AcceptSharedFileSendingDataEvent(session_id=session_id, receiver=receiver)
-
-
-@dataclass
-class UploadTaskAchievementEvent(ContractEvent):
-    """A event of uploading task achievement materials."""
-
-    TYPE = 'task_file_upload'
-
-    FILE_TYPE_REPORT = 'report'
-    FILE_TYPE_MODEL = 'model'
-
-    file_type: str
-    file_url: str
-
-    @classmethod
-    def contract_to_event(cls, contract: dict) -> 'UploadTaskAchievementEvent':
-        event_type = contract.get('type')
-        file_type = contract.get('file_type')
-        file_url = contract.get('file_url')
-        assert event_type == cls.TYPE, f'合约类型错误: {event_type}'
-        assert file_type in (cls.FILE_TYPE_REPORT, cls.FILE_TYPE_MODEL), f'invalid file_type: {file_type}'
-        assert file_url and isinstance(file_url, str), f'invalid file_url: {file_url}'
-        return UploadTaskAchievementEvent(file_type=file_type, file_url=file_url)
-
-
-@dataclass
-class NoticeTaskCompletionEvent(ContractEvent):
-    """A event of noticing task manager that current task is complete."""
-
-    TYPE = 'notice_task_completion'
-
-    result: bool
-
-    @classmethod
-    def contract_to_event(cls, contract: dict) -> 'NoticeTaskCompletionEvent':
-        event_type = contract.get('type')
-        result = contract.get('result')
-        assert event_type == cls.TYPE, f'合约类型错误: {event_type}'
-        assert isinstance(result, bool), f'invalid result: {result}'
-        return NoticeTaskCompletionEvent(result=result)
-
-
-class TaskMessageEventFactory(ContractEventFactory):
-
-    _CLASS_MAP: Dict[str, ContractEvent] = {
-        ApplyGRPCSendingDataEvent.TYPE: ApplyGRPCSendingDataEvent,
-        ApplySharedFileSendingDataEvent.TYPE: ApplySharedFileSendingDataEvent,
-        DenySendingDataEvent.TYPE: DenySendingDataEvent,
-        AcceptGRPCSendingDataEvent.TYPE: AcceptGRPCSendingDataEvent,
-        AcceptSharedFileSendingDataEvent.TYPE: AcceptSharedFileSendingDataEvent,
-        UploadTaskAchievementEvent.TYPE: UploadTaskAchievementEvent,
-        NoticeTaskCompletionEvent.TYPE: NoticeTaskCompletionEvent
-    }
-
-    @classmethod
-    def contract_to_event(cls, contract: dict) -> Optional[ContractEvent]:
-        try:
-            assert contract and isinstance(contract, dict)
-            event_type = contract.get('type')
-            assert event_type in cls._CLASS_MAP.keys()
-            event = cls._CLASS_MAP[event_type].contract_to_event(contract)
-            return event
-        except AssertionError:
-            logger.exception(f'invalid contract data: {contract}')
-            return None
-
-
-class TaskMessageContractor(Contractor):
-    """公共合约."""
-
-    _URL = 'http://federated-service:9080/fed-service/api/v2/message'
-
-    _TASK_INSIDE = 'task_inside'
-    _UPLOAD_TASK_ACHIEVE = 'task_file_upload'
-    _TASK_FINISH = 'task_finish'
-
-    _TITLE_ALL = (_TASK_INSIDE, _UPLOAD_TASK_ACHIEVE, _TASK_FINISH)
-
-    _CHANNEL = 'federated'
-
-    EMPTY_ACHIVEMENT = 'https://minio.ssplabs.com/playground-saas/tmp.zip'
-
-    def __init__(self, task_id: str) -> None:
-        super().__init__()
-        self.task_id = task_id
-        self._event_factory = TaskMessageEventFactory
-        self._task_contractor = TaskContractor(task_id=task_id)
-
-    def _validate_response(self, resp: Response) -> dict:
-        if resp.status_code < 200 or resp.status_code >= 300:
-            raise ContractException(f'failed to submit a contract: {resp}')
-        resp_json: dict = resp.json()
-        if not resp_json or not isinstance(resp_json, dict):
-            raise ContractException(f'invalid response:\nresp: {resp}\njson: {resp_json}')
-        if resp_json.get('code') != 0:
-            raise ContractException(f'failed to handle a contract: {resp_json}')
-        data = resp_json.get('data')
-        if data is None or not isinstance(data, dict):
-            raise ContractException(f'contract data error: {resp_json}')
-        task_id = data.get('task_id')
-        assert task_id is None or task_id == self.task_id, f'task_id dismatch: {task_id}'
-        return data
-
-    @retry(exceptions=ContractException)
-    def _new_contract(self,
-                      targets: List[str],
-                      event: ContractEvent,
-                      message_title: str = _TASK_INSIDE) -> str:
-        assert targets, 'must specify the target consumers of the contract'
-        assert (
-            isinstance(targets, list)
-            and all(_target and isinstance(_target, str) for _target in targets)
-        ), f'the target consumers must be an ID list: {targets}'
-        assert event, 'cannot send empty contract'
-        assert (
-            isinstance(event, ContractEvent)
-        ), f'"event" should be a contract event object: {event}'
-        assert (
-            message_title and message_title in self._TITLE_ALL
-        ), f'invalid message_title: {message_title}'
-
-        event.validate()
-
-        if is_mock_mode():
-            return self._new_contract_mock(targets=targets,
-                                           event=event,
-                                           message_title=message_title)
-        else:
-            return self._new_contract_normal(targets=targets,
-                                             event=event,
-                                             message_title=message_title)
-
-    def _new_contract_mock(self,
-                           targets: List[str],
-                           event: ContractEvent,
-                           message_title: str = _TASK_INSIDE) -> str:
-        content = json.dumps(event.event_to_contract(), ensure_ascii=False)
-        if targets == self.EVERYONE:
-            targets = mock_nodes()
-            if not targets:
-                raise ContractException('Can not obtain Node ID list of current task.')
-        contract_content = {
-            "targets": targets,
-            "message_title": message_title,
-            "content": content,
-            "channel": self._CHANNEL,
-            "task_id": self.task_id
-        }
-        logger.debug(f'try to push a contract in mock context: {contract_content}')
-        return _put_mock_contract(targets=targets,
-                                  message_title=message_title,
-                                  content=content,
-                                  message_time=int(datetime.now().timestamp()),
-                                  channel=self._CHANNEL,
-                                  task_id=self.task_id)
-
-    def _new_contract_normal(self,
-                             targets: List[str],
-                             event: ContractEvent,
-                             message_title: str = _TASK_INSIDE) -> str:
-        url = f'{self._URL}/push'
-        post_data = {
-            'task_id': self.task_id,
-            'node_id_list': targets,
-            'message_title': message_title,
-            'message_content': event.event_to_contract(),
-            'message_time': int(datetime.now().timestamp()),
-            'channel': self._CHANNEL
-        }
-        logger.debug(f'contract content: {post_data}')
-        resp = requests.post(url=url, json=post_data, headers=self._HEADERS)
-        resp_data = self._validate_response(resp=resp)
-        message_uuid: str = resp_data.get('message_uuid')
-        assert message_uuid and isinstance(message_uuid, str), f'invalid TxId: {message_uuid}'
-        logger.info(f'successfully pushed a new contract: {message_uuid=}')
-        # The contract framework doesn't promise the sequence of contractors when
-        # they are pushed almost at the same time, so we have to apart them a little.
-        # TODO remove me when it changes.
-        time.sleep(0.2)
-        return message_uuid
-
-    def _pop_contract(self) -> Optional[dict]:
-        """Popup a contract for consuming if exists."""
-        if is_mock_mode():
-            return self._pop_contract_mock()
-        else:
-            return self._pop_contract_normal()
-
-    def _pop_contract_mock(self) -> Optional[dict]:
-        content = _get_mock_contract(node_id=mock_node_id(),
-                                     channel=self._CHANNEL,
-                                     task_id=self.task_id)
-        if content is None:
-            return None
-        logger.debug(f'popped up a contract in mock context: {content}')
-        return json.loads(content)
-
-    def _pop_contract_normal(self) -> Optional[dict]:
-        post_data = {
-            'task_id': self.task_id,
-            'channel': self._CHANNEL
-        }
-        post_url = f'{self._URL}/pop'
-        resp = requests.post(url=post_url, json=post_data, headers=self._HEADERS)
-        resp_data = self._validate_response(resp=resp)
-        if not resp_data:
-            return None
-        logger.debug(f'popped up a contract: {resp_data}')
-        _content = resp_data.get('message_content')
-        assert _content and isinstance(_content, dict), f'invalid contract content: {_content}'
-        return _content
-
-    @overload
-    def apply_sending_data(self, source: str, target: str, public_key: bytes) -> str:
-        ...
-
-    @overload
-    def apply_sending_data(self, source: str, target: List[str], file_url: str) -> str:
-        ...
-
-    def apply_sending_data(self, source: str, target: Union[str, List[str]], **kwargs) -> str:
-        """发送数据传输请求合约."""
-        session_id = secrets.token_hex(16)
-        file_url = kwargs.get('file_url')
-        public_key = kwargs.get('public_key')
-        if file_url:
-            event = ApplySharedFileSendingDataEvent(session_id=session_id,
-                                                    source=source,
-                                                    target=target,
-                                                    file_url=file_url)
-            self._new_contract(targets=target, event=event)
-        else:
-            event = ApplyGRPCSendingDataEvent(session_id=session_id,
-                                              source=source,
-                                              target=target,
-                                              public_key=public_key)
-            self._new_contract(targets=[target], event=event)
-        return session_id
-
-    def deny_sending_data(self,
-                          target: str,
-                          session_id: str,
-                          rejecter: str,
-                          cause: str = None) -> None:
-        """拒绝数据传输请求合约."""
-        event = DenySendingDataEvent(session_id=session_id, rejecter=rejecter, cause=cause)
-        self._new_contract(targets=[target], event=event)
-
-    @overload
-    def accept_sending_data(self,
-                            target: str,
-                            session_id: str,
-                            public_key: bytes,
-                            cipher_port: bytes) -> None:
-        """接受数据传输请求合约.
-
-        通过 GRPC 数据通道。
-
-        Args:
-            session_id:
-                the session id of this data sending
-            public_key:
-                the public key of the data receiver
-            cipher_port:
-                the port number used for connecting, encrypted by the sender's public key
-        """
-
-    @overload
-    def accept_sending_data(self, target: str, session_id: str, receiver: str) -> None:
-        """接受数据传输请求合约.
-
-        通过共享文件数据通道。
-
-        :args
-            :session_id
-                the session id of this data sending
-            :public_key
-                the public key of the data receiver
-            :cipher_port
-                the port number used for connecting, encrypted by the sender's public key
-        """
-
-    def accept_sending_data(self, target: str, session_id: str, **kwargs) -> None:
-        public_key = kwargs.get('public_key')
-        if public_key:
-            public_key = kwargs.get('public_key')
-            cipher_port = kwargs.get('cipher_port')
-            assert (
-                public_key and isinstance(public_key, bytes)
-            ), f'Invalid public key: {public_key} .'
-            assert (
-                cipher_port and isinstance(cipher_port, bytes)
-            ), f'Invalid cipher port: {cipher_port} .'
-            event = AcceptGRPCSendingDataEvent(session_id=session_id,
-                                               public_key=public_key,
-                                               port=cipher_port)
-        else:
-            receiver = kwargs.get('receiver')
-            assert receiver and isinstance(receiver, str), f'Invalid receiver: {receiver} .'
-            event = AcceptSharedFileSendingDataEvent(session_id=session_id, receiver=receiver)
-        self._new_contract(targets=[target], event=event)
-
-    def contract_events(self, timeout: int = 0) -> ContractEvent:
-        """Return contract events iteratively.
-
-        :args
-            :timeout
-                The seconds to timeout. Will never timeout if is set less or equal to 0.
-        """
-        if not isinstance(timeout, int) or timeout < 0:
-            timeout = 0  # disable timeout
-        if timeout > 0:
-            start = datetime.utcnow().timestamp()
-        while timeout <= 0 or datetime.utcnow().timestamp() - start < timeout:
-            _contract = self._pop_contract()
-            if _contract:
-                event = self._event_factory.contract_to_event(contract=_contract)
-                if event:
-                    yield event
-                else:
-                    logger.warn(f'failed to parse a contract to an event: {_contract}')
-            else:
-                time.sleep(1)
-
-    @retry()
-    def query_address(self, target: str) -> Optional[str]:
-        """Query address of the target."""
-        return self._task_contractor.query_address(target=target)
-    
-    def upload_metric_report(self, receivers: List[str], report_file: str = None):
-        """Upload metrics report materials after a task is complete.
-
-        Args:
-            receivers:
-                Specify who can receive and download this report.
-            report_file:
-                Local path of the report file.
-
-        If nothing need be uploaded, specify report_file to None or an empty value.
-        """
-        if not receivers or not report_file:
-            report_file_url = self.EMPTY_ACHIVEMENT
-        else:
-            assert (
-                isinstance(receivers, list) and all(isinstance(_receiver, str) for _receiver in receivers)
-            ), f'invalid receivers: {receivers}'
-            assert (
-                isinstance(report_file, str) and os.path.isfile(report_file)
-            ), f'the report_file does not exist or can not be accessed: {report_file}'
-
-            with open(report_file, 'rb') as report_fp:
-                report_file_url = self.upload_file(fp=report_fp,
-                                                   persistent=True,
-                                                   upload_name=os.path.basename(report_file))
-
-        event = UploadTaskAchievementEvent(file_type=UploadTaskAchievementEvent.FILE_TYPE_REPORT,
-                                           file_url=report_file_url)
-        TxId = self._new_contract(targets=receivers,
-                                  event=event,
-                                  message_title=self._UPLOAD_TASK_ACHIEVE)
-        if not TxId:
-            raise ContractException('failed to notify task completion')
-    
-    def upload_model(self, receivers: List[str], model_file: str = None):
-        """Upload final model after a task is complete.
-
-        Args:
-            receivers:
-                Specify who can receive and download this report.
-            model_file:
-                Local path of the model file.
-
-        If nothing need be uploaded, specify model_file to None or an empty value.
-        """
-        if not receivers or not model_file:
-            model_file_url = self.EMPTY_ACHIVEMENT
-        else:
-            assert (
-                isinstance(receivers, list) and all(isinstance(_receiver, str) for _receiver in receivers)
-            ), f'invalid receivers: {receivers}'
-            assert (
-                isinstance(model_file, str) and os.path.isfile(model_file)
-            ), f'the model_file does not exist or can not be accessed: {model_file}'
-
-            with open(model_file, 'rb') as model_fp:
-                model_file_url = self.upload_file(fp=model_fp,
-                                                  persistent=True,
-                                                  upload_name=os.path.basename(model_file))
-
-        event = UploadTaskAchievementEvent(file_type=UploadTaskAchievementEvent.FILE_TYPE_MODEL,
-                                           file_url=model_file_url)
-        TxId = self._new_contract(targets=receivers,
-                                  event=event,
-                                  message_title=self._UPLOAD_TASK_ACHIEVE)
-        if not TxId:
-            raise ContractException('failed to notify task completion')
-
-    def notify_task_completion(self, result: bool):
-        """Notify task manager a task is complete.
-
-        :args
-            :result
-                True if successful otherwize False.
-        """
-        event = NoticeTaskCompletionEvent(result=result)
-        TxId = self._new_contract(targets=self.EVERYONE,
-                                  event=event,
-                                  message_title=self._TASK_FINISH)
-        if not TxId:
-            raise ContractException('failed to notify task completion')
-
-    def report_progress(self, percent: int):
-        """Report training progress (percent integer value)."""
-        self._task_contractor.report_progress(percent=percent)
-
-    def query_nodes(self) -> List[str]:
-        """Query all nodes in this task."""
-        return self._task_contractor.query_nodes()
-
-    @overload
-    def upload_file(self, fp: str, persistent: bool = False, upload_name: str = None) -> str: ...
-
-    @overload
-    def upload_file(self, fp: IOBase, persistent: bool = False, upload_name: str = None) -> str: ...
-
-    def upload_file(self, fp, persistent: bool = False, upload_name: str = None) -> str:
-        """Upload a file to file system."""
-        return self._task_contractor.upload_file(fp=fp,
-                                                 upload_name=upload_name,
-                                                 persistent=persistent)
-
-
-class AutoTaskMessageContractor(TaskMessageContractor):
-    """AutoML version of TaskMessageContractor."""
-
-    _CHANNEL = 'automl'
-
-    def __init__(self, task_id: str) -> None:
-        super().__init__(task_id)
-        self._task_contractor = AutoTaskContractor(task_id=task_id)
+"""公共合约."""
+
+import base64
+import json
+import os
+import secrets
+import time
+from abc import ABCMeta
+from dataclasses import dataclass
+from datetime import datetime
+from io import IOBase
+from typing import Dict, List, Optional, Union, overload
+
+import requests
+from requests import Response
+
+from .. import is_mock_mode, logger, mock_node_id, mock_nodes
+from ..mock import _get_mock_contract, _put_mock_contract
+from ..utils import retry
+from .common import (ContractEvent, ContractEventFactory, ContractException,
+                     Contractor)
+from .task_contractor import AutoTaskContractor, TaskContractor
+
+__all__ = [
+    'ApplySendingDataEvent',
+    'ApplyGRPCSendingDataEvent',
+    'ApplySharedFileSendingDataEvent',
+    'DenySendingDataEvent',
+    'AcceptSendingDataEvent',
+    'AcceptGRPCSendingDataEvent',
+    'AcceptSharedFileSendingDataEvent',
+    'TaskMessageEventFactory',
+    'TaskMessageContractor',
+    'AutoTaskMessageContractor'
+]
+
+
+@dataclass
+class ApplySendingDataEvent(ContractEvent, metaclass=ABCMeta):
+    """An event of requesting sending data."""
+
+    session_id: str
+    source: str
+    target: Union[str, List[str]]
+
+
+@dataclass
+class ApplyGRPCSendingDataEvent(ApplySendingDataEvent):
+    """An event of requesting sending data by GRPC."""
+
+    TYPE = 'apply_grpc_sending_data'
+
+    public_key: bytes
+
+    @classmethod
+    def contract_to_event(cls, contract: dict) -> 'ApplyGRPCSendingDataEvent':
+        event_type = contract.get('type')
+        session_id = contract.get('session_id')
+        source = contract.get('source')
+        target = contract.get('target')
+        base64_key = contract.get('public_key')
+        assert event_type == cls.TYPE, f'合约类型错误: {event_type}'
+        assert session_id and isinstance(session_id, str), f'invalid session_id: {session_id}'
+        assert source and isinstance(source, str), f'invalid source: {source}'
+        assert target and isinstance(session_id, str), f'invalid target: {target}'
+        assert base64_key and isinstance(base64_key, str), f'invalid public_key: {base64_key}'
+        public_key = base64.b64decode(base64_key.encode())
+        return ApplyGRPCSendingDataEvent(session_id=session_id,
+                                         source=source,
+                                         target=target,
+                                         public_key=public_key)
+
+
+@dataclass
+class ApplySharedFileSendingDataEvent(ApplySendingDataEvent):
+    """An event of requesting sending data by shared file."""
+
+    TYPE = 'apply_sf_sending_data'
+
+    file_url: str
+
+    @classmethod
+    def contract_to_event(cls, contract: dict) -> 'ApplySharedFileSendingDataEvent':
+        event_type = contract.get('type')
+        session_id = contract.get('session_id')
+        source = contract.get('source')
+        target = contract.get('target')
+        file_url = contract.get('file_url')
+        assert event_type == cls.TYPE, f'合约类型错误: {event_type}'
+        assert session_id and isinstance(session_id, str), f'invalid session_id: {session_id}'
+        assert source and isinstance(source, str), f'invalid source: {source}'
+        assert (
+            target and isinstance(target, list) and all(isinstance(_id, str) for _id in target)
+        ), f'invalid target: {target}'
+        assert file_url and isinstance(file_url, str), f'invalid public_key: {file_url}'
+        return ApplySharedFileSendingDataEvent(session_id=session_id,
+                                               source=source,
+                                               target=target,
+                                               file_url=file_url)
+
+
+@dataclass
+class DenySendingDataEvent(ContractEvent):
+    """An event of denying sending data."""
+
+    TYPE = 'deny_sending_data'
+
+    session_id: str
+    rejecter: str
+    cause: str = None
+
+    @classmethod
+    def contract_to_event(cls, contract: dict) -> 'DenySendingDataEvent':
+        event_type = contract.get('type')
+        session_id = contract.get('session_id')
+        rejecter = contract.get('rejecter')
+        cause = contract.get('cause')
+        assert event_type == cls.TYPE, f'合约类型错误: {event_type}'
+        assert session_id and isinstance(session_id, str), f'invalid session_id: {session_id}'
+        assert rejecter and isinstance(rejecter, str), f'invalid rejecter: {rejecter}'
+        assert not cause or isinstance(cause, str), f'invalid cause: {cause}'
+        return DenySendingDataEvent(session_id=session_id, rejecter=rejecter, cause=cause)
+
+
+@dataclass
+class AcceptSendingDataEvent(ContractEvent, metaclass=ABCMeta):
+    """A event of accepting receiving data."""
+
+    session_id: str
+
+
+@dataclass
+class AcceptGRPCSendingDataEvent(AcceptSendingDataEvent):
+    """A event of accepting receiving data by GRPC."""
+
+    TYPE = 'accept_grpc_sending_data'
+
+    public_key: bytes
+    port: bytes
+
+    @classmethod
+    def contract_to_event(cls, contract: dict) -> 'AcceptGRPCSendingDataEvent':
+        event_type = contract.get('type')
+        session_id = contract.get('session_id')
+        base64_key = contract.get('public_key')
+        base64_port = contract.get('port')
+        assert event_type == cls.TYPE, f'合约类型错误: {event_type}'
+        assert session_id and isinstance(session_id, str), f'invalid session_id: {session_id}'
+        assert base64_key and isinstance(base64_key, str), f'invalid public_key: {base64_key}'
+        assert base64_port and isinstance(base64_port, str), f'invalid port: {base64_port}'
+        public_key = base64.b64decode(base64_key.encode())
+        port = base64.b64decode(base64_port.encode())
+        return AcceptGRPCSendingDataEvent(session_id=session_id,
+                                          public_key=public_key,
+                                          port=port)
+
+
+@dataclass
+class AcceptSharedFileSendingDataEvent(AcceptSendingDataEvent):
+    """A event of accepting receiving data by shared file."""
+
+    TYPE = 'accept_sf_sending_data'
+
+    receiver: str
+
+    @classmethod
+    def contract_to_event(cls, contract: dict) -> 'AcceptSharedFileSendingDataEvent':
+        event_type = contract.get('type')
+        session_id = contract.get('session_id')
+        receiver = contract.get('receiver')
+        assert event_type == cls.TYPE, f'合约类型错误: {event_type}'
+        assert session_id and isinstance(session_id, str), f'invalid session_id: {session_id}'
+        assert receiver and isinstance(receiver, str), f'invalid receiver: {receiver}'
+        return AcceptSharedFileSendingDataEvent(session_id=session_id, receiver=receiver)
+
+
+@dataclass
+class UploadTaskAchievementEvent(ContractEvent):
+    """A event of uploading task achievement materials."""
+
+    TYPE = 'task_file_upload'
+
+    FILE_TYPE_REPORT = 'report'
+    FILE_TYPE_MODEL = 'model'
+
+    file_type: str
+    file_url: str
+
+    @classmethod
+    def contract_to_event(cls, contract: dict) -> 'UploadTaskAchievementEvent':
+        event_type = contract.get('type')
+        file_type = contract.get('file_type')
+        file_url = contract.get('file_url')
+        assert event_type == cls.TYPE, f'合约类型错误: {event_type}'
+        assert file_type in (cls.FILE_TYPE_REPORT, cls.FILE_TYPE_MODEL), f'invalid file_type: {file_type}'
+        assert file_url and isinstance(file_url, str), f'invalid file_url: {file_url}'
+        return UploadTaskAchievementEvent(file_type=file_type, file_url=file_url)
+
+
+@dataclass
+class NoticeTaskCompletionEvent(ContractEvent):
+    """A event of noticing task manager that current task is complete."""
+
+    TYPE = 'notice_task_completion'
+
+    result: bool
+
+    @classmethod
+    def contract_to_event(cls, contract: dict) -> 'NoticeTaskCompletionEvent':
+        event_type = contract.get('type')
+        result = contract.get('result')
+        assert event_type == cls.TYPE, f'合约类型错误: {event_type}'
+        assert isinstance(result, bool), f'invalid result: {result}'
+        return NoticeTaskCompletionEvent(result=result)
+
+
+class TaskMessageEventFactory(ContractEventFactory):
+
+    _CLASS_MAP: Dict[str, ContractEvent] = {
+        ApplyGRPCSendingDataEvent.TYPE: ApplyGRPCSendingDataEvent,
+        ApplySharedFileSendingDataEvent.TYPE: ApplySharedFileSendingDataEvent,
+        DenySendingDataEvent.TYPE: DenySendingDataEvent,
+        AcceptGRPCSendingDataEvent.TYPE: AcceptGRPCSendingDataEvent,
+        AcceptSharedFileSendingDataEvent.TYPE: AcceptSharedFileSendingDataEvent,
+        UploadTaskAchievementEvent.TYPE: UploadTaskAchievementEvent,
+        NoticeTaskCompletionEvent.TYPE: NoticeTaskCompletionEvent
+    }
+
+    @classmethod
+    def contract_to_event(cls, contract: dict) -> Optional[ContractEvent]:
+        try:
+            assert contract and isinstance(contract, dict)
+            event_type = contract.get('type')
+            assert event_type in cls._CLASS_MAP.keys()
+            event = cls._CLASS_MAP[event_type].contract_to_event(contract)
+            return event
+        except AssertionError:
+            logger.exception(f'invalid contract data: {contract}')
+            return None
+
+
+class TaskMessageContractor(Contractor):
+    """公共合约."""
+
+    _URL = 'http://federated-service:9080/fed-service/api/v2/message'
+
+    _TASK_INSIDE = 'task_inside'
+    _UPLOAD_TASK_ACHIEVE = 'task_file_upload'
+    _TASK_FINISH = 'task_finish'
+
+    _TITLE_ALL = (_TASK_INSIDE, _UPLOAD_TASK_ACHIEVE, _TASK_FINISH)
+
+    _CHANNEL = 'federated'
+
+    EMPTY_ACHIVEMENT = 'https://minio.ssplabs.com/playground-saas/tmp.zip'
+
+    def __init__(self, task_id: str) -> None:
+        super().__init__()
+        self.task_id = task_id
+        self._event_factory = TaskMessageEventFactory
+        self._task_contractor = TaskContractor(task_id=task_id)
+
+    def _validate_response(self, resp: Response) -> dict:
+        if resp.status_code < 200 or resp.status_code >= 300:
+            raise ContractException(f'failed to submit a contract: {resp}')
+        resp_json: dict = resp.json()
+        if not resp_json or not isinstance(resp_json, dict):
+            raise ContractException(f'invalid response:\nresp: {resp}\njson: {resp_json}')
+        if resp_json.get('code') != 0:
+            raise ContractException(f'failed to handle a contract: {resp_json}')
+        data = resp_json.get('data')
+        if data is None or not isinstance(data, dict):
+            raise ContractException(f'contract data error: {resp_json}')
+        task_id = data.get('task_id')
+        assert task_id is None or task_id == self.task_id, f'task_id dismatch: {task_id}'
+        return data
+
+    @retry(exceptions=ContractException)
+    def _new_contract(self,
+                      targets: List[str],
+                      event: ContractEvent,
+                      message_title: str = _TASK_INSIDE) -> str:
+        assert targets, 'must specify the target consumers of the contract'
+        assert (
+            isinstance(targets, list)
+            and all(_target and isinstance(_target, str) for _target in targets)
+        ), f'the target consumers must be an ID list: {targets}'
+        assert event, 'cannot send empty contract'
+        assert (
+            isinstance(event, ContractEvent)
+        ), f'"event" should be a contract event object: {event}'
+        assert (
+            message_title and message_title in self._TITLE_ALL
+        ), f'invalid message_title: {message_title}'
+
+        event.validate()
+
+        if is_mock_mode():
+            return self._new_contract_mock(targets=targets,
+                                           event=event,
+                                           message_title=message_title)
+        else:
+            return self._new_contract_normal(targets=targets,
+                                             event=event,
+                                             message_title=message_title)
+
+    def _new_contract_mock(self,
+                           targets: List[str],
+                           event: ContractEvent,
+                           message_title: str = _TASK_INSIDE) -> str:
+        content = json.dumps(event.event_to_contract(), ensure_ascii=False)
+        if targets == self.EVERYONE:
+            targets = mock_nodes()
+            if not targets:
+                raise ContractException('Can not obtain Node ID list of current task.')
+        contract_content = {
+            "targets": targets,
+            "message_title": message_title,
+            "content": content,
+            "channel": self._CHANNEL,
+            "task_id": self.task_id
+        }
+        logger.debug(f'try to push a contract in mock context: {contract_content}')
+        return _put_mock_contract(targets=targets,
+                                  message_title=message_title,
+                                  content=content,
+                                  message_time=int(datetime.now().timestamp()),
+                                  channel=self._CHANNEL,
+                                  task_id=self.task_id)
+
+    def _new_contract_normal(self,
+                             targets: List[str],
+                             event: ContractEvent,
+                             message_title: str = _TASK_INSIDE) -> str:
+        url = f'{self._URL}/push'
+        post_data = {
+            'task_id': self.task_id,
+            'node_id_list': targets,
+            'message_title': message_title,
+            'message_content': event.event_to_contract(),
+            'message_time': int(datetime.now().timestamp()),
+            'channel': self._CHANNEL
+        }
+        logger.debug(f'contract content: {post_data}')
+        resp = requests.post(url=url, json=post_data, headers=self._HEADERS)
+        resp_data = self._validate_response(resp=resp)
+        message_uuid: str = resp_data.get('message_uuid')
+        assert message_uuid and isinstance(message_uuid, str), f'invalid TxId: {message_uuid}'
+        logger.info(f'successfully pushed a new contract: {message_uuid=}')
+        # The contract framework doesn't promise the sequence of contractors when
+        # they are pushed almost at the same time, so we have to apart them a little.
+        # TODO remove me when it changes.
+        time.sleep(0.2)
+        return message_uuid
+
+    def _pop_contract(self) -> Optional[dict]:
+        """Popup a contract for consuming if exists."""
+        if is_mock_mode():
+            return self._pop_contract_mock()
+        else:
+            return self._pop_contract_normal()
+
+    def _pop_contract_mock(self) -> Optional[dict]:
+        content = _get_mock_contract(node_id=mock_node_id(),
+                                     channel=self._CHANNEL,
+                                     task_id=self.task_id)
+        if content is None:
+            return None
+        logger.debug(f'popped up a contract in mock context: {content}')
+        return json.loads(content)
+
+    def _pop_contract_normal(self) -> Optional[dict]:
+        post_data = {
+            'task_id': self.task_id,
+            'channel': self._CHANNEL
+        }
+        post_url = f'{self._URL}/pop'
+        resp = requests.post(url=post_url, json=post_data, headers=self._HEADERS)
+        resp_data = self._validate_response(resp=resp)
+        if not resp_data:
+            return None
+        logger.debug(f'popped up a contract: {resp_data}')
+        _content = resp_data.get('message_content')
+        assert _content and isinstance(_content, dict), f'invalid contract content: {_content}'
+        return _content
+
+    @overload
+    def apply_sending_data(self, source: str, target: str, public_key: bytes) -> str:
+        ...
+
+    @overload
+    def apply_sending_data(self, source: str, target: List[str], file_url: str) -> str:
+        ...
+
+    def apply_sending_data(self, source: str, target: Union[str, List[str]], **kwargs) -> str:
+        """发送数据传输请求合约."""
+        session_id = secrets.token_hex(16)
+        file_url = kwargs.get('file_url')
+        public_key = kwargs.get('public_key')
+        if file_url:
+            event = ApplySharedFileSendingDataEvent(session_id=session_id,
+                                                    source=source,
+                                                    target=target,
+                                                    file_url=file_url)
+            self._new_contract(targets=target, event=event)
+        else:
+            event = ApplyGRPCSendingDataEvent(session_id=session_id,
+                                              source=source,
+                                              target=target,
+                                              public_key=public_key)
+            self._new_contract(targets=[target], event=event)
+        return session_id
+
+    def deny_sending_data(self,
+                          target: str,
+                          session_id: str,
+                          rejecter: str,
+                          cause: str = None) -> None:
+        """拒绝数据传输请求合约."""
+        event = DenySendingDataEvent(session_id=session_id, rejecter=rejecter, cause=cause)
+        self._new_contract(targets=[target], event=event)
+
+    @overload
+    def accept_sending_data(self,
+                            target: str,
+                            session_id: str,
+                            public_key: bytes,
+                            cipher_port: bytes) -> None:
+        """接受数据传输请求合约.
+
+        通过 GRPC 数据通道。
+
+        Args:
+            session_id:
+                the session id of this data sending
+            public_key:
+                the public key of the data receiver
+            cipher_port:
+                the port number used for connecting, encrypted by the sender's public key
+        """
+
+    @overload
+    def accept_sending_data(self, target: str, session_id: str, receiver: str) -> None:
+        """接受数据传输请求合约.
+
+        通过共享文件数据通道。
+
+        :args
+            :session_id
+                the session id of this data sending
+            :public_key
+                the public key of the data receiver
+            :cipher_port
+                the port number used for connecting, encrypted by the sender's public key
+        """
+
+    def accept_sending_data(self, target: str, session_id: str, **kwargs) -> None:
+        public_key = kwargs.get('public_key')
+        if public_key:
+            public_key = kwargs.get('public_key')
+            cipher_port = kwargs.get('cipher_port')
+            assert (
+                public_key and isinstance(public_key, bytes)
+            ), f'Invalid public key: {public_key} .'
+            assert (
+                cipher_port and isinstance(cipher_port, bytes)
+            ), f'Invalid cipher port: {cipher_port} .'
+            event = AcceptGRPCSendingDataEvent(session_id=session_id,
+                                               public_key=public_key,
+                                               port=cipher_port)
+        else:
+            receiver = kwargs.get('receiver')
+            assert receiver and isinstance(receiver, str), f'Invalid receiver: {receiver} .'
+            event = AcceptSharedFileSendingDataEvent(session_id=session_id, receiver=receiver)
+        self._new_contract(targets=[target], event=event)
+
+    def contract_events(self, timeout: int = 0) -> ContractEvent:
+        """Return contract events iteratively.
+
+        :args
+            :timeout
+                The seconds to timeout. Will never timeout if is set less or equal to 0.
+        """
+        if not isinstance(timeout, int) or timeout < 0:
+            timeout = 0  # disable timeout
+        if timeout > 0:
+            start = datetime.utcnow().timestamp()
+        while timeout <= 0 or datetime.utcnow().timestamp() - start < timeout:
+            _contract = self._pop_contract()
+            if _contract:
+                event = self._event_factory.contract_to_event(contract=_contract)
+                if event:
+                    yield event
+                else:
+                    logger.warn(f'failed to parse a contract to an event: {_contract}')
+            else:
+                time.sleep(1)
+
+    @retry()
+    def query_address(self, target: str) -> Optional[str]:
+        """Query address of the target."""
+        return self._task_contractor.query_address(target=target)
+    
+    def upload_metric_report(self, receivers: List[str], report_file: str = None):
+        """Upload metrics report materials after a task is complete.
+
+        Args:
+            receivers:
+                Specify who can receive and download this report.
+            report_file:
+                Local path of the report file.
+
+        If nothing need be uploaded, specify report_file to None or an empty value.
+        """
+        if not receivers or not report_file:
+            report_file_url = self.EMPTY_ACHIVEMENT
+        else:
+            assert (
+                isinstance(receivers, list) and all(isinstance(_receiver, str) for _receiver in receivers)
+            ), f'invalid receivers: {receivers}'
+            assert (
+                isinstance(report_file, str) and os.path.isfile(report_file)
+            ), f'the report_file does not exist or can not be accessed: {report_file}'
+
+            with open(report_file, 'rb') as report_fp:
+                report_file_url = self.upload_file(fp=report_fp,
+                                                   persistent=True,
+                                                   upload_name=os.path.basename(report_file))
+
+        event = UploadTaskAchievementEvent(file_type=UploadTaskAchievementEvent.FILE_TYPE_REPORT,
+                                           file_url=report_file_url)
+        TxId = self._new_contract(targets=receivers,
+                                  event=event,
+                                  message_title=self._UPLOAD_TASK_ACHIEVE)
+        if not TxId:
+            raise ContractException('failed to notify task completion')
+    
+    def upload_model(self, receivers: List[str], model_file: str = None):
+        """Upload final model after a task is complete.
+
+        Args:
+            receivers:
+                Specify who can receive and download this report.
+            model_file:
+                Local path of the model file.
+
+        If nothing need be uploaded, specify model_file to None or an empty value.
+        """
+        if not receivers or not model_file:
+            model_file_url = self.EMPTY_ACHIVEMENT
+        else:
+            assert (
+                isinstance(receivers, list) and all(isinstance(_receiver, str) for _receiver in receivers)
+            ), f'invalid receivers: {receivers}'
+            assert (
+                isinstance(model_file, str) and os.path.isfile(model_file)
+            ), f'the model_file does not exist or can not be accessed: {model_file}'
+
+            with open(model_file, 'rb') as model_fp:
+                model_file_url = self.upload_file(fp=model_fp,
+                                                  persistent=True,
+                                                  upload_name=os.path.basename(model_file))
+
+        event = UploadTaskAchievementEvent(file_type=UploadTaskAchievementEvent.FILE_TYPE_MODEL,
+                                           file_url=model_file_url)
+        TxId = self._new_contract(targets=receivers,
+                                  event=event,
+                                  message_title=self._UPLOAD_TASK_ACHIEVE)
+        if not TxId:
+            raise ContractException('failed to notify task completion')
+
+    def notify_task_completion(self, result: bool):
+        """Notify task manager a task is complete.
+
+        :args
+            :result
+                True if successful otherwize False.
+        """
+        event = NoticeTaskCompletionEvent(result=result)
+        TxId = self._new_contract(targets=self.EVERYONE,
+                                  event=event,
+                                  message_title=self._TASK_FINISH)
+        if not TxId:
+            raise ContractException('failed to notify task completion')
+
+    def report_progress(self, percent: int):
+        """Report training progress (percent integer value)."""
+        self._task_contractor.report_progress(percent=percent)
+
+    def query_nodes(self) -> List[str]:
+        """Query all nodes in this task."""
+        return self._task_contractor.query_nodes()
+
+    @overload
+    def upload_file(self, fp: str, persistent: bool = False, upload_name: str = None) -> str: ...
+
+    @overload
+    def upload_file(self, fp: IOBase, persistent: bool = False, upload_name: str = None) -> str: ...
+
+    def upload_file(self, fp, persistent: bool = False, upload_name: str = None) -> str:
+        """Upload a file to file system."""
+        return self._task_contractor.upload_file(fp=fp,
+                                                 upload_name=upload_name,
+                                                 persistent=persistent)
+
+
+class AutoTaskMessageContractor(TaskMessageContractor):
+    """AutoML version of TaskMessageContractor."""
+
+    _CHANNEL = 'automl'
+
+    def __init__(self, task_id: str) -> None:
+        super().__init__(task_id)
+        self._task_contractor = AutoTaskContractor(task_id=task_id)
```

### Comparing `alphamed-federated-0.4.7/src/alphafed/data_channel/data_channel.py` & `alphamed-federated-0.4.9/src/alphafed/data_channel/data_channel.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/data_channel/data_channel_pb2.py` & `alphamed-federated-0.4.9/src/alphafed/data_channel/data_channel_pb2.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/data_channel/data_channel_pb2_grpc.py` & `alphamed-federated-0.4.9/src/alphafed/data_channel/data_channel_pb2_grpc.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/data_channel/grpc_data_channel.py` & `alphamed-federated-0.4.9/src/alphafed/data_channel/grpc_data_channel.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/data_channel/shared_file_data_channel.py` & `alphamed-federated-0.4.9/src/alphafed/data_channel/shared_file_data_channel.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/docs/auto_ml/res/auto.py` & `alphamed-federated-0.4.9/src/alphafed/docs/auto_ml/res/auto.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/docs/auto_ml/res/res_net.py` & `alphamed-federated-0.4.9/src/alphafed/docs/auto_ml/res/res_net.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/docs/customized_scheduler/contractor.py` & `alphamed-federated-0.4.9/src/alphafed/docs/customized_scheduler/contractor.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/docs/customized_scheduler/scheduler.py` & `alphamed-federated-0.4.9/src/alphafed/docs/customized_scheduler/scheduler.py`

 * *Ordering differences only*

 * *Files 17% similar despite different names*

```diff
@@ -1,460 +1,460 @@
-import io
-import os
-import sys
-import traceback
-from abc import ABCMeta, abstractmethod
-from typing import Dict, Tuple
-from zipfile import ZipFile
-
-import torch
-from torch import Tensor
-from torch.nn import Module
-from torch.optim import Optimizer
-from torch.utils.data import DataLoader
-from torch.utils.tensorboard import SummaryWriter
-
-from alphafed import get_result_dir, logger
-from alphafed.data_channel.shared_file_data_channel import \
-    SharedFileDataChannel
-from alphafed.scheduler import Scheduler
-
-from .contractor import (CheckinEvent, CheckinResponseEvent, CloseRoundEvent,
-                         ReadyForAggregationEvent, SimpleFedAvgContractor,
-                         StartRoundEvent)
-
-
-class SimpleFedAvgScheduler(Scheduler, metaclass=ABCMeta):
-    """A simple FedAvg implementation as an example of customized scheduler."""
-
-    _INIT = 'init'
-    _GETHORING = 'gethering'
-    _READY = 'ready'
-    _IN_A_ROUND = 'in_a_round'
-    _UPDATING = 'updating'
-    _CALCULATING = 'calculating'
-    _WAIT_FOR_AGGR = 'wait_4_aggr'
-    _AGGREGATING = 'aggregating'
-    _PERSISTING = 'persisting'
-    _CLOSING_ROUND = 'closing_round'
-    _FINISHING = 'finishing'
-
-    def __init__(self, clients: int, rounds: int):
-        """Init.
-
-        Args:
-            clients:
-                The number of calculators.
-            rounds:
-                The number of training rounds.
-        """
-        super().__init__()
-        self.state = self._INIT
-
-        self.clients = clients
-        self.rounds = rounds
-
-        self._participants = []
-
-    @abstractmethod
-    def build_model(self) -> Module:
-        """Return a model object which will be used for training."""
-
-    @property
-    def model(self) -> Module:
-        """Get the model object which is used for training."""
-        if not hasattr(self, '_model'):
-            self._model = self.build_model()
-        return self._model
-
-    @abstractmethod
-    def build_optimizer(self, model: Module) -> Optimizer:
-        """Return a optimizer object which will be used for training.
-
-        Args:
-            model:
-                The model object which is used for training.
-        """
-
-    @property
-    def optimizer(self) -> Optimizer:
-        """Get the optimizer object which is used for training."""
-        if not hasattr(self, '_optimizer'):
-            self._optimizer = self.build_optimizer(model=self.model)
-        return self._optimizer
-
-    @abstractmethod
-    def build_train_dataloader(self) -> DataLoader:
-        """Define the training dataloader.
-
-        You can transform the dataset, do some preprocess to the dataset.
-
-        Return:
-            training dataloader
-        """
-
-    @property
-    def train_loader(self) -> DataLoader:
-        """Get the training dataloader object."""
-        if not hasattr(self, '_train_loader'):
-            self._train_loader = self.build_train_dataloader()
-        return self._train_loader
-
-    @abstractmethod
-    def build_test_dataloader(self) -> DataLoader:
-        """Define the testing dataloader.
-
-        You can transform the dataset, do some preprocess to the dataset. If you do not
-        want to do testing after training, simply make it return None.
-
-        Args:
-            dataset:
-                training dataset
-        Return:
-            testing dataloader
-        """
-
-    @property
-    def test_loader(self) -> DataLoader:
-        """Get the testing dataloader object."""
-        if not hasattr(self, '_test_loader'):
-            self._test_loader = self.build_test_dataloader()
-        return self._test_loader
-
-    @abstractmethod
-    def state_dict(self) -> Dict[str, Tensor]:
-        """Get the params that need to train and update.
-
-        Only the params returned by this function will be updated and saved during aggregation.
-
-        Return:
-            List[Tensor], The list of model params.
-        """
-
-    @abstractmethod
-    def load_state_dict(self, state_dict: Dict[str, Tensor]):
-        """Load the params that trained and updated.
-
-        Only the params returned by state_dict() should be loaded by this function.
-        """
-
-    @abstractmethod
-    def train_an_epoch(self):
-        """Define the training steps in an epoch."""
-
-    @abstractmethod
-    def test(self):
-        """Define the testing steps.
-
-        If you do not want to do testing after training, simply make it pass.
-        """
-
-    def _setup_context(self, id: str, task_id: str, is_initiator: bool = False):
-        assert id, 'must specify a unique id for every participant'
-        assert task_id, 'must specify a task_id for every participant'
-
-        self.id = id
-        self.task_id = task_id
-        self._result_dir = get_result_dir(self.task_id)
-        self._log_dir = os.path.join(self._result_dir, 'tb_logs')
-        self.tb_writer = SummaryWriter(log_dir=self._log_dir)
-
-        self.is_initiator = is_initiator
-
-        self.contractor = SimpleFedAvgContractor(task_id=task_id)
-        self.data_channel = SharedFileDataChannel(self.contractor)
-        self.model
-        self.optimizer
-        self.round = 0
-
-    def _run(self, id: str, task_id: str, is_initiator: bool = False, recover: bool = False):
-        self._setup_context(id=id, task_id=task_id, is_initiator=is_initiator)
-        self.push_log(message='Local context is ready.')
-        try:
-            if self.is_initiator and recover:
-                self._recover_progress()
-            else:
-                self._clean_progress()
-            self._launch_process()
-        except Exception:
-            # 将错误信息推送到 Playground 前端界面，有助于了解错误原因并修正
-            err_stack = '\n'.join(traceback.format_exception(*sys.exc_info()))
-            self.push_log(err_stack)
-
-    def _recover_progress(self):
-        """Try to recover and continue from last running."""
-        # 如果上一次执行计算任务因为某些偶发原因失败了。在排除故障原因后，希望能够从失败的地方
-        # 恢复计算进度继续计算，而不是重新开始，可以在这里提供恢复进度的处理逻辑。
-        pass
-
-    def _clean_progress(self):
-        """Clean existing progress data."""
-        # 如果曾经执行过计算任务，在计算环境中留下了一些过往的痕迹。现在想要从头开始重新运行计算
-        # 任务，但是残留的数据可能会干扰当前这一次运行，可以在这里提供清理环境的处理逻辑。
-        pass
-
-    def _launch_process(self):
-        self.push_log(f'Node {self.id} is up.')
-
-        self._switch_status(self._GETHORING)
-        self._check_in()
-
-        self._switch_status(self._READY)
-        self.round = 1
-
-        for _ in range(self.rounds):
-            self._switch_status(self._IN_A_ROUND)
-            self._run_a_round()
-            self._switch_status(self._READY)
-            self.round += 1
-
-        if self.is_initiator:
-            self.push_log(f'Obtained the final results of task {self.task_id}')
-            self._switch_status(self._FINISHING)
-            self.test()
-            self._close_task()
-
-    def _check_in(self):
-        """Check in task and get ready.
-
-        As an initiator (and default the aggregator), records each participants
-        and launches training process.
-        As a participant, checkins and gets ready for training.
-        """
-        if self.is_initiator:
-            self.push_log('Waiting for participants taking part in ...')
-            self._wait_for_gathering()
-        else:
-            is_checked_in = False
-            # the aggregator may be in special state so can not response
-            # correctly nor in time, then retry periodically
-            self.push_log('Checking in the task ...')
-            while not is_checked_in:
-                is_checked_in = self._check_in_task()
-            self.push_log(f'Node {self.id} have taken part in the task.')
-
-    def _wait_for_gathering(self):
-        """Wait for participants gethering."""
-        logger.debug('_wait_for_gathering ...')
-        for _event in self.contractor.contract_events():
-            if isinstance(_event, CheckinEvent):
-                if _event.peer_id not in self._participants:
-                    self._participants.append(_event.peer_id)
-                    self.push_log(f'Welcome a new participant ID: {_event.peer_id}.')
-                    self.push_log(f'There are {len(self._participants)} participants now.')
-                self.contractor.respond_check_in(round=self.round,
-                                                 aggregator=self.id,
-                                                 nonce=_event.nonce,
-                                                 requester_id=_event.peer_id)
-                if len(self._participants) == self.clients:
-                    break
-        self.push_log('All participants gethered.')
-
-    def _check_in_task(self) -> bool:
-        """Try to check in the task."""
-        nonce = self.contractor.checkin(peer_id=self.id)
-        logger.debug('_wait_for_check_in_response ...')
-        for _event in self.contractor.contract_events(timeout=30):
-            if isinstance(_event, CheckinResponseEvent):
-                if _event.nonce != nonce:
-                    continue
-                self.round = _event.round
-                self._aggregator = _event.aggregator
-                return True
-        return False
-
-    def _run_a_round(self):
-        """Perform a round of FedAvg calculation.
-
-        As an aggregator, selects a part of participants as actual calculators
-        in the round, distributes latest parameters to them, collects update and
-        makes aggregation.
-        As a participant, if is selected as a calculator, calculates and uploads
-        parameter update.
-        """
-        if self.is_initiator:
-            self._run_as_aggregator()
-        else:
-            self._run_as_data_owner()
-
-    def _run_as_aggregator(self):
-        self._start_round()
-        self._distribute_model()
-        self._process_aggregation()
-        self._close_round()
-
-    def _start_round(self):
-        """Prepare and start calculation of a round."""
-        self.push_log(f'Begin the training of round {self.round}.')
-        self.contractor.start_round(round=self.round,
-                                    calculators=self._participants,
-                                    aggregator=self.id)
-        self.push_log(f'Calculation of round {self.round} is started.')
-
-    def _distribute_model(self):
-        buffer = io.BytesIO()
-        torch.save(self.state_dict(), buffer)
-        self.push_log('Distributing parameters ...')
-        accept_list = self.data_channel.batch_send_stream(source=self.id,
-                                                          target=self._participants,
-                                                          data_stream=buffer.getvalue())
-        self.push_log(f'Successfully distributed parameters to: {accept_list}')
-        if len(self._participants) != len(accept_list):
-            reject_list = [_target for _target in self._participants
-                           if _target not in accept_list]
-            self.push_log(f'Failed to distribute parameters to: {reject_list}')
-            raise RuntimeError('Failed to distribute parameters to some participants.')
-        self.push_log('Distributed parameters to all participants.')
-
-    def _process_aggregation(self):
-        """Process aggregation depending on specific algorithm."""
-        self._switch_status(self._WAIT_FOR_AGGR)
-        self.contractor.notify_ready_for_aggregation(round=self.round)
-        self.push_log('Now waiting for executing calculation ...')
-        accum_result, result_count = self._wait_for_calculation()
-        if result_count < self.clients:
-            self.push_log('Task failed because some calculation results lost.')
-            raise RuntimeError('Task failed because some calculation results lost.')
-        self.push_log(f'Received {result_count} copies of calculation results.')
-
-        self._switch_status(self._AGGREGATING)
-        self.push_log('Begin to aggregate and update parameters.')
-        for _key in accum_result.keys():
-            if accum_result[_key].dtype in (
-                torch.uint8, torch.int8, torch.int16, torch.int32, torch.int64
-            ):
-                logger.warn(f'average a int value may lose precision: {_key=}')
-                accum_result[_key].div_(result_count, rounding_mode='trunc')
-            else:
-                accum_result[_key].div_(result_count)
-        self.load_state_dict(accum_result)
-        self.push_log('Obtained a new version of parameters.')
-
-    def _wait_for_calculation(self) -> Tuple[Dict[str, torch.Tensor], int]:
-        """Wait for every calculator finish its task or timeout."""
-        result_count = 0
-        accum_result = self.state_dict()
-        for _param in accum_result.values():
-            if isinstance(_param, torch.Tensor):
-                _param.zero_()
-
-        self.push_log('Waiting for training results ...')
-        training_results = self.data_channel.batch_receive_stream(
-            receiver=self.id,
-            source_list=self._participants
-        )
-        for _source, _result in training_results.items():
-            buffer = io.BytesIO(_result)
-            _new_state_dict = torch.load(buffer)
-            for _key in accum_result.keys():
-                accum_result[_key].add_(_new_state_dict[_key])
-            result_count += 1
-            self.push_log(f'Received calculation results from ID: {_source}')
-        return accum_result, result_count
-
-    def _close_round(self):
-        """Close current round when finished."""
-        self._switch_status(self._CLOSING_ROUND)
-        self.contractor.close_round(round=self.round)
-        self.push_log(f'The training of Round {self.round} complete.')
-
-    def _run_as_data_owner(self):
-        self._wait_for_starting_round()
-        self._switch_status(self._UPDATING)
-        self._wait_for_updating_model()
-
-        self._switch_status(self._CALCULATING)
-        self.push_log('Begin to run calculation ...')
-        self.train_an_epoch()
-        self.push_log('Local calculation complete.')
-
-        self._wait_for_uploading_model()
-        buffer = io.BytesIO()
-        torch.save(self.state_dict(), buffer)
-        self.push_log('Pushing local update to the aggregator ...')
-        self.data_channel.send_stream(source=self.id,
-                                      target=self._aggregator,
-                                      data_stream=buffer.getvalue())
-        self.push_log('Successfully pushed local update to the aggregator.')
-        self._switch_status(self._CLOSING_ROUND)
-        self._wait_for_closing_round()
-
-        self.push_log(f'ID: {self.id} finished training task of round {self.round}.')
-
-    def _wait_for_starting_round(self):
-        """Wait for starting a new round of training."""
-        self.push_log(f'Waiting for training of round {self.round} begin ...')
-        for _event in self.contractor.contract_events():
-            if isinstance(_event, StartRoundEvent):
-                self.push_log(f'Training of round {self.round} begins.')
-                return
-
-    def _wait_for_updating_model(self):
-        """Wait for receiving latest parameters from aggregator."""
-        self.push_log('Waiting for receiving latest parameters from the aggregator ...')
-        _, parameters = self.data_channel.receive_stream(receiver=self.id,
-                                                         source=self._aggregator)
-        buffer = io.BytesIO(parameters)
-        new_state_dict = torch.load(buffer)
-        self.load_state_dict(new_state_dict)
-        self.push_log('Successfully received latest parameters.')
-        return
-
-    def _wait_for_uploading_model(self):
-        """Wait for uploading trained parameters to aggregator."""
-        self.push_log('Waiting for aggregation begin ...')
-        for _event in self.contractor.contract_events():
-            if isinstance(_event, ReadyForAggregationEvent):
-                return
-
-    def _wait_for_closing_round(self):
-        """Wait for closing current round of training."""
-        self.push_log(f'Waiting for closing signal of training round {self.round} ...')
-        for _event in self.contractor.contract_events():
-            if isinstance(_event, CloseRoundEvent):
-                return
-
-    def _close_task(self, is_succ: bool = True):
-        """Close the FedAvg calculation.
-
-        As an aggregator, broadcasts the finish task event to all participants,
-        uploads the final parameters and tells L1 task manager the task is complete.
-        As a participant, do nothing.
-        """
-        self.push_log(f'Closing task {self.task_id} ...')
-        if self.is_initiator:
-            self._switch_status(self._FINISHING)
-            report_file_path, model_file_path = self._prepare_task_output()
-            self.contractor.upload_metric_report(receivers=self.contractor.EVERYONE,
-                                                 report_file=report_file_path)
-            self.contractor.upload_model(receivers=self.contractor.EVERYONE,
-                                         model_file=model_file_path)
-            self.contractor.notify_task_completion(result=True)
-        self.push_log(f'Task {self.task_id} closed. Byebye!')
-
-    def _prepare_task_output(self) -> Tuple[str, str]:
-        """Generate final output files of the task.
-
-        Return:
-            Local paths of the report file and model file.
-        """
-        self.push_log('Uploading task achievement and closing task ...')
-
-        os.makedirs(self._result_dir, exist_ok=True)
-
-        report_file = os.path.join(self._result_dir, "report.zip")
-        with ZipFile(report_file, 'w') as report_zip:
-            for path, _, filenames in os.walk(self._log_dir):
-                rel_dir = os.path.relpath(path=path, start=self._result_dir)
-                rel_dir = rel_dir.lstrip('.')  # ./file => file
-                for _file in filenames:
-                    rel_path = os.path.join(rel_dir, _file)
-                    report_zip.write(os.path.join(path, _file), rel_path)
-        report_file_path = os.path.abspath(report_file)
-
-        model_file = os.path.join(self._result_dir, "model.pt")
-        with open(model_file, 'wb') as f:
-            torch.save(self.state_dict(), f)
-        model_file_path = os.path.abspath(model_file)
-
-        self.push_log('Task achievement files are ready.')
-        return report_file_path, model_file_path
+import io
+import os
+import sys
+import traceback
+from abc import ABCMeta, abstractmethod
+from typing import Dict, Tuple
+from zipfile import ZipFile
+
+import torch
+from torch import Tensor
+from torch.nn import Module
+from torch.optim import Optimizer
+from torch.utils.data import DataLoader
+from torch.utils.tensorboard import SummaryWriter
+
+from alphafed import get_result_dir, logger
+from alphafed.data_channel.shared_file_data_channel import \
+    SharedFileDataChannel
+from alphafed.scheduler import Scheduler
+
+from .contractor import (CheckinEvent, CheckinResponseEvent, CloseRoundEvent,
+                         ReadyForAggregationEvent, SimpleFedAvgContractor,
+                         StartRoundEvent)
+
+
+class SimpleFedAvgScheduler(Scheduler, metaclass=ABCMeta):
+    """A simple FedAvg implementation as an example of customized scheduler."""
+
+    _INIT = 'init'
+    _GETHORING = 'gethering'
+    _READY = 'ready'
+    _IN_A_ROUND = 'in_a_round'
+    _UPDATING = 'updating'
+    _CALCULATING = 'calculating'
+    _WAIT_FOR_AGGR = 'wait_4_aggr'
+    _AGGREGATING = 'aggregating'
+    _PERSISTING = 'persisting'
+    _CLOSING_ROUND = 'closing_round'
+    _FINISHING = 'finishing'
+
+    def __init__(self, clients: int, rounds: int):
+        """Init.
+
+        Args:
+            clients:
+                The number of calculators.
+            rounds:
+                The number of training rounds.
+        """
+        super().__init__()
+        self.state = self._INIT
+
+        self.clients = clients
+        self.rounds = rounds
+
+        self._participants = []
+
+    @abstractmethod
+    def build_model(self) -> Module:
+        """Return a model object which will be used for training."""
+
+    @property
+    def model(self) -> Module:
+        """Get the model object which is used for training."""
+        if not hasattr(self, '_model'):
+            self._model = self.build_model()
+        return self._model
+
+    @abstractmethod
+    def build_optimizer(self, model: Module) -> Optimizer:
+        """Return a optimizer object which will be used for training.
+
+        Args:
+            model:
+                The model object which is used for training.
+        """
+
+    @property
+    def optimizer(self) -> Optimizer:
+        """Get the optimizer object which is used for training."""
+        if not hasattr(self, '_optimizer'):
+            self._optimizer = self.build_optimizer(model=self.model)
+        return self._optimizer
+
+    @abstractmethod
+    def build_train_dataloader(self) -> DataLoader:
+        """Define the training dataloader.
+
+        You can transform the dataset, do some preprocess to the dataset.
+
+        Return:
+            training dataloader
+        """
+
+    @property
+    def train_loader(self) -> DataLoader:
+        """Get the training dataloader object."""
+        if not hasattr(self, '_train_loader'):
+            self._train_loader = self.build_train_dataloader()
+        return self._train_loader
+
+    @abstractmethod
+    def build_test_dataloader(self) -> DataLoader:
+        """Define the testing dataloader.
+
+        You can transform the dataset, do some preprocess to the dataset. If you do not
+        want to do testing after training, simply make it return None.
+
+        Args:
+            dataset:
+                training dataset
+        Return:
+            testing dataloader
+        """
+
+    @property
+    def test_loader(self) -> DataLoader:
+        """Get the testing dataloader object."""
+        if not hasattr(self, '_test_loader'):
+            self._test_loader = self.build_test_dataloader()
+        return self._test_loader
+
+    @abstractmethod
+    def state_dict(self) -> Dict[str, Tensor]:
+        """Get the params that need to train and update.
+
+        Only the params returned by this function will be updated and saved during aggregation.
+
+        Return:
+            List[Tensor], The list of model params.
+        """
+
+    @abstractmethod
+    def load_state_dict(self, state_dict: Dict[str, Tensor]):
+        """Load the params that trained and updated.
+
+        Only the params returned by state_dict() should be loaded by this function.
+        """
+
+    @abstractmethod
+    def train_an_epoch(self):
+        """Define the training steps in an epoch."""
+
+    @abstractmethod
+    def test(self):
+        """Define the testing steps.
+
+        If you do not want to do testing after training, simply make it pass.
+        """
+
+    def _setup_context(self, id: str, task_id: str, is_initiator: bool = False):
+        assert id, 'must specify a unique id for every participant'
+        assert task_id, 'must specify a task_id for every participant'
+
+        self.id = id
+        self.task_id = task_id
+        self._result_dir = get_result_dir(self.task_id)
+        self._log_dir = os.path.join(self._result_dir, 'tb_logs')
+        self.tb_writer = SummaryWriter(log_dir=self._log_dir)
+
+        self.is_initiator = is_initiator
+
+        self.contractor = SimpleFedAvgContractor(task_id=task_id)
+        self.data_channel = SharedFileDataChannel(self.contractor)
+        self.model
+        self.optimizer
+        self.round = 0
+
+    def _run(self, id: str, task_id: str, is_initiator: bool = False, recover: bool = False):
+        self._setup_context(id=id, task_id=task_id, is_initiator=is_initiator)
+        self.push_log(message='Local context is ready.')
+        try:
+            if self.is_initiator and recover:
+                self._recover_progress()
+            else:
+                self._clean_progress()
+            self._launch_process()
+        except Exception:
+            # 将错误信息推送到 Playground 前端界面，有助于了解错误原因并修正
+            err_stack = '\n'.join(traceback.format_exception(*sys.exc_info()))
+            self.push_log(err_stack)
+
+    def _recover_progress(self):
+        """Try to recover and continue from last running."""
+        # 如果上一次执行计算任务因为某些偶发原因失败了。在排除故障原因后，希望能够从失败的地方
+        # 恢复计算进度继续计算，而不是重新开始，可以在这里提供恢复进度的处理逻辑。
+        pass
+
+    def _clean_progress(self):
+        """Clean existing progress data."""
+        # 如果曾经执行过计算任务，在计算环境中留下了一些过往的痕迹。现在想要从头开始重新运行计算
+        # 任务，但是残留的数据可能会干扰当前这一次运行，可以在这里提供清理环境的处理逻辑。
+        pass
+
+    def _launch_process(self):
+        self.push_log(f'Node {self.id} is up.')
+
+        self._switch_status(self._GETHORING)
+        self._check_in()
+
+        self._switch_status(self._READY)
+        self.round = 1
+
+        for _ in range(self.rounds):
+            self._switch_status(self._IN_A_ROUND)
+            self._run_a_round()
+            self._switch_status(self._READY)
+            self.round += 1
+
+        if self.is_initiator:
+            self.push_log(f'Obtained the final results of task {self.task_id}')
+            self._switch_status(self._FINISHING)
+            self.test()
+            self._close_task()
+
+    def _check_in(self):
+        """Check in task and get ready.
+
+        As an initiator (and default the aggregator), records each participants
+        and launches training process.
+        As a participant, checkins and gets ready for training.
+        """
+        if self.is_initiator:
+            self.push_log('Waiting for participants taking part in ...')
+            self._wait_for_gathering()
+        else:
+            is_checked_in = False
+            # the aggregator may be in special state so can not response
+            # correctly nor in time, then retry periodically
+            self.push_log('Checking in the task ...')
+            while not is_checked_in:
+                is_checked_in = self._check_in_task()
+            self.push_log(f'Node {self.id} have taken part in the task.')
+
+    def _wait_for_gathering(self):
+        """Wait for participants gethering."""
+        logger.debug('_wait_for_gathering ...')
+        for _event in self.contractor.contract_events():
+            if isinstance(_event, CheckinEvent):
+                if _event.peer_id not in self._participants:
+                    self._participants.append(_event.peer_id)
+                    self.push_log(f'Welcome a new participant ID: {_event.peer_id}.')
+                    self.push_log(f'There are {len(self._participants)} participants now.')
+                self.contractor.respond_check_in(round=self.round,
+                                                 aggregator=self.id,
+                                                 nonce=_event.nonce,
+                                                 requester_id=_event.peer_id)
+                if len(self._participants) == self.clients:
+                    break
+        self.push_log('All participants gethered.')
+
+    def _check_in_task(self) -> bool:
+        """Try to check in the task."""
+        nonce = self.contractor.checkin(peer_id=self.id)
+        logger.debug('_wait_for_check_in_response ...')
+        for _event in self.contractor.contract_events(timeout=30):
+            if isinstance(_event, CheckinResponseEvent):
+                if _event.nonce != nonce:
+                    continue
+                self.round = _event.round
+                self._aggregator = _event.aggregator
+                return True
+        return False
+
+    def _run_a_round(self):
+        """Perform a round of FedAvg calculation.
+
+        As an aggregator, selects a part of participants as actual calculators
+        in the round, distributes latest parameters to them, collects update and
+        makes aggregation.
+        As a participant, if is selected as a calculator, calculates and uploads
+        parameter update.
+        """
+        if self.is_initiator:
+            self._run_as_aggregator()
+        else:
+            self._run_as_data_owner()
+
+    def _run_as_aggregator(self):
+        self._start_round()
+        self._distribute_model()
+        self._process_aggregation()
+        self._close_round()
+
+    def _start_round(self):
+        """Prepare and start calculation of a round."""
+        self.push_log(f'Begin the training of round {self.round}.')
+        self.contractor.start_round(round=self.round,
+                                    calculators=self._participants,
+                                    aggregator=self.id)
+        self.push_log(f'Calculation of round {self.round} is started.')
+
+    def _distribute_model(self):
+        buffer = io.BytesIO()
+        torch.save(self.state_dict(), buffer)
+        self.push_log('Distributing parameters ...')
+        accept_list = self.data_channel.batch_send_stream(source=self.id,
+                                                          target=self._participants,
+                                                          data_stream=buffer.getvalue())
+        self.push_log(f'Successfully distributed parameters to: {accept_list}')
+        if len(self._participants) != len(accept_list):
+            reject_list = [_target for _target in self._participants
+                           if _target not in accept_list]
+            self.push_log(f'Failed to distribute parameters to: {reject_list}')
+            raise RuntimeError('Failed to distribute parameters to some participants.')
+        self.push_log('Distributed parameters to all participants.')
+
+    def _process_aggregation(self):
+        """Process aggregation depending on specific algorithm."""
+        self._switch_status(self._WAIT_FOR_AGGR)
+        self.contractor.notify_ready_for_aggregation(round=self.round)
+        self.push_log('Now waiting for executing calculation ...')
+        accum_result, result_count = self._wait_for_calculation()
+        if result_count < self.clients:
+            self.push_log('Task failed because some calculation results lost.')
+            raise RuntimeError('Task failed because some calculation results lost.')
+        self.push_log(f'Received {result_count} copies of calculation results.')
+
+        self._switch_status(self._AGGREGATING)
+        self.push_log('Begin to aggregate and update parameters.')
+        for _key in accum_result.keys():
+            if accum_result[_key].dtype in (
+                torch.uint8, torch.int8, torch.int16, torch.int32, torch.int64
+            ):
+                logger.warn(f'average a int value may lose precision: {_key=}')
+                accum_result[_key].div_(result_count, rounding_mode='trunc')
+            else:
+                accum_result[_key].div_(result_count)
+        self.load_state_dict(accum_result)
+        self.push_log('Obtained a new version of parameters.')
+
+    def _wait_for_calculation(self) -> Tuple[Dict[str, torch.Tensor], int]:
+        """Wait for every calculator finish its task or timeout."""
+        result_count = 0
+        accum_result = self.state_dict()
+        for _param in accum_result.values():
+            if isinstance(_param, torch.Tensor):
+                _param.zero_()
+
+        self.push_log('Waiting for training results ...')
+        training_results = self.data_channel.batch_receive_stream(
+            receiver=self.id,
+            source_list=self._participants
+        )
+        for _source, _result in training_results.items():
+            buffer = io.BytesIO(_result)
+            _new_state_dict = torch.load(buffer)
+            for _key in accum_result.keys():
+                accum_result[_key].add_(_new_state_dict[_key])
+            result_count += 1
+            self.push_log(f'Received calculation results from ID: {_source}')
+        return accum_result, result_count
+
+    def _close_round(self):
+        """Close current round when finished."""
+        self._switch_status(self._CLOSING_ROUND)
+        self.contractor.close_round(round=self.round)
+        self.push_log(f'The training of Round {self.round} complete.')
+
+    def _run_as_data_owner(self):
+        self._wait_for_starting_round()
+        self._switch_status(self._UPDATING)
+        self._wait_for_updating_model()
+
+        self._switch_status(self._CALCULATING)
+        self.push_log('Begin to run calculation ...')
+        self.train_an_epoch()
+        self.push_log('Local calculation complete.')
+
+        self._wait_for_uploading_model()
+        buffer = io.BytesIO()
+        torch.save(self.state_dict(), buffer)
+        self.push_log('Pushing local update to the aggregator ...')
+        self.data_channel.send_stream(source=self.id,
+                                      target=self._aggregator,
+                                      data_stream=buffer.getvalue())
+        self.push_log('Successfully pushed local update to the aggregator.')
+        self._switch_status(self._CLOSING_ROUND)
+        self._wait_for_closing_round()
+
+        self.push_log(f'ID: {self.id} finished training task of round {self.round}.')
+
+    def _wait_for_starting_round(self):
+        """Wait for starting a new round of training."""
+        self.push_log(f'Waiting for training of round {self.round} begin ...')
+        for _event in self.contractor.contract_events():
+            if isinstance(_event, StartRoundEvent):
+                self.push_log(f'Training of round {self.round} begins.')
+                return
+
+    def _wait_for_updating_model(self):
+        """Wait for receiving latest parameters from aggregator."""
+        self.push_log('Waiting for receiving latest parameters from the aggregator ...')
+        _, parameters = self.data_channel.receive_stream(receiver=self.id,
+                                                         source=self._aggregator)
+        buffer = io.BytesIO(parameters)
+        new_state_dict = torch.load(buffer)
+        self.load_state_dict(new_state_dict)
+        self.push_log('Successfully received latest parameters.')
+        return
+
+    def _wait_for_uploading_model(self):
+        """Wait for uploading trained parameters to aggregator."""
+        self.push_log('Waiting for aggregation begin ...')
+        for _event in self.contractor.contract_events():
+            if isinstance(_event, ReadyForAggregationEvent):
+                return
+
+    def _wait_for_closing_round(self):
+        """Wait for closing current round of training."""
+        self.push_log(f'Waiting for closing signal of training round {self.round} ...')
+        for _event in self.contractor.contract_events():
+            if isinstance(_event, CloseRoundEvent):
+                return
+
+    def _close_task(self, is_succ: bool = True):
+        """Close the FedAvg calculation.
+
+        As an aggregator, broadcasts the finish task event to all participants,
+        uploads the final parameters and tells L1 task manager the task is complete.
+        As a participant, do nothing.
+        """
+        self.push_log(f'Closing task {self.task_id} ...')
+        if self.is_initiator:
+            self._switch_status(self._FINISHING)
+            report_file_path, model_file_path = self._prepare_task_output()
+            self.contractor.upload_metric_report(receivers=self.contractor.EVERYONE,
+                                                 report_file=report_file_path)
+            self.contractor.upload_model(receivers=self.contractor.EVERYONE,
+                                         model_file=model_file_path)
+            self.contractor.notify_task_completion(result=True)
+        self.push_log(f'Task {self.task_id} closed. Byebye!')
+
+    def _prepare_task_output(self) -> Tuple[str, str]:
+        """Generate final output files of the task.
+
+        Return:
+            Local paths of the report file and model file.
+        """
+        self.push_log('Uploading task achievement and closing task ...')
+
+        os.makedirs(self._result_dir, exist_ok=True)
+
+        report_file = os.path.join(self._result_dir, "report.zip")
+        with ZipFile(report_file, 'w') as report_zip:
+            for path, _, filenames in os.walk(self._log_dir):
+                rel_dir = os.path.relpath(path=path, start=self._result_dir)
+                rel_dir = rel_dir.lstrip('.')  # ./file => file
+                for _file in filenames:
+                    rel_path = os.path.join(rel_dir, _file)
+                    report_zip.write(os.path.join(path, _file), rel_path)
+        report_file_path = os.path.abspath(report_file)
+
+        model_file = os.path.join(self._result_dir, "model.pt")
+        with open(model_file, 'wb') as f:
+            torch.save(self.state_dict(), f)
+        model_file_path = os.path.abspath(model_file)
+
+        self.push_log('Task achievement files are ready.')
+        return report_file_path, model_file_path
```

### Comparing `alphamed-federated-0.4.7/src/alphafed/docs/customized_scheduler/simple_task.py` & `alphamed-federated-0.4.9/src/alphafed/docs/customized_scheduler/simple_task.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/docs/fed_avg/net.py` & `alphamed-federated-0.4.9/src/alphafed/docs/fed_avg/net.py`

 * *Ordering differences only*

 * *Files 10% similar despite different names*

```diff
@@ -1,21 +1,21 @@
-from torch import nn
-import torch.nn.functional as F
-
-
-class ConvNet(nn.Module):
-    def __init__(self) -> None:
-        super().__init__()
-        self.conv1 = nn.Conv2d(in_channels=1, out_channels=10, kernel_size=5)
-        self.conv2 = nn.Conv2d(in_channels=10, out_channels=20, kernel_size=5)
-        self.conv2_drop = nn.Dropout2d()
-        self.fc1 = nn.Linear(in_features=320, out_features=50)
-        self.fc2 = nn.Linear(in_features=50, out_features=10)
-
-    def forward(self, x):
-        x = F.relu(F.max_pool2d(self.conv1(x), 2))
-        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))
-        x = x.view(-1, 320)
-        x = F.relu(self.fc1(x))
-        x = F.dropout(x, training=self.training)
-        x = self.fc2(x)
-        return F.log_softmax(x, dim=-1)
+from torch import nn
+import torch.nn.functional as F
+
+
+class ConvNet(nn.Module):
+    def __init__(self) -> None:
+        super().__init__()
+        self.conv1 = nn.Conv2d(in_channels=1, out_channels=10, kernel_size=5)
+        self.conv2 = nn.Conv2d(in_channels=10, out_channels=20, kernel_size=5)
+        self.conv2_drop = nn.Dropout2d()
+        self.fc1 = nn.Linear(in_features=320, out_features=50)
+        self.fc2 = nn.Linear(in_features=50, out_features=10)
+
+    def forward(self, x):
+        x = F.relu(F.max_pool2d(self.conv1(x), 2))
+        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))
+        x = x.view(-1, 320)
+        x = F.relu(self.fc1(x))
+        x = F.dropout(x, training=self.training)
+        x = self.fc2(x)
+        return F.log_softmax(x, dim=-1)
```

### Comparing `alphamed-federated-0.4.7/src/alphafed/docs/mock/net.py` & `alphamed-federated-0.4.9/src/alphafed/docs/mock/net.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/docs/mock/scheduler.py` & `alphamed-federated-0.4.9/src/alphafed/docs/mock/scheduler.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/docs/tutorial/res/auto_model_fed_avg/auto_fed_avg.py` & `alphamed-federated-0.4.9/src/alphafed/docs/tutorial/res/auto_model_fed_avg/auto_fed_avg.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/docs/tutorial/res/auto_model_fed_avg/res_net.py` & `alphamed-federated-0.4.9/src/alphafed/docs/tutorial/res/auto_model_fed_avg/res_net.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/docs/tutorial/res/auto_model_local/auto.py` & `alphamed-federated-0.4.9/src/alphafed/docs/tutorial/res/auto_model_local/auto.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/docs/tutorial/res/auto_model_local/res_net.py` & `alphamed-federated-0.4.9/src/alphafed/docs/tutorial/res/auto_model_local/res_net.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/docs/tutorial/res/cnn_net.py` & `alphamed-federated-0.4.9/src/alphafed/docs/tutorial/res/cnn_net.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/docs/tutorial/res/simple_fed_avg/contractor.py` & `alphamed-federated-0.4.9/src/alphafed/docs/tutorial/res/simple_fed_avg/contractor.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/docs/tutorial/res/simple_fed_avg/scheduler.py` & `alphamed-federated-0.4.9/src/alphafed/docs/tutorial/res/simple_fed_avg/scheduler.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/breast_density_classification/__init__.py` & `alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/breast_density_classification/__init__.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/breast_density_classification/clean_history_msg.py` & `alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/breast_density_classification/clean_history_msg.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/breast_density_classification/res_fed_avg/auto.py` & `alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/breast_density_classification/res_local/auto.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,700 +1,691 @@
-# Copyright 2022 Alphamed
-
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-
-#     http://www.apache.org/licenses/LICENSE-2.0
-
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-
-"""Pretraining breast_density_classification models and schedulers.
-
-Reference: https://arxiv.org/abs/2202.08238
-"""
-
-import json
-import os
-from copy import deepcopy
-from dataclasses import InitVar, asdict, dataclass
-from typing import Dict, List, Optional, Tuple, overload
-
-import torch
-import torch.nn.functional as F
-from alphafed import get_result_dir, logger
-from alphafed.auto_ml.auto_model import (AutoFedAvgModel, AutoFedAvgScheduler,
-                                         AutoModel, DatasetMode,
-                                         MandatoryConfig, Preprocessor)
-from alphafed.auto_ml.cvat.annotation import ImageAnnotationUtils
-from alphafed.auto_ml.exceptions import AutoModelError, ConfigError
-from PIL import Image
-from torch import nn, optim
-from torch.utils.data import DataLoader, Dataset
-from torchvision import transforms
-
-from inception3 import Inception3
-
-
-@dataclass
-class PreprocessorConfig:
-
-    size: int
-    do_affine: bool
-    degrees: int
-    translate: Tuple[float]
-    do_horizontal_flip: bool
-
-    def __post_init__(self):
-        self.translate = tuple(self.translate)
-
-
-class InceptionPreprocessor(Preprocessor):
-
-    def __init__(self, mode: DatasetMode, config: PreprocessorConfig) -> None:
-        layers = []
-        if mode == DatasetMode.TRAINING:
-            if config.do_affine:
-                layers.append(transforms.RandomAffine(degrees=config.degrees,
-                                                      translate=config.translate))
-            if config.do_horizontal_flip:
-                layers.append(transforms.RandomHorizontalFlip())
-        layers.append(transforms.ToTensor())
-        layers.append(transforms.Lambda(lambda image: self._resize(image=image,
-                                                                   size=config.size)))
-        self._transformer = transforms.Compose(layers)
-
-    def _resize(self, image: torch.Tensor, size: int):
-        image = image.permute(0, 2, 1)
-        image = F.interpolate(input=image.unsqueeze(0), size=[size, size], mode='area')
-        return image.squeeze()
-
-    def transform(self, image_file: str) -> torch.Tensor:
-        """Transform an image object into an input tensor."""
-        image = Image.open(image_file).convert('RGB')
-        return self._transformer(image)
-
-
-class InceptionDataset(Dataset):
-
-    def __init__(self,
-                 image_dir: str,
-                 annotation_file: str,
-                 mode: DatasetMode,
-                 config: PreprocessorConfig) -> None:
-        """Init a dataset instance for ResNet auto model families.
-
-        Args:
-            image_dir:
-                The directory including image files.
-            annotation_file:
-                The file including annotation information.
-            mode:
-                One of training or validation or testing.
-            config:
-                The configuration for the preprocessor.
-        """
-        super().__init__()
-        if not image_dir or not isinstance(image_dir, str):
-            raise ConfigError(f'Invalid image directory: {image_dir}.')
-        if not annotation_file or not isinstance(annotation_file, str):
-            raise ConfigError(f'Invalid annotation file path: {annotation_file}.')
-        assert mode and isinstance(mode, DatasetMode), f'Invalid dataset mode: {mode}.'
-        if not os.path.exists(image_dir) or not os.path.isdir(image_dir):
-            raise ConfigError(f'{image_dir} does not exist or is not a directory.')
-        if not os.path.exists(annotation_file) or not os.path.isfile(annotation_file):
-            raise ConfigError(f'{annotation_file} does not exist or is not a file.')
-
-        self.image_dir = image_dir
-        self.annotation_file = annotation_file
-        self.transformer = InceptionPreprocessor(mode=mode, config=config)
-
-        self.images, self.labels = ImageAnnotationUtils.parse_single_category_annotation(
-            annotation_file=self.annotation_file, resource_dir=image_dir, mode=mode
-        )
-
-    def __getitem__(self, index: int):
-        _item = self.images[index]
-        return self.transformer(_item.image_file), _item.class_label
-
-    def __len__(self):
-        return len(self.images)
-
-
-@dataclass
-class ModelConfig(MandatoryConfig):
-
-    id2label: dict
-    label2id: dict
-    learning_rate: int
-    batch_size: int
-    epochs: int
-    image_size: int = 299
-    torch_dtype: InitVar[str] = 'float32'
-
-    def __post_init__(self, torch_dtype: str):
-        super().__post_init__()
-
-        for _label in self.id2label.values():
-            if _label not in self.label2id:
-                raise TypeError(f'Label `{_label}` lost its ID in label2id map.')
-        for _id in self.label2id.values():
-            if str(_id) not in self.id2label:
-                raise TypeError(f'ID `{_id}` lost its label in id2label map.')
-
-        if self.learning_rate <= 0:
-            raise TypeError(f'Invalid learning_rate: `{self.learning_rate}`.')
-        if self.batch_size <= 0:
-            raise TypeError(f'Invalid batch_size: `{self.batch_size}`.')
-        if self.epochs <= 0:
-            raise TypeError(f'Invalid epochs: `{self.epochs}`.')
-
-        if self.image_size <= 0:
-            raise TypeError(f'Invalid image_size: `{self.image_size}`.')
-
-        if torch_dtype == 'float32' or torch_dtype == 'float':
-            self.torch_dtype = torch.float32
-        elif torch_dtype == 'float64':
-            self.torch_dtype = torch.float64
-        elif torch == 'float16':
-            self.torch_dtype = torch.float16
-        else:
-            raise TypeError(f'Invalid torch_dtype: `{torch_dtype}`.')
-
-
-class AutoInception(AutoModel):
-
-    def __init__(self, resource_dir: str, **kwargs) -> None:
-        super().__init__(resource_dir=resource_dir)
-
-        self.config, self.preprocessor_config = self._load_config()
-        self.epochs = self.config.epochs
-        self.batch_size = self.config.batch_size
-        self._lr = self.config.learning_rate
-        self._epoch = 0
-        self.is_cuda = torch.cuda.is_available()
-
-        self.dataset_dir = None
-        self.labels: List[str] = []
-
-        self._best_result = 0
-        self._best_state = None
-        self._overfit_index = 0
-        self._is_dataset_initialized = False
-        self._save_root = '.cache'
-
-    def _load_config(self) -> Tuple[ModelConfig, PreprocessorConfig]:
-        config_file = os.path.join(self.resource_dir, 'config.json')
-        if not os.path.isfile(config_file):
-            raise ConfigError('Config file missing.')
-        try:
-            with open(config_file, 'r') as f:
-                config_json = json.load(f)
-        except json.JSONDecodeError:
-            raise ConfigError('Failed to parse config file.')
-        model_config = ModelConfig(**config_json)
-
-        preprocessor_config_file = os.path.join(self.resource_dir, 'preprocessor_config.json')
-        if not os.path.isfile(preprocessor_config_file):
-            raise ConfigError('Preprocessor config file missing.')
-        try:
-            with open(preprocessor_config_file, 'r') as f:
-                preprocessor_config_json = json.load(f)
-        except json.JSONDecodeError:
-            raise ConfigError('Failed to parse preprocessor config file.')
-        preprocessor_config = PreprocessorConfig(**preprocessor_config_json)
-
-        return model_config, preprocessor_config
-
-    def init_dataset(self, dataset_dir: str) -> Tuple[bool, str]:
-        self.dataset_dir = dataset_dir
-        try:
-            if not self._is_dataset_initialized:
-                self.training_loader
-                self.validation_loader
-                self.testing_loader
-                if not self.training_loader or not self.testing_loader:
-                    logger.error('Both training data and testing data are missing.')
-                    return False, 'Must provide train dataset and test dataset to fine tune.'
-                self.labels = self.training_loader.dataset.labels
-                self._is_dataset_initialized = True
-            return True, 'Initializing dataset complete.'
-        except Exception:
-            logger.exception('Failed to initialize dataset.')
-            return False, '初始化数据失败，请联系模型作者排查原因。'
-
-    @property
-    def annotation_file(self):
-        return os.path.join(self.dataset_dir, 'annotation.json') if self.dataset_dir else None
-
-    @property
-    def training_loader(self) -> DataLoader:
-        """Return a dataloader instance of training data.
-
-        Data augmentation is used to improve performance, so we need to generate a new dataset
-        every epoch in case of training on a same dataset over and over again.
-        """
-        if not hasattr(self, "_training_loader"):
-            self._training_loader = self._build_training_data_loader()
-        return self._training_loader
-
-    def _build_training_data_loader(self) -> Optional[DataLoader]:
-        dataset = InceptionDataset(image_dir=self.dataset_dir,
-                                   annotation_file=self.annotation_file,
-                                   mode=DatasetMode.TRAINING,
-                                   config=self.preprocessor_config)
-        if len(dataset) == 0:
-            return None
-        return DataLoader(dataset=dataset,
-                          batch_size=self.batch_size,
-                          shuffle=True)
-
-    @property
-    def validation_loader(self) -> DataLoader:
-        """Return a dataloader instance of validation data."""
-        if not hasattr(self, "_validation_loader"):
-            self._validation_loader = self._build_validation_data_loader()
-        return self._validation_loader
-
-    def _build_validation_data_loader(self) -> DataLoader:
-        dataset = InceptionDataset(image_dir=self.dataset_dir,
-                                   annotation_file=self.annotation_file,
-                                   mode=DatasetMode.VALIDATION,
-                                   config=self.preprocessor_config)
-        if len(dataset) == 0:
-            return None
-        return DataLoader(dataset=dataset, batch_size=self.batch_size)
-
-    @property
-    def testing_loader(self) -> DataLoader:
-        """Return a dataloader instance of testing data."""
-        if not hasattr(self, "_testing_loader"):
-            self._testing_loader = self._build_testing_data_loader()
-        return self._testing_loader
-
-    def _build_testing_data_loader(self) -> DataLoader:
-        dataset = InceptionDataset(image_dir=self.dataset_dir,
-                                   annotation_file=self.annotation_file,
-                                   mode=DatasetMode.TESTING,
-                                   config=self.preprocessor_config)
-        if len(dataset) == 0:
-            return None
-        return DataLoader(dataset=dataset, batch_size=self.batch_size)
-
-    def _build_model(self):
-        pretrained_num_classes = 4
-        self._model: nn.Module = Inception3(num_classes=pretrained_num_classes,
-                                            init_weights=False)
-
-        self.labels = list(self.config.id2label.values())
-        self._replace_fc_if_diff(len(self.labels))
-
-        param_file = os.path.join(self.resource_dir, self.config.param_file)
-        with open(param_file, 'rb') as f:
-            state_dict = torch.load(f)
-            if self._model.get_parameter('fc.weight').shape[0] != state_dict['fc.weight'].shape[0]:
-                raise AutoModelError('The fine tuned labels dismatched the parameters.')
-            # The original pretrained model's AuxLogits is set with a wrong number of classes(1000)
-            if (
-                self._model.get_parameter('AuxLogits.fc.weight').shape[0]
-                != state_dict['AuxLogits.fc.weight'].shape[0]
-            ):
-                state_dict.pop('AuxLogits.fc.weight')
-                state_dict.pop('AuxLogits.fc.bias')
-                self._model.load_state_dict(state_dict, strict=False)
-            else:
-                self._model.load_state_dict(state_dict)
-
-        return self._model.cuda() if self.is_cuda else self._model
-
-    def _replace_fc_if_diff(self, num_classes: int):
-        """Replace the classify layer with new number of classes."""
-        assert (
-            num_classes and isinstance(num_classes, int) and num_classes > 0
-        ), f'Invalid number of classes: {num_classes} .'
-        if num_classes != self.num_classes:
-            if self.model.aux_logits:
-                self.model.AuxLogits.fc = nn.Linear(768, num_classes)
-                self.model.AuxLogits.fc.stddev = 0.001
-            self.model.fc = nn.Linear(2048, num_classes)
-
-    @property
-    def num_classes(self) -> int:
-        """Return the number of classes of the classification layer of the model."""
-        return self.model.get_parameter('fc.weight').shape[0]
-
-    @property
-    def model(self) -> nn.Module:
-        if not hasattr(self, '_model'):
-            self._model = self._build_model()
-        return self._model
-
-    @property
-    def optimizer(self) -> optim.Optimizer:
-        if not hasattr(self, '_optimizer'):
-            self._optimizer = optim.RMSprop(self.model.parameters(),
-                                            lr=self.lr,
-                                            alpha=0.9,
-                                            eps=1.0,
-                                            momentum=0.9)
-        else:
-            # update lr
-            latest_lr = self.lr
-            for param_group in self._optimizer.param_groups:
-                param_group['lr'] = latest_lr
-        return self._optimizer
-
-    @property
-    def lr(self) -> float:
-        return self._lr * 0.94**((self._epoch - 1) // 2)
-
-    def train(self):
-        self.model.train()
-
-    def eval(self):
-        self.model.eval()
-
-    @overload
-    def forward(self, input: torch.Tensor) -> str:
-        """Predict an image's tensor and give its label."""
-
-    @overload
-    def forward(self, input: str) -> str:
-        """Predict an image defined by a file path and give its label."""
-
-    @torch.no_grad()
-    def forward(self, input) -> str:
-        if not input or not isinstance(input, (str, torch.Tensor)):
-            raise AutoModelError(f'Invalid input data: {input}.')
-        if isinstance(input, str):
-            if not os.path.isfile(input):
-                raise AutoModelError(f'Cannot find or access the image file {input}.')
-            preprocessor = InceptionPreprocessor(mode=DatasetMode.PREDICTING,
-                                                 config=self.preprocessor_config)
-            input = preprocessor.transform(input)
-            input.unsqueeze_(0)
-
-        self.model.eval()
-        input = input.expand(2, 3, 299, 299)  # TODO train mode doesn't accept single input
-        output = self.model(input)
-        predict = output.argmax(1)[0].item()
-        if not self.labels:
-            with open(os.path.join(self.resource_dir, 'fine_tuned.meta')) as f:
-                fine_tuned_json: dict = json.loads(f)
-                self.labels = fine_tuned_json.get('labels')
-        return self.labels[predict]
-
-    def _train_an_epoch(self):
-        self.train()
-        for images, targets in self.training_loader:
-            if self.is_cuda:
-                images, targets = images.cuda(), targets.cuda()
-            outputs, aux_outputs = self.model(images)
-            loss_1 = F.cross_entropy(outputs, targets)
-            loss_2 = F.cross_entropy(aux_outputs, targets)
-            loss = loss_1 + 0.4 * loss_2
-            self.optimizer.zero_grad()
-            loss.backward()
-            self.optimizer.step()
-
-    @torch.no_grad()
-    def _run_test(self) -> Tuple[float, float]:
-        """Run a test and report the result.
-
-        Return:
-            avg_loss, correct_rate
-        """
-        self.push_log(f'Begin testing of epoch {self._epoch}.')
-        self.eval()
-        total_loss = 0
-        total_correct = 0
-        for images, targets in self.testing_loader:
-            if self.is_cuda:
-                images, targets = images.cuda(), targets.cuda()
-            outputs = self.model(images)
-            loss = F.cross_entropy(outputs, targets, reduction='sum').item()
-            total_loss += loss
-            pred = outputs.max(1, keepdim=True)[1]
-            total_correct += pred.eq(targets.view_as(pred)).sum().item()
-
-        avg_loss = total_loss / len(self.testing_loader.dataset)
-        correct_rate = total_correct / len(self.testing_loader.dataset) * 100
-        logger.info(f'Average Loss: {avg_loss:.4f}')
-        logger.info(f'Correct rate: {correct_rate:.2f}')
-
-        return avg_loss, correct_rate
-
-    @torch.no_grad()
-    def _run_validation(self) -> Tuple[float, float]:
-        """Run a round of validation and report the result.
-
-        Return:
-            avg_loss, correct_rate
-        """
-        self.push_log(f'Begin validation of epoch {self._epoch}.')
-        self.eval()
-        total_loss = 0
-        total_correct = 0
-        for images, targets in self.validation_loader:
-            if self.is_cuda:
-                images, targets = images.cuda(), targets.cuda()
-            outputs = self.model(images)
-            loss = F.cross_entropy(outputs, targets, reduction='sum').item()
-            total_loss += loss
-            pred = outputs.max(1, keepdim=True)[1]
-            total_correct += pred.eq(targets.view_as(pred)).sum().item()
-
-        avg_loss = total_loss / len(self.validation_loader.dataset)
-        correct_rate = total_correct / len(self.validation_loader.dataset) * 100
-        logger.info(f'Average Loss: {avg_loss:.4f}')
-        logger.info(f'Correct rate: {correct_rate:.2f}')
-
-        return avg_loss, correct_rate
-
-    @torch.no_grad()
-    def _is_finished(self) -> bool:
-        """Decide if stop training.
-
-        If there are validation dataset, decide depending on validatation results. If
-        the validation result of current epoch is below the best record for 10 continuous
-        times, then stop training.
-        If there are no validation dataset, run for `epochs` (default 20) times.
-        """
-        if not self.validation_loader or len(self.validation_loader) == 0:
-            if self._epoch >= self.epochs:
-                self._best_state = deepcopy(self.model.state_dict())
-            return self._epoch >= self.epochs
-        # make a validation
-        self.push_log(f'Begin validation of epoch {self._epoch}.')
-        avg_loss, correct_rate = self._run_validation()
-        self.push_log('\n'.join(('Validation result:',
-                                 f'avg_loss={avg_loss:.4f}',
-                                 f'correct_rate={correct_rate:.2f}')))
-
-        if correct_rate > self._best_result:
-            self._overfit_index = 0
-            self._best_result = correct_rate
-            self._best_state = deepcopy(self.model.state_dict())
-            self.push_log('Validation result is better than last epoch.')
-            return self._epoch >= self.epochs
-        else:
-            self._overfit_index += 1
-            msg = f'Validation result gets worse for {self._overfit_index} consecutive times.'
-            self.push_log(msg)
-            return self._overfit_index >= 10 or self._epoch >= self.epochs
-
-    def fine_tune(self,
-                  id: str,
-                  task_id: str,
-                  dataset_dir: str,
-                  is_initiator: bool = False,
-                  is_debug_script: bool = False):
-        self.id = id
-        self.task_id = task_id
-        self.is_initiator = is_initiator
-        self.is_debug_script = is_debug_script
-
-        is_succ, err_msg = self.init_dataset(dataset_dir)
-        if not is_succ:
-            raise AutoModelError(f'Failed to initialize dataset. {err_msg}')
-        num_classes = (len(self.training_loader.dataset.labels)
-                       if self.training_loader
-                       else len(self.testing_loader.dataset.labels))
-        self._replace_fc_if_diff(num_classes)
-
-        self.config.id2label = {str(_idx): _label for _idx, _label in enumerate(self.labels)}
-        self.config.label2id = {_label: _idx for _idx, _label in enumerate(self.labels)}
-        self.config.label2id = dict(sorted(self.config.label2id.items()))
-
-        is_finished = False
-        self._epoch = 0
-        while not is_finished:
-            self._epoch += 1
-            self.push_log(f'Begin training of epoch {self._epoch}.')
-            self._train_an_epoch()
-            self.push_log(f'Complete training of epoch {self._epoch}.')
-            is_finished = self._is_finished()
-
-        self._save_fine_tuned()
-        avg_loss, correct_rate = self._run_test()
-        self.push_log('\n'.join(('Testing result:',
-                                 f'avg_loss={avg_loss:.4f}',
-                                 f'correct_rate={correct_rate:.2f}')))
-
-    def _save_fine_tuned(self):
-        """Save the best or final state of fine tuning."""
-        self.result_dir = get_result_dir(self.task_id)
-        os.makedirs(self.result_dir, exist_ok=True)
-        with open(os.path.join(self.result_dir, self.config.param_file), 'wb') as f:
-            torch.save(self._best_state, f)
-        with open(os.path.join(self.result_dir, 'config.json'), 'w') as f:
-            f.write(json.dumps(asdict(self.config), ensure_ascii=False))
-
-
-class AutoInceptionFedAvg(AutoInception, AutoFedAvgModel):
-
-    def state_dict(self) -> Dict[str, torch.Tensor]:
-        return self.model.state_dict()
-
-    def load_state_dict(self, state_dict: Dict[str, torch.Tensor]):
-        return self.model.load_state_dict(state_dict)
-
-    def train_an_epoch(self):
-        self._epoch += 1
-        self._train_an_epoch()
-
-    def run_test(self) -> Tuple[float, float]:
-        """Run a test and report the result.
-
-        Return:
-            avg_loss, correct_rate
-        """
-        return self._run_test()
-
-    def run_validation(self):
-        """Run a test and report the result.
-
-        Return:
-            avg_loss, correct_rate
-        """
-        return self._run_validation()
-
-    def init_dataset(self, dataset_dir: str) -> Tuple[bool, str]:
-        self.dataset_dir = dataset_dir
-        try:
-            if not self._is_dataset_initialized:
-                self.training_loader
-                self.validation_loader
-                self.testing_loader
-                if not self.training_loader and not self.testing_loader:
-                    logger.error('Both training data and testing data are missing.')
-                    err_msg = ' '.join((
-                        'The initiator must provide test dataset.',
-                        'The collaborator must provide train dataset.'
-                    ))
-                    return False, err_msg
-                self.labels = (self.training_loader.dataset.labels
-                               if self.training_loader
-                               else self.testing_loader.dataset.labels)
-                self._is_dataset_initialized = True
-            return True, 'Initializing dataset complete.'
-        except Exception:
-            logger.exception('Failed to initialize dataset.')
-            return False, '初始化数据失败，请联系模型作者排查原因。'
-
-    def fine_tune(self,
-                  id: str,
-                  task_id: str,
-                  dataset_dir: str,
-                  is_initiator: bool = False,
-                  recover: bool = False):
-        is_succ, err_msg = self.init_dataset(dataset_dir)
-        if not is_succ:
-            raise AutoModelError(f'Failed to initialize dataset. {err_msg}')
-        num_classes = (len(self.training_loader.dataset.labels)
-                       if self.training_loader
-                       else len(self.testing_loader.dataset.labels))
-        self._replace_fc_if_diff(num_classes)
-
-        self.config.id2label = {str(_idx): _label for _idx, _label in enumerate(self.labels)}
-        self.config.label2id = {_label: _idx for _idx, _label in enumerate(self.labels)}
-        self.config.label2id = dict(sorted(self.config.label2id.items()))
-
-        self._fine_tune_impl(id=id,
-                             task_id=task_id,
-                             dataset_dir=dataset_dir,
-                             scheduler_impl=InceptionFedAvgScheduler,
-                             is_initiator=is_initiator,
-                             recover=recover,
-                             max_rounds=self.config.epochs,
-                             log_rounds=1)
-
-    def fine_tuned_files_dict(self) -> Optional[Dict[str, str]]:
-        param_file = os.path.join(self.result_dir, self.config.param_file)
-        with open(param_file, 'wb') as f:
-            torch.save(self.scheduler.best_state_dict, f)
-        config_file = os.path.join(self.result_dir, 'config.json')
-        with open(config_file, 'w') as f:
-            f.write(json.dumps(asdict(self.config), ensure_ascii=False))
-        return {
-            self.config.param_file: param_file,
-            'config.json': config_file
-        }
-
-
-class InceptionFedAvgScheduler(AutoFedAvgScheduler):
-
-    def __init__(self,
-                 auto_proxy: AutoInceptionFedAvg,
-                 max_rounds: int = 0,
-                 merge_epochs: int = 1,
-                 calculation_timeout: int = 300,
-                 schedule_timeout: int = 30,
-                 log_rounds: int = 0,
-                 involve_aggregator: bool = False):
-        super().__init__(auto_proxy=auto_proxy,
-                         max_rounds=max_rounds,
-                         merge_epochs=merge_epochs,
-                         calculation_timeout=calculation_timeout,
-                         schedule_timeout=schedule_timeout,
-                         log_rounds=log_rounds,
-                         involve_aggregator=involve_aggregator)
-        self._best_state = None
-        self._best_result = 0
-        self._overfit_index = 0
-
-    @property
-    def best_state_dict(self) -> Dict[str, torch.Tensor]:
-        return self._best_state
-
-    def validate_context(self):
-        super().validate_context()
-        if self.is_initiator:
-            assert self.test_loader and len(self.test_loader) > 0, 'failed to load test data'
-            self.push_log(f'There are {len(self.test_loader.dataset)} samples for testing.')
-        else:
-            assert self.train_loader and len(self.train_loader) > 0, 'failed to load train data'
-            self.push_log(f'There are {len(self.train_loader.dataset)} samples for training.')
-
-    def train_an_epoch(self):
-        self.auto_proxy.train_an_epoch()
-
-    def run_test(self):
-        avg_loss, correct_rate = self.auto_proxy.run_test()
-
-        self.tb_writer.add_scalar('test_results/avg_loss', avg_loss, self.current_round)
-        self.tb_writer.add_scalar('test_results/correct_rate', correct_rate, self.current_round)
-
-    def is_task_finished(self) -> bool:
-        """Decide if stop training.
-
-        If there are validation dataset, decide depending on validatation results. If
-        the validation result of current epoch is below the best record for 10 continuous
-        times, then stop training.
-        If there are no validation dataset, run for `max_rounds` times.
-        """
-        if not self.validation_loader or len(self.validation_loader) == 0:
-            self._best_state = deepcopy(self.state_dict())
-            return self._is_reach_max_rounds()
-
-        # make a validation
-        self.push_log(f'Begin validation of round {self.current_round}.')
-        avg_loss, correct_rate = self.auto_proxy.run_validation()
-        self.push_log('\n'.join(('Validation result:',
-                                 f'avg_loss={avg_loss:.4f}',
-                                 f'correct_rate={correct_rate:.2f}')))
-
-        if correct_rate > self._best_result:
-            self._overfit_index = 0
-            self._best_result = correct_rate
-            self._best_state = deepcopy(self.state_dict())
-            self.push_log('Validation result is better than last epoch.')
-            return self._is_reach_max_rounds()
-        else:
-            self._overfit_index += 1
-            msg = f'Validation result gets worse for {self._overfit_index} consecutive times.'
-            self.push_log(msg)
-            return self._overfit_index >= 10 or self._is_reach_max_rounds()
+# Copyright 2022 Alphamed
+
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+
+#     http://www.apache.org/licenses/LICENSE-2.0
+
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+"""Pretraining breast_density_classification models and schedulers.
+
+Reference: https://arxiv.org/abs/2202.08238
+"""
+
+import json
+import os
+from copy import deepcopy
+from dataclasses import InitVar, asdict, dataclass
+from typing import Dict, List, Optional, Tuple, overload
+
+import torch
+import torch.nn.functional as F
+from inception3 import Inception3
+from PIL import Image
+from torch import nn, optim
+from torch.utils.data import DataLoader, Dataset
+from torchvision import transforms
+
+from alphafed import get_result_dir, logger
+from alphafed.auto_ml.auto_model import (AutoFedAvgModel, AutoFedAvgScheduler,
+                                         AutoModel, DatasetMode,
+                                         MandatoryConfig, Preprocessor)
+from alphafed.auto_ml.cvat.annotation import ImageAnnotationUtils
+from alphafed.auto_ml.exceptions import AutoModelError, ConfigError
+
+
+@dataclass
+class PreprocessorConfig:
+
+    size: int
+    do_affine: bool
+    degrees: int
+    translate: Tuple[float]
+    do_horizontal_flip: bool
+
+    def __post_init__(self):
+        self.translate = tuple(self.translate)
+
+
+class InceptionPreprocessor(Preprocessor):
+
+    def __init__(self, mode: DatasetMode, config: PreprocessorConfig) -> None:
+        layers = []
+        if mode == DatasetMode.TRAINING:
+            if config.do_affine:
+                layers.append(transforms.RandomAffine(degrees=config.degrees,
+                                                      translate=config.translate))
+            if config.do_horizontal_flip:
+                layers.append(transforms.RandomHorizontalFlip())
+        layers.append(transforms.ToTensor())
+        layers.append(transforms.Lambda(lambda image: self._resize(image=image,
+                                                                   size=config.size)))
+        self._transformer = transforms.Compose(layers)
+
+    def _resize(self, image: torch.Tensor, size: int):
+        image = image.permute(0, 2, 1)
+        image = F.interpolate(input=image.unsqueeze(0), size=[size, size], mode='area')
+        return image.squeeze()
+
+    def transform(self, image_file: str) -> torch.Tensor:
+        """Transform an image object into an input tensor."""
+        image = Image.open(image_file).convert('RGB')
+        return self._transformer(image)
+
+
+class InceptionDataset(Dataset):
+
+    def __init__(self,
+                 image_dir: str,
+                 annotation_file: str,
+                 mode: DatasetMode,
+                 config: PreprocessorConfig) -> None:
+        """Init a dataset instance for ResNet auto model families.
+
+        Args:
+            image_dir:
+                The directory including image files.
+            annotation_file:
+                The file including annotation information.
+            mode:
+                One of training or validation or testing.
+            config:
+                The configuration for the preprocessor.
+        """
+        super().__init__()
+        if not image_dir or not isinstance(image_dir, str):
+            raise ConfigError(f'Invalid image directory: {image_dir}.')
+        if not annotation_file or not isinstance(annotation_file, str):
+            raise ConfigError(f'Invalid annotation file path: {annotation_file}.')
+        assert mode and isinstance(mode, DatasetMode), f'Invalid dataset mode: {mode}.'
+        if not os.path.exists(image_dir) or not os.path.isdir(image_dir):
+            raise ConfigError(f'{image_dir} does not exist or is not a directory.')
+        if not os.path.exists(annotation_file) or not os.path.isfile(annotation_file):
+            raise ConfigError(f'{annotation_file} does not exist or is not a file.')
+
+        self.image_dir = image_dir
+        self.annotation_file = annotation_file
+        self.transformer = InceptionPreprocessor(mode=mode, config=config)
+
+        self.images, self.labels = ImageAnnotationUtils.parse_single_category_annotation(
+            annotation_file=self.annotation_file, resource_dir=image_dir, mode=mode
+        )
+
+    def __getitem__(self, index: int):
+        _item = self.images[index]
+        return self.transformer(_item.image_file), _item.class_label
+
+    def __len__(self):
+        return len(self.images)
+
+
+@dataclass
+class ModelConfig(MandatoryConfig):
+
+    id2label: dict
+    label2id: dict
+    learning_rate: int
+    batch_size: int
+    epochs: int
+    image_size: int = 299
+    torch_dtype: InitVar[str] = 'float32'
+
+    def __post_init__(self, torch_dtype: str):
+        super().__post_init__()
+
+        for _label in self.id2label.values():
+            if _label not in self.label2id:
+                raise TypeError(f'Label `{_label}` lost its ID in label2id map.')
+        for _id in self.label2id.values():
+            if str(_id) not in self.id2label:
+                raise TypeError(f'ID `{_id}` lost its label in id2label map.')
+
+        if self.learning_rate <= 0:
+            raise TypeError(f'Invalid learning_rate: `{self.learning_rate}`.')
+        if self.batch_size <= 0:
+            raise TypeError(f'Invalid batch_size: `{self.batch_size}`.')
+        if self.epochs <= 0:
+            raise TypeError(f'Invalid epochs: `{self.epochs}`.')
+
+        if self.image_size <= 0:
+            raise TypeError(f'Invalid image_size: `{self.image_size}`.')
+
+        if torch_dtype == 'float32' or torch_dtype == 'float':
+            self.torch_dtype = torch.float32
+        elif torch_dtype == 'float64':
+            self.torch_dtype = torch.float64
+        elif torch == 'float16':
+            self.torch_dtype = torch.float16
+        else:
+            raise TypeError(f'Invalid torch_dtype: `{torch_dtype}`.')
+
+
+class AutoInception(AutoModel):
+
+    def __init__(self, resource_dir: str, **kwargs) -> None:
+        super().__init__(resource_dir=resource_dir)
+
+        self.config, self.preprocessor_config = self._load_config()
+        self.epochs = self.config.epochs
+        self.batch_size = self.config.batch_size
+        self._lr = self.config.learning_rate
+        self._epoch = 0
+        # 测试部署服务暂时不支持 GPU 环境，使用 GPU 版本会导致部署失败
+        # self.is_cuda = torch.cuda.is_available()
+        self.is_cuda = False
+
+        self.dataset_dir = None
+        self.labels: List[str] = []
+
+        self._best_result = 0
+        self._best_state = None
+        self._overfit_index = 0
+        self._is_dataset_initialized = False
+        self._save_root = '.cache'
+
+    def _load_config(self) -> Tuple[ModelConfig, PreprocessorConfig]:
+        config_file = os.path.join(self.resource_dir, 'config.json')
+        if not os.path.isfile(config_file):
+            raise ConfigError('Config file missing.')
+        try:
+            with open(config_file, 'r') as f:
+                config_json = json.load(f)
+        except json.JSONDecodeError:
+            raise ConfigError('Failed to parse config file.')
+        model_config = ModelConfig(**config_json)
+
+        preprocessor_config_file = os.path.join(self.resource_dir, 'preprocessor_config.json')
+        if not os.path.isfile(preprocessor_config_file):
+            raise ConfigError('Preprocessor config file missing.')
+        try:
+            with open(preprocessor_config_file, 'r') as f:
+                preprocessor_config_json = json.load(f)
+        except json.JSONDecodeError:
+            raise ConfigError('Failed to parse preprocessor config file.')
+        preprocessor_config = PreprocessorConfig(**preprocessor_config_json)
+
+        return model_config, preprocessor_config
+
+    def init_dataset(self, dataset_dir: str) -> Tuple[bool, str]:
+        self.dataset_dir = dataset_dir
+        try:
+            if not self._is_dataset_initialized:
+                self.training_loader
+                self.validation_loader
+                self.testing_loader
+                if not self.training_loader or not self.testing_loader:
+                    logger.error('Both training data and testing data are missing.')
+                    return False, 'Must provide train dataset and test dataset to fine tune.'
+                self.labels = self.training_loader.dataset.labels
+                self._is_dataset_initialized = True
+            return True, 'Initializing dataset complete.'
+        except Exception:
+            logger.exception('Failed to initialize dataset.')
+            return False, '初始化数据失败，请联系模型作者排查原因。'
+
+    @property
+    def annotation_file(self):
+        return os.path.join(self.dataset_dir, 'annotation.json') if self.dataset_dir else None
+
+    @property
+    def training_loader(self) -> DataLoader:
+        """Return a dataloader instance of training data.
+
+        Data augmentation is used to improve performance, so we need to generate a new dataset
+        every epoch in case of training on a same dataset over and over again.
+        """
+        if not hasattr(self, "_training_loader"):
+            self._training_loader = self._build_training_data_loader()
+        return self._training_loader
+
+    def _build_training_data_loader(self) -> Optional[DataLoader]:
+        dataset = InceptionDataset(image_dir=self.dataset_dir,
+                                   annotation_file=self.annotation_file,
+                                   mode=DatasetMode.TRAINING,
+                                   config=self.preprocessor_config)
+        if len(dataset) == 0:
+            return None
+        return DataLoader(dataset=dataset,
+                          batch_size=self.batch_size,
+                          shuffle=True)
+
+    @property
+    def validation_loader(self) -> DataLoader:
+        """Return a dataloader instance of validation data."""
+        if not hasattr(self, "_validation_loader"):
+            self._validation_loader = self._build_validation_data_loader()
+        return self._validation_loader
+
+    def _build_validation_data_loader(self) -> DataLoader:
+        dataset = InceptionDataset(image_dir=self.dataset_dir,
+                                   annotation_file=self.annotation_file,
+                                   mode=DatasetMode.VALIDATION,
+                                   config=self.preprocessor_config)
+        if len(dataset) == 0:
+            return None
+        return DataLoader(dataset=dataset, batch_size=self.batch_size)
+
+    @property
+    def testing_loader(self) -> DataLoader:
+        """Return a dataloader instance of testing data."""
+        if not hasattr(self, "_testing_loader"):
+            self._testing_loader = self._build_testing_data_loader()
+        return self._testing_loader
+
+    def _build_testing_data_loader(self) -> DataLoader:
+        dataset = InceptionDataset(image_dir=self.dataset_dir,
+                                   annotation_file=self.annotation_file,
+                                   mode=DatasetMode.TESTING,
+                                   config=self.preprocessor_config)
+        if len(dataset) == 0:
+            return None
+        return DataLoader(dataset=dataset, batch_size=self.batch_size)
+
+    def _build_model(self):
+        pretrained_num_classes = 4
+        self._model: nn.Module = Inception3(num_classes=pretrained_num_classes,
+                                            init_weights=False)
+
+        self.labels = list(self.config.id2label.values())
+        self._replace_fc_if_diff(len(self.labels))
+
+        param_file = os.path.join(self.resource_dir, self.config.param_file)
+        with open(param_file, 'rb') as f:
+            state_dict = torch.load(f)
+            if self._model.get_parameter('fc.weight').shape[0] != state_dict['fc.weight'].shape[0]:
+                raise AutoModelError('The fine tuned labels dismatched the parameters.')
+            # The original pretrained model's AuxLogits is set with a wrong number of classes(1000)
+            if (
+                self._model.get_parameter('AuxLogits.fc.weight').shape[0]
+                != state_dict['AuxLogits.fc.weight'].shape[0]
+            ):
+                state_dict.pop('AuxLogits.fc.weight')
+                state_dict.pop('AuxLogits.fc.bias')
+                self._model.load_state_dict(state_dict, strict=False)
+            else:
+                self._model.load_state_dict(state_dict)
+
+        return self._model.cuda() if self.is_cuda else self._model
+
+    def _replace_fc_if_diff(self, num_classes: int):
+        """Replace the classify layer with new number of classes."""
+        assert (
+            num_classes and isinstance(num_classes, int) and num_classes > 0
+        ), f'Invalid number of classes: {num_classes} .'
+        if num_classes != self.num_classes:
+            if self.model.aux_logits:
+                self.model.AuxLogits.fc = nn.Linear(768, num_classes)
+                self.model.AuxLogits.fc.stddev = 0.001
+            self.model.fc = nn.Linear(2048, num_classes)
+
+    @property
+    def num_classes(self) -> int:
+        """Return the number of classes of the classification layer of the model."""
+        return self.model.get_parameter('fc.weight').shape[0]
+
+    @property
+    def model(self) -> nn.Module:
+        if not hasattr(self, '_model'):
+            self._model = self._build_model()
+        return self._model
+
+    @property
+    def optimizer(self) -> optim.Optimizer:
+        if not hasattr(self, '_optimizer'):
+            self._optimizer = optim.RMSprop(self.model.parameters(),
+                                            lr=self.lr,
+                                            alpha=0.9,
+                                            eps=1.0,
+                                            momentum=0.9)
+        else:
+            # update lr
+            latest_lr = self.lr
+            for param_group in self._optimizer.param_groups:
+                param_group['lr'] = latest_lr
+        return self._optimizer
+
+    @property
+    def lr(self) -> float:
+        return self._lr * 0.94**((self._epoch - 1) // 2)
+
+    def train(self):
+        self.model.train()
+
+    def eval(self):
+        self.model.eval()
+
+    @overload
+    def forward(self, input: torch.Tensor) -> str:
+        """Predict an image's tensor and give its label."""
+
+    @overload
+    def forward(self, input: str) -> str:
+        """Predict an image defined by a file path and give its label."""
+
+    @torch.no_grad()
+    def forward(self, input):
+        if not input or not isinstance(input, (str, torch.Tensor)):
+            raise AutoModelError(f'Invalid input data: {input}.')
+        if isinstance(input, str):
+            if not os.path.isfile(input):
+                raise AutoModelError(f'Cannot find or access the image file {input}.')
+            preprocessor = InceptionPreprocessor(mode=DatasetMode.PREDICTING,
+                                                 config=self.preprocessor_config)
+            input = preprocessor.transform(input)
+            input.unsqueeze_(0)
+
+        self.model.eval()
+        input = input.expand(2, 3, 299, 299)  # TODO train mode doesn't accept single input
+        output, _ = self.model(input)
+        predict = output.argmax(1)[0].item()
+        if not self.labels:
+            with open(os.path.join(self.resource_dir, 'fine_tuned.meta')) as f:
+                fine_tuned_json: dict = json.loads(f)
+                self.labels = fine_tuned_json.get('labels')
+        return self.labels[predict]
+
+    def _train_an_epoch(self):
+        self.train()
+        for images, targets in self.training_loader:
+            if self.is_cuda:
+                images, targets = images.cuda(), targets.cuda()
+            outputs, aux_outputs = self.model(images)
+            loss_1 = F.cross_entropy(outputs, targets)
+            loss_2 = F.cross_entropy(aux_outputs, targets)
+            loss = loss_1 + 0.4 * loss_2
+            self.optimizer.zero_grad()
+            loss.backward()
+            self.optimizer.step()
+
+    @torch.no_grad()
+    def _run_test(self) -> Tuple[float, float]:
+        """Run a test and report the result.
+
+        Return:
+            avg_loss, correct_rate
+        """
+        self.push_log(f'Begin testing of epoch {self._epoch}.')
+
+        self.eval()
+        total_loss = 0
+        total_correct = 0
+        for images, targets in self.testing_loader:
+            if self.is_cuda:
+                images, targets = images.cuda(), targets.cuda()
+            outputs, _ = self.model(images)
+            loss = F.cross_entropy(outputs, targets, reduction='sum').item()
+            total_loss += loss
+            pred = outputs.max(1, keepdim=True)[1]
+            total_correct += pred.eq(targets.view_as(pred)).sum().item()
+
+        avg_loss = total_loss / len(self.testing_loader.dataset)
+        correct_rate = total_correct / len(self.testing_loader.dataset) * 100
+        logger.info(f'Average Loss: {avg_loss:.4f}')
+        logger.info(f'Correct rate: {correct_rate:.2f}')
+
+        return avg_loss, correct_rate
+
+    @torch.no_grad()
+    def _run_validation(self) -> Tuple[float, float]:
+        """Run a round of validation and report the result.
+
+        Return:
+            avg_loss, correct_rate
+        """
+        self.push_log(f'Begin validation of epoch {self._epoch}.')
+
+        self.eval()
+        total_loss = 0
+        total_correct = 0
+        for images, targets in self.validation_loader:
+            if self.is_cuda:
+                images, targets = images.cuda(), targets.cuda()
+            outputs, _ = self.model(images)
+            loss = F.cross_entropy(outputs, targets, reduction='sum').item()
+            total_loss += loss
+            pred = outputs.max(1, keepdim=True)[1]
+            total_correct += pred.eq(targets.view_as(pred)).sum().item()
+
+        avg_loss = total_loss / len(self.validation_loader.dataset)
+        correct_rate = total_correct / len(self.validation_loader.dataset) * 100
+        logger.info(f'Average Loss: {avg_loss:.4f}')
+        logger.info(f'Correct rate: {correct_rate:.2f}')
+
+        return avg_loss, correct_rate
+
+    @torch.no_grad()
+    def _is_finished(self) -> bool:
+        """Decide if stop training.
+
+        If there are validation dataset, decide depending on validatation results. If
+        the validation result of current epoch is below the best record for 10 continuous
+        times, then stop training.
+        If there are no validation dataset, run for `epochs` (default 20) times.
+        """
+        if not self.validation_loader or len(self.validation_loader) == 0:
+            if self._epoch >= self.epochs:
+                self._best_state = deepcopy(self.model.state_dict())
+            return self._epoch >= self.epochs
+        # make a validation
+        self.push_log(f'Begin validation of epoch {self._epoch}.')
+        avg_loss, correct_rate = self._run_validation()
+        self.push_log('\n'.join(('Validation result:',
+                                 f'avg_loss={avg_loss:.4f}',
+                                 f'correct_rate={correct_rate:.2f}')))
+
+        if correct_rate > self._best_result:
+            self._overfit_index = 0
+            self._best_result = correct_rate
+            self._best_state = deepcopy(self.model.state_dict())
+            self.push_log('Validation result is better than last epoch.')
+            return self._epoch >= self.epochs
+        else:
+            self._overfit_index += 1
+            msg = f'Validation result gets worse for {self._overfit_index} consecutive times.'
+            self.push_log(msg)
+            return self._overfit_index >= 10 or self._epoch >= self.epochs
+
+    def fine_tune(self,
+                  id: str,
+                  task_id: str,
+                  dataset_dir: str,
+                  is_initiator: bool = False,
+                  is_debug_script: bool = False):
+        self.id = id
+        self.task_id = task_id
+        self.is_initiator = is_initiator
+        self.is_debug_script = is_debug_script
+
+        is_succ, err_msg = self.init_dataset(dataset_dir)
+        if not is_succ:
+            raise AutoModelError(f'Failed to initialize dataset. {err_msg}')
+        num_classes = (len(self.training_loader.dataset.labels)
+                       if self.training_loader
+                       else len(self.testing_loader.dataset.labels))
+        self._replace_fc_if_diff(num_classes)
+
+        self.config.id2label = {str(_idx): _label for _idx, _label in enumerate(self.labels)}
+        self.config.label2id = {_label: _idx for _idx, _label in enumerate(self.labels)}
+        self.config.label2id = dict(sorted(self.config.label2id.items()))
+
+        is_finished = False
+        self._epoch = 0
+        while not is_finished:
+            self._epoch += 1
+            self.push_log(f'Begin training of epoch {self._epoch}.')
+            self._train_an_epoch()
+            self.push_log(f'Complete training of epoch {self._epoch}.')
+            is_finished = self._is_finished()
+
+        self._save_fine_tuned()
+        avg_loss, correct_rate = self._run_test()
+        self.push_log('\n'.join(('Testing result:',
+                                 f'avg_loss={avg_loss:.4f}',
+                                 f'correct_rate={correct_rate:.2f}')))
+
+    def _save_fine_tuned(self):
+        """Save the best or final state of fine tuning."""
+        result_dir = get_result_dir(self.task_id)
+        os.makedirs(result_dir, exist_ok=True)
+        with open(os.path.join(result_dir, self.config.param_file), 'wb') as f:
+            torch.save(self._best_state, f)
+        with open(os.path.join(result_dir, 'config.json'), 'w') as f:
+            f.write(json.dumps(asdict(self.config), ensure_ascii=False))
+
+
+class AutoInceptionFedAvg(AutoInception, AutoFedAvgModel):
+
+    @property
+    def param_file(self) -> str:
+        return self.config.param_file
+
+    @property
+    def init_args_for_fine_tuned(self) -> Optional[str]:
+        return json.dumps({'labels': self.labels}, ensure_ascii=False)
+
+    def state_dict(self) -> Dict[str, torch.Tensor]:
+        return self.model.state_dict()
+
+    def load_state_dict(self, state_dict: Dict[str, torch.Tensor]):
+        return self.model.load_state_dict(state_dict)
+
+    def train_an_epoch(self):
+        self._epoch += 1
+        self._train_an_epoch()
+
+    def run_test(self) -> Tuple[float, float]:
+        """Run a test and report the result.
+
+        Return:
+            avg_loss, correct_rate
+        """
+        return self._run_test()
+
+    def run_validation(self):
+        """Run a test and report the result.
+
+        Return:
+            avg_loss, correct_rate
+        """
+        return self._run_validation()
+
+    def init_dataset(self, dataset_dir: str) -> Tuple[bool, str]:
+        self.dataset_dir = dataset_dir
+        try:
+            if not self._is_dataset_initialized:
+                self.training_loader
+                self.validation_loader
+                self.testing_loader
+                if not self.training_loader and not self.testing_loader:
+                    logger.error('Both training data and testing data are missing.')
+                    err_msg = ' '.join((
+                        'The initiator must provide test dataset.',
+                        'The collaborator must provide train dataset.'
+                    ))
+                    return False, err_msg
+                self.labels = (self.training_loader.dataset.labels
+                               if self.training_loader
+                               else self.testing_loader.dataset.labels)
+                self._is_dataset_initialized = True
+            return True, 'Initializing dataset complete.'
+        except Exception:
+            logger.exception('Failed to initialize dataset.')
+            return False, '初始化数据失败，请联系模型作者排查原因。'
+
+    def fine_tune(self,
+                  id: str,
+                  task_id: str,
+                  dataset_dir: str,
+                  is_initiator: bool = False):
+        is_succ, err_msg = self.init_dataset(dataset_dir)
+        if not is_succ:
+            raise AutoModelError(f'Failed to initialize dataset. {err_msg}')
+        num_classes = (len(self.training_loader.dataset.labels)
+                       if self.training_loader
+                       else len(self.testing_loader.dataset.labels))
+        self._replace_fc_if_diff(num_classes)
+
+        self._fine_tune_impl(id=id,
+                             task_id=task_id,
+                             dataset_dir=dataset_dir,
+                             scheduler_impl=InceptionFedAvgScheduler,
+                             is_initiator=is_initiator,
+                             max_rounds=self.config.epochs,
+                             log_rounds=1)
+
+
+class InceptionFedAvgScheduler(AutoFedAvgScheduler):
+
+    def __init__(self,
+                 auto_proxy: AutoInceptionFedAvg,
+                 max_rounds: int = 0,
+                 merge_epochs: int = 1,
+                 calculation_timeout: int = 300,
+                 schedule_timeout: int = 30,
+                 log_rounds: int = 0,
+                 involve_aggregator: bool = False):
+        super().__init__(auto_proxy=auto_proxy,
+                         max_rounds=max_rounds,
+                         merge_epochs=merge_epochs,
+                         calculation_timeout=calculation_timeout,
+                         schedule_timeout=schedule_timeout,
+                         log_rounds=log_rounds,
+                         involve_aggregator=involve_aggregator)
+        self._best_state = None
+        self._best_result = 0
+        self._overfit_index = 0
+
+    @property
+    def best_state_dict(self) -> Dict[str, torch.Tensor]:
+        return self._best_state
+
+    def validate_context(self):
+        super().validate_context()
+        if self.is_initiator:
+            assert self.test_loader and len(self.test_loader) > 0, 'failed to load test data'
+            self.push_log(f'There are {len(self.test_loader.dataset)} samples for testing.')
+        else:
+            assert self.train_loader and len(self.train_loader) > 0, 'failed to load train data'
+            self.push_log(f'There are {len(self.train_loader.dataset)} samples for training.')
+
+    def train_an_epoch(self):
+        self.auto_proxy.train_an_epoch()
+
+    def run_test(self):
+        self.auto_proxy.run_test()
+
+    def is_task_finished(self) -> bool:
+        """Decide if stop training.
+
+        If there are validation dataset, decide depending on validatation results. If
+        the validation result of current epoch is below the best record for 10 continuous
+        times, then stop training.
+        If there are no validation dataset, run for `max_rounds` times.
+        """
+        if not self.validation_loader or len(self.validation_loader) == 0:
+            self._best_state = deepcopy(self.state_dict())
+            return self._is_reach_max_rounds()
+
+        # make a validation
+        self.push_log(f'Begin validation of round {self.current_round}.')
+        avg_loss, correct_rate = self.auto_proxy.run_validation()
+        self.push_log('\n'.join(('Validation result:',
+                                 f'avg_loss={avg_loss:.4f}',
+                                 f'correct_rate={correct_rate:.2f}')))
+
+        if correct_rate > self._best_result:
+            self._overfit_index = 0
+            self._best_result = correct_rate
+            self._best_state = deepcopy(self.state_dict())
+            self.push_log('Validation result is better than last epoch.')
+            return self._is_reach_max_rounds()
+        else:
+            self._overfit_index += 1
+            msg = f'Validation result gets worse for {self._overfit_index} consecutive times.'
+            self.push_log(msg)
+            return self._overfit_index >= 10 or self._is_reach_max_rounds()
```

### Comparing `alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/breast_density_classification/res_fed_avg/inception3.py` & `alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/breast_density_classification/res_fed_avg/inception3.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/breast_density_classification/res_local/auto.py` & `alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/breast_density_classification/res_fed_avg/auto.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,689 +1,702 @@
-# Copyright 2022 Alphamed
-
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-
-#     http://www.apache.org/licenses/LICENSE-2.0
-
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-
-"""Pretraining breast_density_classification models and schedulers.
-
-Reference: https://arxiv.org/abs/2202.08238
-"""
-
-import json
-import os
-from copy import deepcopy
-from dataclasses import InitVar, asdict, dataclass
-from typing import Dict, List, Optional, Tuple, overload
-
-import torch
-import torch.nn.functional as F
-from inception3 import Inception3
-from PIL import Image
-from torch import nn, optim
-from torch.utils.data import DataLoader, Dataset
-from torchvision import transforms
-
-from alphafed import get_result_dir, logger
-from alphafed.auto_ml.auto_model import (AutoFedAvgModel, AutoFedAvgScheduler,
-                                         AutoModel, DatasetMode,
-                                         MandatoryConfig, Preprocessor)
-from alphafed.auto_ml.cvat.annotation import ImageAnnotationUtils
-from alphafed.auto_ml.exceptions import AutoModelError, ConfigError
-
-
-@dataclass
-class PreprocessorConfig:
-
-    size: int
-    do_affine: bool
-    degrees: int
-    translate: Tuple[float]
-    do_horizontal_flip: bool
-
-    def __post_init__(self):
-        self.translate = tuple(self.translate)
-
-
-class InceptionPreprocessor(Preprocessor):
-
-    def __init__(self, mode: DatasetMode, config: PreprocessorConfig) -> None:
-        layers = []
-        if mode == DatasetMode.TRAINING:
-            if config.do_affine:
-                layers.append(transforms.RandomAffine(degrees=config.degrees,
-                                                      translate=config.translate))
-            if config.do_horizontal_flip:
-                layers.append(transforms.RandomHorizontalFlip())
-        layers.append(transforms.ToTensor())
-        layers.append(transforms.Lambda(lambda image: self._resize(image=image,
-                                                                   size=config.size)))
-        self._transformer = transforms.Compose(layers)
-
-    def _resize(self, image: torch.Tensor, size: int):
-        image = image.permute(0, 2, 1)
-        image = F.interpolate(input=image.unsqueeze(0), size=[size, size], mode='area')
-        return image.squeeze()
-
-    def transform(self, image_file: str) -> torch.Tensor:
-        """Transform an image object into an input tensor."""
-        image = Image.open(image_file).convert('RGB')
-        return self._transformer(image)
-
-
-class InceptionDataset(Dataset):
-
-    def __init__(self,
-                 image_dir: str,
-                 annotation_file: str,
-                 mode: DatasetMode,
-                 config: PreprocessorConfig) -> None:
-        """Init a dataset instance for ResNet auto model families.
-
-        Args:
-            image_dir:
-                The directory including image files.
-            annotation_file:
-                The file including annotation information.
-            mode:
-                One of training or validation or testing.
-            config:
-                The configuration for the preprocessor.
-        """
-        super().__init__()
-        if not image_dir or not isinstance(image_dir, str):
-            raise ConfigError(f'Invalid image directory: {image_dir}.')
-        if not annotation_file or not isinstance(annotation_file, str):
-            raise ConfigError(f'Invalid annotation file path: {annotation_file}.')
-        assert mode and isinstance(mode, DatasetMode), f'Invalid dataset mode: {mode}.'
-        if not os.path.exists(image_dir) or not os.path.isdir(image_dir):
-            raise ConfigError(f'{image_dir} does not exist or is not a directory.')
-        if not os.path.exists(annotation_file) or not os.path.isfile(annotation_file):
-            raise ConfigError(f'{annotation_file} does not exist or is not a file.')
-
-        self.image_dir = image_dir
-        self.annotation_file = annotation_file
-        self.transformer = InceptionPreprocessor(mode=mode, config=config)
-
-        self.images, self.labels = ImageAnnotationUtils.parse_single_category_annotation(
-            annotation_file=self.annotation_file, resource_dir=image_dir, mode=mode
-        )
-
-    def __getitem__(self, index: int):
-        _item = self.images[index]
-        return self.transformer(_item.image_file), _item.class_label
-
-    def __len__(self):
-        return len(self.images)
-
-
-@dataclass
-class ModelConfig(MandatoryConfig):
-
-    id2label: dict
-    label2id: dict
-    learning_rate: int
-    batch_size: int
-    epochs: int
-    image_size: int = 299
-    torch_dtype: InitVar[str] = 'float32'
-
-    def __post_init__(self, torch_dtype: str):
-        super().__post_init__()
-
-        for _label in self.id2label.values():
-            if _label not in self.label2id:
-                raise TypeError(f'Label `{_label}` lost its ID in label2id map.')
-        for _id in self.label2id.values():
-            if str(_id) not in self.id2label:
-                raise TypeError(f'ID `{_id}` lost its label in id2label map.')
-
-        if self.learning_rate <= 0:
-            raise TypeError(f'Invalid learning_rate: `{self.learning_rate}`.')
-        if self.batch_size <= 0:
-            raise TypeError(f'Invalid batch_size: `{self.batch_size}`.')
-        if self.epochs <= 0:
-            raise TypeError(f'Invalid epochs: `{self.epochs}`.')
-
-        if self.image_size <= 0:
-            raise TypeError(f'Invalid image_size: `{self.image_size}`.')
-
-        if torch_dtype == 'float32' or torch_dtype == 'float':
-            self.torch_dtype = torch.float32
-        elif torch_dtype == 'float64':
-            self.torch_dtype = torch.float64
-        elif torch == 'float16':
-            self.torch_dtype = torch.float16
-        else:
-            raise TypeError(f'Invalid torch_dtype: `{torch_dtype}`.')
-
-
-class AutoInception(AutoModel):
-
-    def __init__(self, resource_dir: str, **kwargs) -> None:
-        super().__init__(resource_dir=resource_dir)
-
-        self.config, self.preprocessor_config = self._load_config()
-        self.epochs = self.config.epochs
-        self.batch_size = self.config.batch_size
-        self._lr = self.config.learning_rate
-        self._epoch = 0
-        self.is_cuda = torch.cuda.is_available()
-
-        self.dataset_dir = None
-        self.labels: List[str] = []
-
-        self._best_result = 0
-        self._best_state = None
-        self._overfit_index = 0
-        self._is_dataset_initialized = False
-        self._save_root = '.cache'
-
-    def _load_config(self) -> Tuple[ModelConfig, PreprocessorConfig]:
-        config_file = os.path.join(self.resource_dir, 'config.json')
-        if not os.path.isfile(config_file):
-            raise ConfigError('Config file missing.')
-        try:
-            with open(config_file, 'r') as f:
-                config_json = json.load(f)
-        except json.JSONDecodeError:
-            raise ConfigError('Failed to parse config file.')
-        model_config = ModelConfig(**config_json)
-
-        preprocessor_config_file = os.path.join(self.resource_dir, 'preprocessor_config.json')
-        if not os.path.isfile(preprocessor_config_file):
-            raise ConfigError('Preprocessor config file missing.')
-        try:
-            with open(preprocessor_config_file, 'r') as f:
-                preprocessor_config_json = json.load(f)
-        except json.JSONDecodeError:
-            raise ConfigError('Failed to parse preprocessor config file.')
-        preprocessor_config = PreprocessorConfig(**preprocessor_config_json)
-
-        return model_config, preprocessor_config
-
-    def init_dataset(self, dataset_dir: str) -> Tuple[bool, str]:
-        self.dataset_dir = dataset_dir
-        try:
-            if not self._is_dataset_initialized:
-                self.training_loader
-                self.validation_loader
-                self.testing_loader
-                if not self.training_loader or not self.testing_loader:
-                    logger.error('Both training data and testing data are missing.')
-                    return False, 'Must provide train dataset and test dataset to fine tune.'
-                self.labels = self.training_loader.dataset.labels
-                self._is_dataset_initialized = True
-            return True, 'Initializing dataset complete.'
-        except Exception:
-            logger.exception('Failed to initialize dataset.')
-            return False, '初始化数据失败，请联系模型作者排查原因。'
-
-    @property
-    def annotation_file(self):
-        return os.path.join(self.dataset_dir, 'annotation.json') if self.dataset_dir else None
-
-    @property
-    def training_loader(self) -> DataLoader:
-        """Return a dataloader instance of training data.
-
-        Data augmentation is used to improve performance, so we need to generate a new dataset
-        every epoch in case of training on a same dataset over and over again.
-        """
-        if not hasattr(self, "_training_loader"):
-            self._training_loader = self._build_training_data_loader()
-        return self._training_loader
-
-    def _build_training_data_loader(self) -> Optional[DataLoader]:
-        dataset = InceptionDataset(image_dir=self.dataset_dir,
-                                   annotation_file=self.annotation_file,
-                                   mode=DatasetMode.TRAINING,
-                                   config=self.preprocessor_config)
-        if len(dataset) == 0:
-            return None
-        return DataLoader(dataset=dataset,
-                          batch_size=self.batch_size,
-                          shuffle=True)
-
-    @property
-    def validation_loader(self) -> DataLoader:
-        """Return a dataloader instance of validation data."""
-        if not hasattr(self, "_validation_loader"):
-            self._validation_loader = self._build_validation_data_loader()
-        return self._validation_loader
-
-    def _build_validation_data_loader(self) -> DataLoader:
-        dataset = InceptionDataset(image_dir=self.dataset_dir,
-                                   annotation_file=self.annotation_file,
-                                   mode=DatasetMode.VALIDATION,
-                                   config=self.preprocessor_config)
-        if len(dataset) == 0:
-            return None
-        return DataLoader(dataset=dataset, batch_size=self.batch_size)
-
-    @property
-    def testing_loader(self) -> DataLoader:
-        """Return a dataloader instance of testing data."""
-        if not hasattr(self, "_testing_loader"):
-            self._testing_loader = self._build_testing_data_loader()
-        return self._testing_loader
-
-    def _build_testing_data_loader(self) -> DataLoader:
-        dataset = InceptionDataset(image_dir=self.dataset_dir,
-                                   annotation_file=self.annotation_file,
-                                   mode=DatasetMode.TESTING,
-                                   config=self.preprocessor_config)
-        if len(dataset) == 0:
-            return None
-        return DataLoader(dataset=dataset, batch_size=self.batch_size)
-
-    def _build_model(self):
-        pretrained_num_classes = 4
-        self._model: nn.Module = Inception3(num_classes=pretrained_num_classes,
-                                            init_weights=False)
-
-        self.labels = list(self.config.id2label.values())
-        self._replace_fc_if_diff(len(self.labels))
-
-        param_file = os.path.join(self.resource_dir, self.config.param_file)
-        with open(param_file, 'rb') as f:
-            state_dict = torch.load(f)
-            if self._model.get_parameter('fc.weight').shape[0] != state_dict['fc.weight'].shape[0]:
-                raise AutoModelError('The fine tuned labels dismatched the parameters.')
-            # The original pretrained model's AuxLogits is set with a wrong number of classes(1000)
-            if (
-                self._model.get_parameter('AuxLogits.fc.weight').shape[0]
-                != state_dict['AuxLogits.fc.weight'].shape[0]
-            ):
-                state_dict.pop('AuxLogits.fc.weight')
-                state_dict.pop('AuxLogits.fc.bias')
-                self._model.load_state_dict(state_dict, strict=False)
-            else:
-                self._model.load_state_dict(state_dict)
-
-        return self._model.cuda() if self.is_cuda else self._model
-
-    def _replace_fc_if_diff(self, num_classes: int):
-        """Replace the classify layer with new number of classes."""
-        assert (
-            num_classes and isinstance(num_classes, int) and num_classes > 0
-        ), f'Invalid number of classes: {num_classes} .'
-        if num_classes != self.num_classes:
-            if self.model.aux_logits:
-                self.model.AuxLogits.fc = nn.Linear(768, num_classes)
-                self.model.AuxLogits.fc.stddev = 0.001
-            self.model.fc = nn.Linear(2048, num_classes)
-
-    @property
-    def num_classes(self) -> int:
-        """Return the number of classes of the classification layer of the model."""
-        return self.model.get_parameter('fc.weight').shape[0]
-
-    @property
-    def model(self) -> nn.Module:
-        if not hasattr(self, '_model'):
-            self._model = self._build_model()
-        return self._model
-
-    @property
-    def optimizer(self) -> optim.Optimizer:
-        if not hasattr(self, '_optimizer'):
-            self._optimizer = optim.RMSprop(self.model.parameters(),
-                                            lr=self.lr,
-                                            alpha=0.9,
-                                            eps=1.0,
-                                            momentum=0.9)
-        else:
-            # update lr
-            latest_lr = self.lr
-            for param_group in self._optimizer.param_groups:
-                param_group['lr'] = latest_lr
-        return self._optimizer
-
-    @property
-    def lr(self) -> float:
-        return self._lr * 0.94**((self._epoch - 1) // 2)
-
-    def train(self):
-        self.model.train()
-
-    def eval(self):
-        self.model.eval()
-
-    @overload
-    def forward(self, input: torch.Tensor) -> str:
-        """Predict an image's tensor and give its label."""
-
-    @overload
-    def forward(self, input: str) -> str:
-        """Predict an image defined by a file path and give its label."""
-
-    @torch.no_grad()
-    def forward(self, input):
-        if not input or not isinstance(input, (str, torch.Tensor)):
-            raise AutoModelError(f'Invalid input data: {input}.')
-        if isinstance(input, str):
-            if not os.path.isfile(input):
-                raise AutoModelError(f'Cannot find or access the image file {input}.')
-            preprocessor = InceptionPreprocessor(mode=DatasetMode.PREDICTING,
-                                                 config=self.preprocessor_config)
-            input = preprocessor.transform(input)
-            input.unsqueeze_(0)
-
-        self.model.eval()
-        input = input.expand(2, 3, 299, 299)  # TODO train mode doesn't accept single input
-        output, _ = self.model(input)
-        predict = output.argmax(1)[0].item()
-        if not self.labels:
-            with open(os.path.join(self.resource_dir, 'fine_tuned.meta')) as f:
-                fine_tuned_json: dict = json.loads(f)
-                self.labels = fine_tuned_json.get('labels')
-        return self.labels[predict]
-
-    def _train_an_epoch(self):
-        self.train()
-        for images, targets in self.training_loader:
-            if self.is_cuda:
-                images, targets = images.cuda(), targets.cuda()
-            outputs, aux_outputs = self.model(images)
-            loss_1 = F.cross_entropy(outputs, targets)
-            loss_2 = F.cross_entropy(aux_outputs, targets)
-            loss = loss_1 + 0.4 * loss_2
-            self.optimizer.zero_grad()
-            loss.backward()
-            self.optimizer.step()
-
-    @torch.no_grad()
-    def _run_test(self) -> Tuple[float, float]:
-        """Run a test and report the result.
-
-        Return:
-            avg_loss, correct_rate
-        """
-        self.push_log(f'Begin testing of epoch {self._epoch}.')
-
-        self.eval()
-        total_loss = 0
-        total_correct = 0
-        for images, targets in self.testing_loader:
-            if self.is_cuda:
-                images, targets = images.cuda(), targets.cuda()
-            outputs, _ = self.model(images)
-            loss = F.cross_entropy(outputs, targets, reduction='sum').item()
-            total_loss += loss
-            pred = outputs.max(1, keepdim=True)[1]
-            total_correct += pred.eq(targets.view_as(pred)).sum().item()
-
-        avg_loss = total_loss / len(self.testing_loader.dataset)
-        correct_rate = total_correct / len(self.testing_loader.dataset) * 100
-        logger.info(f'Average Loss: {avg_loss:.4f}')
-        logger.info(f'Correct rate: {correct_rate:.2f}')
-
-        return avg_loss, correct_rate
-
-    @torch.no_grad()
-    def _run_validation(self) -> Tuple[float, float]:
-        """Run a round of validation and report the result.
-
-        Return:
-            avg_loss, correct_rate
-        """
-        self.push_log(f'Begin validation of epoch {self._epoch}.')
-
-        self.eval()
-        total_loss = 0
-        total_correct = 0
-        for images, targets in self.validation_loader:
-            if self.is_cuda:
-                images, targets = images.cuda(), targets.cuda()
-            outputs, _ = self.model(images)
-            loss = F.cross_entropy(outputs, targets, reduction='sum').item()
-            total_loss += loss
-            pred = outputs.max(1, keepdim=True)[1]
-            total_correct += pred.eq(targets.view_as(pred)).sum().item()
-
-        avg_loss = total_loss / len(self.validation_loader.dataset)
-        correct_rate = total_correct / len(self.validation_loader.dataset) * 100
-        logger.info(f'Average Loss: {avg_loss:.4f}')
-        logger.info(f'Correct rate: {correct_rate:.2f}')
-
-        return avg_loss, correct_rate
-
-    @torch.no_grad()
-    def _is_finished(self) -> bool:
-        """Decide if stop training.
-
-        If there are validation dataset, decide depending on validatation results. If
-        the validation result of current epoch is below the best record for 10 continuous
-        times, then stop training.
-        If there are no validation dataset, run for `epochs` (default 20) times.
-        """
-        if not self.validation_loader or len(self.validation_loader) == 0:
-            if self._epoch >= self.epochs:
-                self._best_state = deepcopy(self.model.state_dict())
-            return self._epoch >= self.epochs
-        # make a validation
-        self.push_log(f'Begin validation of epoch {self._epoch}.')
-        avg_loss, correct_rate = self._run_validation()
-        self.push_log('\n'.join(('Validation result:',
-                                 f'avg_loss={avg_loss:.4f}',
-                                 f'correct_rate={correct_rate:.2f}')))
-
-        if correct_rate > self._best_result:
-            self._overfit_index = 0
-            self._best_result = correct_rate
-            self._best_state = deepcopy(self.model.state_dict())
-            self.push_log('Validation result is better than last epoch.')
-            return self._epoch >= self.epochs
-        else:
-            self._overfit_index += 1
-            msg = f'Validation result gets worse for {self._overfit_index} consecutive times.'
-            self.push_log(msg)
-            return self._overfit_index >= 10 or self._epoch >= self.epochs
-
-    def fine_tune(self,
-                  id: str,
-                  task_id: str,
-                  dataset_dir: str,
-                  is_initiator: bool = False,
-                  is_debug_script: bool = False):
-        self.id = id
-        self.task_id = task_id
-        self.is_initiator = is_initiator
-        self.is_debug_script = is_debug_script
-
-        is_succ, err_msg = self.init_dataset(dataset_dir)
-        if not is_succ:
-            raise AutoModelError(f'Failed to initialize dataset. {err_msg}')
-        num_classes = (len(self.training_loader.dataset.labels)
-                       if self.training_loader
-                       else len(self.testing_loader.dataset.labels))
-        self._replace_fc_if_diff(num_classes)
-
-        self.config.id2label = {str(_idx): _label for _idx, _label in enumerate(self.labels)}
-        self.config.label2id = {_label: _idx for _idx, _label in enumerate(self.labels)}
-        self.config.label2id = dict(sorted(self.config.label2id.items()))
-
-        is_finished = False
-        self._epoch = 0
-        while not is_finished:
-            self._epoch += 1
-            self.push_log(f'Begin training of epoch {self._epoch}.')
-            self._train_an_epoch()
-            self.push_log(f'Complete training of epoch {self._epoch}.')
-            is_finished = self._is_finished()
-
-        self._save_fine_tuned()
-        avg_loss, correct_rate = self._run_test()
-        self.push_log('\n'.join(('Testing result:',
-                                 f'avg_loss={avg_loss:.4f}',
-                                 f'correct_rate={correct_rate:.2f}')))
-
-    def _save_fine_tuned(self):
-        """Save the best or final state of fine tuning."""
-        result_dir = get_result_dir(self.task_id)
-        os.makedirs(result_dir, exist_ok=True)
-        with open(os.path.join(result_dir, self.config.param_file), 'wb') as f:
-            torch.save(self._best_state, f)
-        with open(os.path.join(result_dir, 'config.json'), 'w') as f:
-            f.write(json.dumps(asdict(self.config), ensure_ascii=False))
-
-
-class AutoInceptionFedAvg(AutoInception, AutoFedAvgModel):
-
-    @property
-    def param_file(self) -> str:
-        return self.config.param_file
-
-    @property
-    def init_args_for_fine_tuned(self) -> Optional[str]:
-        return json.dumps({'labels': self.labels}, ensure_ascii=False)
-
-    def state_dict(self) -> Dict[str, torch.Tensor]:
-        return self.model.state_dict()
-
-    def load_state_dict(self, state_dict: Dict[str, torch.Tensor]):
-        return self.model.load_state_dict(state_dict)
-
-    def train_an_epoch(self):
-        self._epoch += 1
-        self._train_an_epoch()
-
-    def run_test(self) -> Tuple[float, float]:
-        """Run a test and report the result.
-
-        Return:
-            avg_loss, correct_rate
-        """
-        return self._run_test()
-
-    def run_validation(self):
-        """Run a test and report the result.
-
-        Return:
-            avg_loss, correct_rate
-        """
-        return self._run_validation()
-
-    def init_dataset(self, dataset_dir: str) -> Tuple[bool, str]:
-        self.dataset_dir = dataset_dir
-        try:
-            if not self._is_dataset_initialized:
-                self.training_loader
-                self.validation_loader
-                self.testing_loader
-                if not self.training_loader and not self.testing_loader:
-                    logger.error('Both training data and testing data are missing.')
-                    err_msg = ' '.join((
-                        'The initiator must provide test dataset.',
-                        'The collaborator must provide train dataset.'
-                    ))
-                    return False, err_msg
-                self.labels = (self.training_loader.dataset.labels
-                               if self.training_loader
-                               else self.testing_loader.dataset.labels)
-                self._is_dataset_initialized = True
-            return True, 'Initializing dataset complete.'
-        except Exception:
-            logger.exception('Failed to initialize dataset.')
-            return False, '初始化数据失败，请联系模型作者排查原因。'
-
-    def fine_tune(self,
-                  id: str,
-                  task_id: str,
-                  dataset_dir: str,
-                  is_initiator: bool = False):
-        is_succ, err_msg = self.init_dataset(dataset_dir)
-        if not is_succ:
-            raise AutoModelError(f'Failed to initialize dataset. {err_msg}')
-        num_classes = (len(self.training_loader.dataset.labels)
-                       if self.training_loader
-                       else len(self.testing_loader.dataset.labels))
-        self._replace_fc_if_diff(num_classes)
-
-        self._fine_tune_impl(id=id,
-                             task_id=task_id,
-                             dataset_dir=dataset_dir,
-                             scheduler_impl=InceptionFedAvgScheduler,
-                             is_initiator=is_initiator,
-                             max_rounds=self.config.epochs,
-                             log_rounds=1)
-
-
-class InceptionFedAvgScheduler(AutoFedAvgScheduler):
-
-    def __init__(self,
-                 auto_proxy: AutoInceptionFedAvg,
-                 max_rounds: int = 0,
-                 merge_epochs: int = 1,
-                 calculation_timeout: int = 300,
-                 schedule_timeout: int = 30,
-                 log_rounds: int = 0,
-                 involve_aggregator: bool = False):
-        super().__init__(auto_proxy=auto_proxy,
-                         max_rounds=max_rounds,
-                         merge_epochs=merge_epochs,
-                         calculation_timeout=calculation_timeout,
-                         schedule_timeout=schedule_timeout,
-                         log_rounds=log_rounds,
-                         involve_aggregator=involve_aggregator)
-        self._best_state = None
-        self._best_result = 0
-        self._overfit_index = 0
-
-    @property
-    def best_state_dict(self) -> Dict[str, torch.Tensor]:
-        return self._best_state
-
-    def validate_context(self):
-        super().validate_context()
-        if self.is_initiator:
-            assert self.test_loader and len(self.test_loader) > 0, 'failed to load test data'
-            self.push_log(f'There are {len(self.test_loader.dataset)} samples for testing.')
-        else:
-            assert self.train_loader and len(self.train_loader) > 0, 'failed to load train data'
-            self.push_log(f'There are {len(self.train_loader.dataset)} samples for training.')
-
-    def train_an_epoch(self):
-        self.auto_proxy.train_an_epoch()
-
-    def run_test(self):
-        self.auto_proxy.run_test()
-
-    def is_task_finished(self) -> bool:
-        """Decide if stop training.
-
-        If there are validation dataset, decide depending on validatation results. If
-        the validation result of current epoch is below the best record for 10 continuous
-        times, then stop training.
-        If there are no validation dataset, run for `max_rounds` times.
-        """
-        if not self.validation_loader or len(self.validation_loader) == 0:
-            self._best_state = deepcopy(self.state_dict())
-            return self._is_reach_max_rounds()
-
-        # make a validation
-        self.push_log(f'Begin validation of round {self.current_round}.')
-        avg_loss, correct_rate = self.auto_proxy.run_validation()
-        self.push_log('\n'.join(('Validation result:',
-                                 f'avg_loss={avg_loss:.4f}',
-                                 f'correct_rate={correct_rate:.2f}')))
-
-        if correct_rate > self._best_result:
-            self._overfit_index = 0
-            self._best_result = correct_rate
-            self._best_state = deepcopy(self.state_dict())
-            self.push_log('Validation result is better than last epoch.')
-            return self._is_reach_max_rounds()
-        else:
-            self._overfit_index += 1
-            msg = f'Validation result gets worse for {self._overfit_index} consecutive times.'
-            self.push_log(msg)
-            return self._overfit_index >= 10 or self._is_reach_max_rounds()
+# Copyright 2022 Alphamed
+
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+
+#     http://www.apache.org/licenses/LICENSE-2.0
+
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+"""Pretraining breast_density_classification models and schedulers.
+
+Reference: https://arxiv.org/abs/2202.08238
+"""
+
+import json
+import os
+from copy import deepcopy
+from dataclasses import InitVar, asdict, dataclass
+from typing import Dict, List, Optional, Tuple, overload
+
+import torch
+import torch.nn.functional as F
+from alphafed import get_result_dir, logger
+from alphafed.auto_ml.auto_model import (AutoFedAvgModel, AutoFedAvgScheduler,
+                                         AutoModel, DatasetMode,
+                                         MandatoryConfig, Preprocessor)
+from alphafed.auto_ml.cvat.annotation import ImageAnnotationUtils
+from alphafed.auto_ml.exceptions import AutoModelError, ConfigError
+from PIL import Image
+from torch import nn, optim
+from torch.utils.data import DataLoader, Dataset
+from torchvision import transforms
+
+from inception3 import Inception3
+
+
+@dataclass
+class PreprocessorConfig:
+
+    size: int
+    do_affine: bool
+    degrees: int
+    translate: Tuple[float]
+    do_horizontal_flip: bool
+
+    def __post_init__(self):
+        self.translate = tuple(self.translate)
+
+
+class InceptionPreprocessor(Preprocessor):
+
+    def __init__(self, mode: DatasetMode, config: PreprocessorConfig) -> None:
+        layers = []
+        if mode == DatasetMode.TRAINING:
+            if config.do_affine:
+                layers.append(transforms.RandomAffine(degrees=config.degrees,
+                                                      translate=config.translate))
+            if config.do_horizontal_flip:
+                layers.append(transforms.RandomHorizontalFlip())
+        layers.append(transforms.ToTensor())
+        layers.append(transforms.Lambda(lambda image: self._resize(image=image,
+                                                                   size=config.size)))
+        self._transformer = transforms.Compose(layers)
+
+    def _resize(self, image: torch.Tensor, size: int):
+        image = image.permute(0, 2, 1)
+        image = F.interpolate(input=image.unsqueeze(0), size=[size, size], mode='area')
+        return image.squeeze()
+
+    def transform(self, image_file: str) -> torch.Tensor:
+        """Transform an image object into an input tensor."""
+        image = Image.open(image_file).convert('RGB')
+        return self._transformer(image)
+
+
+class InceptionDataset(Dataset):
+
+    def __init__(self,
+                 image_dir: str,
+                 annotation_file: str,
+                 mode: DatasetMode,
+                 config: PreprocessorConfig) -> None:
+        """Init a dataset instance for ResNet auto model families.
+
+        Args:
+            image_dir:
+                The directory including image files.
+            annotation_file:
+                The file including annotation information.
+            mode:
+                One of training or validation or testing.
+            config:
+                The configuration for the preprocessor.
+        """
+        super().__init__()
+        if not image_dir or not isinstance(image_dir, str):
+            raise ConfigError(f'Invalid image directory: {image_dir}.')
+        if not annotation_file or not isinstance(annotation_file, str):
+            raise ConfigError(f'Invalid annotation file path: {annotation_file}.')
+        assert mode and isinstance(mode, DatasetMode), f'Invalid dataset mode: {mode}.'
+        if not os.path.exists(image_dir) or not os.path.isdir(image_dir):
+            raise ConfigError(f'{image_dir} does not exist or is not a directory.')
+        if not os.path.exists(annotation_file) or not os.path.isfile(annotation_file):
+            raise ConfigError(f'{annotation_file} does not exist or is not a file.')
+
+        self.image_dir = image_dir
+        self.annotation_file = annotation_file
+        self.transformer = InceptionPreprocessor(mode=mode, config=config)
+
+        self.images, self.labels = ImageAnnotationUtils.parse_single_category_annotation(
+            annotation_file=self.annotation_file, resource_dir=image_dir, mode=mode
+        )
+
+    def __getitem__(self, index: int):
+        _item = self.images[index]
+        return self.transformer(_item.image_file), _item.class_label
+
+    def __len__(self):
+        return len(self.images)
+
+
+@dataclass
+class ModelConfig(MandatoryConfig):
+
+    id2label: dict
+    label2id: dict
+    learning_rate: int
+    batch_size: int
+    epochs: int
+    image_size: int = 299
+    torch_dtype: InitVar[str] = 'float32'
+
+    def __post_init__(self, torch_dtype: str):
+        super().__post_init__()
+
+        for _label in self.id2label.values():
+            if _label not in self.label2id:
+                raise TypeError(f'Label `{_label}` lost its ID in label2id map.')
+        for _id in self.label2id.values():
+            if str(_id) not in self.id2label:
+                raise TypeError(f'ID `{_id}` lost its label in id2label map.')
+
+        if self.learning_rate <= 0:
+            raise TypeError(f'Invalid learning_rate: `{self.learning_rate}`.')
+        if self.batch_size <= 0:
+            raise TypeError(f'Invalid batch_size: `{self.batch_size}`.')
+        if self.epochs <= 0:
+            raise TypeError(f'Invalid epochs: `{self.epochs}`.')
+
+        if self.image_size <= 0:
+            raise TypeError(f'Invalid image_size: `{self.image_size}`.')
+
+        if torch_dtype == 'float32' or torch_dtype == 'float':
+            self.torch_dtype = torch.float32
+        elif torch_dtype == 'float64':
+            self.torch_dtype = torch.float64
+        elif torch == 'float16':
+            self.torch_dtype = torch.float16
+        else:
+            raise TypeError(f'Invalid torch_dtype: `{torch_dtype}`.')
+
+
+class AutoInception(AutoModel):
+
+    def __init__(self, resource_dir: str, **kwargs) -> None:
+        super().__init__(resource_dir=resource_dir)
+
+        self.config, self.preprocessor_config = self._load_config()
+        self.epochs = self.config.epochs
+        self.batch_size = self.config.batch_size
+        self._lr = self.config.learning_rate
+        self._epoch = 0
+        # 测试部署服务暂时不支持 GPU 环境，使用 GPU 版本会导致部署失败
+        # self.is_cuda = torch.cuda.is_available()
+        self.is_cuda = False
+
+        self.dataset_dir = None
+        self.labels: List[str] = []
+
+        self._best_result = 0
+        self._best_state = None
+        self._overfit_index = 0
+        self._is_dataset_initialized = False
+        self._save_root = '.cache'
+
+    def _load_config(self) -> Tuple[ModelConfig, PreprocessorConfig]:
+        config_file = os.path.join(self.resource_dir, 'config.json')
+        if not os.path.isfile(config_file):
+            raise ConfigError('Config file missing.')
+        try:
+            with open(config_file, 'r') as f:
+                config_json = json.load(f)
+        except json.JSONDecodeError:
+            raise ConfigError('Failed to parse config file.')
+        model_config = ModelConfig(**config_json)
+
+        preprocessor_config_file = os.path.join(self.resource_dir, 'preprocessor_config.json')
+        if not os.path.isfile(preprocessor_config_file):
+            raise ConfigError('Preprocessor config file missing.')
+        try:
+            with open(preprocessor_config_file, 'r') as f:
+                preprocessor_config_json = json.load(f)
+        except json.JSONDecodeError:
+            raise ConfigError('Failed to parse preprocessor config file.')
+        preprocessor_config = PreprocessorConfig(**preprocessor_config_json)
+
+        return model_config, preprocessor_config
+
+    def init_dataset(self, dataset_dir: str) -> Tuple[bool, str]:
+        self.dataset_dir = dataset_dir
+        try:
+            if not self._is_dataset_initialized:
+                self.training_loader
+                self.validation_loader
+                self.testing_loader
+                if not self.training_loader or not self.testing_loader:
+                    logger.error('Both training data and testing data are missing.')
+                    return False, 'Must provide train dataset and test dataset to fine tune.'
+                self.labels = self.training_loader.dataset.labels
+                self._is_dataset_initialized = True
+            return True, 'Initializing dataset complete.'
+        except Exception:
+            logger.exception('Failed to initialize dataset.')
+            return False, '初始化数据失败，请联系模型作者排查原因。'
+
+    @property
+    def annotation_file(self):
+        return os.path.join(self.dataset_dir, 'annotation.json') if self.dataset_dir else None
+
+    @property
+    def training_loader(self) -> DataLoader:
+        """Return a dataloader instance of training data.
+
+        Data augmentation is used to improve performance, so we need to generate a new dataset
+        every epoch in case of training on a same dataset over and over again.
+        """
+        if not hasattr(self, "_training_loader"):
+            self._training_loader = self._build_training_data_loader()
+        return self._training_loader
+
+    def _build_training_data_loader(self) -> Optional[DataLoader]:
+        dataset = InceptionDataset(image_dir=self.dataset_dir,
+                                   annotation_file=self.annotation_file,
+                                   mode=DatasetMode.TRAINING,
+                                   config=self.preprocessor_config)
+        if len(dataset) == 0:
+            return None
+        return DataLoader(dataset=dataset,
+                          batch_size=self.batch_size,
+                          shuffle=True)
+
+    @property
+    def validation_loader(self) -> DataLoader:
+        """Return a dataloader instance of validation data."""
+        if not hasattr(self, "_validation_loader"):
+            self._validation_loader = self._build_validation_data_loader()
+        return self._validation_loader
+
+    def _build_validation_data_loader(self) -> DataLoader:
+        dataset = InceptionDataset(image_dir=self.dataset_dir,
+                                   annotation_file=self.annotation_file,
+                                   mode=DatasetMode.VALIDATION,
+                                   config=self.preprocessor_config)
+        if len(dataset) == 0:
+            return None
+        return DataLoader(dataset=dataset, batch_size=self.batch_size)
+
+    @property
+    def testing_loader(self) -> DataLoader:
+        """Return a dataloader instance of testing data."""
+        if not hasattr(self, "_testing_loader"):
+            self._testing_loader = self._build_testing_data_loader()
+        return self._testing_loader
+
+    def _build_testing_data_loader(self) -> DataLoader:
+        dataset = InceptionDataset(image_dir=self.dataset_dir,
+                                   annotation_file=self.annotation_file,
+                                   mode=DatasetMode.TESTING,
+                                   config=self.preprocessor_config)
+        if len(dataset) == 0:
+            return None
+        return DataLoader(dataset=dataset, batch_size=self.batch_size)
+
+    def _build_model(self):
+        pretrained_num_classes = 4
+        self._model: nn.Module = Inception3(num_classes=pretrained_num_classes,
+                                            init_weights=False)
+
+        self.labels = list(self.config.id2label.values())
+        self._replace_fc_if_diff(len(self.labels))
+
+        param_file = os.path.join(self.resource_dir, self.config.param_file)
+        with open(param_file, 'rb') as f:
+            state_dict = torch.load(f)
+            if self._model.get_parameter('fc.weight').shape[0] != state_dict['fc.weight'].shape[0]:
+                raise AutoModelError('The fine tuned labels dismatched the parameters.')
+            # The original pretrained model's AuxLogits is set with a wrong number of classes(1000)
+            if (
+                self._model.get_parameter('AuxLogits.fc.weight').shape[0]
+                != state_dict['AuxLogits.fc.weight'].shape[0]
+            ):
+                state_dict.pop('AuxLogits.fc.weight')
+                state_dict.pop('AuxLogits.fc.bias')
+                self._model.load_state_dict(state_dict, strict=False)
+            else:
+                self._model.load_state_dict(state_dict)
+
+        return self._model.cuda() if self.is_cuda else self._model
+
+    def _replace_fc_if_diff(self, num_classes: int):
+        """Replace the classify layer with new number of classes."""
+        assert (
+            num_classes and isinstance(num_classes, int) and num_classes > 0
+        ), f'Invalid number of classes: {num_classes} .'
+        if num_classes != self.num_classes:
+            if self.model.aux_logits:
+                self.model.AuxLogits.fc = nn.Linear(768, num_classes)
+                self.model.AuxLogits.fc.stddev = 0.001
+            self.model.fc = nn.Linear(2048, num_classes)
+
+    @property
+    def num_classes(self) -> int:
+        """Return the number of classes of the classification layer of the model."""
+        return self.model.get_parameter('fc.weight').shape[0]
+
+    @property
+    def model(self) -> nn.Module:
+        if not hasattr(self, '_model'):
+            self._model = self._build_model()
+        return self._model
+
+    @property
+    def optimizer(self) -> optim.Optimizer:
+        if not hasattr(self, '_optimizer'):
+            self._optimizer = optim.RMSprop(self.model.parameters(),
+                                            lr=self.lr,
+                                            alpha=0.9,
+                                            eps=1.0,
+                                            momentum=0.9)
+        else:
+            # update lr
+            latest_lr = self.lr
+            for param_group in self._optimizer.param_groups:
+                param_group['lr'] = latest_lr
+        return self._optimizer
+
+    @property
+    def lr(self) -> float:
+        return self._lr * 0.94**((self._epoch - 1) // 2)
+
+    def train(self):
+        self.model.train()
+
+    def eval(self):
+        self.model.eval()
+
+    @overload
+    def forward(self, input: torch.Tensor) -> str:
+        """Predict an image's tensor and give its label."""
+
+    @overload
+    def forward(self, input: str) -> str:
+        """Predict an image defined by a file path and give its label."""
+
+    @torch.no_grad()
+    def forward(self, input) -> str:
+        if not input or not isinstance(input, (str, torch.Tensor)):
+            raise AutoModelError(f'Invalid input data: {input}.')
+        if isinstance(input, str):
+            if not os.path.isfile(input):
+                raise AutoModelError(f'Cannot find or access the image file {input}.')
+            preprocessor = InceptionPreprocessor(mode=DatasetMode.PREDICTING,
+                                                 config=self.preprocessor_config)
+            input = preprocessor.transform(input)
+            input.unsqueeze_(0)
+
+        self.model.eval()
+        input = input.expand(2, 3, 299, 299)  # TODO train mode doesn't accept single input
+        output = self.model(input)
+        predict = output.argmax(1)[0].item()
+        if not self.labels:
+            with open(os.path.join(self.resource_dir, 'fine_tuned.meta')) as f:
+                fine_tuned_json: dict = json.loads(f)
+                self.labels = fine_tuned_json.get('labels')
+        return self.labels[predict]
+
+    def _train_an_epoch(self):
+        self.train()
+        for images, targets in self.training_loader:
+            if self.is_cuda:
+                images, targets = images.cuda(), targets.cuda()
+            outputs, aux_outputs = self.model(images)
+            loss_1 = F.cross_entropy(outputs, targets)
+            loss_2 = F.cross_entropy(aux_outputs, targets)
+            loss = loss_1 + 0.4 * loss_2
+            self.optimizer.zero_grad()
+            loss.backward()
+            self.optimizer.step()
+
+    @torch.no_grad()
+    def _run_test(self) -> Tuple[float, float]:
+        """Run a test and report the result.
+
+        Return:
+            avg_loss, correct_rate
+        """
+        self.push_log(f'Begin testing of epoch {self._epoch}.')
+        self.eval()
+        total_loss = 0
+        total_correct = 0
+        for images, targets in self.testing_loader:
+            if self.is_cuda:
+                images, targets = images.cuda(), targets.cuda()
+            outputs = self.model(images)
+            loss = F.cross_entropy(outputs, targets, reduction='sum').item()
+            total_loss += loss
+            pred = outputs.max(1, keepdim=True)[1]
+            total_correct += pred.eq(targets.view_as(pred)).sum().item()
+
+        avg_loss = total_loss / len(self.testing_loader.dataset)
+        correct_rate = total_correct / len(self.testing_loader.dataset) * 100
+        logger.info(f'Average Loss: {avg_loss:.4f}')
+        logger.info(f'Correct rate: {correct_rate:.2f}')
+
+        return avg_loss, correct_rate
+
+    @torch.no_grad()
+    def _run_validation(self) -> Tuple[float, float]:
+        """Run a round of validation and report the result.
+
+        Return:
+            avg_loss, correct_rate
+        """
+        self.push_log(f'Begin validation of epoch {self._epoch}.')
+        self.eval()
+        total_loss = 0
+        total_correct = 0
+        for images, targets in self.validation_loader:
+            if self.is_cuda:
+                images, targets = images.cuda(), targets.cuda()
+            outputs = self.model(images)
+            loss = F.cross_entropy(outputs, targets, reduction='sum').item()
+            total_loss += loss
+            pred = outputs.max(1, keepdim=True)[1]
+            total_correct += pred.eq(targets.view_as(pred)).sum().item()
+
+        avg_loss = total_loss / len(self.validation_loader.dataset)
+        correct_rate = total_correct / len(self.validation_loader.dataset) * 100
+        logger.info(f'Average Loss: {avg_loss:.4f}')
+        logger.info(f'Correct rate: {correct_rate:.2f}')
+
+        return avg_loss, correct_rate
+
+    @torch.no_grad()
+    def _is_finished(self) -> bool:
+        """Decide if stop training.
+
+        If there are validation dataset, decide depending on validatation results. If
+        the validation result of current epoch is below the best record for 10 continuous
+        times, then stop training.
+        If there are no validation dataset, run for `epochs` (default 20) times.
+        """
+        if not self.validation_loader or len(self.validation_loader) == 0:
+            if self._epoch >= self.epochs:
+                self._best_state = deepcopy(self.model.state_dict())
+            return self._epoch >= self.epochs
+        # make a validation
+        self.push_log(f'Begin validation of epoch {self._epoch}.')
+        avg_loss, correct_rate = self._run_validation()
+        self.push_log('\n'.join(('Validation result:',
+                                 f'avg_loss={avg_loss:.4f}',
+                                 f'correct_rate={correct_rate:.2f}')))
+
+        if correct_rate > self._best_result:
+            self._overfit_index = 0
+            self._best_result = correct_rate
+            self._best_state = deepcopy(self.model.state_dict())
+            self.push_log('Validation result is better than last epoch.')
+            return self._epoch >= self.epochs
+        else:
+            self._overfit_index += 1
+            msg = f'Validation result gets worse for {self._overfit_index} consecutive times.'
+            self.push_log(msg)
+            return self._overfit_index >= 10 or self._epoch >= self.epochs
+
+    def fine_tune(self,
+                  id: str,
+                  task_id: str,
+                  dataset_dir: str,
+                  is_initiator: bool = False,
+                  is_debug_script: bool = False):
+        self.id = id
+        self.task_id = task_id
+        self.is_initiator = is_initiator
+        self.is_debug_script = is_debug_script
+
+        is_succ, err_msg = self.init_dataset(dataset_dir)
+        if not is_succ:
+            raise AutoModelError(f'Failed to initialize dataset. {err_msg}')
+        num_classes = (len(self.training_loader.dataset.labels)
+                       if self.training_loader
+                       else len(self.testing_loader.dataset.labels))
+        self._replace_fc_if_diff(num_classes)
+
+        self.config.id2label = {str(_idx): _label for _idx, _label in enumerate(self.labels)}
+        self.config.label2id = {_label: _idx for _idx, _label in enumerate(self.labels)}
+        self.config.label2id = dict(sorted(self.config.label2id.items()))
+
+        is_finished = False
+        self._epoch = 0
+        while not is_finished:
+            self._epoch += 1
+            self.push_log(f'Begin training of epoch {self._epoch}.')
+            self._train_an_epoch()
+            self.push_log(f'Complete training of epoch {self._epoch}.')
+            is_finished = self._is_finished()
+
+        self._save_fine_tuned()
+        avg_loss, correct_rate = self._run_test()
+        self.push_log('\n'.join(('Testing result:',
+                                 f'avg_loss={avg_loss:.4f}',
+                                 f'correct_rate={correct_rate:.2f}')))
+
+    def _save_fine_tuned(self):
+        """Save the best or final state of fine tuning."""
+        self.result_dir = get_result_dir(self.task_id)
+        os.makedirs(self.result_dir, exist_ok=True)
+        with open(os.path.join(self.result_dir, self.config.param_file), 'wb') as f:
+            torch.save(self._best_state, f)
+        with open(os.path.join(self.result_dir, 'config.json'), 'w') as f:
+            f.write(json.dumps(asdict(self.config), ensure_ascii=False))
+
+
+class AutoInceptionFedAvg(AutoInception, AutoFedAvgModel):
+
+    def state_dict(self) -> Dict[str, torch.Tensor]:
+        return self.model.state_dict()
+
+    def load_state_dict(self, state_dict: Dict[str, torch.Tensor]):
+        return self.model.load_state_dict(state_dict)
+
+    def train_an_epoch(self):
+        self._epoch += 1
+        self._train_an_epoch()
+
+    def run_test(self) -> Tuple[float, float]:
+        """Run a test and report the result.
+
+        Return:
+            avg_loss, correct_rate
+        """
+        return self._run_test()
+
+    def run_validation(self):
+        """Run a test and report the result.
+
+        Return:
+            avg_loss, correct_rate
+        """
+        return self._run_validation()
+
+    def init_dataset(self, dataset_dir: str) -> Tuple[bool, str]:
+        self.dataset_dir = dataset_dir
+        try:
+            if not self._is_dataset_initialized:
+                self.training_loader
+                self.validation_loader
+                self.testing_loader
+                if not self.training_loader and not self.testing_loader:
+                    logger.error('Both training data and testing data are missing.')
+                    err_msg = ' '.join((
+                        'The initiator must provide test dataset.',
+                        'The collaborator must provide train dataset.'
+                    ))
+                    return False, err_msg
+                self.labels = (self.training_loader.dataset.labels
+                               if self.training_loader
+                               else self.testing_loader.dataset.labels)
+                self._is_dataset_initialized = True
+            return True, 'Initializing dataset complete.'
+        except Exception:
+            logger.exception('Failed to initialize dataset.')
+            return False, '初始化数据失败，请联系模型作者排查原因。'
+
+    def fine_tune(self,
+                  id: str,
+                  task_id: str,
+                  dataset_dir: str,
+                  is_initiator: bool = False,
+                  recover: bool = False):
+        is_succ, err_msg = self.init_dataset(dataset_dir)
+        if not is_succ:
+            raise AutoModelError(f'Failed to initialize dataset. {err_msg}')
+        num_classes = (len(self.training_loader.dataset.labels)
+                       if self.training_loader
+                       else len(self.testing_loader.dataset.labels))
+        self._replace_fc_if_diff(num_classes)
+
+        self.config.id2label = {str(_idx): _label for _idx, _label in enumerate(self.labels)}
+        self.config.label2id = {_label: _idx for _idx, _label in enumerate(self.labels)}
+        self.config.label2id = dict(sorted(self.config.label2id.items()))
+
+        self._fine_tune_impl(id=id,
+                             task_id=task_id,
+                             dataset_dir=dataset_dir,
+                             scheduler_impl=InceptionFedAvgScheduler,
+                             is_initiator=is_initiator,
+                             recover=recover,
+                             max_rounds=self.config.epochs,
+                             log_rounds=1)
+
+    def fine_tuned_files_dict(self) -> Optional[Dict[str, str]]:
+        param_file = os.path.join(self.result_dir, self.config.param_file)
+        with open(param_file, 'wb') as f:
+            torch.save(self.scheduler.best_state_dict, f)
+        config_file = os.path.join(self.result_dir, 'config.json')
+        with open(config_file, 'w') as f:
+            f.write(json.dumps(asdict(self.config), ensure_ascii=False))
+        return {
+            self.config.param_file: param_file,
+            'config.json': config_file
+        }
+
+
+class InceptionFedAvgScheduler(AutoFedAvgScheduler):
+
+    def __init__(self,
+                 auto_proxy: AutoInceptionFedAvg,
+                 max_rounds: int = 0,
+                 merge_epochs: int = 1,
+                 calculation_timeout: int = 300,
+                 schedule_timeout: int = 30,
+                 log_rounds: int = 0,
+                 involve_aggregator: bool = False):
+        super().__init__(auto_proxy=auto_proxy,
+                         max_rounds=max_rounds,
+                         merge_epochs=merge_epochs,
+                         calculation_timeout=calculation_timeout,
+                         schedule_timeout=schedule_timeout,
+                         log_rounds=log_rounds,
+                         involve_aggregator=involve_aggregator)
+        self._best_state = None
+        self._best_result = 0
+        self._overfit_index = 0
+
+    @property
+    def best_state_dict(self) -> Dict[str, torch.Tensor]:
+        return self._best_state
+
+    def validate_context(self):
+        super().validate_context()
+        if self.is_initiator:
+            assert self.test_loader and len(self.test_loader) > 0, 'failed to load test data'
+            self.push_log(f'There are {len(self.test_loader.dataset)} samples for testing.')
+        else:
+            assert self.train_loader and len(self.train_loader) > 0, 'failed to load train data'
+            self.push_log(f'There are {len(self.train_loader.dataset)} samples for training.')
+
+    def train_an_epoch(self):
+        self.auto_proxy.train_an_epoch()
+
+    def run_test(self):
+        avg_loss, correct_rate = self.auto_proxy.run_test()
+
+        self.tb_writer.add_scalar('test_results/avg_loss', avg_loss, self.current_round)
+        self.tb_writer.add_scalar('test_results/correct_rate', correct_rate, self.current_round)
+
+    def is_task_finished(self) -> bool:
+        """Decide if stop training.
+
+        If there are validation dataset, decide depending on validatation results. If
+        the validation result of current epoch is below the best record for 10 continuous
+        times, then stop training.
+        If there are no validation dataset, run for `max_rounds` times.
+        """
+        if not self.validation_loader or len(self.validation_loader) == 0:
+            self._best_state = deepcopy(self.state_dict())
+            return self._is_reach_max_rounds()
+
+        # make a validation
+        self.push_log(f'Begin validation of round {self.current_round}.')
+        avg_loss, correct_rate = self.auto_proxy.run_validation()
+        self.push_log('\n'.join(('Validation result:',
+                                 f'avg_loss={avg_loss:.4f}',
+                                 f'correct_rate={correct_rate:.2f}')))
+
+        if correct_rate > self._best_result:
+            self._overfit_index = 0
+            self._best_result = correct_rate
+            self._best_state = deepcopy(self.state_dict())
+            self.push_log('Validation result is better than last epoch.')
+            return self._is_reach_max_rounds()
+        else:
+            self._overfit_index += 1
+            msg = f'Validation result gets worse for {self._overfit_index} consecutive times.'
+            self.push_log(msg)
+            return self._overfit_index >= 10 or self._is_reach_max_rounds()
```

### Comparing `alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/breast_density_classification/res_local/inception3.py` & `alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/breast_density_classification/res_local/inception3.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/breast_density_classification/run_aggregator.py` & `alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/breast_density_classification/run_aggregator.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/breast_density_classification/run_data_owner_2.py` & `alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/breast_density_classification/run_data_owner_2.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/breast_density_classification/run_data_owner_4.py` & `alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/breast_density_classification/run_data_owner_4.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/breast_density_classification/run_local.py` & `alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/endoscopic_inbody_classification/run_local.py`

 * *Files 14% similar despite different names*

```diff
@@ -5,23 +5,23 @@
 PYTHONPATH = os.path.join(CURRENT_DIR, os.pardir, os.pardir, os.pardir, os.pardir, os.pardir)
 sys.path.insert(0, PYTHONPATH)
 
 
 if True:
     import alphafed  # noqa: F401, setup latest alphafed running context
     from alphafed.auto_ml import from_pretrained
-    from alphafed.examples.auto_ml.breast_density_classification import (
+    from alphafed.examples.auto_ml.endoscopic_inbody_classification import (
         AGGREGATOR_ID, DEV_TASK_ID)
 
 
 if __name__ == '__main__':
     resource_dir = os.path.join(CURRENT_DIR, 'res_local')
-    auto_model = from_pretrained(name='breast_density_classification',
+    auto_model = from_pretrained(name='endoscopic_inbody_classification',
                                  resource_dir=resource_dir,
                                  download=True)
     auto_model.fine_tune(id=AGGREGATOR_ID,
                          task_id=DEV_TASK_ID,
                          dataset_dir=os.path.join(CURRENT_DIR, 'data'),
                          is_debug_script=True)
-    image = os.path.join(CURRENT_DIR, 'data', 'sample_A2.jpg')
+    image = os.path.join(CURRENT_DIR, 'data', '53125.jpg')
     predict = auto_model(image)
     print(f'{predict=}')
```

### Comparing `alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/endoscopic_inbody_classification/__init__.py` & `alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/endoscopic_inbody_classification/__init__.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/endoscopic_inbody_classification/clean_history_msg.py` & `alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/endoscopic_inbody_classification/clean_history_msg.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/endoscopic_inbody_classification/res_fed_avg/auto.py` & `alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/endoscopic_inbody_classification/res_fed_avg/auto.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,743 +1,745 @@
-# Copyright 2022 Alphamed
-
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-
-#     http://www.apache.org/licenses/LICENSE-2.0
-
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-
-"""Pretraining endoscopic_inbody_classification models and schedulers."""
-
-import json
-import os
-from copy import deepcopy
-from dataclasses import InitVar, asdict, dataclass
-from typing import Dict, Optional, Tuple, overload
-
-import numpy as np
-import torch
-import torch.nn.functional as F
-from PIL import Image
-from senet.cv.senet import SEResNet50
-from torch import nn, optim
-from torch.utils.data import DataLoader, Dataset
-from torchvision import transforms
-
-from alphafed import get_result_dir, logger
-from alphafed.auto_ml.auto_model import (AutoFedAvgModel, AutoFedAvgScheduler,
-                                         AutoModel, DatasetMode,
-                                         MandatoryConfig, Preprocessor)
-from alphafed.auto_ml.cvat.annotation import ImageAnnotationUtils
-from alphafed.auto_ml.exceptions import AutoModelError, ConfigError
-
-
-@dataclass
-class PreprocessorConfig:
-
-    size: int
-    do_rotation: bool
-    do_scale_intensity: bool
-    do_shift_intensity: bool
-    do_gaussian_noised: bool
-    do_horizontal_flip: bool
-    do_vertical_flip: bool
-    do_channel_wise_normalize: bool
-
-    prob_rotation: float = 0.0
-    degrees: float = 0.0
-    prob_scale_intensity: float = 0.0
-    prob_shift_intensity: float = 0.0
-    prob_gaussian_noised: float = 0.0
-
-    def __post_init__(self):
-        if self.do_rotation and (self.prob_rotation < 0 or self.prob_rotation > 1):
-            raise ConfigError(f'Invalid prob_rotation: `{self.prob_rotation}`.')
-        if (
-            self.do_scale_intensity
-            and (self.prob_scale_intensity < 0 or self.prob_scale_intensity > 1)
-        ):
-            raise ConfigError(f'Invalid prob_scale_intensity: `{self.prob_scale_intensity}`.')
-        if (
-            self.do_shift_intensity
-            and (self.prob_shift_intensity < 0 or self.prob_shift_intensity > 1)
-        ):
-            raise ConfigError(f'Invalid prob_shift_intensity: `{self.prob_shift_intensity}`.')
-        if (
-            self.do_gaussian_noised
-            and (self.prob_gaussian_noised < 0 or self.prob_gaussian_noised > 1)
-        ):
-            raise ConfigError(f'Invalid prob_gaussian_noised: `{self.prob_gaussian_noised}`.')
-
-
-class SEResNetPreprocessor(Preprocessor):
-
-    class ScaleIntensity(nn.Module):
-
-        def __init__(self) -> None:
-            super().__init__()
-
-        def forward(self, image: torch.Tensor, factor: float = 0.3) -> torch.Tensor:
-            return image * (1 + factor)
-
-    def __init__(self, mode: DatasetMode, config: PreprocessorConfig) -> None:
-        super().__init__()
-        self.R = np.random.RandomState()
-        layers = [transforms.Resize((config.size, config.size))]
-        if mode == DatasetMode.TRAINING:
-            if config.do_rotation:
-                layers.append(transforms.RandomApply(
-                    nn.Sequential(
-                        transforms.RandomRotation(
-                            degrees=config.degrees,
-                            interpolation=transforms.InterpolationMode.BILINEAR
-                        )
-                    ),
-                    p=config.prob_rotation
-                ))
-        layers.append(transforms.ToTensor())
-        if mode == DatasetMode.TRAINING:
-            if config.do_scale_intensity:
-                layers.append(transforms.RandomApply([self._scale_intensity],
-                                                     p=config.prob_scale_intensity))
-            if config.do_shift_intensity:
-                layers.append(transforms.RandomApply([self._shift_intensity],
-                                                     p=config.prob_shift_intensity))
-            if config.do_gaussian_noised:
-                layers.append(transforms.RandomApply([self._gaussian_noised],
-                                                     p=config.prob_gaussian_noised))
-            if config.do_horizontal_flip:
-                layers.append(transforms.RandomHorizontalFlip())
-            if config.do_vertical_flip:
-                layers.append(transforms.RandomVerticalFlip())
-        layers.append(transforms.Lambda(lambda image: self._channel_wise_normalize(image=image)))
-        self._transformer = transforms.Compose(layers)
-
-    def _channel_wise_normalize(self, image: torch.Tensor) -> torch.Tensor:
-        for i, _chn in enumerate(image):
-            slices = _chn != 0
-            _mean = torch.mean(_chn[slices])
-            _std = torch.std(_chn[slices], unbiased=False)
-            _chn = (_chn - _mean) / _std
-            image[i] = _chn
-        return image
-
-    def _scale_intensity(self, image: torch.Tensor, factor: float = 0.3) -> torch.Tensor:
-        return image * (1 + factor)
-
-    def _shift_intensity(self, image: torch.Tensor, offset: float = 0.1) -> torch.Tensor:
-        return image + offset
-
-    def _gaussian_noised(self,
-                         image: torch.Tensor,
-                         mean: float = 0.0,
-                         std: float = 0.01) -> torch.Tensor:
-        rand_std = self.R.uniform(0, std)
-        noise = self.R.normal(mean, rand_std, size=image.shape)
-        return image + noise.astype(np.float32)
-
-    def transform(self, image_file: str) -> torch.Tensor:
-        """Transform an image object into an input tensor."""
-        image = Image.open(image_file).convert('RGB')
-        image = self._transformer(image)
-        return image
-
-
-class SEResNetDataset(Dataset):
-
-    def __init__(self,
-                 image_dir: str,
-                 annotation_file: str,
-                 mode: DatasetMode,
-                 config: PreprocessorConfig) -> None:
-        """Init a dataset instance for ResNet auto model families.
-
-        Args:
-            image_dir:
-                The directory including image files.
-            annotation_file:
-                The file including annotation information.
-            mode:
-                One of training or validation or testing.
-            config:
-                The configuration for the preprocessor.
-        """
-        super().__init__()
-        if not image_dir or not isinstance(image_dir, str):
-            raise ConfigError(f'Invalid image directory: {image_dir}.')
-        if not annotation_file or not isinstance(annotation_file, str):
-            raise ConfigError(f'Invalid annotation file path: {annotation_file}.')
-        assert mode and isinstance(mode, DatasetMode), f'Invalid dataset mode: {mode}.'
-        if not os.path.exists(image_dir) or not os.path.isdir(image_dir):
-            raise ConfigError(f'{image_dir} does not exist or is not a directory.')
-        if not os.path.exists(annotation_file) or not os.path.isfile(annotation_file):
-            raise ConfigError(f'{annotation_file} does not exist or is not a file.')
-
-        self.image_dir = image_dir
-        self.annotation_file = annotation_file
-        self.transformer = SEResNetPreprocessor(mode=mode, config=config)
-
-        self.images, self.labels = ImageAnnotationUtils.parse_single_category_annotation(
-            annotation_file=self.annotation_file, resource_dir=image_dir, mode=mode
-        )
-
-    def __getitem__(self, index: int):
-        _item = self.images[index]
-        return self.transformer(_item.image_file), _item.class_label
-
-    def __len__(self):
-        return len(self.images)
-
-
-@dataclass
-class ModelConfig(MandatoryConfig):
-
-    id2label: dict
-    label2id: dict
-    learning_rate: int
-    batch_size: int
-    epochs: int
-    image_size: int = 256
-    torch_dtype: InitVar[str] = 'float32'
-
-    def __post_init__(self, torch_dtype: str):
-        super().__post_init__()
-
-        for _label in self.id2label.values():
-            if _label not in self.label2id:
-                raise TypeError(f'Label `{_label}` lost its ID in label2id map.')
-        for _id in self.label2id.values():
-            if str(_id) not in self.id2label:
-                raise TypeError(f'ID `{_id}` lost its label in id2label map.')
-
-        if self.learning_rate <= 0:
-            raise TypeError(f'Invalid learning_rate: `{self.learning_rate}`.')
-        if self.batch_size <= 0:
-            raise TypeError(f'Invalid batch_size: `{self.batch_size}`.')
-        if self.epochs <= 0:
-            raise TypeError(f'Invalid epochs: `{self.epochs}`.')
-
-        if self.image_size <= 0:
-            raise TypeError(f'Invalid image_size: `{self.image_size}`.')
-
-        if torch_dtype == 'float32' or torch_dtype == 'float':
-            self.torch_dtype = torch.float32
-        elif torch_dtype == 'float64':
-            self.torch_dtype = torch.float64
-        elif torch == 'float16':
-            self.torch_dtype = torch.float16
-        else:
-            raise TypeError(f'Invalid torch_dtype: `{torch_dtype}`.')
-
-
-class AutoSEResNet(AutoModel):
-
-    def __init__(self, resource_dir: str, **kwargs) -> None:
-        super().__init__(resource_dir=resource_dir)
-
-        self.config, self.preprocessor_config = self._load_config()
-        self.epochs = self.config.epochs
-        self.batch_size = self.config.batch_size
-        self.lr = self.config.learning_rate
-        self._epoch = 0
-        self.is_cuda = torch.cuda.is_available()
-
-        self.dataset_dir = None
-        self.labels = None
-
-        self._best_result = 0
-        self._best_state = None
-        self._overfit_index = 0
-        self._is_dataset_initialized = False
-        self._save_root = '.cache'
-
-    def _load_config(self) -> Tuple[ModelConfig, PreprocessorConfig]:
-        config_file = os.path.join(self.resource_dir, 'config.json')
-        if not os.path.isfile(config_file):
-            raise ConfigError('Config file missing.')
-        try:
-            with open(config_file, 'r') as f:
-                config_json = json.load(f)
-        except json.JSONDecodeError:
-            raise ConfigError('Failed to parse config file.')
-        model_config = ModelConfig(**config_json)
-
-        preprocessor_config_file = os.path.join(self.resource_dir, 'preprocessor_config.json')
-        if not os.path.isfile(preprocessor_config_file):
-            raise ConfigError('Preprocessor config file missing.')
-        try:
-            with open(preprocessor_config_file, 'r') as f:
-                preprocessor_config_json = json.load(f)
-        except json.JSONDecodeError:
-            raise ConfigError('Failed to parse preprocessor config file.')
-        preprocessor_config = PreprocessorConfig(**preprocessor_config_json)
-
-        return model_config, preprocessor_config
-
-    @property
-    def annotation_file(self):
-        return os.path.join(self.dataset_dir, 'annotation.json') if self.dataset_dir else None
-
-    def init_dataset(self, dataset_dir: str) -> Tuple[bool, str]:
-        self.dataset_dir = dataset_dir
-        try:
-            if not self._is_dataset_initialized:
-                self.training_loader
-                self.validation_loader
-                self.testing_loader
-                if not self.training_loader or not self.testing_loader:
-                    logger.error('Both training data and testing data are missing.')
-                    return False, 'Must provide train dataset and test dataset to fine tune.'
-                self.labels = (self.training_loader.dataset.labels
-                               if self.training_loader
-                               else self.testing_loader.dataset.labels)
-                self._is_dataset_initialized = True
-            return True, 'Initializing dataset complete.'
-        except Exception:
-            logger.exception('Failed to initialize dataset.')
-            return False, '初始化数据失败，请联系模型作者排查原因。'
-
-    @property
-    def training_loader(self) -> DataLoader:
-        """Return a dataloader instance of training data.
-
-        Data augmentation is used to improve performance, so we need to generate a new dataset
-        every epoch in case of training on a same dataset over and over again.
-        """
-        if not hasattr(self, "_training_loader"):
-            self._training_loader = self._build_training_data_loader()
-        return self._training_loader
-
-    def _build_training_data_loader(self) -> Optional[DataLoader]:
-        dataset = SEResNetDataset(image_dir=self.dataset_dir,
-                                  annotation_file=self.annotation_file,
-                                  mode=DatasetMode.TRAINING,
-                                  config=self.preprocessor_config)
-        if len(dataset) == 0:
-            return None
-        return DataLoader(dataset=dataset,
-                          batch_size=self.batch_size,
-                          shuffle=True)
-
-    @property
-    def validation_loader(self) -> DataLoader:
-        """Return a dataloader instance of validation data."""
-        if not hasattr(self, "_validation_loader"):
-            self._validation_loader = self._build_validation_data_loader()
-        return self._validation_loader
-
-    def _build_validation_data_loader(self) -> DataLoader:
-        dataset = SEResNetDataset(image_dir=self.dataset_dir,
-                                  annotation_file=self.annotation_file,
-                                  mode=DatasetMode.VALIDATION,
-                                  config=self.preprocessor_config)
-        if len(dataset) == 0:
-            return None
-        return DataLoader(dataset=dataset, batch_size=self.batch_size)
-
-    @property
-    def testing_loader(self) -> DataLoader:
-        """Return a dataloader instance of testing data."""
-        if not hasattr(self, "_testing_loader"):
-            self._testing_loader = self._build_testing_data_loader()
-        return self._testing_loader
-
-    def _build_testing_data_loader(self) -> DataLoader:
-        dataset = SEResNetDataset(image_dir=self.dataset_dir,
-                                  annotation_file=self.annotation_file,
-                                  mode=DatasetMode.TESTING,
-                                  config=self.preprocessor_config)
-        if len(dataset) == 0:
-            return None
-        return DataLoader(dataset=dataset, batch_size=self.batch_size)
-
-    def _build_model(self):
-        self._model: nn.Module = SEResNet50(spatial_dims=2, in_channels=3)
-
-        self.labels = list(self.config.id2label.values())
-        self._replace_fc_if_diff(len(self.labels))
-
-        param_file = os.path.join(self.resource_dir, self.config.param_file)
-        with open(param_file, 'rb') as f:
-            state_dict = torch.load(f)
-            model_num_classes = self._model.get_parameter('last_linear.weight').shape[0]
-            param_num_classes = state_dict['last_linear.weight'].shape[0]
-            if model_num_classes != param_num_classes:
-                raise AutoModelError('The fine tuned labels dismatched the parameters.')
-            self._model.load_state_dict(state_dict)
-
-        return self._model.cuda() if self.is_cuda else self._model
-
-    def _replace_fc_if_diff(self, num_classes: int):
-        """Replace the classify layer with new number of classes."""
-        assert (
-            num_classes and isinstance(num_classes, int) and num_classes > 0
-        ), f'Invalid number of classes: {num_classes} .'
-        if num_classes != self.num_classes:
-            self.model.last_linear = nn.Linear(2048, num_classes)
-
-    @property
-    def num_classes(self) -> int:
-        """Return the number of classes of the classification layer of the model."""
-        return self.model.get_parameter('last_linear.weight').shape[0]
-
-    @property
-    def model(self) -> nn.Module:
-        if not hasattr(self, '_model'):
-            self._model = self._build_model()
-        return self._model
-
-    @property
-    def optimizer(self) -> optim.Optimizer:
-        if not hasattr(self, '_optimizer'):
-            self._optimizer = optim.Adam(self.model.parameters(), lr=self.lr)
-        return self._optimizer
-
-    def train(self):
-        self.model.train()
-
-    def eval(self):
-        self.model.eval()
-
-    @overload
-    def forward(self, input: torch.Tensor) -> str:
-        """Predict an image's tensor and give its label."""
-
-    @overload
-    def forward(self, input: str) -> str:
-        """Predict an image defined by a file path and give its label."""
-
-    @torch.no_grad()
-    def forward(self, input):
-        if not input or not isinstance(input, (str, torch.Tensor)):
-            raise AutoModelError(f'Invalid input data: {input}.')
-        if isinstance(input, str):
-            if not os.path.isfile(input):
-                raise AutoModelError(f'Cannot find or access the image file {input}.')
-            preprocessor = SEResNetPreprocessor(mode=DatasetMode.PREDICTING,
-                                                config=self.preprocessor_config)
-            input = preprocessor.transform(input)
-            input.unsqueeze_(0)
-        self.model.eval()
-        output: torch.Tensor = self.model(input)
-        predict = output.argmax(1)[0].item()
-        if not self.labels:
-            if not os.path.isfile(os.path.join(self.resource_dir, 'fine_tuned.meta')):
-                raise AutoModel('The `fine_tuned.meta` file is required to make prediction.')
-            with open(os.path.join(self.resource_dir, 'fine_tuned.meta')) as f:
-                fine_tuned_json: dict = json.loads(f)
-                self.labels = fine_tuned_json.get('labels')
-        return self.labels[predict]
-
-    def _train_an_epoch(self):
-        self.train()
-        for images, targets in self.training_loader:
-            if self.is_cuda:
-                images, targets = images.cuda(), targets.cuda()
-            output = self.model(images)
-            loss = F.cross_entropy(output, targets)
-            self.optimizer.zero_grad()
-            loss.backward()
-            self.optimizer.step()
-
-    @torch.no_grad()
-    def _run_test(self) -> Tuple[float, float]:
-        """Run a round of test and report the result.
-
-        Return:
-            avg_loss, correct_rate
-        """
-        self.push_log(f'Begin testing of epoch {self._epoch}.')
-        self.eval()
-        total_loss = 0
-        total_correct = 0
-        for images, targets in self.testing_loader:
-            if self.is_cuda:
-                images, targets = images.cuda(), targets.cuda()
-            output = self.model(images)
-            loss = F.cross_entropy(output, targets, reduction='sum').item()
-            total_loss += loss
-            pred = output.max(1, keepdim=True)[1]
-            total_correct += pred.eq(targets.view_as(pred)).sum().item()
-
-        avg_loss = total_loss / len(self.testing_loader.dataset)
-        correct_rate = total_correct / len(self.testing_loader.dataset) * 100
-        logger.info(f'Testing Average Loss: {avg_loss:.4f}')
-        logger.info(f'Testing Correct Rate: {correct_rate:.2f}')
-
-        return avg_loss, correct_rate
-
-    @torch.no_grad()
-    def _run_validation(self) -> Tuple[float, float]:
-        """Run a round of validation and report the result.
-
-        Return:
-            avg_loss, correct_rate
-        """
-        self.eval()
-        total_loss = 0
-        total_correct = 0
-        for images, targets in self.validation_loader:
-            if self.is_cuda:
-                images, targets = images.cuda(), targets.cuda()
-            output = self.model(images)
-            loss = F.cross_entropy(output, targets, reduction='sum').item()
-            total_loss += loss
-            pred = output.max(1, keepdim=True)[1]
-            total_correct += pred.eq(targets.view_as(pred)).sum().item()
-
-        avg_loss = total_loss / len(self.validation_loader.dataset)
-        correct_rate = total_correct / len(self.validation_loader.dataset) * 100
-        logger.info(f'Validation Average Loss: {avg_loss:.4f}')
-        logger.info(f'Validation Correct Rate: {correct_rate:.2f}')
-        return avg_loss, correct_rate
-
-    @torch.no_grad()
-    def _is_finished(self) -> bool:
-        """Decide if stop training.
-
-        If there are validation dataset, decide depending on validatation results. If
-        the validation result of current epoch is below the best record for 10 continuous
-        times, then stop training.
-        If there are no validation dataset, run for `epochs` times.
-        """
-        if not self.validation_loader or len(self.validation_loader) == 0:
-            if self._epoch >= self.epochs:
-                self._best_state = deepcopy(self.model.state_dict())
-            return self._epoch >= self.epochs
-        # make a validation
-        self.push_log(f'Begin validation of epoch {self._epoch}.')
-        avg_loss, correct_rate = self._run_validation()
-        self.push_log('\n'.join(('Validation result:',
-                                 f'avg_loss={avg_loss:.4f}',
-                                 f'correct_rate={correct_rate:.2f}')))
-
-        if correct_rate > self._best_result:
-            self._overfit_index = 0
-            self._best_result = correct_rate
-            self._best_state = deepcopy(self.model.state_dict())
-            self.push_log('Validation result is better than last epoch.')
-            return self._epoch >= self.epochs
-        else:
-            self._overfit_index += 1
-            msg = f'Validation result gets worse for {self._overfit_index} consecutive times.'
-            self.push_log(msg)
-            return self._overfit_index >= 10 or self._epoch >= self.epochs
-
-    def fine_tune(self,
-                  id: str,
-                  task_id: str,
-                  dataset_dir: str,
-                  is_initiator: bool = False,
-                  is_debug_script: bool = False):
-        self.id = id
-        self.task_id = task_id
-        self.is_initiator = is_initiator
-        self.is_debug_script = is_debug_script
-
-        is_succ, err_msg = self.init_dataset(dataset_dir)
-        if not is_succ:
-            raise AutoModelError(f'Failed to initialize dataset. {err_msg}')
-        num_classes = (len(self.training_loader.dataset.labels)
-                       if self.training_loader
-                       else len(self.testing_loader.dataset.labels))
-        self._replace_fc_if_diff(num_classes)
-
-        self.config.id2label = {str(_idx): _label for _idx, _label in enumerate(self.labels)}
-        self.config.label2id = {_label: _idx for _idx, _label in enumerate(self.labels)}
-        self.config.label2id = dict(sorted(self.config.label2id.items()))
-
-        is_finished = False
-        self._epoch = 0
-        while not is_finished:
-            self._epoch += 1
-            self.push_log(f'Begin training of epoch {self._epoch}.')
-            self._train_an_epoch()
-            self.push_log(f'Complete training of epoch {self._epoch}.')
-            is_finished = self._is_finished()
-
-        self._save_fine_tuned()
-        avg_loss, correct_rate = self._run_test()
-        self.push_log('\n'.join(('Testing result:',
-                                 f'avg_loss={avg_loss:.4f}',
-                                 f'correct_rate={correct_rate:.2f}')))
-
-    def _save_fine_tuned(self):
-        """Save the best or final state of fine tuning."""
-        self.result_dir = get_result_dir(self.task_id)
-        os.makedirs(self.result_dir, exist_ok=True)
-        with open(os.path.join(self.result_dir, self.config.param_file), 'wb') as f:
-            torch.save(self._best_state, f)
-        with open(os.path.join(self.result_dir, 'config.json'), 'w') as f:
-            f.write(json.dumps(asdict(self.config), ensure_ascii=False))
-
-
-class AutoSEResNetFedAvg(AutoSEResNet, AutoFedAvgModel):
-
-    def state_dict(self) -> Dict[str, torch.Tensor]:
-        return self.model.state_dict()
-
-    def load_state_dict(self, state_dict: Dict[str, torch.Tensor]):
-        return self.model.load_state_dict(state_dict)
-
-    def train_an_epoch(self):
-        self._epoch += 1
-        self._train_an_epoch()
-
-    def run_test(self) -> Tuple[float, float]:
-        """Run a test and report the result.
-
-        Return:
-            avg_loss, correct_rate
-        """
-        return self._run_test()
-
-    def run_validation(self):
-        """Run a test and report the result.
-
-        Return:
-            avg_loss, correct_rate
-        """
-        return self._run_validation()
-
-    def init_dataset(self, dataset_dir: str) -> Tuple[bool, str]:
-        self.dataset_dir = dataset_dir
-        try:
-            if not self._is_dataset_initialized:
-                self.training_loader
-                self.validation_loader
-                self.testing_loader
-                if not self.training_loader and not self.testing_loader:
-                    logger.error('Both training data and testing data are missing.')
-                    err_msg = ' '.join((
-                        'The initiator must provide test dataset.',
-                        'The collaborator must provide train dataset.'
-                    ))
-                    return False, err_msg
-                self.labels = (self.training_loader.dataset.labels
-                               if self.training_loader
-                               else self.testing_loader.dataset.labels)
-                self._is_dataset_initialized = True
-            return True, 'Initializing dataset complete.'
-        except Exception:
-            logger.exception('Failed to initialize dataset.')
-            return False, '初始化数据失败，请联系模型作者排查原因。'
-
-    def fine_tune(self,
-                  id: str,
-                  task_id: str,
-                  dataset_dir: str,
-                  is_initiator: bool = False,
-                  recover: bool = False):
-        is_succ, err_msg = self.init_dataset(dataset_dir)
-        if not is_succ:
-            raise AutoModelError(f'Failed to initialize dataset. {err_msg}')
-        num_classes = (len(self.training_loader.dataset.labels)
-                       if self.training_loader
-                       else len(self.testing_loader.dataset.labels))
-        self._replace_fc_if_diff(num_classes)
-
-        self.config.id2label = {str(_idx): _label for _idx, _label in enumerate(self.labels)}
-        self.config.label2id = {_label: _idx for _idx, _label in enumerate(self.labels)}
-        self.config.label2id = dict(sorted(self.config.label2id.items()))
-
-        self._fine_tune_impl(id=id,
-                             task_id=task_id,
-                             dataset_dir=dataset_dir,
-                             scheduler_impl=SEResNetFedAvgScheduler,
-                             is_initiator=is_initiator,
-                             recover=recover,
-                             max_rounds=self.config.epochs,
-                             log_rounds=1)
-
-    def fine_tuned_files_dict(self) -> Optional[Dict[str, str]]:
-        param_file = os.path.join(self.result_dir, self.config.param_file)
-        with open(param_file, 'wb') as f:
-            torch.save(self.scheduler.best_state_dict, f)
-        config_file = os.path.join(self.result_dir, 'config.json')
-        with open(config_file, 'w') as f:
-            f.write(json.dumps(asdict(self.config), ensure_ascii=False))
-        return {
-            self.config.param_file: param_file,
-            'config.json': config_file
-        }
-
-
-class SEResNetFedAvgScheduler(AutoFedAvgScheduler):
-
-    def __init__(self,
-                 auto_proxy: AutoSEResNetFedAvg,
-                 max_rounds: int = 0,
-                 merge_epochs: int = 1,
-                 calculation_timeout: int = 300,
-                 schedule_timeout: int = 30,
-                 log_rounds: int = 0,
-                 involve_aggregator: bool = False):
-        super().__init__(auto_proxy=auto_proxy,
-                         max_rounds=max_rounds,
-                         merge_epochs=merge_epochs,
-                         calculation_timeout=calculation_timeout,
-                         schedule_timeout=schedule_timeout,
-                         log_rounds=log_rounds,
-                         involve_aggregator=involve_aggregator)
-        self._best_state = None
-        self._best_result = 0
-        self._overfit_index = 0
-
-    @property
-    def best_state_dict(self) -> Dict[str, torch.Tensor]:
-        return self._best_state
-
-    def validate_context(self):
-        super().validate_context()
-        if self.is_initiator:
-            assert self.test_loader and len(self.test_loader) > 0, 'failed to load test data'
-            self.push_log(f'There are {len(self.test_loader.dataset)} samples for testing.')
-        else:
-            assert self.train_loader and len(self.train_loader) > 0, 'failed to load train data'
-            self.push_log(f'There are {len(self.train_loader.dataset)} samples for training.')
-
-    def train_an_epoch(self):
-        self.auto_proxy.train_an_epoch()
-
-    def run_test(self):
-        avg_loss, correct_rate = self.auto_proxy.run_test()
-
-        self.tb_writer.add_scalar('test_results/avg_loss', avg_loss, self.current_round)
-        self.tb_writer.add_scalar('test_results/correct_rate', correct_rate, self.current_round)
-
-    def is_task_finished(self) -> bool:
-        """Decide if stop training.
-
-        If there are validation dataset, decide depending on validatation results. If
-        the validation result of current epoch is below the best record for 10 continuous
-        times, then stop training.
-        If there are no validation dataset, run for `max_rounds` times.
-        """
-        if not self.validation_loader or len(self.validation_loader) == 0:
-            self._best_state = deepcopy(self.state_dict())
-            return self._is_reach_max_rounds()
-
-        # make a validation
-        self.push_log(f'Begin validation of round {self.current_round}.')
-        avg_loss, correct_rate = self.auto_proxy.run_validation()
-        self.push_log('\n'.join(('Validation result:',
-                                 f'avg_loss={avg_loss:.4f}',
-                                 f'correct_rate={correct_rate:.2f}')))
-
-        if correct_rate > self._best_result:
-            self._overfit_index = 0
-            self._best_result = correct_rate
-            self._best_state = deepcopy(self.state_dict())
-            self.push_log('Validation result is better than last epoch.')
-            return self._is_reach_max_rounds()
-        else:
-            self._overfit_index += 1
-            msg = f'Validation result gets worse for {self._overfit_index} consecutive times.'
-            self.push_log(msg)
-            return self._overfit_index >= 10 or self._is_reach_max_rounds()
+# Copyright 2022 Alphamed
+
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+
+#     http://www.apache.org/licenses/LICENSE-2.0
+
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+"""Pretraining endoscopic_inbody_classification models and schedulers."""
+
+import json
+import os
+from copy import deepcopy
+from dataclasses import InitVar, asdict, dataclass
+from typing import Dict, Optional, Tuple, overload
+
+import numpy as np
+import torch
+import torch.nn.functional as F
+from PIL import Image
+from senet.cv.senet import SEResNet50
+from torch import nn, optim
+from torch.utils.data import DataLoader, Dataset
+from torchvision import transforms
+
+from alphafed import get_result_dir, logger
+from alphafed.auto_ml.auto_model import (AutoFedAvgModel, AutoFedAvgScheduler,
+                                         AutoModel, DatasetMode,
+                                         MandatoryConfig, Preprocessor)
+from alphafed.auto_ml.cvat.annotation import ImageAnnotationUtils
+from alphafed.auto_ml.exceptions import AutoModelError, ConfigError
+
+
+@dataclass
+class PreprocessorConfig:
+
+    size: int
+    do_rotation: bool
+    do_scale_intensity: bool
+    do_shift_intensity: bool
+    do_gaussian_noised: bool
+    do_horizontal_flip: bool
+    do_vertical_flip: bool
+    do_channel_wise_normalize: bool
+
+    prob_rotation: float = 0.0
+    degrees: float = 0.0
+    prob_scale_intensity: float = 0.0
+    prob_shift_intensity: float = 0.0
+    prob_gaussian_noised: float = 0.0
+
+    def __post_init__(self):
+        if self.do_rotation and (self.prob_rotation < 0 or self.prob_rotation > 1):
+            raise ConfigError(f'Invalid prob_rotation: `{self.prob_rotation}`.')
+        if (
+            self.do_scale_intensity
+            and (self.prob_scale_intensity < 0 or self.prob_scale_intensity > 1)
+        ):
+            raise ConfigError(f'Invalid prob_scale_intensity: `{self.prob_scale_intensity}`.')
+        if (
+            self.do_shift_intensity
+            and (self.prob_shift_intensity < 0 or self.prob_shift_intensity > 1)
+        ):
+            raise ConfigError(f'Invalid prob_shift_intensity: `{self.prob_shift_intensity}`.')
+        if (
+            self.do_gaussian_noised
+            and (self.prob_gaussian_noised < 0 or self.prob_gaussian_noised > 1)
+        ):
+            raise ConfigError(f'Invalid prob_gaussian_noised: `{self.prob_gaussian_noised}`.')
+
+
+class SEResNetPreprocessor(Preprocessor):
+
+    class ScaleIntensity(nn.Module):
+
+        def __init__(self) -> None:
+            super().__init__()
+
+        def forward(self, image: torch.Tensor, factor: float = 0.3) -> torch.Tensor:
+            return image * (1 + factor)
+
+    def __init__(self, mode: DatasetMode, config: PreprocessorConfig) -> None:
+        super().__init__()
+        self.R = np.random.RandomState()
+        layers = [transforms.Resize((config.size, config.size))]
+        if mode == DatasetMode.TRAINING:
+            if config.do_rotation:
+                layers.append(transforms.RandomApply(
+                    nn.Sequential(
+                        transforms.RandomRotation(
+                            degrees=config.degrees,
+                            interpolation=transforms.InterpolationMode.BILINEAR
+                        )
+                    ),
+                    p=config.prob_rotation
+                ))
+        layers.append(transforms.ToTensor())
+        if mode == DatasetMode.TRAINING:
+            if config.do_scale_intensity:
+                layers.append(transforms.RandomApply([self._scale_intensity],
+                                                     p=config.prob_scale_intensity))
+            if config.do_shift_intensity:
+                layers.append(transforms.RandomApply([self._shift_intensity],
+                                                     p=config.prob_shift_intensity))
+            if config.do_gaussian_noised:
+                layers.append(transforms.RandomApply([self._gaussian_noised],
+                                                     p=config.prob_gaussian_noised))
+            if config.do_horizontal_flip:
+                layers.append(transforms.RandomHorizontalFlip())
+            if config.do_vertical_flip:
+                layers.append(transforms.RandomVerticalFlip())
+        layers.append(transforms.Lambda(lambda image: self._channel_wise_normalize(image=image)))
+        self._transformer = transforms.Compose(layers)
+
+    def _channel_wise_normalize(self, image: torch.Tensor) -> torch.Tensor:
+        for i, _chn in enumerate(image):
+            slices = _chn != 0
+            _mean = torch.mean(_chn[slices])
+            _std = torch.std(_chn[slices], unbiased=False)
+            _chn = (_chn - _mean) / _std
+            image[i] = _chn
+        return image
+
+    def _scale_intensity(self, image: torch.Tensor, factor: float = 0.3) -> torch.Tensor:
+        return image * (1 + factor)
+
+    def _shift_intensity(self, image: torch.Tensor, offset: float = 0.1) -> torch.Tensor:
+        return image + offset
+
+    def _gaussian_noised(self,
+                         image: torch.Tensor,
+                         mean: float = 0.0,
+                         std: float = 0.01) -> torch.Tensor:
+        rand_std = self.R.uniform(0, std)
+        noise = self.R.normal(mean, rand_std, size=image.shape)
+        return image + noise.astype(np.float32)
+
+    def transform(self, image_file: str) -> torch.Tensor:
+        """Transform an image object into an input tensor."""
+        image = Image.open(image_file).convert('RGB')
+        image = self._transformer(image)
+        return image
+
+
+class SEResNetDataset(Dataset):
+
+    def __init__(self,
+                 image_dir: str,
+                 annotation_file: str,
+                 mode: DatasetMode,
+                 config: PreprocessorConfig) -> None:
+        """Init a dataset instance for ResNet auto model families.
+
+        Args:
+            image_dir:
+                The directory including image files.
+            annotation_file:
+                The file including annotation information.
+            mode:
+                One of training or validation or testing.
+            config:
+                The configuration for the preprocessor.
+        """
+        super().__init__()
+        if not image_dir or not isinstance(image_dir, str):
+            raise ConfigError(f'Invalid image directory: {image_dir}.')
+        if not annotation_file or not isinstance(annotation_file, str):
+            raise ConfigError(f'Invalid annotation file path: {annotation_file}.')
+        assert mode and isinstance(mode, DatasetMode), f'Invalid dataset mode: {mode}.'
+        if not os.path.exists(image_dir) or not os.path.isdir(image_dir):
+            raise ConfigError(f'{image_dir} does not exist or is not a directory.')
+        if not os.path.exists(annotation_file) or not os.path.isfile(annotation_file):
+            raise ConfigError(f'{annotation_file} does not exist or is not a file.')
+
+        self.image_dir = image_dir
+        self.annotation_file = annotation_file
+        self.transformer = SEResNetPreprocessor(mode=mode, config=config)
+
+        self.images, self.labels = ImageAnnotationUtils.parse_single_category_annotation(
+            annotation_file=self.annotation_file, resource_dir=image_dir, mode=mode
+        )
+
+    def __getitem__(self, index: int):
+        _item = self.images[index]
+        return self.transformer(_item.image_file), _item.class_label
+
+    def __len__(self):
+        return len(self.images)
+
+
+@dataclass
+class ModelConfig(MandatoryConfig):
+
+    id2label: dict
+    label2id: dict
+    learning_rate: int
+    batch_size: int
+    epochs: int
+    image_size: int = 256
+    torch_dtype: InitVar[str] = 'float32'
+
+    def __post_init__(self, torch_dtype: str):
+        super().__post_init__()
+
+        for _label in self.id2label.values():
+            if _label not in self.label2id:
+                raise TypeError(f'Label `{_label}` lost its ID in label2id map.')
+        for _id in self.label2id.values():
+            if str(_id) not in self.id2label:
+                raise TypeError(f'ID `{_id}` lost its label in id2label map.')
+
+        if self.learning_rate <= 0:
+            raise TypeError(f'Invalid learning_rate: `{self.learning_rate}`.')
+        if self.batch_size <= 0:
+            raise TypeError(f'Invalid batch_size: `{self.batch_size}`.')
+        if self.epochs <= 0:
+            raise TypeError(f'Invalid epochs: `{self.epochs}`.')
+
+        if self.image_size <= 0:
+            raise TypeError(f'Invalid image_size: `{self.image_size}`.')
+
+        if torch_dtype == 'float32' or torch_dtype == 'float':
+            self.torch_dtype = torch.float32
+        elif torch_dtype == 'float64':
+            self.torch_dtype = torch.float64
+        elif torch == 'float16':
+            self.torch_dtype = torch.float16
+        else:
+            raise TypeError(f'Invalid torch_dtype: `{torch_dtype}`.')
+
+
+class AutoSEResNet(AutoModel):
+
+    def __init__(self, resource_dir: str, **kwargs) -> None:
+        super().__init__(resource_dir=resource_dir)
+
+        self.config, self.preprocessor_config = self._load_config()
+        self.epochs = self.config.epochs
+        self.batch_size = self.config.batch_size
+        self.lr = self.config.learning_rate
+        self._epoch = 0
+        # 测试部署服务暂时不支持 GPU 环境，使用 GPU 版本会导致部署失败
+        # self.is_cuda = torch.cuda.is_available()
+        self.is_cuda = False
+
+        self.dataset_dir = None
+        self.labels = None
+
+        self._best_result = 0
+        self._best_state = None
+        self._overfit_index = 0
+        self._is_dataset_initialized = False
+        self._save_root = '.cache'
+
+    def _load_config(self) -> Tuple[ModelConfig, PreprocessorConfig]:
+        config_file = os.path.join(self.resource_dir, 'config.json')
+        if not os.path.isfile(config_file):
+            raise ConfigError('Config file missing.')
+        try:
+            with open(config_file, 'r') as f:
+                config_json = json.load(f)
+        except json.JSONDecodeError:
+            raise ConfigError('Failed to parse config file.')
+        model_config = ModelConfig(**config_json)
+
+        preprocessor_config_file = os.path.join(self.resource_dir, 'preprocessor_config.json')
+        if not os.path.isfile(preprocessor_config_file):
+            raise ConfigError('Preprocessor config file missing.')
+        try:
+            with open(preprocessor_config_file, 'r') as f:
+                preprocessor_config_json = json.load(f)
+        except json.JSONDecodeError:
+            raise ConfigError('Failed to parse preprocessor config file.')
+        preprocessor_config = PreprocessorConfig(**preprocessor_config_json)
+
+        return model_config, preprocessor_config
+
+    @property
+    def annotation_file(self):
+        return os.path.join(self.dataset_dir, 'annotation.json') if self.dataset_dir else None
+
+    def init_dataset(self, dataset_dir: str) -> Tuple[bool, str]:
+        self.dataset_dir = dataset_dir
+        try:
+            if not self._is_dataset_initialized:
+                self.training_loader
+                self.validation_loader
+                self.testing_loader
+                if not self.training_loader or not self.testing_loader:
+                    logger.error('Both training data and testing data are missing.')
+                    return False, 'Must provide train dataset and test dataset to fine tune.'
+                self.labels = (self.training_loader.dataset.labels
+                               if self.training_loader
+                               else self.testing_loader.dataset.labels)
+                self._is_dataset_initialized = True
+            return True, 'Initializing dataset complete.'
+        except Exception:
+            logger.exception('Failed to initialize dataset.')
+            return False, '初始化数据失败，请联系模型作者排查原因。'
+
+    @property
+    def training_loader(self) -> DataLoader:
+        """Return a dataloader instance of training data.
+
+        Data augmentation is used to improve performance, so we need to generate a new dataset
+        every epoch in case of training on a same dataset over and over again.
+        """
+        if not hasattr(self, "_training_loader"):
+            self._training_loader = self._build_training_data_loader()
+        return self._training_loader
+
+    def _build_training_data_loader(self) -> Optional[DataLoader]:
+        dataset = SEResNetDataset(image_dir=self.dataset_dir,
+                                  annotation_file=self.annotation_file,
+                                  mode=DatasetMode.TRAINING,
+                                  config=self.preprocessor_config)
+        if len(dataset) == 0:
+            return None
+        return DataLoader(dataset=dataset,
+                          batch_size=self.batch_size,
+                          shuffle=True)
+
+    @property
+    def validation_loader(self) -> DataLoader:
+        """Return a dataloader instance of validation data."""
+        if not hasattr(self, "_validation_loader"):
+            self._validation_loader = self._build_validation_data_loader()
+        return self._validation_loader
+
+    def _build_validation_data_loader(self) -> DataLoader:
+        dataset = SEResNetDataset(image_dir=self.dataset_dir,
+                                  annotation_file=self.annotation_file,
+                                  mode=DatasetMode.VALIDATION,
+                                  config=self.preprocessor_config)
+        if len(dataset) == 0:
+            return None
+        return DataLoader(dataset=dataset, batch_size=self.batch_size)
+
+    @property
+    def testing_loader(self) -> DataLoader:
+        """Return a dataloader instance of testing data."""
+        if not hasattr(self, "_testing_loader"):
+            self._testing_loader = self._build_testing_data_loader()
+        return self._testing_loader
+
+    def _build_testing_data_loader(self) -> DataLoader:
+        dataset = SEResNetDataset(image_dir=self.dataset_dir,
+                                  annotation_file=self.annotation_file,
+                                  mode=DatasetMode.TESTING,
+                                  config=self.preprocessor_config)
+        if len(dataset) == 0:
+            return None
+        return DataLoader(dataset=dataset, batch_size=self.batch_size)
+
+    def _build_model(self):
+        self._model: nn.Module = SEResNet50(spatial_dims=2, in_channels=3)
+
+        self.labels = list(self.config.id2label.values())
+        self._replace_fc_if_diff(len(self.labels))
+
+        param_file = os.path.join(self.resource_dir, self.config.param_file)
+        with open(param_file, 'rb') as f:
+            state_dict = torch.load(f)
+            model_num_classes = self._model.get_parameter('last_linear.weight').shape[0]
+            param_num_classes = state_dict['last_linear.weight'].shape[0]
+            if model_num_classes != param_num_classes:
+                raise AutoModelError('The fine tuned labels dismatched the parameters.')
+            self._model.load_state_dict(state_dict)
+
+        return self._model.cuda() if self.is_cuda else self._model
+
+    def _replace_fc_if_diff(self, num_classes: int):
+        """Replace the classify layer with new number of classes."""
+        assert (
+            num_classes and isinstance(num_classes, int) and num_classes > 0
+        ), f'Invalid number of classes: {num_classes} .'
+        if num_classes != self.num_classes:
+            self.model.last_linear = nn.Linear(2048, num_classes)
+
+    @property
+    def num_classes(self) -> int:
+        """Return the number of classes of the classification layer of the model."""
+        return self.model.get_parameter('last_linear.weight').shape[0]
+
+    @property
+    def model(self) -> nn.Module:
+        if not hasattr(self, '_model'):
+            self._model = self._build_model()
+        return self._model
+
+    @property
+    def optimizer(self) -> optim.Optimizer:
+        if not hasattr(self, '_optimizer'):
+            self._optimizer = optim.Adam(self.model.parameters(), lr=self.lr)
+        return self._optimizer
+
+    def train(self):
+        self.model.train()
+
+    def eval(self):
+        self.model.eval()
+
+    @overload
+    def forward(self, input: torch.Tensor) -> str:
+        """Predict an image's tensor and give its label."""
+
+    @overload
+    def forward(self, input: str) -> str:
+        """Predict an image defined by a file path and give its label."""
+
+    @torch.no_grad()
+    def forward(self, input):
+        if not input or not isinstance(input, (str, torch.Tensor)):
+            raise AutoModelError(f'Invalid input data: {input}.')
+        if isinstance(input, str):
+            if not os.path.isfile(input):
+                raise AutoModelError(f'Cannot find or access the image file {input}.')
+            preprocessor = SEResNetPreprocessor(mode=DatasetMode.PREDICTING,
+                                                config=self.preprocessor_config)
+            input = preprocessor.transform(input)
+            input.unsqueeze_(0)
+        self.model.eval()
+        output: torch.Tensor = self.model(input)
+        predict = output.argmax(1)[0].item()
+        if not self.labels:
+            if not os.path.isfile(os.path.join(self.resource_dir, 'fine_tuned.meta')):
+                raise AutoModel('The `fine_tuned.meta` file is required to make prediction.')
+            with open(os.path.join(self.resource_dir, 'fine_tuned.meta')) as f:
+                fine_tuned_json: dict = json.loads(f)
+                self.labels = fine_tuned_json.get('labels')
+        return self.labels[predict]
+
+    def _train_an_epoch(self):
+        self.train()
+        for images, targets in self.training_loader:
+            if self.is_cuda:
+                images, targets = images.cuda(), targets.cuda()
+            output = self.model(images)
+            loss = F.cross_entropy(output, targets)
+            self.optimizer.zero_grad()
+            loss.backward()
+            self.optimizer.step()
+
+    @torch.no_grad()
+    def _run_test(self) -> Tuple[float, float]:
+        """Run a round of test and report the result.
+
+        Return:
+            avg_loss, correct_rate
+        """
+        self.push_log(f'Begin testing of epoch {self._epoch}.')
+        self.eval()
+        total_loss = 0
+        total_correct = 0
+        for images, targets in self.testing_loader:
+            if self.is_cuda:
+                images, targets = images.cuda(), targets.cuda()
+            output = self.model(images)
+            loss = F.cross_entropy(output, targets, reduction='sum').item()
+            total_loss += loss
+            pred = output.max(1, keepdim=True)[1]
+            total_correct += pred.eq(targets.view_as(pred)).sum().item()
+
+        avg_loss = total_loss / len(self.testing_loader.dataset)
+        correct_rate = total_correct / len(self.testing_loader.dataset) * 100
+        logger.info(f'Testing Average Loss: {avg_loss:.4f}')
+        logger.info(f'Testing Correct Rate: {correct_rate:.2f}')
+
+        return avg_loss, correct_rate
+
+    @torch.no_grad()
+    def _run_validation(self) -> Tuple[float, float]:
+        """Run a round of validation and report the result.
+
+        Return:
+            avg_loss, correct_rate
+        """
+        self.eval()
+        total_loss = 0
+        total_correct = 0
+        for images, targets in self.validation_loader:
+            if self.is_cuda:
+                images, targets = images.cuda(), targets.cuda()
+            output = self.model(images)
+            loss = F.cross_entropy(output, targets, reduction='sum').item()
+            total_loss += loss
+            pred = output.max(1, keepdim=True)[1]
+            total_correct += pred.eq(targets.view_as(pred)).sum().item()
+
+        avg_loss = total_loss / len(self.validation_loader.dataset)
+        correct_rate = total_correct / len(self.validation_loader.dataset) * 100
+        logger.info(f'Validation Average Loss: {avg_loss:.4f}')
+        logger.info(f'Validation Correct Rate: {correct_rate:.2f}')
+        return avg_loss, correct_rate
+
+    @torch.no_grad()
+    def _is_finished(self) -> bool:
+        """Decide if stop training.
+
+        If there are validation dataset, decide depending on validatation results. If
+        the validation result of current epoch is below the best record for 10 continuous
+        times, then stop training.
+        If there are no validation dataset, run for `epochs` times.
+        """
+        if not self.validation_loader or len(self.validation_loader) == 0:
+            if self._epoch >= self.epochs:
+                self._best_state = deepcopy(self.model.state_dict())
+            return self._epoch >= self.epochs
+        # make a validation
+        self.push_log(f'Begin validation of epoch {self._epoch}.')
+        avg_loss, correct_rate = self._run_validation()
+        self.push_log('\n'.join(('Validation result:',
+                                 f'avg_loss={avg_loss:.4f}',
+                                 f'correct_rate={correct_rate:.2f}')))
+
+        if correct_rate > self._best_result:
+            self._overfit_index = 0
+            self._best_result = correct_rate
+            self._best_state = deepcopy(self.model.state_dict())
+            self.push_log('Validation result is better than last epoch.')
+            return self._epoch >= self.epochs
+        else:
+            self._overfit_index += 1
+            msg = f'Validation result gets worse for {self._overfit_index} consecutive times.'
+            self.push_log(msg)
+            return self._overfit_index >= 10 or self._epoch >= self.epochs
+
+    def fine_tune(self,
+                  id: str,
+                  task_id: str,
+                  dataset_dir: str,
+                  is_initiator: bool = False,
+                  is_debug_script: bool = False):
+        self.id = id
+        self.task_id = task_id
+        self.is_initiator = is_initiator
+        self.is_debug_script = is_debug_script
+
+        is_succ, err_msg = self.init_dataset(dataset_dir)
+        if not is_succ:
+            raise AutoModelError(f'Failed to initialize dataset. {err_msg}')
+        num_classes = (len(self.training_loader.dataset.labels)
+                       if self.training_loader
+                       else len(self.testing_loader.dataset.labels))
+        self._replace_fc_if_diff(num_classes)
+
+        self.config.id2label = {str(_idx): _label for _idx, _label in enumerate(self.labels)}
+        self.config.label2id = {_label: _idx for _idx, _label in enumerate(self.labels)}
+        self.config.label2id = dict(sorted(self.config.label2id.items()))
+
+        is_finished = False
+        self._epoch = 0
+        while not is_finished:
+            self._epoch += 1
+            self.push_log(f'Begin training of epoch {self._epoch}.')
+            self._train_an_epoch()
+            self.push_log(f'Complete training of epoch {self._epoch}.')
+            is_finished = self._is_finished()
+
+        self._save_fine_tuned()
+        avg_loss, correct_rate = self._run_test()
+        self.push_log('\n'.join(('Testing result:',
+                                 f'avg_loss={avg_loss:.4f}',
+                                 f'correct_rate={correct_rate:.2f}')))
+
+    def _save_fine_tuned(self):
+        """Save the best or final state of fine tuning."""
+        self.result_dir = get_result_dir(self.task_id)
+        os.makedirs(self.result_dir, exist_ok=True)
+        with open(os.path.join(self.result_dir, self.config.param_file), 'wb') as f:
+            torch.save(self._best_state, f)
+        with open(os.path.join(self.result_dir, 'config.json'), 'w') as f:
+            f.write(json.dumps(asdict(self.config), ensure_ascii=False))
+
+
+class AutoSEResNetFedAvg(AutoSEResNet, AutoFedAvgModel):
+
+    def state_dict(self) -> Dict[str, torch.Tensor]:
+        return self.model.state_dict()
+
+    def load_state_dict(self, state_dict: Dict[str, torch.Tensor]):
+        return self.model.load_state_dict(state_dict)
+
+    def train_an_epoch(self):
+        self._epoch += 1
+        self._train_an_epoch()
+
+    def run_test(self) -> Tuple[float, float]:
+        """Run a test and report the result.
+
+        Return:
+            avg_loss, correct_rate
+        """
+        return self._run_test()
+
+    def run_validation(self):
+        """Run a test and report the result.
+
+        Return:
+            avg_loss, correct_rate
+        """
+        return self._run_validation()
+
+    def init_dataset(self, dataset_dir: str) -> Tuple[bool, str]:
+        self.dataset_dir = dataset_dir
+        try:
+            if not self._is_dataset_initialized:
+                self.training_loader
+                self.validation_loader
+                self.testing_loader
+                if not self.training_loader and not self.testing_loader:
+                    logger.error('Both training data and testing data are missing.')
+                    err_msg = ' '.join((
+                        'The initiator must provide test dataset.',
+                        'The collaborator must provide train dataset.'
+                    ))
+                    return False, err_msg
+                self.labels = (self.training_loader.dataset.labels
+                               if self.training_loader
+                               else self.testing_loader.dataset.labels)
+                self._is_dataset_initialized = True
+            return True, 'Initializing dataset complete.'
+        except Exception:
+            logger.exception('Failed to initialize dataset.')
+            return False, '初始化数据失败，请联系模型作者排查原因。'
+
+    def fine_tune(self,
+                  id: str,
+                  task_id: str,
+                  dataset_dir: str,
+                  is_initiator: bool = False,
+                  recover: bool = False):
+        is_succ, err_msg = self.init_dataset(dataset_dir)
+        if not is_succ:
+            raise AutoModelError(f'Failed to initialize dataset. {err_msg}')
+        num_classes = (len(self.training_loader.dataset.labels)
+                       if self.training_loader
+                       else len(self.testing_loader.dataset.labels))
+        self._replace_fc_if_diff(num_classes)
+
+        self.config.id2label = {str(_idx): _label for _idx, _label in enumerate(self.labels)}
+        self.config.label2id = {_label: _idx for _idx, _label in enumerate(self.labels)}
+        self.config.label2id = dict(sorted(self.config.label2id.items()))
+
+        self._fine_tune_impl(id=id,
+                             task_id=task_id,
+                             dataset_dir=dataset_dir,
+                             scheduler_impl=SEResNetFedAvgScheduler,
+                             is_initiator=is_initiator,
+                             recover=recover,
+                             max_rounds=self.config.epochs,
+                             log_rounds=1)
+
+    def fine_tuned_files_dict(self) -> Optional[Dict[str, str]]:
+        param_file = os.path.join(self.result_dir, self.config.param_file)
+        with open(param_file, 'wb') as f:
+            torch.save(self.scheduler.best_state_dict, f)
+        config_file = os.path.join(self.result_dir, 'config.json')
+        with open(config_file, 'w') as f:
+            f.write(json.dumps(asdict(self.config), ensure_ascii=False))
+        return {
+            self.config.param_file: param_file,
+            'config.json': config_file
+        }
+
+
+class SEResNetFedAvgScheduler(AutoFedAvgScheduler):
+
+    def __init__(self,
+                 auto_proxy: AutoSEResNetFedAvg,
+                 max_rounds: int = 0,
+                 merge_epochs: int = 1,
+                 calculation_timeout: int = 300,
+                 schedule_timeout: int = 30,
+                 log_rounds: int = 0,
+                 involve_aggregator: bool = False):
+        super().__init__(auto_proxy=auto_proxy,
+                         max_rounds=max_rounds,
+                         merge_epochs=merge_epochs,
+                         calculation_timeout=calculation_timeout,
+                         schedule_timeout=schedule_timeout,
+                         log_rounds=log_rounds,
+                         involve_aggregator=involve_aggregator)
+        self._best_state = None
+        self._best_result = 0
+        self._overfit_index = 0
+
+    @property
+    def best_state_dict(self) -> Dict[str, torch.Tensor]:
+        return self._best_state
+
+    def validate_context(self):
+        super().validate_context()
+        if self.is_initiator:
+            assert self.test_loader and len(self.test_loader) > 0, 'failed to load test data'
+            self.push_log(f'There are {len(self.test_loader.dataset)} samples for testing.')
+        else:
+            assert self.train_loader and len(self.train_loader) > 0, 'failed to load train data'
+            self.push_log(f'There are {len(self.train_loader.dataset)} samples for training.')
+
+    def train_an_epoch(self):
+        self.auto_proxy.train_an_epoch()
+
+    def run_test(self):
+        avg_loss, correct_rate = self.auto_proxy.run_test()
+
+        self.tb_writer.add_scalar('test_results/avg_loss', avg_loss, self.current_round)
+        self.tb_writer.add_scalar('test_results/correct_rate', correct_rate, self.current_round)
+
+    def is_task_finished(self) -> bool:
+        """Decide if stop training.
+
+        If there are validation dataset, decide depending on validatation results. If
+        the validation result of current epoch is below the best record for 10 continuous
+        times, then stop training.
+        If there are no validation dataset, run for `max_rounds` times.
+        """
+        if not self.validation_loader or len(self.validation_loader) == 0:
+            self._best_state = deepcopy(self.state_dict())
+            return self._is_reach_max_rounds()
+
+        # make a validation
+        self.push_log(f'Begin validation of round {self.current_round}.')
+        avg_loss, correct_rate = self.auto_proxy.run_validation()
+        self.push_log('\n'.join(('Validation result:',
+                                 f'avg_loss={avg_loss:.4f}',
+                                 f'correct_rate={correct_rate:.2f}')))
+
+        if correct_rate > self._best_result:
+            self._overfit_index = 0
+            self._best_result = correct_rate
+            self._best_state = deepcopy(self.state_dict())
+            self.push_log('Validation result is better than last epoch.')
+            return self._is_reach_max_rounds()
+        else:
+            self._overfit_index += 1
+            msg = f'Validation result gets worse for {self._overfit_index} consecutive times.'
+            self.push_log(msg)
+            return self._overfit_index >= 10 or self._is_reach_max_rounds()
```

### Comparing `alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/endoscopic_inbody_classification/res_fed_avg/senet/convolutions.py` & `alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/endoscopic_inbody_classification/res_fed_avg/senet/convolutions.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/endoscopic_inbody_classification/res_fed_avg/senet/cv/senet.py` & `alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/endoscopic_inbody_classification/res_fed_avg/senet/cv/senet.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/endoscopic_inbody_classification/res_fed_avg/senet/layer_factories.py` & `alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/endoscopic_inbody_classification/res_fed_avg/senet/layer_factories.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/endoscopic_inbody_classification/res_local/auto.py` & `alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/endoscopic_inbody_classification/res_local/auto.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,730 +1,732 @@
-# Copyright 2022 Alphamed
-
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-
-#     http://www.apache.org/licenses/LICENSE-2.0
-
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-
-"""Pretraining endoscopic_inbody_classification models and schedulers."""
-
-import json
-import os
-from copy import deepcopy
-from dataclasses import InitVar, asdict, dataclass
-from typing import Dict, Optional, Tuple, overload
-
-import numpy as np
-import torch
-import torch.nn.functional as F
-from PIL import Image
-from senet.cv.senet import SEResNet50
-from torch import nn, optim
-from torch.utils.data import DataLoader, Dataset
-from torchvision import transforms
-
-from alphafed import get_result_dir, logger
-from alphafed.auto_ml.auto_model import (AutoFedAvgModel, AutoFedAvgScheduler,
-                                         AutoModel, DatasetMode,
-                                         MandatoryConfig, Preprocessor)
-from alphafed.auto_ml.cvat.annotation import ImageAnnotationUtils
-from alphafed.auto_ml.exceptions import AutoModelError, ConfigError
-
-
-@dataclass
-class PreprocessorConfig:
-
-    size: int
-    do_rotation: bool
-    do_scale_intensity: bool
-    do_shift_intensity: bool
-    do_gaussian_noised: bool
-    do_horizontal_flip: bool
-    do_vertical_flip: bool
-    do_channel_wise_normalize: bool
-
-    prob_rotation: float = 0.0
-    degrees: float = 0.0
-    prob_scale_intensity: float = 0.0
-    prob_shift_intensity: float = 0.0
-    prob_gaussian_noised: float = 0.0
-
-    def __post_init__(self):
-        if self.do_rotation and (self.prob_rotation < 0 or self.prob_rotation > 1):
-            raise ConfigError(f'Invalid prob_rotation: `{self.prob_rotation}`.')
-        if (
-            self.do_scale_intensity
-            and (self.prob_scale_intensity < 0 or self.prob_scale_intensity > 1)
-        ):
-            raise ConfigError(f'Invalid prob_scale_intensity: `{self.prob_scale_intensity}`.')
-        if (
-            self.do_shift_intensity
-            and (self.prob_shift_intensity < 0 or self.prob_shift_intensity > 1)
-        ):
-            raise ConfigError(f'Invalid prob_shift_intensity: `{self.prob_shift_intensity}`.')
-        if (
-            self.do_gaussian_noised
-            and (self.prob_gaussian_noised < 0 or self.prob_gaussian_noised > 1)
-        ):
-            raise ConfigError(f'Invalid prob_gaussian_noised: `{self.prob_gaussian_noised}`.')
-
-
-class SEResNetPreprocessor(Preprocessor):
-
-    class ScaleIntensity(nn.Module):
-
-        def __init__(self) -> None:
-            super().__init__()
-
-        def forward(self, image: torch.Tensor, factor: float = 0.3) -> torch.Tensor:
-            return image * (1 + factor)
-
-    def __init__(self, mode: DatasetMode, config: PreprocessorConfig) -> None:
-        super().__init__()
-        self.R = np.random.RandomState()
-        layers = [transforms.Resize((config.size, config.size))]
-        if mode == DatasetMode.TRAINING:
-            if config.do_rotation:
-                layers.append(transforms.RandomApply(
-                    nn.Sequential(
-                        transforms.RandomRotation(
-                            degrees=config.degrees,
-                            interpolation=transforms.InterpolationMode.BILINEAR
-                        )
-                    ),
-                    p=config.prob_rotation
-                ))
-        layers.append(transforms.ToTensor())
-        if mode == DatasetMode.TRAINING:
-            if config.do_scale_intensity:
-                layers.append(transforms.RandomApply([self._scale_intensity],
-                                                     p=config.prob_scale_intensity))
-            if config.do_shift_intensity:
-                layers.append(transforms.RandomApply([self._shift_intensity],
-                                                     p=config.prob_shift_intensity))
-            if config.do_gaussian_noised:
-                layers.append(transforms.RandomApply([self._gaussian_noised],
-                                                     p=config.prob_gaussian_noised))
-            if config.do_horizontal_flip:
-                layers.append(transforms.RandomHorizontalFlip())
-            if config.do_vertical_flip:
-                layers.append(transforms.RandomVerticalFlip())
-        layers.append(transforms.Lambda(lambda image: self._channel_wise_normalize(image=image)))
-        self._transformer = transforms.Compose(layers)
-
-    def _channel_wise_normalize(self, image: torch.Tensor) -> torch.Tensor:
-        for i, _chn in enumerate(image):
-            slices = _chn != 0
-            _mean = torch.mean(_chn[slices])
-            _std = torch.std(_chn[slices], unbiased=False)
-            _chn = (_chn - _mean) / _std
-            image[i] = _chn
-        return image
-
-    def _scale_intensity(self, image: torch.Tensor, factor: float = 0.3) -> torch.Tensor:
-        return image * (1 + factor)
-
-    def _shift_intensity(self, image: torch.Tensor, offset: float = 0.1) -> torch.Tensor:
-        return image + offset
-
-    def _gaussian_noised(self,
-                         image: torch.Tensor,
-                         mean: float = 0.0,
-                         std: float = 0.01) -> torch.Tensor:
-        rand_std = self.R.uniform(0, std)
-        noise = self.R.normal(mean, rand_std, size=image.shape)
-        return image + noise.astype(np.float32)
-
-    def transform(self, image_file: str) -> torch.Tensor:
-        """Transform an image object into an input tensor."""
-        image = Image.open(image_file).convert('RGB')
-        image = self._transformer(image)
-        return image
-
-
-class SEResNetDataset(Dataset):
-
-    def __init__(self,
-                 image_dir: str,
-                 annotation_file: str,
-                 mode: DatasetMode,
-                 config: PreprocessorConfig) -> None:
-        """Init a dataset instance for ResNet auto model families.
-
-        Args:
-            image_dir:
-                The directory including image files.
-            annotation_file:
-                The file including annotation information.
-            mode:
-                One of training or validation or testing.
-            config:
-                The configuration for the preprocessor.
-        """
-        super().__init__()
-        if not image_dir or not isinstance(image_dir, str):
-            raise ConfigError(f'Invalid image directory: {image_dir}.')
-        if not annotation_file or not isinstance(annotation_file, str):
-            raise ConfigError(f'Invalid annotation file path: {annotation_file}.')
-        assert mode and isinstance(mode, DatasetMode), f'Invalid dataset mode: {mode}.'
-        if not os.path.exists(image_dir) or not os.path.isdir(image_dir):
-            raise ConfigError(f'{image_dir} does not exist or is not a directory.')
-        if not os.path.exists(annotation_file) or not os.path.isfile(annotation_file):
-            raise ConfigError(f'{annotation_file} does not exist or is not a file.')
-
-        self.image_dir = image_dir
-        self.annotation_file = annotation_file
-        self.transformer = SEResNetPreprocessor(mode=mode, config=config)
-
-        self.images, self.labels = ImageAnnotationUtils.parse_single_category_annotation(
-            annotation_file=self.annotation_file, resource_dir=image_dir, mode=mode
-        )
-
-    def __getitem__(self, index: int):
-        _item = self.images[index]
-        return self.transformer(_item.image_file), _item.class_label
-
-    def __len__(self):
-        return len(self.images)
-
-
-@dataclass
-class ModelConfig(MandatoryConfig):
-
-    id2label: dict
-    label2id: dict
-    learning_rate: int
-    batch_size: int
-    epochs: int
-    image_size: int = 256
-    torch_dtype: InitVar[str] = 'float32'
-
-    def __post_init__(self, torch_dtype: str):
-        super().__post_init__()
-
-        for _label in self.id2label.values():
-            if _label not in self.label2id:
-                raise TypeError(f'Label `{_label}` lost its ID in label2id map.')
-        for _id in self.label2id.values():
-            if str(_id) not in self.id2label:
-                raise TypeError(f'ID `{_id}` lost its label in id2label map.')
-
-        if self.learning_rate <= 0:
-            raise TypeError(f'Invalid learning_rate: `{self.learning_rate}`.')
-        if self.batch_size <= 0:
-            raise TypeError(f'Invalid batch_size: `{self.batch_size}`.')
-        if self.epochs <= 0:
-            raise TypeError(f'Invalid epochs: `{self.epochs}`.')
-
-        if self.image_size <= 0:
-            raise TypeError(f'Invalid image_size: `{self.image_size}`.')
-
-        if torch_dtype == 'float32' or torch_dtype == 'float':
-            self.torch_dtype = torch.float32
-        elif torch_dtype == 'float64':
-            self.torch_dtype = torch.float64
-        elif torch == 'float16':
-            self.torch_dtype = torch.float16
-        else:
-            raise TypeError(f'Invalid torch_dtype: `{torch_dtype}`.')
-
-
-class AutoSEResNet(AutoModel):
-
-    def __init__(self, resource_dir: str, **kwargs) -> None:
-        super().__init__(resource_dir=resource_dir)
-
-        self.config, self.preprocessor_config = self._load_config()
-        self.epochs = self.config.epochs
-        self.batch_size = self.config.batch_size
-        self.lr = self.config.learning_rate
-        self._epoch = 0
-        self.is_cuda = torch.cuda.is_available()
-
-        self.dataset_dir = None
-        self.labels = None
-
-        self._best_result = 0
-        self._best_state = None
-        self._overfit_index = 0
-        self._is_dataset_initialized = False
-        self._save_root = '.cache'
-
-    def _load_config(self) -> Tuple[ModelConfig, PreprocessorConfig]:
-        config_file = os.path.join(self.resource_dir, 'config.json')
-        if not os.path.isfile(config_file):
-            raise ConfigError('Config file missing.')
-        try:
-            with open(config_file, 'r') as f:
-                config_json = json.load(f)
-        except json.JSONDecodeError:
-            raise ConfigError('Failed to parse config file.')
-        model_config = ModelConfig(**config_json)
-
-        preprocessor_config_file = os.path.join(self.resource_dir, 'preprocessor_config.json')
-        if not os.path.isfile(preprocessor_config_file):
-            raise ConfigError('Preprocessor config file missing.')
-        try:
-            with open(preprocessor_config_file, 'r') as f:
-                preprocessor_config_json = json.load(f)
-        except json.JSONDecodeError:
-            raise ConfigError('Failed to parse preprocessor config file.')
-        preprocessor_config = PreprocessorConfig(**preprocessor_config_json)
-
-        return model_config, preprocessor_config
-
-    @property
-    def annotation_file(self):
-        return os.path.join(self.dataset_dir, 'annotation.json') if self.dataset_dir else None
-
-    def init_dataset(self, dataset_dir: str) -> Tuple[bool, str]:
-        self.dataset_dir = dataset_dir
-        try:
-            if not self._is_dataset_initialized:
-                self.training_loader
-                self.validation_loader
-                self.testing_loader
-                if not self.training_loader or not self.testing_loader:
-                    logger.error('Both training data and testing data are missing.')
-                    return False, 'Must provide train dataset and test dataset to fine tune.'
-                self.labels = (self.training_loader.dataset.labels
-                               if self.training_loader
-                               else self.testing_loader.dataset.labels)
-                self._is_dataset_initialized = True
-            return True, 'Initializing dataset complete.'
-        except Exception:
-            logger.exception('Failed to initialize dataset.')
-            return False, '初始化数据失败，请联系模型作者排查原因。'
-
-    @property
-    def training_loader(self) -> DataLoader:
-        """Return a dataloader instance of training data.
-
-        Data augmentation is used to improve performance, so we need to generate a new dataset
-        every epoch in case of training on a same dataset over and over again.
-        """
-        if not hasattr(self, "_training_loader"):
-            self._training_loader = self._build_training_data_loader()
-        return self._training_loader
-
-    def _build_training_data_loader(self) -> Optional[DataLoader]:
-        dataset = SEResNetDataset(image_dir=self.dataset_dir,
-                                  annotation_file=self.annotation_file,
-                                  mode=DatasetMode.TRAINING,
-                                  config=self.preprocessor_config)
-        if len(dataset) == 0:
-            return None
-        return DataLoader(dataset=dataset,
-                          batch_size=self.batch_size,
-                          shuffle=True)
-
-    @property
-    def validation_loader(self) -> DataLoader:
-        """Return a dataloader instance of validation data."""
-        if not hasattr(self, "_validation_loader"):
-            self._validation_loader = self._build_validation_data_loader()
-        return self._validation_loader
-
-    def _build_validation_data_loader(self) -> DataLoader:
-        dataset = SEResNetDataset(image_dir=self.dataset_dir,
-                                  annotation_file=self.annotation_file,
-                                  mode=DatasetMode.VALIDATION,
-                                  config=self.preprocessor_config)
-        if len(dataset) == 0:
-            return None
-        return DataLoader(dataset=dataset, batch_size=self.batch_size)
-
-    @property
-    def testing_loader(self) -> DataLoader:
-        """Return a dataloader instance of testing data."""
-        if not hasattr(self, "_testing_loader"):
-            self._testing_loader = self._build_testing_data_loader()
-        return self._testing_loader
-
-    def _build_testing_data_loader(self) -> DataLoader:
-        dataset = SEResNetDataset(image_dir=self.dataset_dir,
-                                  annotation_file=self.annotation_file,
-                                  mode=DatasetMode.TESTING,
-                                  config=self.preprocessor_config)
-        if len(dataset) == 0:
-            return None
-        return DataLoader(dataset=dataset, batch_size=self.batch_size)
-
-    def _build_model(self):
-        self._model: nn.Module = SEResNet50(spatial_dims=2, in_channels=3)
-
-        self.labels = list(self.config.id2label.values())
-        self._replace_fc_if_diff(len(self.labels))
-
-        param_file = os.path.join(self.resource_dir, self.config.param_file)
-        with open(param_file, 'rb') as f:
-            state_dict = torch.load(f)
-            model_num_classes = self._model.get_parameter('last_linear.weight').shape[0]
-            param_num_classes = state_dict['last_linear.weight'].shape[0]
-            if model_num_classes != param_num_classes:
-                raise AutoModelError('The fine tuned labels dismatched the parameters.')
-            self._model.load_state_dict(state_dict)
-
-        return self._model.cuda() if self.is_cuda else self._model
-
-    def _replace_fc_if_diff(self, num_classes: int):
-        """Replace the classify layer with new number of classes."""
-        assert (
-            num_classes and isinstance(num_classes, int) and num_classes > 0
-        ), f'Invalid number of classes: {num_classes} .'
-        if num_classes != self.num_classes:
-            self.model.last_linear = nn.Linear(2048, num_classes)
-
-    @property
-    def num_classes(self) -> int:
-        """Return the number of classes of the classification layer of the model."""
-        return self.model.get_parameter('last_linear.weight').shape[0]
-
-    @property
-    def model(self) -> nn.Module:
-        if not hasattr(self, '_model'):
-            self._model = self._build_model()
-        return self._model
-
-    @property
-    def optimizer(self) -> optim.Optimizer:
-        if not hasattr(self, '_optimizer'):
-            self._optimizer = optim.Adam(self.model.parameters(), lr=self.lr)
-        return self._optimizer
-
-    def train(self):
-        self.model.train()
-
-    def eval(self):
-        self.model.eval()
-
-    @overload
-    def forward(self, input: torch.Tensor) -> str:
-        """Predict an image's tensor and give its label."""
-
-    @overload
-    def forward(self, input: str) -> str:
-        """Predict an image defined by a file path and give its label."""
-
-    @torch.no_grad()
-    def forward(self, input):
-        if not input or not isinstance(input, (str, torch.Tensor)):
-            raise AutoModelError(f'Invalid input data: {input}.')
-        if isinstance(input, str):
-            if not os.path.isfile(input):
-                raise AutoModelError(f'Cannot find or access the image file {input}.')
-            preprocessor = SEResNetPreprocessor(mode=DatasetMode.PREDICTING,
-                                                config=self.preprocessor_config)
-            input = preprocessor.transform(input)
-            input.unsqueeze_(0)
-        self.model.eval()
-        output: torch.Tensor = self.model(input)
-        predict = output.argmax(1)[0].item()
-        if not self.labels:
-            if not os.path.isfile(os.path.join(self.resource_dir, 'fine_tuned.meta')):
-                raise AutoModel('The `fine_tuned.meta` file is required to make prediction.')
-            with open(os.path.join(self.resource_dir, 'fine_tuned.meta')) as f:
-                fine_tuned_json: dict = json.loads(f)
-                self.labels = fine_tuned_json.get('labels')
-        return self.labels[predict]
-
-    def _train_an_epoch(self):
-        self.train()
-        for images, targets in self.training_loader:
-            if self.is_cuda:
-                images, targets = images.cuda(), targets.cuda()
-            output = self.model(images)
-            loss = F.cross_entropy(output, targets)
-            self.optimizer.zero_grad()
-            loss.backward()
-            self.optimizer.step()
-
-    @torch.no_grad()
-    def _run_test(self) -> Tuple[float, float]:
-        """Run a round of test and report the result.
-
-        Return:
-            avg_loss, correct_rate
-        """
-        self.push_log(f'Begin testing of epoch {self._epoch}.')
-        self.eval()
-        total_loss = 0
-        total_correct = 0
-        for images, targets in self.testing_loader:
-            if self.is_cuda:
-                images, targets = images.cuda(), targets.cuda()
-            output = self.model(images)
-            loss = F.cross_entropy(output, targets, reduction='sum').item()
-            total_loss += loss
-            pred = output.max(1, keepdim=True)[1]
-            total_correct += pred.eq(targets.view_as(pred)).sum().item()
-
-        avg_loss = total_loss / len(self.testing_loader.dataset)
-        correct_rate = total_correct / len(self.testing_loader.dataset) * 100
-        logger.info(f'Testing Average Loss: {avg_loss:.4f}')
-        logger.info(f'Testing Correct Rate: {correct_rate:.2f}')
-
-        return avg_loss, correct_rate
-
-    @torch.no_grad()
-    def _run_validation(self) -> Tuple[float, float]:
-        """Run a round of validation and report the result.
-
-        Return:
-            avg_loss, correct_rate
-        """
-        self.eval()
-        total_loss = 0
-        total_correct = 0
-        for images, targets in self.validation_loader:
-            if self.is_cuda:
-                images, targets = images.cuda(), targets.cuda()
-            output = self.model(images)
-            loss = F.cross_entropy(output, targets, reduction='sum').item()
-            total_loss += loss
-            pred = output.max(1, keepdim=True)[1]
-            total_correct += pred.eq(targets.view_as(pred)).sum().item()
-
-        avg_loss = total_loss / len(self.validation_loader.dataset)
-        correct_rate = total_correct / len(self.validation_loader.dataset) * 100
-        logger.info(f'Validation Average Loss: {avg_loss:.4f}')
-        logger.info(f'Validation Correct Rate: {correct_rate:.2f}')
-        return avg_loss, correct_rate
-
-    @torch.no_grad()
-    def _is_finished(self) -> bool:
-        """Decide if stop training.
-
-        If there are validation dataset, decide depending on validatation results. If
-        the validation result of current epoch is below the best record for 10 continuous
-        times, then stop training.
-        If there are no validation dataset, run for `epochs` times.
-        """
-        if not self.validation_loader or len(self.validation_loader) == 0:
-            if self._epoch >= self.epochs:
-                self._best_state = deepcopy(self.model.state_dict())
-            return self._epoch >= self.epochs
-        # make a validation
-        self.push_log(f'Begin validation of epoch {self._epoch}.')
-        avg_loss, correct_rate = self._run_validation()
-        self.push_log('\n'.join(('Validation result:',
-                                 f'avg_loss={avg_loss:.4f}',
-                                 f'correct_rate={correct_rate:.2f}')))
-
-        if correct_rate > self._best_result:
-            self._overfit_index = 0
-            self._best_result = correct_rate
-            self._best_state = deepcopy(self.model.state_dict())
-            self.push_log('Validation result is better than last epoch.')
-            return self._epoch >= self.epochs
-        else:
-            self._overfit_index += 1
-            msg = f'Validation result gets worse for {self._overfit_index} consecutive times.'
-            self.push_log(msg)
-            return self._overfit_index >= 10 or self._epoch >= self.epochs
-
-    def fine_tune(self,
-                  id: str,
-                  task_id: str,
-                  dataset_dir: str,
-                  is_initiator: bool = False,
-                  is_debug_script: bool = False):
-        self.id = id
-        self.task_id = task_id
-        self.is_initiator = is_initiator
-        self.is_debug_script = is_debug_script
-
-        is_succ, err_msg = self.init_dataset(dataset_dir)
-        if not is_succ:
-            raise AutoModelError(f'Failed to initialize dataset. {err_msg}')
-        num_classes = (len(self.training_loader.dataset.labels)
-                       if self.training_loader
-                       else len(self.testing_loader.dataset.labels))
-        self._replace_fc_if_diff(num_classes)
-
-        self.config.id2label = {str(_idx): _label for _idx, _label in enumerate(self.labels)}
-        self.config.label2id = {_label: _idx for _idx, _label in enumerate(self.labels)}
-        self.config.label2id = dict(sorted(self.config.label2id.items()))
-
-        is_finished = False
-        self._epoch = 0
-        while not is_finished:
-            self._epoch += 1
-            self.push_log(f'Begin training of epoch {self._epoch}.')
-            self._train_an_epoch()
-            self.push_log(f'Complete training of epoch {self._epoch}.')
-            is_finished = self._is_finished()
-
-        self._save_fine_tuned()
-        avg_loss, correct_rate = self._run_test()
-        self.push_log('\n'.join(('Testing result:',
-                                 f'avg_loss={avg_loss:.4f}',
-                                 f'correct_rate={correct_rate:.2f}')))
-
-    def _save_fine_tuned(self):
-        """Save the best or final state of fine tuning."""
-        result_dir = get_result_dir(self.task_id)
-        os.makedirs(result_dir, exist_ok=True)
-        with open(os.path.join(result_dir, self.config.param_file), 'wb') as f:
-            torch.save(self._best_state, f)
-        with open(os.path.join(result_dir, 'config.json'), 'w') as f:
-            f.write(json.dumps(asdict(self.config), ensure_ascii=False))
-
-
-class AutoSEResNetFedAvg(AutoSEResNet, AutoFedAvgModel):
-
-    @property
-    def param_file(self) -> str:
-        return self.config.param_file
-
-    @property
-    def init_args_for_fine_tuned(self) -> Optional[str]:
-        return json.dumps({'labels': self.labels}, ensure_ascii=False)
-
-    def state_dict(self) -> Dict[str, torch.Tensor]:
-        return self.model.state_dict()
-
-    def load_state_dict(self, state_dict: Dict[str, torch.Tensor]):
-        return self.model.load_state_dict(state_dict)
-
-    def train_an_epoch(self):
-        self._epoch += 1
-        self._train_an_epoch()
-
-    def run_test(self) -> Tuple[float, float]:
-        """Run a test and report the result.
-
-        Return:
-            avg_loss, correct_rate
-        """
-        return self._run_test()
-
-    def run_validation(self):
-        """Run a test and report the result.
-
-        Return:
-            avg_loss, correct_rate
-        """
-        return self._run_validation()
-
-    def init_dataset(self, dataset_dir: str) -> Tuple[bool, str]:
-        self.dataset_dir = dataset_dir
-        try:
-            if not self._is_dataset_initialized:
-                self.training_loader
-                self.validation_loader
-                self.testing_loader
-                if not self.training_loader and not self.testing_loader:
-                    logger.error('Both training data and testing data are missing.')
-                    err_msg = ' '.join((
-                        'The initiator must provide test dataset.',
-                        'The collaborator must provide train dataset.'
-                    ))
-                    return False, err_msg
-                self.labels = (self.training_loader.dataset.labels
-                               if self.training_loader
-                               else self.testing_loader.dataset.labels)
-                self._is_dataset_initialized = True
-            return True, 'Initializing dataset complete.'
-        except Exception:
-            logger.exception('Failed to initialize dataset.')
-            return False, '初始化数据失败，请联系模型作者排查原因。'
-
-    def fine_tune(self,
-                  id: str,
-                  task_id: str,
-                  dataset_dir: str,
-                  is_initiator: bool = False):
-        is_succ, err_msg = self.init_dataset(dataset_dir)
-        if not is_succ:
-            raise AutoModelError(f'Failed to initialize dataset. {err_msg}')
-        num_classes = (len(self.training_loader.dataset.labels)
-                       if self.training_loader
-                       else len(self.testing_loader.dataset.labels))
-        self._replace_fc_if_diff(num_classes)
-
-        self._fine_tune_impl(id=id,
-                             task_id=task_id,
-                             dataset_dir=dataset_dir,
-                             scheduler_impl=SEResNetFedAvgScheduler,
-                             is_initiator=is_initiator,
-                             max_rounds=self.config.epochs,
-                             log_rounds=1)
-
-
-class SEResNetFedAvgScheduler(AutoFedAvgScheduler):
-
-    def __init__(self,
-                 auto_proxy: AutoSEResNetFedAvg,
-                 max_rounds: int = 0,
-                 merge_epochs: int = 1,
-                 calculation_timeout: int = 300,
-                 schedule_timeout: int = 30,
-                 log_rounds: int = 0,
-                 involve_aggregator: bool = False):
-        super().__init__(auto_proxy=auto_proxy,
-                         max_rounds=max_rounds,
-                         merge_epochs=merge_epochs,
-                         calculation_timeout=calculation_timeout,
-                         schedule_timeout=schedule_timeout,
-                         log_rounds=log_rounds,
-                         involve_aggregator=involve_aggregator)
-        self._best_state = None
-        self._best_result = 0
-        self._overfit_index = 0
-
-    @property
-    def best_state_dict(self) -> Dict[str, torch.Tensor]:
-        return self._best_state
-
-    def validate_context(self):
-        super().validate_context()
-        if self.is_initiator:
-            assert self.test_loader and len(self.test_loader) > 0, 'failed to load test data'
-            self.push_log(f'There are {len(self.test_loader.dataset)} samples for testing.')
-        else:
-            assert self.train_loader and len(self.train_loader) > 0, 'failed to load train data'
-            self.push_log(f'There are {len(self.train_loader.dataset)} samples for training.')
-
-    def train_an_epoch(self):
-        self.auto_proxy.train_an_epoch()
-
-    def run_test(self):
-        self.auto_proxy.run_test()
-
-    def is_task_finished(self) -> bool:
-        """Decide if stop training.
-
-        If there are validation dataset, decide depending on validatation results. If
-        the validation result of current epoch is below the best record for 10 continuous
-        times, then stop training.
-        If there are no validation dataset, run for `max_rounds` times.
-        """
-        if not self.validation_loader or len(self.validation_loader) == 0:
-            self._best_state = deepcopy(self.state_dict())
-            return self._is_reach_max_rounds()
-
-        # make a validation
-        self.push_log(f'Begin validation of round {self.current_round}.')
-        avg_loss, correct_rate = self.auto_proxy.run_validation()
-        self.push_log('\n'.join(('Validation result:',
-                                 f'avg_loss={avg_loss:.4f}',
-                                 f'correct_rate={correct_rate:.2f}')))
-
-        if correct_rate > self._best_result:
-            self._overfit_index = 0
-            self._best_result = correct_rate
-            self._best_state = deepcopy(self.state_dict())
-            self.push_log('Validation result is better than last epoch.')
-            return self._is_reach_max_rounds()
-        else:
-            self._overfit_index += 1
-            msg = f'Validation result gets worse for {self._overfit_index} consecutive times.'
-            self.push_log(msg)
-            return self._overfit_index >= 10 or self._is_reach_max_rounds()
+# Copyright 2022 Alphamed
+
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+
+#     http://www.apache.org/licenses/LICENSE-2.0
+
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+"""Pretraining endoscopic_inbody_classification models and schedulers."""
+
+import json
+import os
+from copy import deepcopy
+from dataclasses import InitVar, asdict, dataclass
+from typing import Dict, Optional, Tuple, overload
+
+import numpy as np
+import torch
+import torch.nn.functional as F
+from PIL import Image
+from senet.cv.senet import SEResNet50
+from torch import nn, optim
+from torch.utils.data import DataLoader, Dataset
+from torchvision import transforms
+
+from alphafed import get_result_dir, logger
+from alphafed.auto_ml.auto_model import (AutoFedAvgModel, AutoFedAvgScheduler,
+                                         AutoModel, DatasetMode,
+                                         MandatoryConfig, Preprocessor)
+from alphafed.auto_ml.cvat.annotation import ImageAnnotationUtils
+from alphafed.auto_ml.exceptions import AutoModelError, ConfigError
+
+
+@dataclass
+class PreprocessorConfig:
+
+    size: int
+    do_rotation: bool
+    do_scale_intensity: bool
+    do_shift_intensity: bool
+    do_gaussian_noised: bool
+    do_horizontal_flip: bool
+    do_vertical_flip: bool
+    do_channel_wise_normalize: bool
+
+    prob_rotation: float = 0.0
+    degrees: float = 0.0
+    prob_scale_intensity: float = 0.0
+    prob_shift_intensity: float = 0.0
+    prob_gaussian_noised: float = 0.0
+
+    def __post_init__(self):
+        if self.do_rotation and (self.prob_rotation < 0 or self.prob_rotation > 1):
+            raise ConfigError(f'Invalid prob_rotation: `{self.prob_rotation}`.')
+        if (
+            self.do_scale_intensity
+            and (self.prob_scale_intensity < 0 or self.prob_scale_intensity > 1)
+        ):
+            raise ConfigError(f'Invalid prob_scale_intensity: `{self.prob_scale_intensity}`.')
+        if (
+            self.do_shift_intensity
+            and (self.prob_shift_intensity < 0 or self.prob_shift_intensity > 1)
+        ):
+            raise ConfigError(f'Invalid prob_shift_intensity: `{self.prob_shift_intensity}`.')
+        if (
+            self.do_gaussian_noised
+            and (self.prob_gaussian_noised < 0 or self.prob_gaussian_noised > 1)
+        ):
+            raise ConfigError(f'Invalid prob_gaussian_noised: `{self.prob_gaussian_noised}`.')
+
+
+class SEResNetPreprocessor(Preprocessor):
+
+    class ScaleIntensity(nn.Module):
+
+        def __init__(self) -> None:
+            super().__init__()
+
+        def forward(self, image: torch.Tensor, factor: float = 0.3) -> torch.Tensor:
+            return image * (1 + factor)
+
+    def __init__(self, mode: DatasetMode, config: PreprocessorConfig) -> None:
+        super().__init__()
+        self.R = np.random.RandomState()
+        layers = [transforms.Resize((config.size, config.size))]
+        if mode == DatasetMode.TRAINING:
+            if config.do_rotation:
+                layers.append(transforms.RandomApply(
+                    nn.Sequential(
+                        transforms.RandomRotation(
+                            degrees=config.degrees,
+                            interpolation=transforms.InterpolationMode.BILINEAR
+                        )
+                    ),
+                    p=config.prob_rotation
+                ))
+        layers.append(transforms.ToTensor())
+        if mode == DatasetMode.TRAINING:
+            if config.do_scale_intensity:
+                layers.append(transforms.RandomApply([self._scale_intensity],
+                                                     p=config.prob_scale_intensity))
+            if config.do_shift_intensity:
+                layers.append(transforms.RandomApply([self._shift_intensity],
+                                                     p=config.prob_shift_intensity))
+            if config.do_gaussian_noised:
+                layers.append(transforms.RandomApply([self._gaussian_noised],
+                                                     p=config.prob_gaussian_noised))
+            if config.do_horizontal_flip:
+                layers.append(transforms.RandomHorizontalFlip())
+            if config.do_vertical_flip:
+                layers.append(transforms.RandomVerticalFlip())
+        layers.append(transforms.Lambda(lambda image: self._channel_wise_normalize(image=image)))
+        self._transformer = transforms.Compose(layers)
+
+    def _channel_wise_normalize(self, image: torch.Tensor) -> torch.Tensor:
+        for i, _chn in enumerate(image):
+            slices = _chn != 0
+            _mean = torch.mean(_chn[slices])
+            _std = torch.std(_chn[slices], unbiased=False)
+            _chn = (_chn - _mean) / _std
+            image[i] = _chn
+        return image
+
+    def _scale_intensity(self, image: torch.Tensor, factor: float = 0.3) -> torch.Tensor:
+        return image * (1 + factor)
+
+    def _shift_intensity(self, image: torch.Tensor, offset: float = 0.1) -> torch.Tensor:
+        return image + offset
+
+    def _gaussian_noised(self,
+                         image: torch.Tensor,
+                         mean: float = 0.0,
+                         std: float = 0.01) -> torch.Tensor:
+        rand_std = self.R.uniform(0, std)
+        noise = self.R.normal(mean, rand_std, size=image.shape)
+        return image + noise.astype(np.float32)
+
+    def transform(self, image_file: str) -> torch.Tensor:
+        """Transform an image object into an input tensor."""
+        image = Image.open(image_file).convert('RGB')
+        image = self._transformer(image)
+        return image
+
+
+class SEResNetDataset(Dataset):
+
+    def __init__(self,
+                 image_dir: str,
+                 annotation_file: str,
+                 mode: DatasetMode,
+                 config: PreprocessorConfig) -> None:
+        """Init a dataset instance for ResNet auto model families.
+
+        Args:
+            image_dir:
+                The directory including image files.
+            annotation_file:
+                The file including annotation information.
+            mode:
+                One of training or validation or testing.
+            config:
+                The configuration for the preprocessor.
+        """
+        super().__init__()
+        if not image_dir or not isinstance(image_dir, str):
+            raise ConfigError(f'Invalid image directory: {image_dir}.')
+        if not annotation_file or not isinstance(annotation_file, str):
+            raise ConfigError(f'Invalid annotation file path: {annotation_file}.')
+        assert mode and isinstance(mode, DatasetMode), f'Invalid dataset mode: {mode}.'
+        if not os.path.exists(image_dir) or not os.path.isdir(image_dir):
+            raise ConfigError(f'{image_dir} does not exist or is not a directory.')
+        if not os.path.exists(annotation_file) or not os.path.isfile(annotation_file):
+            raise ConfigError(f'{annotation_file} does not exist or is not a file.')
+
+        self.image_dir = image_dir
+        self.annotation_file = annotation_file
+        self.transformer = SEResNetPreprocessor(mode=mode, config=config)
+
+        self.images, self.labels = ImageAnnotationUtils.parse_single_category_annotation(
+            annotation_file=self.annotation_file, resource_dir=image_dir, mode=mode
+        )
+
+    def __getitem__(self, index: int):
+        _item = self.images[index]
+        return self.transformer(_item.image_file), _item.class_label
+
+    def __len__(self):
+        return len(self.images)
+
+
+@dataclass
+class ModelConfig(MandatoryConfig):
+
+    id2label: dict
+    label2id: dict
+    learning_rate: int
+    batch_size: int
+    epochs: int
+    image_size: int = 256
+    torch_dtype: InitVar[str] = 'float32'
+
+    def __post_init__(self, torch_dtype: str):
+        super().__post_init__()
+
+        for _label in self.id2label.values():
+            if _label not in self.label2id:
+                raise TypeError(f'Label `{_label}` lost its ID in label2id map.')
+        for _id in self.label2id.values():
+            if str(_id) not in self.id2label:
+                raise TypeError(f'ID `{_id}` lost its label in id2label map.')
+
+        if self.learning_rate <= 0:
+            raise TypeError(f'Invalid learning_rate: `{self.learning_rate}`.')
+        if self.batch_size <= 0:
+            raise TypeError(f'Invalid batch_size: `{self.batch_size}`.')
+        if self.epochs <= 0:
+            raise TypeError(f'Invalid epochs: `{self.epochs}`.')
+
+        if self.image_size <= 0:
+            raise TypeError(f'Invalid image_size: `{self.image_size}`.')
+
+        if torch_dtype == 'float32' or torch_dtype == 'float':
+            self.torch_dtype = torch.float32
+        elif torch_dtype == 'float64':
+            self.torch_dtype = torch.float64
+        elif torch == 'float16':
+            self.torch_dtype = torch.float16
+        else:
+            raise TypeError(f'Invalid torch_dtype: `{torch_dtype}`.')
+
+
+class AutoSEResNet(AutoModel):
+
+    def __init__(self, resource_dir: str, **kwargs) -> None:
+        super().__init__(resource_dir=resource_dir)
+
+        self.config, self.preprocessor_config = self._load_config()
+        self.epochs = self.config.epochs
+        self.batch_size = self.config.batch_size
+        self.lr = self.config.learning_rate
+        self._epoch = 0
+        # 测试部署服务暂时不支持 GPU 环境，使用 GPU 版本会导致部署失败
+        # self.is_cuda = torch.cuda.is_available()
+        self.is_cuda = False
+
+        self.dataset_dir = None
+        self.labels = None
+
+        self._best_result = 0
+        self._best_state = None
+        self._overfit_index = 0
+        self._is_dataset_initialized = False
+        self._save_root = '.cache'
+
+    def _load_config(self) -> Tuple[ModelConfig, PreprocessorConfig]:
+        config_file = os.path.join(self.resource_dir, 'config.json')
+        if not os.path.isfile(config_file):
+            raise ConfigError('Config file missing.')
+        try:
+            with open(config_file, 'r') as f:
+                config_json = json.load(f)
+        except json.JSONDecodeError:
+            raise ConfigError('Failed to parse config file.')
+        model_config = ModelConfig(**config_json)
+
+        preprocessor_config_file = os.path.join(self.resource_dir, 'preprocessor_config.json')
+        if not os.path.isfile(preprocessor_config_file):
+            raise ConfigError('Preprocessor config file missing.')
+        try:
+            with open(preprocessor_config_file, 'r') as f:
+                preprocessor_config_json = json.load(f)
+        except json.JSONDecodeError:
+            raise ConfigError('Failed to parse preprocessor config file.')
+        preprocessor_config = PreprocessorConfig(**preprocessor_config_json)
+
+        return model_config, preprocessor_config
+
+    @property
+    def annotation_file(self):
+        return os.path.join(self.dataset_dir, 'annotation.json') if self.dataset_dir else None
+
+    def init_dataset(self, dataset_dir: str) -> Tuple[bool, str]:
+        self.dataset_dir = dataset_dir
+        try:
+            if not self._is_dataset_initialized:
+                self.training_loader
+                self.validation_loader
+                self.testing_loader
+                if not self.training_loader or not self.testing_loader:
+                    logger.error('Both training data and testing data are missing.')
+                    return False, 'Must provide train dataset and test dataset to fine tune.'
+                self.labels = (self.training_loader.dataset.labels
+                               if self.training_loader
+                               else self.testing_loader.dataset.labels)
+                self._is_dataset_initialized = True
+            return True, 'Initializing dataset complete.'
+        except Exception:
+            logger.exception('Failed to initialize dataset.')
+            return False, '初始化数据失败，请联系模型作者排查原因。'
+
+    @property
+    def training_loader(self) -> DataLoader:
+        """Return a dataloader instance of training data.
+
+        Data augmentation is used to improve performance, so we need to generate a new dataset
+        every epoch in case of training on a same dataset over and over again.
+        """
+        if not hasattr(self, "_training_loader"):
+            self._training_loader = self._build_training_data_loader()
+        return self._training_loader
+
+    def _build_training_data_loader(self) -> Optional[DataLoader]:
+        dataset = SEResNetDataset(image_dir=self.dataset_dir,
+                                  annotation_file=self.annotation_file,
+                                  mode=DatasetMode.TRAINING,
+                                  config=self.preprocessor_config)
+        if len(dataset) == 0:
+            return None
+        return DataLoader(dataset=dataset,
+                          batch_size=self.batch_size,
+                          shuffle=True)
+
+    @property
+    def validation_loader(self) -> DataLoader:
+        """Return a dataloader instance of validation data."""
+        if not hasattr(self, "_validation_loader"):
+            self._validation_loader = self._build_validation_data_loader()
+        return self._validation_loader
+
+    def _build_validation_data_loader(self) -> DataLoader:
+        dataset = SEResNetDataset(image_dir=self.dataset_dir,
+                                  annotation_file=self.annotation_file,
+                                  mode=DatasetMode.VALIDATION,
+                                  config=self.preprocessor_config)
+        if len(dataset) == 0:
+            return None
+        return DataLoader(dataset=dataset, batch_size=self.batch_size)
+
+    @property
+    def testing_loader(self) -> DataLoader:
+        """Return a dataloader instance of testing data."""
+        if not hasattr(self, "_testing_loader"):
+            self._testing_loader = self._build_testing_data_loader()
+        return self._testing_loader
+
+    def _build_testing_data_loader(self) -> DataLoader:
+        dataset = SEResNetDataset(image_dir=self.dataset_dir,
+                                  annotation_file=self.annotation_file,
+                                  mode=DatasetMode.TESTING,
+                                  config=self.preprocessor_config)
+        if len(dataset) == 0:
+            return None
+        return DataLoader(dataset=dataset, batch_size=self.batch_size)
+
+    def _build_model(self):
+        self._model: nn.Module = SEResNet50(spatial_dims=2, in_channels=3)
+
+        self.labels = list(self.config.id2label.values())
+        self._replace_fc_if_diff(len(self.labels))
+
+        param_file = os.path.join(self.resource_dir, self.config.param_file)
+        with open(param_file, 'rb') as f:
+            state_dict = torch.load(f)
+            model_num_classes = self._model.get_parameter('last_linear.weight').shape[0]
+            param_num_classes = state_dict['last_linear.weight'].shape[0]
+            if model_num_classes != param_num_classes:
+                raise AutoModelError('The fine tuned labels dismatched the parameters.')
+            self._model.load_state_dict(state_dict)
+
+        return self._model.cuda() if self.is_cuda else self._model
+
+    def _replace_fc_if_diff(self, num_classes: int):
+        """Replace the classify layer with new number of classes."""
+        assert (
+            num_classes and isinstance(num_classes, int) and num_classes > 0
+        ), f'Invalid number of classes: {num_classes} .'
+        if num_classes != self.num_classes:
+            self.model.last_linear = nn.Linear(2048, num_classes)
+
+    @property
+    def num_classes(self) -> int:
+        """Return the number of classes of the classification layer of the model."""
+        return self.model.get_parameter('last_linear.weight').shape[0]
+
+    @property
+    def model(self) -> nn.Module:
+        if not hasattr(self, '_model'):
+            self._model = self._build_model()
+        return self._model
+
+    @property
+    def optimizer(self) -> optim.Optimizer:
+        if not hasattr(self, '_optimizer'):
+            self._optimizer = optim.Adam(self.model.parameters(), lr=self.lr)
+        return self._optimizer
+
+    def train(self):
+        self.model.train()
+
+    def eval(self):
+        self.model.eval()
+
+    @overload
+    def forward(self, input: torch.Tensor) -> str:
+        """Predict an image's tensor and give its label."""
+
+    @overload
+    def forward(self, input: str) -> str:
+        """Predict an image defined by a file path and give its label."""
+
+    @torch.no_grad()
+    def forward(self, input):
+        if not input or not isinstance(input, (str, torch.Tensor)):
+            raise AutoModelError(f'Invalid input data: {input}.')
+        if isinstance(input, str):
+            if not os.path.isfile(input):
+                raise AutoModelError(f'Cannot find or access the image file {input}.')
+            preprocessor = SEResNetPreprocessor(mode=DatasetMode.PREDICTING,
+                                                config=self.preprocessor_config)
+            input = preprocessor.transform(input)
+            input.unsqueeze_(0)
+        self.model.eval()
+        output: torch.Tensor = self.model(input)
+        predict = output.argmax(1)[0].item()
+        if not self.labels:
+            if not os.path.isfile(os.path.join(self.resource_dir, 'fine_tuned.meta')):
+                raise AutoModel('The `fine_tuned.meta` file is required to make prediction.')
+            with open(os.path.join(self.resource_dir, 'fine_tuned.meta')) as f:
+                fine_tuned_json: dict = json.loads(f)
+                self.labels = fine_tuned_json.get('labels')
+        return self.labels[predict]
+
+    def _train_an_epoch(self):
+        self.train()
+        for images, targets in self.training_loader:
+            if self.is_cuda:
+                images, targets = images.cuda(), targets.cuda()
+            output = self.model(images)
+            loss = F.cross_entropy(output, targets)
+            self.optimizer.zero_grad()
+            loss.backward()
+            self.optimizer.step()
+
+    @torch.no_grad()
+    def _run_test(self) -> Tuple[float, float]:
+        """Run a round of test and report the result.
+
+        Return:
+            avg_loss, correct_rate
+        """
+        self.push_log(f'Begin testing of epoch {self._epoch}.')
+        self.eval()
+        total_loss = 0
+        total_correct = 0
+        for images, targets in self.testing_loader:
+            if self.is_cuda:
+                images, targets = images.cuda(), targets.cuda()
+            output = self.model(images)
+            loss = F.cross_entropy(output, targets, reduction='sum').item()
+            total_loss += loss
+            pred = output.max(1, keepdim=True)[1]
+            total_correct += pred.eq(targets.view_as(pred)).sum().item()
+
+        avg_loss = total_loss / len(self.testing_loader.dataset)
+        correct_rate = total_correct / len(self.testing_loader.dataset) * 100
+        logger.info(f'Testing Average Loss: {avg_loss:.4f}')
+        logger.info(f'Testing Correct Rate: {correct_rate:.2f}')
+
+        return avg_loss, correct_rate
+
+    @torch.no_grad()
+    def _run_validation(self) -> Tuple[float, float]:
+        """Run a round of validation and report the result.
+
+        Return:
+            avg_loss, correct_rate
+        """
+        self.eval()
+        total_loss = 0
+        total_correct = 0
+        for images, targets in self.validation_loader:
+            if self.is_cuda:
+                images, targets = images.cuda(), targets.cuda()
+            output = self.model(images)
+            loss = F.cross_entropy(output, targets, reduction='sum').item()
+            total_loss += loss
+            pred = output.max(1, keepdim=True)[1]
+            total_correct += pred.eq(targets.view_as(pred)).sum().item()
+
+        avg_loss = total_loss / len(self.validation_loader.dataset)
+        correct_rate = total_correct / len(self.validation_loader.dataset) * 100
+        logger.info(f'Validation Average Loss: {avg_loss:.4f}')
+        logger.info(f'Validation Correct Rate: {correct_rate:.2f}')
+        return avg_loss, correct_rate
+
+    @torch.no_grad()
+    def _is_finished(self) -> bool:
+        """Decide if stop training.
+
+        If there are validation dataset, decide depending on validatation results. If
+        the validation result of current epoch is below the best record for 10 continuous
+        times, then stop training.
+        If there are no validation dataset, run for `epochs` times.
+        """
+        if not self.validation_loader or len(self.validation_loader) == 0:
+            if self._epoch >= self.epochs:
+                self._best_state = deepcopy(self.model.state_dict())
+            return self._epoch >= self.epochs
+        # make a validation
+        self.push_log(f'Begin validation of epoch {self._epoch}.')
+        avg_loss, correct_rate = self._run_validation()
+        self.push_log('\n'.join(('Validation result:',
+                                 f'avg_loss={avg_loss:.4f}',
+                                 f'correct_rate={correct_rate:.2f}')))
+
+        if correct_rate > self._best_result:
+            self._overfit_index = 0
+            self._best_result = correct_rate
+            self._best_state = deepcopy(self.model.state_dict())
+            self.push_log('Validation result is better than last epoch.')
+            return self._epoch >= self.epochs
+        else:
+            self._overfit_index += 1
+            msg = f'Validation result gets worse for {self._overfit_index} consecutive times.'
+            self.push_log(msg)
+            return self._overfit_index >= 10 or self._epoch >= self.epochs
+
+    def fine_tune(self,
+                  id: str,
+                  task_id: str,
+                  dataset_dir: str,
+                  is_initiator: bool = False,
+                  is_debug_script: bool = False):
+        self.id = id
+        self.task_id = task_id
+        self.is_initiator = is_initiator
+        self.is_debug_script = is_debug_script
+
+        is_succ, err_msg = self.init_dataset(dataset_dir)
+        if not is_succ:
+            raise AutoModelError(f'Failed to initialize dataset. {err_msg}')
+        num_classes = (len(self.training_loader.dataset.labels)
+                       if self.training_loader
+                       else len(self.testing_loader.dataset.labels))
+        self._replace_fc_if_diff(num_classes)
+
+        self.config.id2label = {str(_idx): _label for _idx, _label in enumerate(self.labels)}
+        self.config.label2id = {_label: _idx for _idx, _label in enumerate(self.labels)}
+        self.config.label2id = dict(sorted(self.config.label2id.items()))
+
+        is_finished = False
+        self._epoch = 0
+        while not is_finished:
+            self._epoch += 1
+            self.push_log(f'Begin training of epoch {self._epoch}.')
+            self._train_an_epoch()
+            self.push_log(f'Complete training of epoch {self._epoch}.')
+            is_finished = self._is_finished()
+
+        self._save_fine_tuned()
+        avg_loss, correct_rate = self._run_test()
+        self.push_log('\n'.join(('Testing result:',
+                                 f'avg_loss={avg_loss:.4f}',
+                                 f'correct_rate={correct_rate:.2f}')))
+
+    def _save_fine_tuned(self):
+        """Save the best or final state of fine tuning."""
+        result_dir = get_result_dir(self.task_id)
+        os.makedirs(result_dir, exist_ok=True)
+        with open(os.path.join(result_dir, self.config.param_file), 'wb') as f:
+            torch.save(self._best_state, f)
+        with open(os.path.join(result_dir, 'config.json'), 'w') as f:
+            f.write(json.dumps(asdict(self.config), ensure_ascii=False))
+
+
+class AutoSEResNetFedAvg(AutoSEResNet, AutoFedAvgModel):
+
+    @property
+    def param_file(self) -> str:
+        return self.config.param_file
+
+    @property
+    def init_args_for_fine_tuned(self) -> Optional[str]:
+        return json.dumps({'labels': self.labels}, ensure_ascii=False)
+
+    def state_dict(self) -> Dict[str, torch.Tensor]:
+        return self.model.state_dict()
+
+    def load_state_dict(self, state_dict: Dict[str, torch.Tensor]):
+        return self.model.load_state_dict(state_dict)
+
+    def train_an_epoch(self):
+        self._epoch += 1
+        self._train_an_epoch()
+
+    def run_test(self) -> Tuple[float, float]:
+        """Run a test and report the result.
+
+        Return:
+            avg_loss, correct_rate
+        """
+        return self._run_test()
+
+    def run_validation(self):
+        """Run a test and report the result.
+
+        Return:
+            avg_loss, correct_rate
+        """
+        return self._run_validation()
+
+    def init_dataset(self, dataset_dir: str) -> Tuple[bool, str]:
+        self.dataset_dir = dataset_dir
+        try:
+            if not self._is_dataset_initialized:
+                self.training_loader
+                self.validation_loader
+                self.testing_loader
+                if not self.training_loader and not self.testing_loader:
+                    logger.error('Both training data and testing data are missing.')
+                    err_msg = ' '.join((
+                        'The initiator must provide test dataset.',
+                        'The collaborator must provide train dataset.'
+                    ))
+                    return False, err_msg
+                self.labels = (self.training_loader.dataset.labels
+                               if self.training_loader
+                               else self.testing_loader.dataset.labels)
+                self._is_dataset_initialized = True
+            return True, 'Initializing dataset complete.'
+        except Exception:
+            logger.exception('Failed to initialize dataset.')
+            return False, '初始化数据失败，请联系模型作者排查原因。'
+
+    def fine_tune(self,
+                  id: str,
+                  task_id: str,
+                  dataset_dir: str,
+                  is_initiator: bool = False):
+        is_succ, err_msg = self.init_dataset(dataset_dir)
+        if not is_succ:
+            raise AutoModelError(f'Failed to initialize dataset. {err_msg}')
+        num_classes = (len(self.training_loader.dataset.labels)
+                       if self.training_loader
+                       else len(self.testing_loader.dataset.labels))
+        self._replace_fc_if_diff(num_classes)
+
+        self._fine_tune_impl(id=id,
+                             task_id=task_id,
+                             dataset_dir=dataset_dir,
+                             scheduler_impl=SEResNetFedAvgScheduler,
+                             is_initiator=is_initiator,
+                             max_rounds=self.config.epochs,
+                             log_rounds=1)
+
+
+class SEResNetFedAvgScheduler(AutoFedAvgScheduler):
+
+    def __init__(self,
+                 auto_proxy: AutoSEResNetFedAvg,
+                 max_rounds: int = 0,
+                 merge_epochs: int = 1,
+                 calculation_timeout: int = 300,
+                 schedule_timeout: int = 30,
+                 log_rounds: int = 0,
+                 involve_aggregator: bool = False):
+        super().__init__(auto_proxy=auto_proxy,
+                         max_rounds=max_rounds,
+                         merge_epochs=merge_epochs,
+                         calculation_timeout=calculation_timeout,
+                         schedule_timeout=schedule_timeout,
+                         log_rounds=log_rounds,
+                         involve_aggregator=involve_aggregator)
+        self._best_state = None
+        self._best_result = 0
+        self._overfit_index = 0
+
+    @property
+    def best_state_dict(self) -> Dict[str, torch.Tensor]:
+        return self._best_state
+
+    def validate_context(self):
+        super().validate_context()
+        if self.is_initiator:
+            assert self.test_loader and len(self.test_loader) > 0, 'failed to load test data'
+            self.push_log(f'There are {len(self.test_loader.dataset)} samples for testing.')
+        else:
+            assert self.train_loader and len(self.train_loader) > 0, 'failed to load train data'
+            self.push_log(f'There are {len(self.train_loader.dataset)} samples for training.')
+
+    def train_an_epoch(self):
+        self.auto_proxy.train_an_epoch()
+
+    def run_test(self):
+        self.auto_proxy.run_test()
+
+    def is_task_finished(self) -> bool:
+        """Decide if stop training.
+
+        If there are validation dataset, decide depending on validatation results. If
+        the validation result of current epoch is below the best record for 10 continuous
+        times, then stop training.
+        If there are no validation dataset, run for `max_rounds` times.
+        """
+        if not self.validation_loader or len(self.validation_loader) == 0:
+            self._best_state = deepcopy(self.state_dict())
+            return self._is_reach_max_rounds()
+
+        # make a validation
+        self.push_log(f'Begin validation of round {self.current_round}.')
+        avg_loss, correct_rate = self.auto_proxy.run_validation()
+        self.push_log('\n'.join(('Validation result:',
+                                 f'avg_loss={avg_loss:.4f}',
+                                 f'correct_rate={correct_rate:.2f}')))
+
+        if correct_rate > self._best_result:
+            self._overfit_index = 0
+            self._best_result = correct_rate
+            self._best_state = deepcopy(self.state_dict())
+            self.push_log('Validation result is better than last epoch.')
+            return self._is_reach_max_rounds()
+        else:
+            self._overfit_index += 1
+            msg = f'Validation result gets worse for {self._overfit_index} consecutive times.'
+            self.push_log(msg)
+            return self._overfit_index >= 10 or self._is_reach_max_rounds()
```

### Comparing `alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/endoscopic_inbody_classification/res_local/senet/convolutions.py` & `alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/endoscopic_inbody_classification/res_local/senet/convolutions.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/endoscopic_inbody_classification/res_local/senet/cv/senet.py` & `alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/endoscopic_inbody_classification/res_local/senet/cv/senet.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/endoscopic_inbody_classification/res_local/senet/layer_factories.py` & `alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/endoscopic_inbody_classification/res_local/senet/layer_factories.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/endoscopic_inbody_classification/run_aggregator.py` & `alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/endoscopic_inbody_classification/run_aggregator.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/endoscopic_inbody_classification/run_data_owner_2.py` & `alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/endoscopic_inbody_classification/run_data_owner_2.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/endoscopic_inbody_classification/run_data_owner_4.py` & `alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/endoscopic_inbody_classification/run_data_owner_4.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/endoscopic_inbody_classification/run_local.py` & `alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/skin_lesion_diagnosis/run_local.py`

 * *Files 8% similar despite different names*

```diff
@@ -5,23 +5,23 @@
 PYTHONPATH = os.path.join(CURRENT_DIR, os.pardir, os.pardir, os.pardir, os.pardir, os.pardir)
 sys.path.insert(0, PYTHONPATH)
 
 
 if True:
     import alphafed  # noqa: F401, setup latest alphafed running context
     from alphafed.auto_ml import from_pretrained
-    from alphafed.examples.auto_ml.endoscopic_inbody_classification import (
-        AGGREGATOR_ID, DEV_TASK_ID)
+    from alphafed.examples.auto_ml.skin_lesion_diagnosis import (AGGREGATOR_ID,
+                                                                 DEV_TASK_ID)
 
 
 if __name__ == '__main__':
     resource_dir = os.path.join(CURRENT_DIR, 'res_local')
-    auto_model = from_pretrained(name='endoscopic_inbody_classification',
+    auto_model = from_pretrained(name='skin_lesion_diagnosis',
                                  resource_dir=resource_dir,
                                  download=True)
     auto_model.fine_tune(id=AGGREGATOR_ID,
                          task_id=DEV_TASK_ID,
-                         dataset_dir=os.path.join(CURRENT_DIR, 'data'),
+                         dataset_dir=os.path.join(CURRENT_DIR, 'data_local'),
                          is_debug_script=True)
-    image = os.path.join(CURRENT_DIR, 'data', '53125.jpg')
+    image = os.path.join(CURRENT_DIR, 'data_local', 'ISIC_0024669.jpg')
     predict = auto_model(image)
     print(f'{predict=}')
```

### Comparing `alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/skin_lesion_diagnosis/__init__.py` & `alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/skin_lesion_diagnosis/__init__.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/skin_lesion_diagnosis/clean_history_msg.py` & `alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/skin_lesion_diagnosis/clean_history_msg.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/skin_lesion_diagnosis/res_fed_avg/auto.py` & `alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/skin_lesion_diagnosis/res_fed_avg/auto.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,679 +1,681 @@
-# Copyright 2022 Alphamed
-
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-
-#     http://www.apache.org/licenses/LICENSE-2.0
-
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-
-"""Pretraining skin_lesion_diagnosis models and schedulers."""
-
-import json
-import os
-from copy import deepcopy
-from dataclasses import InitVar, asdict, dataclass
-from typing import Dict, List, Optional, Tuple, overload
-
-import torch
-import torch.nn.functional as F
-from PIL import Image
-from res_net import ResNet18
-from torch import nn, optim
-from torch.utils.data import DataLoader, Dataset
-from torchvision import transforms
-
-from alphafed import get_result_dir, logger
-from alphafed.auto_ml.auto_model import (AutoFedAvgModel, AutoFedAvgScheduler,
-                                         AutoModel, DatasetMode,
-                                         MandatoryConfig, Preprocessor)
-from alphafed.auto_ml.cvat.annotation import ImageAnnotationUtils
-from alphafed.auto_ml.exceptions import AutoModelError, ConfigError
-
-
-@dataclass
-class PreprocessorConfig:
-
-    size: int
-    do_affine: bool
-    degrees: int
-    translate: Tuple[float]
-    do_horizontal_flip: bool
-    image_mean: List[float]
-    image_std: List[float]
-
-    def __post_init__(self):
-        self.translate = tuple(self.translate)
-
-
-class ResNetPreprocessor(Preprocessor):
-
-    def __init__(self, mode: DatasetMode, config: PreprocessorConfig) -> None:
-        layers = []
-        layers.append(transforms.Resize((config.size, config.size)))
-        if mode == DatasetMode.TRAINING:
-            if config.do_affine:
-                layers.append(transforms.RandomAffine(degrees=config.degrees,
-                                                      translate=config.translate))
-            if config.do_horizontal_flip:
-                layers.append(transforms.RandomHorizontalFlip())
-        layers.append(transforms.ToTensor())
-        layers.append(transforms.Normalize(config.image_mean, config.image_std))
-        self._transformer = transforms.Compose(layers)
-
-    def transform(self, image_file: str) -> torch.Tensor:
-        """Transform an image object into an input tensor."""
-        image = Image.open(image_file).convert('RGB')
-        return self._transformer(image)
-
-
-class ResNetDataset(Dataset):
-
-    def __init__(self,
-                 image_dir: str,
-                 annotation_file: str,
-                 mode: DatasetMode,
-                 config: PreprocessorConfig) -> None:
-        """Init a dataset instance for ResNet auto model families.
-
-        Args:
-            image_dir:
-                The directory including image files.
-            annotation_file:
-                The file including annotation information.
-            mode:
-                One of training or validation or testing.
-            config:
-                The configuration for the preprocessor.
-        """
-        super().__init__()
-        if not image_dir or not isinstance(image_dir, str):
-            raise ConfigError(f'Invalid image directory: {image_dir}.')
-        if not annotation_file or not isinstance(annotation_file, str):
-            raise ConfigError(f'Invalid annotation file path: {annotation_file}.')
-        assert mode and isinstance(mode, DatasetMode), f'Invalid dataset mode: {mode}.'
-        if not os.path.exists(image_dir) or not os.path.isdir(image_dir):
-            raise ConfigError(f'{image_dir} does not exist or is not a directory.')
-        if not os.path.exists(annotation_file) or not os.path.isfile(annotation_file):
-            raise ConfigError(f'{annotation_file} does not exist or is not a file.')
-
-        self.image_dir = image_dir
-        self.annotation_file = annotation_file
-        self.transformer = ResNetPreprocessor(mode=mode, config=config)
-
-        self.images, self.labels = ImageAnnotationUtils.parse_single_category_annotation(
-            annotation_file=self.annotation_file, resource_dir=image_dir, mode=mode
-        )
-
-    def __getitem__(self, index: int):
-        _item = self.images[index]
-        return self.transformer(_item.image_file), _item.class_label
-
-    def __len__(self):
-        return len(self.images)
-
-
-@dataclass
-class ModelConfig(MandatoryConfig):
-
-    id2label: dict
-    label2id: dict
-    learning_rate: int
-    batch_size: int
-    epochs: int
-    image_size: int = 224
-    torch_dtype: InitVar[str] = 'float32'
-
-    def __post_init__(self, torch_dtype: str):
-        super().__post_init__()
-
-        for _label in self.id2label.values():
-            if _label not in self.label2id:
-                raise TypeError(f'Label `{_label}` lost its ID in label2id map.')
-        for _id in self.label2id.values():
-            if str(_id) not in self.id2label:
-                raise TypeError(f'ID `{_id}` lost its label in id2label map.')
-
-        if self.learning_rate <= 0:
-            raise TypeError(f'Invalid learning_rate: `{self.learning_rate}`.')
-        if self.batch_size <= 0:
-            raise TypeError(f'Invalid batch_size: `{self.batch_size}`.')
-        if self.epochs <= 0:
-            raise TypeError(f'Invalid epochs: `{self.epochs}`.')
-
-        if self.image_size <= 0:
-            raise TypeError(f'Invalid image_size: `{self.image_size}`.')
-
-        if torch_dtype == 'float32' or torch_dtype == 'float':
-            self.torch_dtype = torch.float32
-        elif torch_dtype == 'float64':
-            self.torch_dtype = torch.float64
-        elif torch == 'float16':
-            self.torch_dtype = torch.float16
-        else:
-            raise TypeError(f'Invalid torch_dtype: `{torch_dtype}`.')
-
-
-class AutoResNet(AutoModel):
-
-    def __init__(self, resource_dir: str, **kwargs) -> None:
-        super().__init__(resource_dir=resource_dir)
-
-        self.config, self.preprocessor_config = self._load_config()
-        self.epochs = self.config.epochs
-        self.batch_size = self.config.batch_size
-        self._lr = self.config.learning_rate
-        self._epoch = 0
-        self.is_cuda = torch.cuda.is_available()
-
-        self.dataset_dir = None
-        self.labels = None
-
-        self._best_result = 0
-        self._best_state = None
-        self._overfit_index = 0
-        self._is_dataset_initialized = False
-        self._save_root = '.cache'
-
-    def _load_config(self) -> Tuple[ModelConfig, PreprocessorConfig]:
-        config_file = os.path.join(self.resource_dir, 'config.json')
-        if not os.path.isfile(config_file):
-            raise ConfigError('Config file missing.')
-        try:
-            with open(config_file, 'r') as f:
-                config_json = json.load(f)
-        except json.JSONDecodeError:
-            raise ConfigError('Failed to parse config file.')
-        model_config = ModelConfig(**config_json)
-
-        preprocessor_config_file = os.path.join(self.resource_dir, 'preprocessor_config.json')
-        if not os.path.isfile(preprocessor_config_file):
-            raise ConfigError('Preprocessor config file missing.')
-        try:
-            with open(preprocessor_config_file, 'r') as f:
-                preprocessor_config_json = json.load(f)
-        except json.JSONDecodeError:
-            raise ConfigError('Failed to parse preprocessor config file.')
-        preprocessor_config = PreprocessorConfig(**preprocessor_config_json)
-
-        return model_config, preprocessor_config
-
-    @property
-    def annotation_file(self):
-        return os.path.join(self.dataset_dir, 'annotation.json') if self.dataset_dir else None
-
-    def init_dataset(self, dataset_dir: str) -> Tuple[bool, str]:
-        self.dataset_dir = dataset_dir
-        try:
-            if not self._is_dataset_initialized:
-                self.training_loader
-                self.validation_loader
-                self.testing_loader
-                if not self.training_loader or not self.testing_loader:
-                    logger.error('Both training data and testing data are missing.')
-                    return False, 'Must provide train dataset and test dataset to fine tune.'
-                self.labels = (self.training_loader.dataset.labels
-                               if self.training_loader
-                               else self.testing_loader.dataset.labels)
-                self._is_dataset_initialized = True
-            return True, 'Initializing dataset complete.'
-        except Exception:
-            logger.exception('Failed to initialize dataset.')
-            return False, '初始化数据失败，请联系模型作者排查原因。'
-
-    @property
-    def training_loader(self) -> DataLoader:
-        """Return a dataloader instance of training data.
-
-        Data augmentation is used to improve performance, so we need to generate a new dataset
-        every epoch in case of training on a same dataset over and over again.
-        """
-        if not hasattr(self, "_training_loader"):
-            self._training_loader = self._build_training_data_loader()
-        return self._training_loader
-
-    def _build_training_data_loader(self) -> Optional[DataLoader]:
-        dataset = ResNetDataset(image_dir=self.dataset_dir,
-                                annotation_file=self.annotation_file,
-                                mode=DatasetMode.TRAINING,
-                                config=self.preprocessor_config)
-        if len(dataset) == 0:
-            return None
-        return DataLoader(dataset=dataset,
-                          batch_size=self.batch_size,
-                          shuffle=True)
-
-    @property
-    def validation_loader(self) -> DataLoader:
-        """Return a dataloader instance of validation data."""
-        if not hasattr(self, "_validation_loader"):
-            self._validation_loader = self._build_validation_data_loader()
-        return self._validation_loader
-
-    def _build_validation_data_loader(self) -> DataLoader:
-        dataset = ResNetDataset(image_dir=self.dataset_dir,
-                                annotation_file=self.annotation_file,
-                                mode=DatasetMode.VALIDATION,
-                                config=self.preprocessor_config)
-        if len(dataset) == 0:
-            return None
-        return DataLoader(dataset=dataset, batch_size=self.batch_size)
-
-    @property
-    def testing_loader(self) -> DataLoader:
-        """Return a dataloader instance of testing data."""
-        if not hasattr(self, "_testing_loader"):
-            self._testing_loader = self._build_testing_data_loader()
-        return self._testing_loader
-
-    def _build_testing_data_loader(self) -> DataLoader:
-        dataset = ResNetDataset(image_dir=self.dataset_dir,
-                                annotation_file=self.annotation_file,
-                                mode=DatasetMode.TESTING,
-                                config=self.preprocessor_config)
-        if len(dataset) == 0:
-            return None
-        return DataLoader(dataset=dataset, batch_size=self.batch_size)
-
-    def _build_model(self):
-        self._model: nn.Module = ResNet18()
-        self.labels = list(self.config.id2label.values())
-        self._replace_fc_if_diff(len(self.labels))
-
-        param_file = os.path.join(self.resource_dir, self.config.param_file)
-        with open(param_file, 'rb') as f:
-            state_dict = torch.load(f)
-            if self._model.get_parameter('fc.weight').shape[0] != state_dict['fc.weight'].shape[0]:
-                raise AutoModelError('The fine tuned labels dismatched the parameters.')
-            self._model.load_state_dict(state_dict)
-
-        return self._model.cuda() if self.is_cuda else self._model
-
-    def _replace_fc_if_diff(self, num_classes: int):
-        """Replace the classify layer with new number of classes."""
-        assert (
-            num_classes and isinstance(num_classes, int) and num_classes > 0
-        ), f'Invalid number of classes: {num_classes} .'
-        if num_classes != self.num_classes:
-            self.model.fc = nn.Linear(self.model.layer1[0].expansion * 512, num_classes)
-
-    @property
-    def num_classes(self) -> int:
-        """Return the number of classes of the classification layer of the model."""
-        return self.model.get_parameter('fc.weight').shape[0]
-
-    @property
-    def model(self) -> nn.Module:
-        if not hasattr(self, '_model'):
-            self._model = self._build_model()
-        return self._model
-
-    @property
-    def optimizer(self) -> optim.Optimizer:
-        if not hasattr(self, '_optimizer'):
-            self._optimizer = optim.Adam(self.model.parameters(),
-                                         lr=self.lr,
-                                         betas=(0.9, 0.999),
-                                         weight_decay=5e-4)
-        else:
-            # update lr
-            latest_lr = self.lr
-            for param_group in self._optimizer.param_groups:
-                param_group['lr'] = latest_lr
-        return self._optimizer
-
-    @property
-    def lr(self) -> float:
-        return self._lr * 0.95**((self._epoch - 1) // 5)
-
-    def train(self):
-        self.model.train()
-
-    def eval(self):
-        self.model.eval()
-
-    @overload
-    def forward(self, input: torch.Tensor) -> str:
-        """Predict an image's tensor and give its label."""
-
-    @overload
-    def forward(self, input: str) -> str:
-        """Predict an image defined by a file path and give its label."""
-
-    @torch.no_grad()
-    def forward(self, input) -> str:
-        if not input or not isinstance(input, (str, torch.Tensor)):
-            raise AutoModelError(f'Invalid input data: {input}.')
-        if isinstance(input, str):
-            if not os.path.isfile(input):
-                raise AutoModelError(f'Cannot find or access the image file {input}.')
-            preprocessor = ResNetPreprocessor(mode=DatasetMode.PREDICTING,
-                                              config=self.preprocessor_config)
-            input = preprocessor.transform(input)
-            input.unsqueeze_(0)
-        self.model.eval()
-        output: torch.Tensor = self.model(input)
-        predict = output.argmax(1)[0].item()
-        if not self.labels:
-            if not os.path.isfile(os.path.join(self.resource_dir, 'fine_tuned.meta')):
-                raise AutoModel('The `fine_tuned.meta` file is required to make prediction.')
-            with open(os.path.join(self.resource_dir, 'fine_tuned.meta')) as f:
-                fine_tuned_json: dict = json.loads(f)
-                self.labels = fine_tuned_json.get('labels')
-        return self.labels[predict]
-
-    def _train_an_epoch(self):
-        self.train()
-        for images, targets in self.training_loader:
-            if self.is_cuda:
-                images, targets = images.cuda(), targets.cuda()
-            output = self.model(images)
-            output = F.log_softmax(output, dim=-1)
-            loss = F.nll_loss(output, targets)
-            self.optimizer.zero_grad()
-            loss.backward()
-            self.optimizer.step()
-
-    @torch.no_grad()
-    def _run_test(self) -> Tuple[float, float]:
-        """Run a round of test and report the result.
-
-        Return:
-            avg_loss, correct_rate
-        """
-        self.push_log(f'Begin testing of epoch {self._epoch}.')
-        self.eval()
-        total_loss = 0
-        total_correct = 0
-        for images, targets in self.testing_loader:
-            if self.is_cuda:
-                images, targets = images.cuda(), targets.cuda()
-            output = self.model(images)
-            output = F.log_softmax(output, dim=-1)
-            loss = F.nll_loss(output, targets, reduction='sum').item()
-            total_loss += loss
-            pred = output.max(1, keepdim=True)[1]
-            total_correct += pred.eq(targets.view_as(pred)).sum().item()
-
-        avg_loss = total_loss / len(self.testing_loader.dataset)
-        correct_rate = total_correct / len(self.testing_loader.dataset) * 100
-        logger.info(f'Testing Average Loss: {avg_loss:.4f}')
-        logger.info(f'Testing Correct Rate: {correct_rate:.2f}')
-
-        return avg_loss, correct_rate
-
-    @torch.no_grad()
-    def _run_validation(self) -> Tuple[float, float]:
-        """Run a round of validation and report the result.
-
-        Return:
-            avg_loss, correct_rate
-        """
-        self.eval()
-        total_loss = 0
-        total_correct = 0
-        for images, targets in self.validation_loader:
-            if self.is_cuda:
-                images, targets = images.cuda(), targets.cuda()
-            output = self.model(images)
-            output = F.log_softmax(output, dim=-1)
-            loss = F.nll_loss(output, targets, reduction='sum').item()
-            total_loss += loss
-            pred = output.max(1, keepdim=True)[1]
-            total_correct += pred.eq(targets.view_as(pred)).sum().item()
-
-        avg_loss = total_loss / len(self.validation_loader.dataset)
-        correct_rate = total_correct / len(self.validation_loader.dataset) * 100
-        logger.info(f'Validation Average Loss: {avg_loss:.4f}')
-        logger.info(f'Validation Correct Rate: {correct_rate:.2f}')
-        return avg_loss, correct_rate
-
-    @torch.no_grad()
-    def _is_finished(self) -> bool:
-        """Decide if stop training.
-
-        If there are validation dataset, decide depending on validatation results. If
-        the validation result of current epoch is below the best record for 10 continuous
-        times, then stop training.
-        If there are no validation dataset, run for `epochs` times.
-        """
-        if not self.validation_loader or len(self.validation_loader) == 0:
-            if self._epoch >= self.epochs:
-                self._best_state = deepcopy(self.model.state_dict())
-            return self._epoch >= self.epochs
-        # make a validation
-        self.push_log(f'Begin validation of epoch {self._epoch}.')
-        avg_loss, correct_rate = self._run_validation()
-        self.push_log('\n'.join(('Validation result:',
-                                 f'avg_loss={avg_loss:.4f}',
-                                 f'correct_rate={correct_rate:.2f}')))
-
-        if correct_rate > self._best_result:
-            self._overfit_index = 0
-            self._best_result = correct_rate
-            self._best_state = deepcopy(self.model.state_dict())
-            self.push_log('Validation result is better than last epoch.')
-            return self._epoch >= self.epochs
-        else:
-            self._overfit_index += 1
-            msg = f'Validation result gets worse for {self._overfit_index} consecutive times.'
-            self.push_log(msg)
-            return self._overfit_index >= 10 or self._epoch >= self.epochs
-
-    def fine_tune(self,
-                  id: str,
-                  task_id: str,
-                  dataset_dir: str,
-                  is_initiator: bool = False,
-                  is_debug_script: bool = False):
-        self.id = id
-        self.task_id = task_id
-        self.is_initiator = is_initiator
-        self.is_debug_script = is_debug_script
-
-        is_succ, err_msg = self.init_dataset(dataset_dir)
-        if not is_succ:
-            raise AutoModelError(f'Failed to initialize dataset. {err_msg}')
-        num_classes = (len(self.training_loader.dataset.labels)
-                       if self.training_loader
-                       else len(self.testing_loader.dataset.labels))
-        self._replace_fc_if_diff(num_classes)
-
-        self.config.id2label = {str(_idx): _label for _idx, _label in enumerate(self.labels)}
-        self.config.label2id = {_label: _idx for _idx, _label in enumerate(self.labels)}
-        self.config.label2id = dict(sorted(self.config.label2id.items()))
-
-        is_finished = False
-        self._epoch = 0
-        while not is_finished:
-            self._epoch += 1
-            self.push_log(f'Begin training of epoch {self._epoch}.')
-            self._train_an_epoch()
-            self.push_log(f'Complete training of epoch {self._epoch}.')
-            is_finished = self._is_finished()
-
-        self._save_fine_tuned()
-        avg_loss, correct_rate = self._run_test()
-        self.push_log('\n'.join(('Testing result:',
-                                 f'avg_loss={avg_loss:.4f}',
-                                 f'correct_rate={correct_rate:.2f}')))
-
-    def _save_fine_tuned(self):
-        """Save the best or final state of fine tuning."""
-        self.result_dir = get_result_dir(self.task_id)
-        os.makedirs(self.result_dir, exist_ok=True)
-        with open(os.path.join(self.result_dir, self.config.param_file), 'wb') as f:
-            torch.save(self._best_state, f)
-        with open(os.path.join(self.result_dir, 'config.json'), 'w') as f:
-            f.write(json.dumps(asdict(self.config), ensure_ascii=False))
-
-
-class AutoResNetFedAvg(AutoResNet, AutoFedAvgModel):
-
-    def state_dict(self) -> Dict[str, torch.Tensor]:
-        return self.model.state_dict()
-
-    def load_state_dict(self, state_dict: Dict[str, torch.Tensor]):
-        return self.model.load_state_dict(state_dict)
-
-    def train_an_epoch(self):
-        self._epoch += 1
-        self._train_an_epoch()
-
-    def run_test(self) -> Tuple[float, float]:
-        """Run a test and report the result.
-
-        Return:
-            avg_loss, correct_rate
-        """
-        return self._run_test()
-
-    def run_validation(self):
-        """Run a test and report the result.
-
-        Return:
-            avg_loss, correct_rate
-        """
-        return self._run_validation()
-
-    def init_dataset(self, dataset_dir: str) -> Tuple[bool, str]:
-        self.dataset_dir = dataset_dir
-        try:
-            if not self._is_dataset_initialized:
-                self.training_loader
-                self.validation_loader
-                self.testing_loader
-                if not self.training_loader and not self.testing_loader:
-                    logger.error('Both training data and testing data are missing.')
-                    err_msg = ' '.join((
-                        'The initiator must provide test dataset.',
-                        'The collaborator must provide train dataset.'
-                    ))
-                    return False, err_msg
-                self.labels = (self.training_loader.dataset.labels
-                               if self.training_loader
-                               else self.testing_loader.dataset.labels)
-                self._is_dataset_initialized = True
-            return True, 'Initializing dataset complete.'
-        except Exception:
-            logger.exception('Failed to initialize dataset.')
-            return False, '初始化数据失败，请联系模型作者排查原因。'
-
-    def fine_tune(self,
-                  id: str,
-                  task_id: str,
-                  dataset_dir: str,
-                  is_initiator: bool = False,
-                  recover: bool = False):
-        is_succ, err_msg = self.init_dataset(dataset_dir)
-        if not is_succ:
-            raise AutoModelError(f'Failed to initialize dataset. {err_msg}')
-        num_classes = (len(self.training_loader.dataset.labels)
-                       if self.training_loader
-                       else len(self.testing_loader.dataset.labels))
-        self._replace_fc_if_diff(num_classes)
-
-        self.config.id2label = {str(_idx): _label for _idx, _label in enumerate(self.labels)}
-        self.config.label2id = {_label: _idx for _idx, _label in enumerate(self.labels)}
-        self.config.label2id = dict(sorted(self.config.label2id.items()))
-
-        self._fine_tune_impl(id=id,
-                             task_id=task_id,
-                             dataset_dir=dataset_dir,
-                             scheduler_impl=ResNetFedAvgScheduler,
-                             is_initiator=is_initiator,
-                             recover=recover,
-                             max_rounds=self.config.epochs,
-                             log_rounds=1)
-
-    def fine_tuned_files_dict(self) -> Optional[Dict[str, str]]:
-        param_file = os.path.join(self.result_dir, self.config.param_file)
-        with open(param_file, 'wb') as f:
-            torch.save(self.scheduler.best_state_dict, f)
-        config_file = os.path.join(self.result_dir, 'config.json')
-        with open(config_file, 'w') as f:
-            f.write(json.dumps(asdict(self.config), ensure_ascii=False))
-        return {
-            self.config.param_file: param_file,
-            'config.json': config_file
-        }
-
-
-class ResNetFedAvgScheduler(AutoFedAvgScheduler):
-
-    def __init__(self,
-                 auto_proxy: AutoResNetFedAvg,
-                 max_rounds: int = 0,
-                 merge_epochs: int = 1,
-                 calculation_timeout: int = 300,
-                 schedule_timeout: int = 30,
-                 log_rounds: int = 0,
-                 involve_aggregator: bool = False):
-        super().__init__(auto_proxy=auto_proxy,
-                         max_rounds=max_rounds,
-                         merge_epochs=merge_epochs,
-                         calculation_timeout=calculation_timeout,
-                         schedule_timeout=schedule_timeout,
-                         log_rounds=log_rounds,
-                         involve_aggregator=involve_aggregator)
-        self._best_state = None
-        self._best_result = 0
-        self._overfit_index = 0
-
-    @property
-    def best_state_dict(self) -> Dict[str, torch.Tensor]:
-        return self._best_state
-
-    def validate_context(self):
-        super().validate_context()
-        if self.is_initiator:
-            assert self.test_loader and len(self.test_loader) > 0, 'failed to load test data'
-            self.push_log(f'There are {len(self.test_loader.dataset)} samples for testing.')
-        else:
-            assert self.train_loader and len(self.train_loader) > 0, 'failed to load train data'
-            self.push_log(f'There are {len(self.train_loader.dataset)} samples for training.')
-
-    def train_an_epoch(self):
-        self.auto_proxy.train_an_epoch()
-
-    def run_test(self):
-        avg_loss, correct_rate = self.auto_proxy.run_test()
-
-        self.tb_writer.add_scalar('test_results/avg_loss', avg_loss, self.current_round)
-        self.tb_writer.add_scalar('test_results/correct_rate', correct_rate, self.current_round)
-
-    def is_task_finished(self) -> bool:
-        """Decide if stop training.
-
-        If there are validation dataset, decide depending on validatation results. If
-        the validation result of current epoch is below the best record for 10 continuous
-        times, then stop training.
-        If there are no validation dataset, run for `max_rounds` times.
-        """
-        if not self.validation_loader or len(self.validation_loader) == 0:
-            self._best_state = deepcopy(self.model.state_dict())
-            return self._is_reach_max_rounds()
-
-        # make a validation
-        self.push_log(f'Begin validation of round {self.current_round}.')
-        avg_loss, correct_rate = self.auto_proxy.run_validation()
-        self.push_log('\n'.join(('Validation result:',
-                                 f'avg_loss={avg_loss:.4f}',
-                                 f'correct_rate={correct_rate:.2f}')))
-
-        if correct_rate > self._best_result:
-            self._overfit_index = 0
-            self._best_result = correct_rate
-            self._best_state = deepcopy(self.state_dict())
-            self.push_log('Validation result is better than last epoch.')
-            return self._is_reach_max_rounds()
-        else:
-            self._overfit_index += 1
-            msg = f'Validation result gets worse for {self._overfit_index} consecutive times.'
-            self.push_log(msg)
-            return self._overfit_index >= 10 or self._is_reach_max_rounds()
+# Copyright 2022 Alphamed
+
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+
+#     http://www.apache.org/licenses/LICENSE-2.0
+
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+"""Pretraining skin_lesion_diagnosis models and schedulers."""
+
+import json
+import os
+from copy import deepcopy
+from dataclasses import InitVar, asdict, dataclass
+from typing import Dict, List, Optional, Tuple, overload
+
+import torch
+import torch.nn.functional as F
+from PIL import Image
+from res_net import ResNet18
+from torch import nn, optim
+from torch.utils.data import DataLoader, Dataset
+from torchvision import transforms
+
+from alphafed import get_result_dir, logger
+from alphafed.auto_ml.auto_model import (AutoFedAvgModel, AutoFedAvgScheduler,
+                                         AutoModel, DatasetMode,
+                                         MandatoryConfig, Preprocessor)
+from alphafed.auto_ml.cvat.annotation import ImageAnnotationUtils
+from alphafed.auto_ml.exceptions import AutoModelError, ConfigError
+
+
+@dataclass
+class PreprocessorConfig:
+
+    size: int
+    do_affine: bool
+    degrees: int
+    translate: Tuple[float]
+    do_horizontal_flip: bool
+    image_mean: List[float]
+    image_std: List[float]
+
+    def __post_init__(self):
+        self.translate = tuple(self.translate)
+
+
+class ResNetPreprocessor(Preprocessor):
+
+    def __init__(self, mode: DatasetMode, config: PreprocessorConfig) -> None:
+        layers = []
+        layers.append(transforms.Resize((config.size, config.size)))
+        if mode == DatasetMode.TRAINING:
+            if config.do_affine:
+                layers.append(transforms.RandomAffine(degrees=config.degrees,
+                                                      translate=config.translate))
+            if config.do_horizontal_flip:
+                layers.append(transforms.RandomHorizontalFlip())
+        layers.append(transforms.ToTensor())
+        layers.append(transforms.Normalize(config.image_mean, config.image_std))
+        self._transformer = transforms.Compose(layers)
+
+    def transform(self, image_file: str) -> torch.Tensor:
+        """Transform an image object into an input tensor."""
+        image = Image.open(image_file).convert('RGB')
+        return self._transformer(image)
+
+
+class ResNetDataset(Dataset):
+
+    def __init__(self,
+                 image_dir: str,
+                 annotation_file: str,
+                 mode: DatasetMode,
+                 config: PreprocessorConfig) -> None:
+        """Init a dataset instance for ResNet auto model families.
+
+        Args:
+            image_dir:
+                The directory including image files.
+            annotation_file:
+                The file including annotation information.
+            mode:
+                One of training or validation or testing.
+            config:
+                The configuration for the preprocessor.
+        """
+        super().__init__()
+        if not image_dir or not isinstance(image_dir, str):
+            raise ConfigError(f'Invalid image directory: {image_dir}.')
+        if not annotation_file or not isinstance(annotation_file, str):
+            raise ConfigError(f'Invalid annotation file path: {annotation_file}.')
+        assert mode and isinstance(mode, DatasetMode), f'Invalid dataset mode: {mode}.'
+        if not os.path.exists(image_dir) or not os.path.isdir(image_dir):
+            raise ConfigError(f'{image_dir} does not exist or is not a directory.')
+        if not os.path.exists(annotation_file) or not os.path.isfile(annotation_file):
+            raise ConfigError(f'{annotation_file} does not exist or is not a file.')
+
+        self.image_dir = image_dir
+        self.annotation_file = annotation_file
+        self.transformer = ResNetPreprocessor(mode=mode, config=config)
+
+        self.images, self.labels = ImageAnnotationUtils.parse_single_category_annotation(
+            annotation_file=self.annotation_file, resource_dir=image_dir, mode=mode
+        )
+
+    def __getitem__(self, index: int):
+        _item = self.images[index]
+        return self.transformer(_item.image_file), _item.class_label
+
+    def __len__(self):
+        return len(self.images)
+
+
+@dataclass
+class ModelConfig(MandatoryConfig):
+
+    id2label: dict
+    label2id: dict
+    learning_rate: int
+    batch_size: int
+    epochs: int
+    image_size: int = 224
+    torch_dtype: InitVar[str] = 'float32'
+
+    def __post_init__(self, torch_dtype: str):
+        super().__post_init__()
+
+        for _label in self.id2label.values():
+            if _label not in self.label2id:
+                raise TypeError(f'Label `{_label}` lost its ID in label2id map.')
+        for _id in self.label2id.values():
+            if str(_id) not in self.id2label:
+                raise TypeError(f'ID `{_id}` lost its label in id2label map.')
+
+        if self.learning_rate <= 0:
+            raise TypeError(f'Invalid learning_rate: `{self.learning_rate}`.')
+        if self.batch_size <= 0:
+            raise TypeError(f'Invalid batch_size: `{self.batch_size}`.')
+        if self.epochs <= 0:
+            raise TypeError(f'Invalid epochs: `{self.epochs}`.')
+
+        if self.image_size <= 0:
+            raise TypeError(f'Invalid image_size: `{self.image_size}`.')
+
+        if torch_dtype == 'float32' or torch_dtype == 'float':
+            self.torch_dtype = torch.float32
+        elif torch_dtype == 'float64':
+            self.torch_dtype = torch.float64
+        elif torch == 'float16':
+            self.torch_dtype = torch.float16
+        else:
+            raise TypeError(f'Invalid torch_dtype: `{torch_dtype}`.')
+
+
+class AutoResNet(AutoModel):
+
+    def __init__(self, resource_dir: str, **kwargs) -> None:
+        super().__init__(resource_dir=resource_dir)
+
+        self.config, self.preprocessor_config = self._load_config()
+        self.epochs = self.config.epochs
+        self.batch_size = self.config.batch_size
+        self._lr = self.config.learning_rate
+        self._epoch = 0
+        # 测试部署服务暂时不支持 GPU 环境，使用 GPU 版本会导致部署失败
+        # self.is_cuda = torch.cuda.is_available()
+        self.is_cuda = False
+
+        self.dataset_dir = None
+        self.labels = None
+
+        self._best_result = 0
+        self._best_state = None
+        self._overfit_index = 0
+        self._is_dataset_initialized = False
+        self._save_root = '.cache'
+
+    def _load_config(self) -> Tuple[ModelConfig, PreprocessorConfig]:
+        config_file = os.path.join(self.resource_dir, 'config.json')
+        if not os.path.isfile(config_file):
+            raise ConfigError('Config file missing.')
+        try:
+            with open(config_file, 'r') as f:
+                config_json = json.load(f)
+        except json.JSONDecodeError:
+            raise ConfigError('Failed to parse config file.')
+        model_config = ModelConfig(**config_json)
+
+        preprocessor_config_file = os.path.join(self.resource_dir, 'preprocessor_config.json')
+        if not os.path.isfile(preprocessor_config_file):
+            raise ConfigError('Preprocessor config file missing.')
+        try:
+            with open(preprocessor_config_file, 'r') as f:
+                preprocessor_config_json = json.load(f)
+        except json.JSONDecodeError:
+            raise ConfigError('Failed to parse preprocessor config file.')
+        preprocessor_config = PreprocessorConfig(**preprocessor_config_json)
+
+        return model_config, preprocessor_config
+
+    @property
+    def annotation_file(self):
+        return os.path.join(self.dataset_dir, 'annotation.json') if self.dataset_dir else None
+
+    def init_dataset(self, dataset_dir: str) -> Tuple[bool, str]:
+        self.dataset_dir = dataset_dir
+        try:
+            if not self._is_dataset_initialized:
+                self.training_loader
+                self.validation_loader
+                self.testing_loader
+                if not self.training_loader or not self.testing_loader:
+                    logger.error('Both training data and testing data are missing.')
+                    return False, 'Must provide train dataset and test dataset to fine tune.'
+                self.labels = (self.training_loader.dataset.labels
+                               if self.training_loader
+                               else self.testing_loader.dataset.labels)
+                self._is_dataset_initialized = True
+            return True, 'Initializing dataset complete.'
+        except Exception:
+            logger.exception('Failed to initialize dataset.')
+            return False, '初始化数据失败，请联系模型作者排查原因。'
+
+    @property
+    def training_loader(self) -> DataLoader:
+        """Return a dataloader instance of training data.
+
+        Data augmentation is used to improve performance, so we need to generate a new dataset
+        every epoch in case of training on a same dataset over and over again.
+        """
+        if not hasattr(self, "_training_loader"):
+            self._training_loader = self._build_training_data_loader()
+        return self._training_loader
+
+    def _build_training_data_loader(self) -> Optional[DataLoader]:
+        dataset = ResNetDataset(image_dir=self.dataset_dir,
+                                annotation_file=self.annotation_file,
+                                mode=DatasetMode.TRAINING,
+                                config=self.preprocessor_config)
+        if len(dataset) == 0:
+            return None
+        return DataLoader(dataset=dataset,
+                          batch_size=self.batch_size,
+                          shuffle=True)
+
+    @property
+    def validation_loader(self) -> DataLoader:
+        """Return a dataloader instance of validation data."""
+        if not hasattr(self, "_validation_loader"):
+            self._validation_loader = self._build_validation_data_loader()
+        return self._validation_loader
+
+    def _build_validation_data_loader(self) -> DataLoader:
+        dataset = ResNetDataset(image_dir=self.dataset_dir,
+                                annotation_file=self.annotation_file,
+                                mode=DatasetMode.VALIDATION,
+                                config=self.preprocessor_config)
+        if len(dataset) == 0:
+            return None
+        return DataLoader(dataset=dataset, batch_size=self.batch_size)
+
+    @property
+    def testing_loader(self) -> DataLoader:
+        """Return a dataloader instance of testing data."""
+        if not hasattr(self, "_testing_loader"):
+            self._testing_loader = self._build_testing_data_loader()
+        return self._testing_loader
+
+    def _build_testing_data_loader(self) -> DataLoader:
+        dataset = ResNetDataset(image_dir=self.dataset_dir,
+                                annotation_file=self.annotation_file,
+                                mode=DatasetMode.TESTING,
+                                config=self.preprocessor_config)
+        if len(dataset) == 0:
+            return None
+        return DataLoader(dataset=dataset, batch_size=self.batch_size)
+
+    def _build_model(self):
+        self._model: nn.Module = ResNet18()
+        self.labels = list(self.config.id2label.values())
+        self._replace_fc_if_diff(len(self.labels))
+
+        param_file = os.path.join(self.resource_dir, self.config.param_file)
+        with open(param_file, 'rb') as f:
+            state_dict = torch.load(f)
+            if self._model.get_parameter('fc.weight').shape[0] != state_dict['fc.weight'].shape[0]:
+                raise AutoModelError('The fine tuned labels dismatched the parameters.')
+            self._model.load_state_dict(state_dict)
+
+        return self._model.cuda() if self.is_cuda else self._model
+
+    def _replace_fc_if_diff(self, num_classes: int):
+        """Replace the classify layer with new number of classes."""
+        assert (
+            num_classes and isinstance(num_classes, int) and num_classes > 0
+        ), f'Invalid number of classes: {num_classes} .'
+        if num_classes != self.num_classes:
+            self.model.fc = nn.Linear(self.model.layer1[0].expansion * 512, num_classes)
+
+    @property
+    def num_classes(self) -> int:
+        """Return the number of classes of the classification layer of the model."""
+        return self.model.get_parameter('fc.weight').shape[0]
+
+    @property
+    def model(self) -> nn.Module:
+        if not hasattr(self, '_model'):
+            self._model = self._build_model()
+        return self._model
+
+    @property
+    def optimizer(self) -> optim.Optimizer:
+        if not hasattr(self, '_optimizer'):
+            self._optimizer = optim.Adam(self.model.parameters(),
+                                         lr=self.lr,
+                                         betas=(0.9, 0.999),
+                                         weight_decay=5e-4)
+        else:
+            # update lr
+            latest_lr = self.lr
+            for param_group in self._optimizer.param_groups:
+                param_group['lr'] = latest_lr
+        return self._optimizer
+
+    @property
+    def lr(self) -> float:
+        return self._lr * 0.95**((self._epoch - 1) // 5)
+
+    def train(self):
+        self.model.train()
+
+    def eval(self):
+        self.model.eval()
+
+    @overload
+    def forward(self, input: torch.Tensor) -> str:
+        """Predict an image's tensor and give its label."""
+
+    @overload
+    def forward(self, input: str) -> str:
+        """Predict an image defined by a file path and give its label."""
+
+    @torch.no_grad()
+    def forward(self, input) -> str:
+        if not input or not isinstance(input, (str, torch.Tensor)):
+            raise AutoModelError(f'Invalid input data: {input}.')
+        if isinstance(input, str):
+            if not os.path.isfile(input):
+                raise AutoModelError(f'Cannot find or access the image file {input}.')
+            preprocessor = ResNetPreprocessor(mode=DatasetMode.PREDICTING,
+                                              config=self.preprocessor_config)
+            input = preprocessor.transform(input)
+            input.unsqueeze_(0)
+        self.model.eval()
+        output: torch.Tensor = self.model(input)
+        predict = output.argmax(1)[0].item()
+        if not self.labels:
+            if not os.path.isfile(os.path.join(self.resource_dir, 'fine_tuned.meta')):
+                raise AutoModel('The `fine_tuned.meta` file is required to make prediction.')
+            with open(os.path.join(self.resource_dir, 'fine_tuned.meta')) as f:
+                fine_tuned_json: dict = json.loads(f)
+                self.labels = fine_tuned_json.get('labels')
+        return self.labels[predict]
+
+    def _train_an_epoch(self):
+        self.train()
+        for images, targets in self.training_loader:
+            if self.is_cuda:
+                images, targets = images.cuda(), targets.cuda()
+            output = self.model(images)
+            output = F.log_softmax(output, dim=-1)
+            loss = F.nll_loss(output, targets)
+            self.optimizer.zero_grad()
+            loss.backward()
+            self.optimizer.step()
+
+    @torch.no_grad()
+    def _run_test(self) -> Tuple[float, float]:
+        """Run a round of test and report the result.
+
+        Return:
+            avg_loss, correct_rate
+        """
+        self.push_log(f'Begin testing of epoch {self._epoch}.')
+        self.eval()
+        total_loss = 0
+        total_correct = 0
+        for images, targets in self.testing_loader:
+            if self.is_cuda:
+                images, targets = images.cuda(), targets.cuda()
+            output = self.model(images)
+            output = F.log_softmax(output, dim=-1)
+            loss = F.nll_loss(output, targets, reduction='sum').item()
+            total_loss += loss
+            pred = output.max(1, keepdim=True)[1]
+            total_correct += pred.eq(targets.view_as(pred)).sum().item()
+
+        avg_loss = total_loss / len(self.testing_loader.dataset)
+        correct_rate = total_correct / len(self.testing_loader.dataset) * 100
+        logger.info(f'Testing Average Loss: {avg_loss:.4f}')
+        logger.info(f'Testing Correct Rate: {correct_rate:.2f}')
+
+        return avg_loss, correct_rate
+
+    @torch.no_grad()
+    def _run_validation(self) -> Tuple[float, float]:
+        """Run a round of validation and report the result.
+
+        Return:
+            avg_loss, correct_rate
+        """
+        self.eval()
+        total_loss = 0
+        total_correct = 0
+        for images, targets in self.validation_loader:
+            if self.is_cuda:
+                images, targets = images.cuda(), targets.cuda()
+            output = self.model(images)
+            output = F.log_softmax(output, dim=-1)
+            loss = F.nll_loss(output, targets, reduction='sum').item()
+            total_loss += loss
+            pred = output.max(1, keepdim=True)[1]
+            total_correct += pred.eq(targets.view_as(pred)).sum().item()
+
+        avg_loss = total_loss / len(self.validation_loader.dataset)
+        correct_rate = total_correct / len(self.validation_loader.dataset) * 100
+        logger.info(f'Validation Average Loss: {avg_loss:.4f}')
+        logger.info(f'Validation Correct Rate: {correct_rate:.2f}')
+        return avg_loss, correct_rate
+
+    @torch.no_grad()
+    def _is_finished(self) -> bool:
+        """Decide if stop training.
+
+        If there are validation dataset, decide depending on validatation results. If
+        the validation result of current epoch is below the best record for 10 continuous
+        times, then stop training.
+        If there are no validation dataset, run for `epochs` times.
+        """
+        if not self.validation_loader or len(self.validation_loader) == 0:
+            if self._epoch >= self.epochs:
+                self._best_state = deepcopy(self.model.state_dict())
+            return self._epoch >= self.epochs
+        # make a validation
+        self.push_log(f'Begin validation of epoch {self._epoch}.')
+        avg_loss, correct_rate = self._run_validation()
+        self.push_log('\n'.join(('Validation result:',
+                                 f'avg_loss={avg_loss:.4f}',
+                                 f'correct_rate={correct_rate:.2f}')))
+
+        if correct_rate > self._best_result:
+            self._overfit_index = 0
+            self._best_result = correct_rate
+            self._best_state = deepcopy(self.model.state_dict())
+            self.push_log('Validation result is better than last epoch.')
+            return self._epoch >= self.epochs
+        else:
+            self._overfit_index += 1
+            msg = f'Validation result gets worse for {self._overfit_index} consecutive times.'
+            self.push_log(msg)
+            return self._overfit_index >= 10 or self._epoch >= self.epochs
+
+    def fine_tune(self,
+                  id: str,
+                  task_id: str,
+                  dataset_dir: str,
+                  is_initiator: bool = False,
+                  is_debug_script: bool = False):
+        self.id = id
+        self.task_id = task_id
+        self.is_initiator = is_initiator
+        self.is_debug_script = is_debug_script
+
+        is_succ, err_msg = self.init_dataset(dataset_dir)
+        if not is_succ:
+            raise AutoModelError(f'Failed to initialize dataset. {err_msg}')
+        num_classes = (len(self.training_loader.dataset.labels)
+                       if self.training_loader
+                       else len(self.testing_loader.dataset.labels))
+        self._replace_fc_if_diff(num_classes)
+
+        self.config.id2label = {str(_idx): _label for _idx, _label in enumerate(self.labels)}
+        self.config.label2id = {_label: _idx for _idx, _label in enumerate(self.labels)}
+        self.config.label2id = dict(sorted(self.config.label2id.items()))
+
+        is_finished = False
+        self._epoch = 0
+        while not is_finished:
+            self._epoch += 1
+            self.push_log(f'Begin training of epoch {self._epoch}.')
+            self._train_an_epoch()
+            self.push_log(f'Complete training of epoch {self._epoch}.')
+            is_finished = self._is_finished()
+
+        self._save_fine_tuned()
+        avg_loss, correct_rate = self._run_test()
+        self.push_log('\n'.join(('Testing result:',
+                                 f'avg_loss={avg_loss:.4f}',
+                                 f'correct_rate={correct_rate:.2f}')))
+
+    def _save_fine_tuned(self):
+        """Save the best or final state of fine tuning."""
+        self.result_dir = get_result_dir(self.task_id)
+        os.makedirs(self.result_dir, exist_ok=True)
+        with open(os.path.join(self.result_dir, self.config.param_file), 'wb') as f:
+            torch.save(self._best_state, f)
+        with open(os.path.join(self.result_dir, 'config.json'), 'w') as f:
+            f.write(json.dumps(asdict(self.config), ensure_ascii=False))
+
+
+class AutoResNetFedAvg(AutoResNet, AutoFedAvgModel):
+
+    def state_dict(self) -> Dict[str, torch.Tensor]:
+        return self.model.state_dict()
+
+    def load_state_dict(self, state_dict: Dict[str, torch.Tensor]):
+        return self.model.load_state_dict(state_dict)
+
+    def train_an_epoch(self):
+        self._epoch += 1
+        self._train_an_epoch()
+
+    def run_test(self) -> Tuple[float, float]:
+        """Run a test and report the result.
+
+        Return:
+            avg_loss, correct_rate
+        """
+        return self._run_test()
+
+    def run_validation(self):
+        """Run a test and report the result.
+
+        Return:
+            avg_loss, correct_rate
+        """
+        return self._run_validation()
+
+    def init_dataset(self, dataset_dir: str) -> Tuple[bool, str]:
+        self.dataset_dir = dataset_dir
+        try:
+            if not self._is_dataset_initialized:
+                self.training_loader
+                self.validation_loader
+                self.testing_loader
+                if not self.training_loader and not self.testing_loader:
+                    logger.error('Both training data and testing data are missing.')
+                    err_msg = ' '.join((
+                        'The initiator must provide test dataset.',
+                        'The collaborator must provide train dataset.'
+                    ))
+                    return False, err_msg
+                self.labels = (self.training_loader.dataset.labels
+                               if self.training_loader
+                               else self.testing_loader.dataset.labels)
+                self._is_dataset_initialized = True
+            return True, 'Initializing dataset complete.'
+        except Exception:
+            logger.exception('Failed to initialize dataset.')
+            return False, '初始化数据失败，请联系模型作者排查原因。'
+
+    def fine_tune(self,
+                  id: str,
+                  task_id: str,
+                  dataset_dir: str,
+                  is_initiator: bool = False,
+                  recover: bool = False):
+        is_succ, err_msg = self.init_dataset(dataset_dir)
+        if not is_succ:
+            raise AutoModelError(f'Failed to initialize dataset. {err_msg}')
+        num_classes = (len(self.training_loader.dataset.labels)
+                       if self.training_loader
+                       else len(self.testing_loader.dataset.labels))
+        self._replace_fc_if_diff(num_classes)
+
+        self.config.id2label = {str(_idx): _label for _idx, _label in enumerate(self.labels)}
+        self.config.label2id = {_label: _idx for _idx, _label in enumerate(self.labels)}
+        self.config.label2id = dict(sorted(self.config.label2id.items()))
+
+        self._fine_tune_impl(id=id,
+                             task_id=task_id,
+                             dataset_dir=dataset_dir,
+                             scheduler_impl=ResNetFedAvgScheduler,
+                             is_initiator=is_initiator,
+                             recover=recover,
+                             max_rounds=self.config.epochs,
+                             log_rounds=1)
+
+    def fine_tuned_files_dict(self) -> Optional[Dict[str, str]]:
+        param_file = os.path.join(self.result_dir, self.config.param_file)
+        with open(param_file, 'wb') as f:
+            torch.save(self.scheduler.best_state_dict, f)
+        config_file = os.path.join(self.result_dir, 'config.json')
+        with open(config_file, 'w') as f:
+            f.write(json.dumps(asdict(self.config), ensure_ascii=False))
+        return {
+            self.config.param_file: param_file,
+            'config.json': config_file
+        }
+
+
+class ResNetFedAvgScheduler(AutoFedAvgScheduler):
+
+    def __init__(self,
+                 auto_proxy: AutoResNetFedAvg,
+                 max_rounds: int = 0,
+                 merge_epochs: int = 1,
+                 calculation_timeout: int = 300,
+                 schedule_timeout: int = 30,
+                 log_rounds: int = 0,
+                 involve_aggregator: bool = False):
+        super().__init__(auto_proxy=auto_proxy,
+                         max_rounds=max_rounds,
+                         merge_epochs=merge_epochs,
+                         calculation_timeout=calculation_timeout,
+                         schedule_timeout=schedule_timeout,
+                         log_rounds=log_rounds,
+                         involve_aggregator=involve_aggregator)
+        self._best_state = None
+        self._best_result = 0
+        self._overfit_index = 0
+
+    @property
+    def best_state_dict(self) -> Dict[str, torch.Tensor]:
+        return self._best_state
+
+    def validate_context(self):
+        super().validate_context()
+        if self.is_initiator:
+            assert self.test_loader and len(self.test_loader) > 0, 'failed to load test data'
+            self.push_log(f'There are {len(self.test_loader.dataset)} samples for testing.')
+        else:
+            assert self.train_loader and len(self.train_loader) > 0, 'failed to load train data'
+            self.push_log(f'There are {len(self.train_loader.dataset)} samples for training.')
+
+    def train_an_epoch(self):
+        self.auto_proxy.train_an_epoch()
+
+    def run_test(self):
+        avg_loss, correct_rate = self.auto_proxy.run_test()
+
+        self.tb_writer.add_scalar('test_results/avg_loss', avg_loss, self.current_round)
+        self.tb_writer.add_scalar('test_results/correct_rate', correct_rate, self.current_round)
+
+    def is_task_finished(self) -> bool:
+        """Decide if stop training.
+
+        If there are validation dataset, decide depending on validatation results. If
+        the validation result of current epoch is below the best record for 10 continuous
+        times, then stop training.
+        If there are no validation dataset, run for `max_rounds` times.
+        """
+        if not self.validation_loader or len(self.validation_loader) == 0:
+            self._best_state = deepcopy(self.model.state_dict())
+            return self._is_reach_max_rounds()
+
+        # make a validation
+        self.push_log(f'Begin validation of round {self.current_round}.')
+        avg_loss, correct_rate = self.auto_proxy.run_validation()
+        self.push_log('\n'.join(('Validation result:',
+                                 f'avg_loss={avg_loss:.4f}',
+                                 f'correct_rate={correct_rate:.2f}')))
+
+        if correct_rate > self._best_result:
+            self._overfit_index = 0
+            self._best_result = correct_rate
+            self._best_state = deepcopy(self.state_dict())
+            self.push_log('Validation result is better than last epoch.')
+            return self._is_reach_max_rounds()
+        else:
+            self._overfit_index += 1
+            msg = f'Validation result gets worse for {self._overfit_index} consecutive times.'
+            self.push_log(msg)
+            return self._overfit_index >= 10 or self._is_reach_max_rounds()
```

### Comparing `alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/skin_lesion_diagnosis/res_fed_avg/res_net.py` & `alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/skin_lesion_diagnosis/res_fed_avg/res_net.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/skin_lesion_diagnosis/res_local/auto.py` & `alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/skin_lesion_diagnosis/res_local/auto.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,666 +1,668 @@
-# Copyright 2022 Alphamed
-
-# Licensed under the Apache License, Version 2.0 (the "License");
-# you may not use this file except in compliance with the License.
-# You may obtain a copy of the License at
-
-#     http://www.apache.org/licenses/LICENSE-2.0
-
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-
-"""Pretraining skin_lesion_diagnosis models and schedulers."""
-
-import json
-import os
-from copy import deepcopy
-from dataclasses import InitVar, asdict, dataclass
-from typing import Dict, List, Optional, Tuple, overload
-
-import torch
-import torch.nn.functional as F
-from PIL import Image
-from res_net import ResNet18
-from torch import nn, optim
-from torch.utils.data import DataLoader, Dataset
-from torchvision import transforms
-
-from alphafed import get_result_dir, logger
-from alphafed.auto_ml.auto_model import (AutoFedAvgModel, AutoFedAvgScheduler,
-                                         AutoModel, DatasetMode,
-                                         MandatoryConfig, Preprocessor)
-from alphafed.auto_ml.cvat.annotation import ImageAnnotationUtils
-from alphafed.auto_ml.exceptions import AutoModelError, ConfigError
-
-
-@dataclass
-class PreprocessorConfig:
-
-    size: int
-    do_affine: bool
-    degrees: int
-    translate: Tuple[float]
-    do_horizontal_flip: bool
-    image_mean: List[float]
-    image_std: List[float]
-
-    def __post_init__(self):
-        self.translate = tuple(self.translate)
-
-
-class ResNetPreprocessor(Preprocessor):
-
-    def __init__(self, mode: DatasetMode, config: PreprocessorConfig) -> None:
-        layers = []
-        layers.append(transforms.Resize((config.size, config.size)))
-        if mode == DatasetMode.TRAINING:
-            if config.do_affine:
-                layers.append(transforms.RandomAffine(degrees=config.degrees,
-                                                      translate=config.translate))
-            if config.do_horizontal_flip:
-                layers.append(transforms.RandomHorizontalFlip())
-        layers.append(transforms.ToTensor())
-        layers.append(transforms.Normalize(config.image_mean, config.image_std))
-        self._transformer = transforms.Compose(layers)
-
-    def transform(self, image_file: str) -> torch.Tensor:
-        """Transform an image object into an input tensor."""
-        image = Image.open(image_file).convert('RGB')
-        return self._transformer(image)
-
-
-class ResNetDataset(Dataset):
-
-    def __init__(self,
-                 image_dir: str,
-                 annotation_file: str,
-                 mode: DatasetMode,
-                 config: PreprocessorConfig) -> None:
-        """Init a dataset instance for ResNet auto model families.
-
-        Args:
-            image_dir:
-                The directory including image files.
-            annotation_file:
-                The file including annotation information.
-            mode:
-                One of training or validation or testing.
-            config:
-                The configuration for the preprocessor.
-        """
-        super().__init__()
-        if not image_dir or not isinstance(image_dir, str):
-            raise ConfigError(f'Invalid image directory: {image_dir}.')
-        if not annotation_file or not isinstance(annotation_file, str):
-            raise ConfigError(f'Invalid annotation file path: {annotation_file}.')
-        assert mode and isinstance(mode, DatasetMode), f'Invalid dataset mode: {mode}.'
-        if not os.path.exists(image_dir) or not os.path.isdir(image_dir):
-            raise ConfigError(f'{image_dir} does not exist or is not a directory.')
-        if not os.path.exists(annotation_file) or not os.path.isfile(annotation_file):
-            raise ConfigError(f'{annotation_file} does not exist or is not a file.')
-
-        self.image_dir = image_dir
-        self.annotation_file = annotation_file
-        self.transformer = ResNetPreprocessor(mode=mode, config=config)
-
-        self.images, self.labels = ImageAnnotationUtils.parse_single_category_annotation(
-            annotation_file=self.annotation_file, resource_dir=image_dir, mode=mode
-        )
-
-    def __getitem__(self, index: int):
-        _item = self.images[index]
-        return self.transformer(_item.image_file), _item.class_label
-
-    def __len__(self):
-        return len(self.images)
-
-
-@dataclass
-class ModelConfig(MandatoryConfig):
-
-    id2label: dict
-    label2id: dict
-    learning_rate: int
-    batch_size: int
-    epochs: int
-    image_size: int = 224
-    torch_dtype: InitVar[str] = 'float32'
-
-    def __post_init__(self, torch_dtype: str):
-        super().__post_init__()
-
-        for _label in self.id2label.values():
-            if _label not in self.label2id:
-                raise TypeError(f'Label `{_label}` lost its ID in label2id map.')
-        for _id in self.label2id.values():
-            if str(_id) not in self.id2label:
-                raise TypeError(f'ID `{_id}` lost its label in id2label map.')
-
-        if self.learning_rate <= 0:
-            raise TypeError(f'Invalid learning_rate: `{self.learning_rate}`.')
-        if self.batch_size <= 0:
-            raise TypeError(f'Invalid batch_size: `{self.batch_size}`.')
-        if self.epochs <= 0:
-            raise TypeError(f'Invalid epochs: `{self.epochs}`.')
-
-        if self.image_size <= 0:
-            raise TypeError(f'Invalid image_size: `{self.image_size}`.')
-
-        if torch_dtype == 'float32' or torch_dtype == 'float':
-            self.torch_dtype = torch.float32
-        elif torch_dtype == 'float64':
-            self.torch_dtype = torch.float64
-        elif torch == 'float16':
-            self.torch_dtype = torch.float16
-        else:
-            raise TypeError(f'Invalid torch_dtype: `{torch_dtype}`.')
-
-
-class AutoResNet(AutoModel):
-
-    def __init__(self, resource_dir: str, **kwargs) -> None:
-        super().__init__(resource_dir=resource_dir)
-
-        self.config, self.preprocessor_config = self._load_config()
-        self.epochs = self.config.epochs
-        self.batch_size = self.config.batch_size
-        self._lr = self.config.learning_rate
-        self._epoch = 0
-        self.is_cuda = torch.cuda.is_available()
-
-        self.dataset_dir = None
-        self.labels = None
-
-        self._best_result = 0
-        self._best_state = None
-        self._overfit_index = 0
-        self._is_dataset_initialized = False
-        self._save_root = '.cache'
-
-    def _load_config(self) -> Tuple[ModelConfig, PreprocessorConfig]:
-        config_file = os.path.join(self.resource_dir, 'config.json')
-        if not os.path.isfile(config_file):
-            raise ConfigError('Config file missing.')
-        try:
-            with open(config_file, 'r') as f:
-                config_json = json.load(f)
-        except json.JSONDecodeError:
-            raise ConfigError('Failed to parse config file.')
-        model_config = ModelConfig(**config_json)
-
-        preprocessor_config_file = os.path.join(self.resource_dir, 'preprocessor_config.json')
-        if not os.path.isfile(preprocessor_config_file):
-            raise ConfigError('Preprocessor config file missing.')
-        try:
-            with open(preprocessor_config_file, 'r') as f:
-                preprocessor_config_json = json.load(f)
-        except json.JSONDecodeError:
-            raise ConfigError('Failed to parse preprocessor config file.')
-        preprocessor_config = PreprocessorConfig(**preprocessor_config_json)
-
-        return model_config, preprocessor_config
-
-    @property
-    def annotation_file(self):
-        return os.path.join(self.dataset_dir, 'annotation.json') if self.dataset_dir else None
-
-    def init_dataset(self, dataset_dir: str) -> Tuple[bool, str]:
-        self.dataset_dir = dataset_dir
-        try:
-            if not self._is_dataset_initialized:
-                self.training_loader
-                self.validation_loader
-                self.testing_loader
-                if not self.training_loader or not self.testing_loader:
-                    logger.error('Both training data and testing data are missing.')
-                    return False, 'Must provide train dataset and test dataset to fine tune.'
-                self.labels = (self.training_loader.dataset.labels
-                               if self.training_loader
-                               else self.testing_loader.dataset.labels)
-                self._is_dataset_initialized = True
-            return True, 'Initializing dataset complete.'
-        except Exception:
-            logger.exception('Failed to initialize dataset.')
-            return False, '初始化数据失败，请联系模型作者排查原因。'
-
-    @property
-    def training_loader(self) -> DataLoader:
-        """Return a dataloader instance of training data.
-
-        Data augmentation is used to improve performance, so we need to generate a new dataset
-        every epoch in case of training on a same dataset over and over again.
-        """
-        if not hasattr(self, "_training_loader"):
-            self._training_loader = self._build_training_data_loader()
-        return self._training_loader
-
-    def _build_training_data_loader(self) -> Optional[DataLoader]:
-        dataset = ResNetDataset(image_dir=self.dataset_dir,
-                                annotation_file=self.annotation_file,
-                                mode=DatasetMode.TRAINING,
-                                config=self.preprocessor_config)
-        if len(dataset) == 0:
-            return None
-        return DataLoader(dataset=dataset,
-                          batch_size=self.batch_size,
-                          shuffle=True)
-
-    @property
-    def validation_loader(self) -> DataLoader:
-        """Return a dataloader instance of validation data."""
-        if not hasattr(self, "_validation_loader"):
-            self._validation_loader = self._build_validation_data_loader()
-        return self._validation_loader
-
-    def _build_validation_data_loader(self) -> DataLoader:
-        dataset = ResNetDataset(image_dir=self.dataset_dir,
-                                annotation_file=self.annotation_file,
-                                mode=DatasetMode.VALIDATION,
-                                config=self.preprocessor_config)
-        if len(dataset) == 0:
-            return None
-        return DataLoader(dataset=dataset, batch_size=self.batch_size)
-
-    @property
-    def testing_loader(self) -> DataLoader:
-        """Return a dataloader instance of testing data."""
-        if not hasattr(self, "_testing_loader"):
-            self._testing_loader = self._build_testing_data_loader()
-        return self._testing_loader
-
-    def _build_testing_data_loader(self) -> DataLoader:
-        dataset = ResNetDataset(image_dir=self.dataset_dir,
-                                annotation_file=self.annotation_file,
-                                mode=DatasetMode.TESTING,
-                                config=self.preprocessor_config)
-        if len(dataset) == 0:
-            return None
-        return DataLoader(dataset=dataset, batch_size=self.batch_size)
-
-    def _build_model(self):
-        self._model: nn.Module = ResNet18()
-        self.labels = list(self.config.id2label.values())
-        self._replace_fc_if_diff(len(self.labels))
-
-        param_file = os.path.join(self.resource_dir, self.config.param_file)
-        with open(param_file, 'rb') as f:
-            state_dict = torch.load(f)
-            if self._model.get_parameter('fc.weight').shape[0] != state_dict['fc.weight'].shape[0]:
-                raise AutoModelError('The fine tuned labels dismatched the parameters.')
-            self._model.load_state_dict(state_dict)
-
-        return self._model.cuda() if self.is_cuda else self._model
-
-    def _replace_fc_if_diff(self, num_classes: int):
-        """Replace the classify layer with new number of classes."""
-        assert (
-            num_classes and isinstance(num_classes, int) and num_classes > 0
-        ), f'Invalid number of classes: {num_classes} .'
-        if num_classes != self.num_classes:
-            self.model.fc = nn.Linear(self.model.layer1[0].expansion * 512, num_classes)
-
-    @property
-    def num_classes(self) -> int:
-        """Return the number of classes of the classification layer of the model."""
-        return self.model.get_parameter('fc.weight').shape[0]
-
-    @property
-    def model(self) -> nn.Module:
-        if not hasattr(self, '_model'):
-            self._model = self._build_model()
-        return self._model
-
-    @property
-    def optimizer(self) -> optim.Optimizer:
-        if not hasattr(self, '_optimizer'):
-            self._optimizer = optim.Adam(self.model.parameters(),
-                                         lr=self.lr,
-                                         betas=(0.9, 0.999),
-                                         weight_decay=5e-4)
-        else:
-            # update lr
-            latest_lr = self.lr
-            for param_group in self._optimizer.param_groups:
-                param_group['lr'] = latest_lr
-        return self._optimizer
-
-    @property
-    def lr(self) -> float:
-        return self._lr * 0.95**((self._epoch - 1) // 5)
-
-    def train(self):
-        self.model.train()
-
-    def eval(self):
-        self.model.eval()
-
-    @overload
-    def forward(self, input: torch.Tensor) -> str:
-        """Predict an image's tensor and give its label."""
-
-    @overload
-    def forward(self, input: str) -> str:
-        """Predict an image defined by a file path and give its label."""
-
-    @torch.no_grad()
-    def forward(self, input):
-        if not input or not isinstance(input, (str, torch.Tensor)):
-            raise AutoModelError(f'Invalid input data: {input}.')
-        if isinstance(input, str):
-            if not os.path.isfile(input):
-                raise AutoModelError(f'Cannot find or access the image file {input}.')
-            preprocessor = ResNetPreprocessor(mode=DatasetMode.PREDICTING,
-                                              config=self.preprocessor_config)
-            input = preprocessor.transform(input)
-            input.unsqueeze_(0)
-        self.model.eval()
-        output: torch.Tensor = self.model(input)
-        predict = output.argmax(1)[0].item()
-        if not self.labels:
-            if not os.path.isfile(os.path.join(self.resource_dir, 'fine_tuned.meta')):
-                raise AutoModel('The `fine_tuned.meta` file is required to make prediction.')
-            with open(os.path.join(self.resource_dir, 'fine_tuned.meta')) as f:
-                fine_tuned_json: dict = json.loads(f)
-                self.labels = fine_tuned_json.get('labels')
-        return self.labels[predict]
-
-    def _train_an_epoch(self):
-        self.train()
-        for images, targets in self.training_loader:
-            if self.is_cuda:
-                images, targets = images.cuda(), targets.cuda()
-            output = self.model(images)
-            output = F.log_softmax(output, dim=-1)
-            loss = F.nll_loss(output, targets)
-            self.optimizer.zero_grad()
-            loss.backward()
-            self.optimizer.step()
-
-    @torch.no_grad()
-    def _run_test(self) -> Tuple[float, float]:
-        """Run a round of test and report the result.
-
-        Return:
-            avg_loss, correct_rate
-        """
-        self.push_log(f'Begin testing of epoch {self._epoch}.')
-        self.eval()
-        total_loss = 0
-        total_correct = 0
-        for images, targets in self.testing_loader:
-            if self.is_cuda:
-                images, targets = images.cuda(), targets.cuda()
-            output = self.model(images)
-            output = F.log_softmax(output, dim=-1)
-            loss = F.nll_loss(output, targets, reduction='sum').item()
-            total_loss += loss
-            pred = output.max(1, keepdim=True)[1]
-            total_correct += pred.eq(targets.view_as(pred)).sum().item()
-
-        avg_loss = total_loss / len(self.testing_loader.dataset)
-        correct_rate = total_correct / len(self.testing_loader.dataset) * 100
-        logger.info(f'Testing Average Loss: {avg_loss:.4f}')
-        logger.info(f'Testing Correct Rate: {correct_rate:.2f}')
-
-        return avg_loss, correct_rate
-
-    @torch.no_grad()
-    def _run_validation(self) -> Tuple[float, float]:
-        """Run a round of validation and report the result.
-
-        Return:
-            avg_loss, correct_rate
-        """
-        self.eval()
-        total_loss = 0
-        total_correct = 0
-        for images, targets in self.validation_loader:
-            if self.is_cuda:
-                images, targets = images.cuda(), targets.cuda()
-            output = self.model(images)
-            output = F.log_softmax(output, dim=-1)
-            loss = F.nll_loss(output, targets, reduction='sum').item()
-            total_loss += loss
-            pred = output.max(1, keepdim=True)[1]
-            total_correct += pred.eq(targets.view_as(pred)).sum().item()
-
-        avg_loss = total_loss / len(self.validation_loader.dataset)
-        correct_rate = total_correct / len(self.validation_loader.dataset) * 100
-        logger.info(f'Validation Average Loss: {avg_loss:.4f}')
-        logger.info(f'Validation Correct Rate: {correct_rate:.2f}')
-        return avg_loss, correct_rate
-
-    @torch.no_grad()
-    def _is_finished(self) -> bool:
-        """Decide if stop training.
-
-        If there are validation dataset, decide depending on validatation results. If
-        the validation result of current epoch is below the best record for 10 continuous
-        times, then stop training.
-        If there are no validation dataset, run for `epochs` times.
-        """
-        if not self.validation_loader or len(self.validation_loader) == 0:
-            if self._epoch >= self.epochs:
-                self._best_state = deepcopy(self.model.state_dict())
-            return self._epoch >= self.epochs
-        # make a validation
-        self.push_log(f'Begin validation of epoch {self._epoch}.')
-        avg_loss, correct_rate = self._run_validation()
-        self.push_log('\n'.join(('Validation result:',
-                                 f'avg_loss={avg_loss:.4f}',
-                                 f'correct_rate={correct_rate:.2f}')))
-
-        if correct_rate > self._best_result:
-            self._overfit_index = 0
-            self._best_result = correct_rate
-            self._best_state = deepcopy(self.model.state_dict())
-            self.push_log('Validation result is better than last epoch.')
-            return self._epoch >= self.epochs
-        else:
-            self._overfit_index += 1
-            msg = f'Validation result gets worse for {self._overfit_index} consecutive times.'
-            self.push_log(msg)
-            return self._overfit_index >= 10 or self._epoch >= self.epochs
-
-    def fine_tune(self,
-                  id: str,
-                  task_id: str,
-                  dataset_dir: str,
-                  is_initiator: bool = False,
-                  is_debug_script: bool = False):
-        self.id = id
-        self.task_id = task_id
-        self.is_initiator = is_initiator
-        self.is_debug_script = is_debug_script
-
-        is_succ, err_msg = self.init_dataset(dataset_dir)
-        if not is_succ:
-            raise AutoModelError(f'Failed to initialize dataset. {err_msg}')
-        num_classes = (len(self.training_loader.dataset.labels)
-                       if self.training_loader
-                       else len(self.testing_loader.dataset.labels))
-        self._replace_fc_if_diff(num_classes)
-
-        self.config.id2label = {str(_idx): _label for _idx, _label in enumerate(self.labels)}
-        self.config.label2id = {_label: _idx for _idx, _label in enumerate(self.labels)}
-        self.config.label2id = dict(sorted(self.config.label2id.items()))
-
-        is_finished = False
-        self._epoch = 0
-        while not is_finished:
-            self._epoch += 1
-            self.push_log(f'Begin training of epoch {self._epoch}.')
-            self._train_an_epoch()
-            self.push_log(f'Complete training of epoch {self._epoch}.')
-            is_finished = self._is_finished()
-
-        self._save_fine_tuned()
-        avg_loss, correct_rate = self._run_test()
-        self.push_log('\n'.join(('Testing result:',
-                                 f'avg_loss={avg_loss:.4f}',
-                                 f'correct_rate={correct_rate:.2f}')))
-
-    def _save_fine_tuned(self):
-        """Save the best or final state of fine tuning."""
-        save_dir = get_result_dir(self.task_id)
-        os.makedirs(save_dir, exist_ok=True)
-        with open(os.path.join(save_dir, self.config.param_file), 'wb') as f:
-            torch.save(self._best_state, f)
-        with open(os.path.join(save_dir, 'config.json'), 'w') as f:
-            f.write(json.dumps(asdict(self.config), ensure_ascii=False))
-
-
-class AutoResNetFedAvg(AutoResNet, AutoFedAvgModel):
-
-    @property
-    def param_file(self) -> str:
-        return self.config.param_file
-
-    @property
-    def init_args_for_fine_tuned(self) -> Optional[str]:
-        return json.dumps({'labels': self.labels}, ensure_ascii=False)
-
-    def state_dict(self) -> Dict[str, torch.Tensor]:
-        return self.model.state_dict()
-
-    def load_state_dict(self, state_dict: Dict[str, torch.Tensor]):
-        return self.model.load_state_dict(state_dict)
-
-    def train_an_epoch(self):
-        self._epoch += 1
-        self._train_an_epoch()
-
-    def run_test(self) -> Tuple[float, float]:
-        """Run a test and report the result.
-
-        Return:
-            avg_loss, correct_rate
-        """
-        return self._run_test()
-
-    def run_validation(self):
-        """Run a test and report the result.
-
-        Return:
-            avg_loss, correct_rate
-        """
-        return self._run_validation()
-
-    def init_dataset(self, dataset_dir: str) -> Tuple[bool, str]:
-        self.dataset_dir = dataset_dir
-        try:
-            if not self._is_dataset_initialized:
-                self.training_loader
-                self.validation_loader
-                self.testing_loader
-                if not self.training_loader and not self.testing_loader:
-                    logger.error('Both training data and testing data are missing.')
-                    err_msg = ' '.join((
-                        'The initiator must provide test dataset.',
-                        'The collaborator must provide train dataset.'
-                    ))
-                    return False, err_msg
-                self.labels = (self.training_loader.dataset.labels
-                               if self.training_loader
-                               else self.testing_loader.dataset.labels)
-                self._is_dataset_initialized = True
-            return True, 'Initializing dataset complete.'
-        except Exception:
-            logger.exception('Failed to initialize dataset.')
-            return False, '初始化数据失败，请联系模型作者排查原因。'
-
-    def fine_tune(self,
-                  id: str,
-                  task_id: str,
-                  dataset_dir: str,
-                  is_initiator: bool = False):
-        is_succ, err_msg = self.init_dataset(dataset_dir)
-        if not is_succ:
-            raise AutoModelError(f'Failed to initialize dataset. {err_msg}')
-        num_classes = (len(self.training_loader.dataset.labels)
-                       if self.training_loader
-                       else len(self.testing_loader.dataset.labels))
-        self._replace_fc_if_diff(num_classes)
-
-        self._fine_tune_impl(id=id,
-                             task_id=task_id,
-                             dataset_dir=dataset_dir,
-                             scheduler_impl=ResNetFedAvgScheduler,
-                             is_initiator=is_initiator,
-                             max_rounds=self.config.epochs,
-                             log_rounds=1)
-
-
-class ResNetFedAvgScheduler(AutoFedAvgScheduler):
-
-    def __init__(self,
-                 auto_proxy: AutoResNetFedAvg,
-                 max_rounds: int = 0,
-                 merge_epochs: int = 1,
-                 calculation_timeout: int = 300,
-                 schedule_timeout: int = 30,
-                 log_rounds: int = 0,
-                 involve_aggregator: bool = False):
-        super().__init__(auto_proxy=auto_proxy,
-                         max_rounds=max_rounds,
-                         merge_epochs=merge_epochs,
-                         calculation_timeout=calculation_timeout,
-                         schedule_timeout=schedule_timeout,
-                         log_rounds=log_rounds,
-                         involve_aggregator=involve_aggregator)
-        self._best_state = None
-        self._best_result = 0
-        self._overfit_index = 0
-
-    @property
-    def best_state_dict(self) -> Dict[str, torch.Tensor]:
-        return self._best_state
-
-    def validate_context(self):
-        super().validate_context()
-        if self.is_initiator:
-            assert self.test_loader and len(self.test_loader) > 0, 'failed to load test data'
-            self.push_log(f'There are {len(self.test_loader.dataset)} samples for testing.')
-        else:
-            assert self.train_loader and len(self.train_loader) > 0, 'failed to load train data'
-            self.push_log(f'There are {len(self.train_loader.dataset)} samples for training.')
-
-    def train_an_epoch(self):
-        self.auto_proxy.train_an_epoch()
-
-    def run_test(self):
-        self.auto_proxy.run_test()
-
-    def is_task_finished(self) -> bool:
-        """Decide if stop training.
-
-        If there are validation dataset, decide depending on validatation results. If
-        the validation result of current epoch is below the best record for 10 continuous
-        times, then stop training.
-        If there are no validation dataset, run for `max_rounds` times.
-        """
-        if not self.validation_loader or len(self.validation_loader) == 0:
-            self._best_state = deepcopy(self.state_dict())
-            return self._is_reach_max_rounds()
-
-        # make a validation
-        self.push_log(f'Begin validation of round {self.current_round}.')
-        avg_loss, correct_rate = self.auto_proxy.run_validation()
-        self.push_log('\n'.join(('Validation result:',
-                                 f'avg_loss={avg_loss:.4f}',
-                                 f'correct_rate={correct_rate:.2f}')))
-
-        if correct_rate > self._best_result:
-            self._overfit_index = 0
-            self._best_result = correct_rate
-            self._best_state = deepcopy(self.state_dict())
-            self.push_log('Validation result is better than last epoch.')
-            return self._is_reach_max_rounds()
-        else:
-            self._overfit_index += 1
-            msg = f'Validation result gets worse for {self._overfit_index} consecutive times.'
-            self.push_log(msg)
-            return self._overfit_index >= 10 or self._is_reach_max_rounds()
+# Copyright 2022 Alphamed
+
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+
+#     http://www.apache.org/licenses/LICENSE-2.0
+
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+"""Pretraining skin_lesion_diagnosis models and schedulers."""
+
+import json
+import os
+from copy import deepcopy
+from dataclasses import InitVar, asdict, dataclass
+from typing import Dict, List, Optional, Tuple, overload
+
+import torch
+import torch.nn.functional as F
+from PIL import Image
+from res_net import ResNet18
+from torch import nn, optim
+from torch.utils.data import DataLoader, Dataset
+from torchvision import transforms
+
+from alphafed import get_result_dir, logger
+from alphafed.auto_ml.auto_model import (AutoFedAvgModel, AutoFedAvgScheduler,
+                                         AutoModel, DatasetMode,
+                                         MandatoryConfig, Preprocessor)
+from alphafed.auto_ml.cvat.annotation import ImageAnnotationUtils
+from alphafed.auto_ml.exceptions import AutoModelError, ConfigError
+
+
+@dataclass
+class PreprocessorConfig:
+
+    size: int
+    do_affine: bool
+    degrees: int
+    translate: Tuple[float]
+    do_horizontal_flip: bool
+    image_mean: List[float]
+    image_std: List[float]
+
+    def __post_init__(self):
+        self.translate = tuple(self.translate)
+
+
+class ResNetPreprocessor(Preprocessor):
+
+    def __init__(self, mode: DatasetMode, config: PreprocessorConfig) -> None:
+        layers = []
+        layers.append(transforms.Resize((config.size, config.size)))
+        if mode == DatasetMode.TRAINING:
+            if config.do_affine:
+                layers.append(transforms.RandomAffine(degrees=config.degrees,
+                                                      translate=config.translate))
+            if config.do_horizontal_flip:
+                layers.append(transforms.RandomHorizontalFlip())
+        layers.append(transforms.ToTensor())
+        layers.append(transforms.Normalize(config.image_mean, config.image_std))
+        self._transformer = transforms.Compose(layers)
+
+    def transform(self, image_file: str) -> torch.Tensor:
+        """Transform an image object into an input tensor."""
+        image = Image.open(image_file).convert('RGB')
+        return self._transformer(image)
+
+
+class ResNetDataset(Dataset):
+
+    def __init__(self,
+                 image_dir: str,
+                 annotation_file: str,
+                 mode: DatasetMode,
+                 config: PreprocessorConfig) -> None:
+        """Init a dataset instance for ResNet auto model families.
+
+        Args:
+            image_dir:
+                The directory including image files.
+            annotation_file:
+                The file including annotation information.
+            mode:
+                One of training or validation or testing.
+            config:
+                The configuration for the preprocessor.
+        """
+        super().__init__()
+        if not image_dir or not isinstance(image_dir, str):
+            raise ConfigError(f'Invalid image directory: {image_dir}.')
+        if not annotation_file or not isinstance(annotation_file, str):
+            raise ConfigError(f'Invalid annotation file path: {annotation_file}.')
+        assert mode and isinstance(mode, DatasetMode), f'Invalid dataset mode: {mode}.'
+        if not os.path.exists(image_dir) or not os.path.isdir(image_dir):
+            raise ConfigError(f'{image_dir} does not exist or is not a directory.')
+        if not os.path.exists(annotation_file) or not os.path.isfile(annotation_file):
+            raise ConfigError(f'{annotation_file} does not exist or is not a file.')
+
+        self.image_dir = image_dir
+        self.annotation_file = annotation_file
+        self.transformer = ResNetPreprocessor(mode=mode, config=config)
+
+        self.images, self.labels = ImageAnnotationUtils.parse_single_category_annotation(
+            annotation_file=self.annotation_file, resource_dir=image_dir, mode=mode
+        )
+
+    def __getitem__(self, index: int):
+        _item = self.images[index]
+        return self.transformer(_item.image_file), _item.class_label
+
+    def __len__(self):
+        return len(self.images)
+
+
+@dataclass
+class ModelConfig(MandatoryConfig):
+
+    id2label: dict
+    label2id: dict
+    learning_rate: int
+    batch_size: int
+    epochs: int
+    image_size: int = 224
+    torch_dtype: InitVar[str] = 'float32'
+
+    def __post_init__(self, torch_dtype: str):
+        super().__post_init__()
+
+        for _label in self.id2label.values():
+            if _label not in self.label2id:
+                raise TypeError(f'Label `{_label}` lost its ID in label2id map.')
+        for _id in self.label2id.values():
+            if str(_id) not in self.id2label:
+                raise TypeError(f'ID `{_id}` lost its label in id2label map.')
+
+        if self.learning_rate <= 0:
+            raise TypeError(f'Invalid learning_rate: `{self.learning_rate}`.')
+        if self.batch_size <= 0:
+            raise TypeError(f'Invalid batch_size: `{self.batch_size}`.')
+        if self.epochs <= 0:
+            raise TypeError(f'Invalid epochs: `{self.epochs}`.')
+
+        if self.image_size <= 0:
+            raise TypeError(f'Invalid image_size: `{self.image_size}`.')
+
+        if torch_dtype == 'float32' or torch_dtype == 'float':
+            self.torch_dtype = torch.float32
+        elif torch_dtype == 'float64':
+            self.torch_dtype = torch.float64
+        elif torch == 'float16':
+            self.torch_dtype = torch.float16
+        else:
+            raise TypeError(f'Invalid torch_dtype: `{torch_dtype}`.')
+
+
+class AutoResNet(AutoModel):
+
+    def __init__(self, resource_dir: str, **kwargs) -> None:
+        super().__init__(resource_dir=resource_dir)
+
+        self.config, self.preprocessor_config = self._load_config()
+        self.epochs = self.config.epochs
+        self.batch_size = self.config.batch_size
+        self._lr = self.config.learning_rate
+        self._epoch = 0
+        # 测试部署服务暂时不支持 GPU 环境，使用 GPU 版本会导致部署失败
+        # self.is_cuda = torch.cuda.is_available()
+        self.is_cuda = False
+
+        self.dataset_dir = None
+        self.labels = None
+
+        self._best_result = 0
+        self._best_state = None
+        self._overfit_index = 0
+        self._is_dataset_initialized = False
+        self._save_root = '.cache'
+
+    def _load_config(self) -> Tuple[ModelConfig, PreprocessorConfig]:
+        config_file = os.path.join(self.resource_dir, 'config.json')
+        if not os.path.isfile(config_file):
+            raise ConfigError('Config file missing.')
+        try:
+            with open(config_file, 'r') as f:
+                config_json = json.load(f)
+        except json.JSONDecodeError:
+            raise ConfigError('Failed to parse config file.')
+        model_config = ModelConfig(**config_json)
+
+        preprocessor_config_file = os.path.join(self.resource_dir, 'preprocessor_config.json')
+        if not os.path.isfile(preprocessor_config_file):
+            raise ConfigError('Preprocessor config file missing.')
+        try:
+            with open(preprocessor_config_file, 'r') as f:
+                preprocessor_config_json = json.load(f)
+        except json.JSONDecodeError:
+            raise ConfigError('Failed to parse preprocessor config file.')
+        preprocessor_config = PreprocessorConfig(**preprocessor_config_json)
+
+        return model_config, preprocessor_config
+
+    @property
+    def annotation_file(self):
+        return os.path.join(self.dataset_dir, 'annotation.json') if self.dataset_dir else None
+
+    def init_dataset(self, dataset_dir: str) -> Tuple[bool, str]:
+        self.dataset_dir = dataset_dir
+        try:
+            if not self._is_dataset_initialized:
+                self.training_loader
+                self.validation_loader
+                self.testing_loader
+                if not self.training_loader or not self.testing_loader:
+                    logger.error('Both training data and testing data are missing.')
+                    return False, 'Must provide train dataset and test dataset to fine tune.'
+                self.labels = (self.training_loader.dataset.labels
+                               if self.training_loader
+                               else self.testing_loader.dataset.labels)
+                self._is_dataset_initialized = True
+            return True, 'Initializing dataset complete.'
+        except Exception:
+            logger.exception('Failed to initialize dataset.')
+            return False, '初始化数据失败，请联系模型作者排查原因。'
+
+    @property
+    def training_loader(self) -> DataLoader:
+        """Return a dataloader instance of training data.
+
+        Data augmentation is used to improve performance, so we need to generate a new dataset
+        every epoch in case of training on a same dataset over and over again.
+        """
+        if not hasattr(self, "_training_loader"):
+            self._training_loader = self._build_training_data_loader()
+        return self._training_loader
+
+    def _build_training_data_loader(self) -> Optional[DataLoader]:
+        dataset = ResNetDataset(image_dir=self.dataset_dir,
+                                annotation_file=self.annotation_file,
+                                mode=DatasetMode.TRAINING,
+                                config=self.preprocessor_config)
+        if len(dataset) == 0:
+            return None
+        return DataLoader(dataset=dataset,
+                          batch_size=self.batch_size,
+                          shuffle=True)
+
+    @property
+    def validation_loader(self) -> DataLoader:
+        """Return a dataloader instance of validation data."""
+        if not hasattr(self, "_validation_loader"):
+            self._validation_loader = self._build_validation_data_loader()
+        return self._validation_loader
+
+    def _build_validation_data_loader(self) -> DataLoader:
+        dataset = ResNetDataset(image_dir=self.dataset_dir,
+                                annotation_file=self.annotation_file,
+                                mode=DatasetMode.VALIDATION,
+                                config=self.preprocessor_config)
+        if len(dataset) == 0:
+            return None
+        return DataLoader(dataset=dataset, batch_size=self.batch_size)
+
+    @property
+    def testing_loader(self) -> DataLoader:
+        """Return a dataloader instance of testing data."""
+        if not hasattr(self, "_testing_loader"):
+            self._testing_loader = self._build_testing_data_loader()
+        return self._testing_loader
+
+    def _build_testing_data_loader(self) -> DataLoader:
+        dataset = ResNetDataset(image_dir=self.dataset_dir,
+                                annotation_file=self.annotation_file,
+                                mode=DatasetMode.TESTING,
+                                config=self.preprocessor_config)
+        if len(dataset) == 0:
+            return None
+        return DataLoader(dataset=dataset, batch_size=self.batch_size)
+
+    def _build_model(self):
+        self._model: nn.Module = ResNet18()
+        self.labels = list(self.config.id2label.values())
+        self._replace_fc_if_diff(len(self.labels))
+
+        param_file = os.path.join(self.resource_dir, self.config.param_file)
+        with open(param_file, 'rb') as f:
+            state_dict = torch.load(f)
+            if self._model.get_parameter('fc.weight').shape[0] != state_dict['fc.weight'].shape[0]:
+                raise AutoModelError('The fine tuned labels dismatched the parameters.')
+            self._model.load_state_dict(state_dict)
+
+        return self._model.cuda() if self.is_cuda else self._model
+
+    def _replace_fc_if_diff(self, num_classes: int):
+        """Replace the classify layer with new number of classes."""
+        assert (
+            num_classes and isinstance(num_classes, int) and num_classes > 0
+        ), f'Invalid number of classes: {num_classes} .'
+        if num_classes != self.num_classes:
+            self.model.fc = nn.Linear(self.model.layer1[0].expansion * 512, num_classes)
+
+    @property
+    def num_classes(self) -> int:
+        """Return the number of classes of the classification layer of the model."""
+        return self.model.get_parameter('fc.weight').shape[0]
+
+    @property
+    def model(self) -> nn.Module:
+        if not hasattr(self, '_model'):
+            self._model = self._build_model()
+        return self._model
+
+    @property
+    def optimizer(self) -> optim.Optimizer:
+        if not hasattr(self, '_optimizer'):
+            self._optimizer = optim.Adam(self.model.parameters(),
+                                         lr=self.lr,
+                                         betas=(0.9, 0.999),
+                                         weight_decay=5e-4)
+        else:
+            # update lr
+            latest_lr = self.lr
+            for param_group in self._optimizer.param_groups:
+                param_group['lr'] = latest_lr
+        return self._optimizer
+
+    @property
+    def lr(self) -> float:
+        return self._lr * 0.95**((self._epoch - 1) // 5)
+
+    def train(self):
+        self.model.train()
+
+    def eval(self):
+        self.model.eval()
+
+    @overload
+    def forward(self, input: torch.Tensor) -> str:
+        """Predict an image's tensor and give its label."""
+
+    @overload
+    def forward(self, input: str) -> str:
+        """Predict an image defined by a file path and give its label."""
+
+    @torch.no_grad()
+    def forward(self, input):
+        if not input or not isinstance(input, (str, torch.Tensor)):
+            raise AutoModelError(f'Invalid input data: {input}.')
+        if isinstance(input, str):
+            if not os.path.isfile(input):
+                raise AutoModelError(f'Cannot find or access the image file {input}.')
+            preprocessor = ResNetPreprocessor(mode=DatasetMode.PREDICTING,
+                                              config=self.preprocessor_config)
+            input = preprocessor.transform(input)
+            input.unsqueeze_(0)
+        self.model.eval()
+        output: torch.Tensor = self.model(input)
+        predict = output.argmax(1)[0].item()
+        if not self.labels:
+            if not os.path.isfile(os.path.join(self.resource_dir, 'fine_tuned.meta')):
+                raise AutoModel('The `fine_tuned.meta` file is required to make prediction.')
+            with open(os.path.join(self.resource_dir, 'fine_tuned.meta')) as f:
+                fine_tuned_json: dict = json.loads(f)
+                self.labels = fine_tuned_json.get('labels')
+        return self.labels[predict]
+
+    def _train_an_epoch(self):
+        self.train()
+        for images, targets in self.training_loader:
+            if self.is_cuda:
+                images, targets = images.cuda(), targets.cuda()
+            output = self.model(images)
+            output = F.log_softmax(output, dim=-1)
+            loss = F.nll_loss(output, targets)
+            self.optimizer.zero_grad()
+            loss.backward()
+            self.optimizer.step()
+
+    @torch.no_grad()
+    def _run_test(self) -> Tuple[float, float]:
+        """Run a round of test and report the result.
+
+        Return:
+            avg_loss, correct_rate
+        """
+        self.push_log(f'Begin testing of epoch {self._epoch}.')
+        self.eval()
+        total_loss = 0
+        total_correct = 0
+        for images, targets in self.testing_loader:
+            if self.is_cuda:
+                images, targets = images.cuda(), targets.cuda()
+            output = self.model(images)
+            output = F.log_softmax(output, dim=-1)
+            loss = F.nll_loss(output, targets, reduction='sum').item()
+            total_loss += loss
+            pred = output.max(1, keepdim=True)[1]
+            total_correct += pred.eq(targets.view_as(pred)).sum().item()
+
+        avg_loss = total_loss / len(self.testing_loader.dataset)
+        correct_rate = total_correct / len(self.testing_loader.dataset) * 100
+        logger.info(f'Testing Average Loss: {avg_loss:.4f}')
+        logger.info(f'Testing Correct Rate: {correct_rate:.2f}')
+
+        return avg_loss, correct_rate
+
+    @torch.no_grad()
+    def _run_validation(self) -> Tuple[float, float]:
+        """Run a round of validation and report the result.
+
+        Return:
+            avg_loss, correct_rate
+        """
+        self.eval()
+        total_loss = 0
+        total_correct = 0
+        for images, targets in self.validation_loader:
+            if self.is_cuda:
+                images, targets = images.cuda(), targets.cuda()
+            output = self.model(images)
+            output = F.log_softmax(output, dim=-1)
+            loss = F.nll_loss(output, targets, reduction='sum').item()
+            total_loss += loss
+            pred = output.max(1, keepdim=True)[1]
+            total_correct += pred.eq(targets.view_as(pred)).sum().item()
+
+        avg_loss = total_loss / len(self.validation_loader.dataset)
+        correct_rate = total_correct / len(self.validation_loader.dataset) * 100
+        logger.info(f'Validation Average Loss: {avg_loss:.4f}')
+        logger.info(f'Validation Correct Rate: {correct_rate:.2f}')
+        return avg_loss, correct_rate
+
+    @torch.no_grad()
+    def _is_finished(self) -> bool:
+        """Decide if stop training.
+
+        If there are validation dataset, decide depending on validatation results. If
+        the validation result of current epoch is below the best record for 10 continuous
+        times, then stop training.
+        If there are no validation dataset, run for `epochs` times.
+        """
+        if not self.validation_loader or len(self.validation_loader) == 0:
+            if self._epoch >= self.epochs:
+                self._best_state = deepcopy(self.model.state_dict())
+            return self._epoch >= self.epochs
+        # make a validation
+        self.push_log(f'Begin validation of epoch {self._epoch}.')
+        avg_loss, correct_rate = self._run_validation()
+        self.push_log('\n'.join(('Validation result:',
+                                 f'avg_loss={avg_loss:.4f}',
+                                 f'correct_rate={correct_rate:.2f}')))
+
+        if correct_rate > self._best_result:
+            self._overfit_index = 0
+            self._best_result = correct_rate
+            self._best_state = deepcopy(self.model.state_dict())
+            self.push_log('Validation result is better than last epoch.')
+            return self._epoch >= self.epochs
+        else:
+            self._overfit_index += 1
+            msg = f'Validation result gets worse for {self._overfit_index} consecutive times.'
+            self.push_log(msg)
+            return self._overfit_index >= 10 or self._epoch >= self.epochs
+
+    def fine_tune(self,
+                  id: str,
+                  task_id: str,
+                  dataset_dir: str,
+                  is_initiator: bool = False,
+                  is_debug_script: bool = False):
+        self.id = id
+        self.task_id = task_id
+        self.is_initiator = is_initiator
+        self.is_debug_script = is_debug_script
+
+        is_succ, err_msg = self.init_dataset(dataset_dir)
+        if not is_succ:
+            raise AutoModelError(f'Failed to initialize dataset. {err_msg}')
+        num_classes = (len(self.training_loader.dataset.labels)
+                       if self.training_loader
+                       else len(self.testing_loader.dataset.labels))
+        self._replace_fc_if_diff(num_classes)
+
+        self.config.id2label = {str(_idx): _label for _idx, _label in enumerate(self.labels)}
+        self.config.label2id = {_label: _idx for _idx, _label in enumerate(self.labels)}
+        self.config.label2id = dict(sorted(self.config.label2id.items()))
+
+        is_finished = False
+        self._epoch = 0
+        while not is_finished:
+            self._epoch += 1
+            self.push_log(f'Begin training of epoch {self._epoch}.')
+            self._train_an_epoch()
+            self.push_log(f'Complete training of epoch {self._epoch}.')
+            is_finished = self._is_finished()
+
+        self._save_fine_tuned()
+        avg_loss, correct_rate = self._run_test()
+        self.push_log('\n'.join(('Testing result:',
+                                 f'avg_loss={avg_loss:.4f}',
+                                 f'correct_rate={correct_rate:.2f}')))
+
+    def _save_fine_tuned(self):
+        """Save the best or final state of fine tuning."""
+        save_dir = get_result_dir(self.task_id)
+        os.makedirs(save_dir, exist_ok=True)
+        with open(os.path.join(save_dir, self.config.param_file), 'wb') as f:
+            torch.save(self._best_state, f)
+        with open(os.path.join(save_dir, 'config.json'), 'w') as f:
+            f.write(json.dumps(asdict(self.config), ensure_ascii=False))
+
+
+class AutoResNetFedAvg(AutoResNet, AutoFedAvgModel):
+
+    @property
+    def param_file(self) -> str:
+        return self.config.param_file
+
+    @property
+    def init_args_for_fine_tuned(self) -> Optional[str]:
+        return json.dumps({'labels': self.labels}, ensure_ascii=False)
+
+    def state_dict(self) -> Dict[str, torch.Tensor]:
+        return self.model.state_dict()
+
+    def load_state_dict(self, state_dict: Dict[str, torch.Tensor]):
+        return self.model.load_state_dict(state_dict)
+
+    def train_an_epoch(self):
+        self._epoch += 1
+        self._train_an_epoch()
+
+    def run_test(self) -> Tuple[float, float]:
+        """Run a test and report the result.
+
+        Return:
+            avg_loss, correct_rate
+        """
+        return self._run_test()
+
+    def run_validation(self):
+        """Run a test and report the result.
+
+        Return:
+            avg_loss, correct_rate
+        """
+        return self._run_validation()
+
+    def init_dataset(self, dataset_dir: str) -> Tuple[bool, str]:
+        self.dataset_dir = dataset_dir
+        try:
+            if not self._is_dataset_initialized:
+                self.training_loader
+                self.validation_loader
+                self.testing_loader
+                if not self.training_loader and not self.testing_loader:
+                    logger.error('Both training data and testing data are missing.')
+                    err_msg = ' '.join((
+                        'The initiator must provide test dataset.',
+                        'The collaborator must provide train dataset.'
+                    ))
+                    return False, err_msg
+                self.labels = (self.training_loader.dataset.labels
+                               if self.training_loader
+                               else self.testing_loader.dataset.labels)
+                self._is_dataset_initialized = True
+            return True, 'Initializing dataset complete.'
+        except Exception:
+            logger.exception('Failed to initialize dataset.')
+            return False, '初始化数据失败，请联系模型作者排查原因。'
+
+    def fine_tune(self,
+                  id: str,
+                  task_id: str,
+                  dataset_dir: str,
+                  is_initiator: bool = False):
+        is_succ, err_msg = self.init_dataset(dataset_dir)
+        if not is_succ:
+            raise AutoModelError(f'Failed to initialize dataset. {err_msg}')
+        num_classes = (len(self.training_loader.dataset.labels)
+                       if self.training_loader
+                       else len(self.testing_loader.dataset.labels))
+        self._replace_fc_if_diff(num_classes)
+
+        self._fine_tune_impl(id=id,
+                             task_id=task_id,
+                             dataset_dir=dataset_dir,
+                             scheduler_impl=ResNetFedAvgScheduler,
+                             is_initiator=is_initiator,
+                             max_rounds=self.config.epochs,
+                             log_rounds=1)
+
+
+class ResNetFedAvgScheduler(AutoFedAvgScheduler):
+
+    def __init__(self,
+                 auto_proxy: AutoResNetFedAvg,
+                 max_rounds: int = 0,
+                 merge_epochs: int = 1,
+                 calculation_timeout: int = 300,
+                 schedule_timeout: int = 30,
+                 log_rounds: int = 0,
+                 involve_aggregator: bool = False):
+        super().__init__(auto_proxy=auto_proxy,
+                         max_rounds=max_rounds,
+                         merge_epochs=merge_epochs,
+                         calculation_timeout=calculation_timeout,
+                         schedule_timeout=schedule_timeout,
+                         log_rounds=log_rounds,
+                         involve_aggregator=involve_aggregator)
+        self._best_state = None
+        self._best_result = 0
+        self._overfit_index = 0
+
+    @property
+    def best_state_dict(self) -> Dict[str, torch.Tensor]:
+        return self._best_state
+
+    def validate_context(self):
+        super().validate_context()
+        if self.is_initiator:
+            assert self.test_loader and len(self.test_loader) > 0, 'failed to load test data'
+            self.push_log(f'There are {len(self.test_loader.dataset)} samples for testing.')
+        else:
+            assert self.train_loader and len(self.train_loader) > 0, 'failed to load train data'
+            self.push_log(f'There are {len(self.train_loader.dataset)} samples for training.')
+
+    def train_an_epoch(self):
+        self.auto_proxy.train_an_epoch()
+
+    def run_test(self):
+        self.auto_proxy.run_test()
+
+    def is_task_finished(self) -> bool:
+        """Decide if stop training.
+
+        If there are validation dataset, decide depending on validatation results. If
+        the validation result of current epoch is below the best record for 10 continuous
+        times, then stop training.
+        If there are no validation dataset, run for `max_rounds` times.
+        """
+        if not self.validation_loader or len(self.validation_loader) == 0:
+            self._best_state = deepcopy(self.state_dict())
+            return self._is_reach_max_rounds()
+
+        # make a validation
+        self.push_log(f'Begin validation of round {self.current_round}.')
+        avg_loss, correct_rate = self.auto_proxy.run_validation()
+        self.push_log('\n'.join(('Validation result:',
+                                 f'avg_loss={avg_loss:.4f}',
+                                 f'correct_rate={correct_rate:.2f}')))
+
+        if correct_rate > self._best_result:
+            self._overfit_index = 0
+            self._best_result = correct_rate
+            self._best_state = deepcopy(self.state_dict())
+            self.push_log('Validation result is better than last epoch.')
+            return self._is_reach_max_rounds()
+        else:
+            self._overfit_index += 1
+            msg = f'Validation result gets worse for {self._overfit_index} consecutive times.'
+            self.push_log(msg)
+            return self._overfit_index >= 10 or self._is_reach_max_rounds()
```

### Comparing `alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/skin_lesion_diagnosis/res_local/res_net.py` & `alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/skin_lesion_diagnosis/res_local/res_net.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/skin_lesion_diagnosis/run_aggregator.py` & `alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/skin_lesion_diagnosis/run_aggregator.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/skin_lesion_diagnosis/run_data_owner_2.py` & `alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/skin_lesion_diagnosis/run_data_owner_2.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/examples/auto_ml/skin_lesion_diagnosis/run_data_owner_4.py` & `alphamed-federated-0.4.9/src/alphafed/examples/auto_ml/skin_lesion_diagnosis/run_data_owner_4.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/examples/data_channel/__init__.py` & `alphamed-federated-0.4.9/src/alphafed/examples/data_channel/__init__.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/examples/data_channel/run_receiver_2.py` & `alphamed-federated-0.4.9/src/alphafed/examples/data_channel/run_receiver_2.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/examples/data_channel/run_receiver_4.py` & `alphamed-federated-0.4.9/src/alphafed/examples/data_channel/run_receiver_4.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/examples/data_channel/run_sender.py` & `alphamed-federated-0.4.9/src/alphafed/examples/data_channel/run_sender.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/examples/fed_avg/__init__.py` & `alphamed-federated-0.4.9/src/alphafed/examples/fed_avg/__init__.py`

 * *Ordering differences only*

 * *Files 12% similar despite different names*

```diff
@@ -1,16 +1,16 @@
-# CPU mode
-DEV_TASK_ID = 'd041d19f-59d0-467f-bc6c-7f5cf42436c2'
-
-AGGREGATOR_ID = 'QmXLxxW7W1cxdU7eeeq5yRXte53zekxiTRApSWxxssdzQP'
-DATA_OWNER_2_ID = 'QmUXV1ds7mNfZ5udaLauubMC5ve4mGpuwS6sTy6Keh2VJN'
-DATA_OWNER_3_ID = 'QmXG7aTnKk1AcLhKmauCkYpYafoxj1dG5xLBnCQNniuaeF'
-DATA_OWNER_4_ID = 'QmfFQ1CDXU8kYGMSkqPGqMw7NfnjGsfr3jPU9GbSBY4P3J'
-DATA_OWNER_5_ID = 'QmYX5KatFyFve3xVjadX2h7fEt1SzpdA8wnQsQ4v9muCyR'
-
-# GPU mode
-# DEV_TASK_ID = '45b0eb180eb34ba7a77f6df36fbf9e1b'
-
-# AGGREGATOR_ID = 'QmQERKLbhy2bbhWA6eSd4ENpr37BA7G3xzbm6BJqsERJ58'
-# DATA_OWNER_3_ID = 'QmPUhKyCbQ7V73gMNVUaGVnqsVbkNFxSotS7pEEFD8X1SP'
-# DATA_OWNER_4_ID = 'QmScck6og9ZRqeSKTqUpe4Phub45mxFeUHGysV2DWCouEg'
-# DATA_OWNER_5_ID = 'QmNwzJAbWSkcjdi2PS1wGCgbnZAxEdiwDtF8ZPVBn9EFGq'
+# CPU mode
+DEV_TASK_ID = 'd041d19f-59d0-467f-bc6c-7f5cf42436c2'
+
+AGGREGATOR_ID = 'QmXLxxW7W1cxdU7eeeq5yRXte53zekxiTRApSWxxssdzQP'
+DATA_OWNER_2_ID = 'QmUXV1ds7mNfZ5udaLauubMC5ve4mGpuwS6sTy6Keh2VJN'
+DATA_OWNER_3_ID = 'QmXG7aTnKk1AcLhKmauCkYpYafoxj1dG5xLBnCQNniuaeF'
+DATA_OWNER_4_ID = 'QmfFQ1CDXU8kYGMSkqPGqMw7NfnjGsfr3jPU9GbSBY4P3J'
+DATA_OWNER_5_ID = 'QmYX5KatFyFve3xVjadX2h7fEt1SzpdA8wnQsQ4v9muCyR'
+
+# GPU mode
+# DEV_TASK_ID = '45b0eb180eb34ba7a77f6df36fbf9e1b'
+
+# AGGREGATOR_ID = 'QmQERKLbhy2bbhWA6eSd4ENpr37BA7G3xzbm6BJqsERJ58'
+# DATA_OWNER_3_ID = 'QmPUhKyCbQ7V73gMNVUaGVnqsVbkNFxSotS7pEEFD8X1SP'
+# DATA_OWNER_4_ID = 'QmScck6og9ZRqeSKTqUpe4Phub45mxFeUHGysV2DWCouEg'
+# DATA_OWNER_5_ID = 'QmNwzJAbWSkcjdi2PS1wGCgbnZAxEdiwDtF8ZPVBn9EFGq'
```

### Comparing `alphamed-federated-0.4.7/src/alphafed/examples/fed_avg/demos.py` & `alphamed-federated-0.4.9/src/alphafed/examples/hetero_nn/demos.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,151 +1,186 @@
-"""Process demo."""
+"""HeteroNN demos."""
 
 import os
+from hashlib import md5
 from time import time
+from typing import Dict, List, Set, Tuple, Union
 
+import cloudpickle as pickle
 import torch
 import torch.nn as nn
 import torch.nn.functional as F
+import torch.optim as optim
 import torchvision
-from torch import optim
-from torch.utils.data import DataLoader
+from torch.utils.data import DataLoader, Subset
 
-from ... import get_dataset_dir, logger
-from ...fed_avg import FedAvgScheduler, FedSGDScheduler, SecureFedAvgScheduler
-from ...fed_avg.dp_fed_avg import DPFedAvgScheduler
+from ... import logger
+from ...hetero_nn import (HeteroNNCollaboratorScheduler, HeteroNNHostScheduler,
+                          SecureHeteroNNCollaboratorScheduler,
+                          SecureHeteroNNHostScheduler)
 from . import DEV_TASK_ID
-from .demo_FedIRM import DemoFedIRM
 
 CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
 
+_DATA_DIR = os.path.join(CURRENT_DIR, 'data')
 
 VANILLA = 'vanilla'
-SGD = 'sgd'
-DP = 'dp'
 SECURE = 'secure'
-FED_IRM = 'fedirm'
+
+torch.manual_seed(42)
 
 
 class ConvNet(nn.Module):
     def __init__(self) -> None:
         super().__init__()
-        self.conv1 = nn.Conv2d(in_channels=1, out_channels=10, kernel_size=5)
+        self.conv1 = nn.Conv2d(in_channels=1, out_channels=10, kernel_size=(5, 3))
         self.conv2 = nn.Conv2d(in_channels=10, out_channels=20, kernel_size=5)
         self.conv2_drop = nn.Dropout2d()
-        self.fc1 = nn.Linear(in_features=320, out_features=50)
+        self.fc1 = nn.Linear(in_features=80, out_features=50)
         self.fc2 = nn.Linear(in_features=50, out_features=10)
 
     def forward(self, x):
         x = F.relu(F.max_pool2d(self.conv1(x), 2))
         x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))
-        x = x.view(-1, 320)
+        x = x.view(-1, 80)
         x = F.relu(self.fc1(x))
         x = F.dropout(x, training=self.training)
-        x = self.fc2(x)
-        return F.log_softmax(x, dim=-1)
+        return self.fc2(x)
+
+
+class InferModule(nn.Module):
+
+    def __init__(self) -> None:
+        super().__init__()
+        self.fc1 = nn.Linear(20, 20)
+        self.fc2 = nn.Linear(20, 10)
 
+    def forward(self, input):
+        out = F.relu(self.fc1(input))
+        out = self.fc2(out)
+        return F.log_softmax(out, dim=-1)
 
-class DemoAvg(FedAvgScheduler):
+
+class DemoHeteroHost(HeteroNNHostScheduler):
 
     def __init__(self,
+                 feature_key: str,
+                 batch_size: int,
+                 data_dir: str,
                  max_rounds: int = 0,
-                 merge_epochs: int = 1,
                  calculation_timeout: int = 300,
-                 log_rounds: int = 0,
-                 involve_aggregator: bool = False,
-                 batch_size: int = 128,
-                 learning_rate: float = 0.01,
-                 momentum: float = 0.9) -> None:
-        super().__init__(max_rounds=max_rounds,
-                         merge_epochs=merge_epochs,
+                 schedule_timeout: int = 30,
+                 log_rounds: int = 0) -> None:
+        super().__init__(feature_key=feature_key,
+                         max_rounds=max_rounds,
                          calculation_timeout=calculation_timeout,
-                         log_rounds=log_rounds,
-                         involve_aggregator=involve_aggregator)
+                         schedule_timeout=schedule_timeout,
+                         log_rounds=log_rounds)
         self.batch_size = batch_size
-        self.learning_rate = learning_rate
-        self.momentum = momentum
+        self.data_dir = data_dir
 
-        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
-        self.seed = 42
-        torch.manual_seed(self.seed)
-
-    def build_model(self) -> nn.Module:
-        model = ConvNet()
-        return model.to(self.device)
-
-    def build_optimizer(self, model: nn.Module) -> optim.Optimizer:
-        assert self.model, 'must initialize model first'
-        return optim.SGD(model.parameters(),
-                         lr=self.learning_rate,
-                         momentum=self.momentum)
-
-    def build_train_dataloader(self) -> DataLoader:
-        return DataLoader(
-            torchvision.datasets.MNIST(
-                get_dataset_dir(self.task_id),
-                train=True,
-                download=True,
-                transform=torchvision.transforms.Compose([
-                    torchvision.transforms.ToTensor(),
-                    torchvision.transforms.Normalize((0.1307,), (0.3081,))
-                ])
-            ),
-            batch_size=self.batch_size,
-            shuffle=True
+    def load_local_ids(self) -> List[str]:
+        train_ids = [str(i) for i in range(0, 20000)]
+        test_ids = [str(i) for i in range(100000, 105000)]
+        return train_ids + test_ids
+
+    def split_dataset(self, id_intersection: Set[str]) -> Tuple[Set[str], Set[str]]:
+        ids = [int(_id) for _id in id_intersection]
+        ids.sort()
+        train_ids = ids[:10000]
+        test_ids = ids[10000:]
+
+        logger.info(f'Got {len(train_ids)} intersecting samples for training.')
+        logger.info(f'Got {len(test_ids)} intersecting samples for testing.')
+
+        return set(train_ids), set(test_ids)
+
+    def build_feature_model(self) -> nn.Module:
+        return ConvNet()
+
+    def build_feature_optimizer(self, feature_model: nn.Module) -> optim.Optimizer:
+        return optim.SGD(feature_model.parameters(), lr=0.01, momentum=0.9)
+
+    def _erase_right(self, _image: torch.Tensor) -> torch.Tensor:
+        return _image[:, :, :, :14]
+
+    def iterate_train_feature(self,
+                              feature_model: nn.Module,
+                              train_ids: Set[str]) -> Tuple[torch.Tensor, torch.Tensor]:
+        train_dataset = torchvision.datasets.MNIST(
+            self.data_dir,
+            train=True,
+            download=True,
+            transform=torchvision.transforms.Compose([
+                torchvision.transforms.ToTensor(),
+                torchvision.transforms.Normalize((0.1307,), (0.3081,))
+            ])
         )
+        train_ids: List = list(train_ids)
+        train_ids.sort(key=lambda x: md5(bytes(x + self.current_round)).digest())
 
-    def build_test_dataloader(self) -> DataLoader:
-        return DataLoader(
-            torchvision.datasets.MNIST(
-                get_dataset_dir(self.task_id),
-                train=False,
-                download=True,
-                transform=torchvision.transforms.Compose([
-                    torchvision.transforms.ToTensor(),
-                    torchvision.transforms.Normalize((0.1307,), (0.3081,))
-                ])
-            ),
-            batch_size=self.batch_size,
-            shuffle=False
+        train_dataset = Subset(train_dataset, train_ids)
+        self.train_loader = DataLoader(train_dataset,
+                                       batch_size=self.batch_size,
+                                       shuffle=False)
+
+        for _data, _labels in self.train_loader:
+            _data = self._erase_right(_data)
+            yield feature_model(_data), _labels
+
+    def iterate_test_feature(self,
+                             feature_model: nn.Module,
+                             test_ids: Set[str]) -> Tuple[torch.Tensor, torch.Tensor]:
+        test_dataset = torchvision.datasets.MNIST(
+            self.data_dir,
+            train=False,
+            download=True,
+            transform=torchvision.transforms.Compose([
+                torchvision.transforms.ToTensor(),
+                torchvision.transforms.Normalize((0.1307,), (0.3081,))
+            ])
         )
+        test_ids = [(i - 100000) for i in test_ids]
+        test_dataset = Subset(test_dataset, test_ids)
+        self.test_loader = DataLoader(test_dataset,
+                                      batch_size=self.batch_size,
+                                      shuffle=False)
+
+        for _data, _labels in self.test_loader:
+            _data = self._erase_right(_data)
+            yield feature_model(_data), _labels
+
+    def build_infer_model(self) -> nn.Module:
+        return InferModule()
+
+    def build_infer_optimizer(self, infer_model: nn.Module) -> optim.Optimizer:
+        return optim.SGD(infer_model.parameters(), lr=0.01, momentum=0.9)
+
+    def train_a_batch(self, feature_projection: Dict[str, torch.Tensor], labels: torch.Tensor):
+        fusion_tensor = torch.concat((feature_projection['demo_host'],
+                                      feature_projection['demo_collaborator']), dim=1)
+        self.optimizer.zero_grad()
+        out = self.infer_model(fusion_tensor)
+        loss = F.nll_loss(out, labels)
+        loss.backward()
+        self.optimizer.step()
 
-    def validate_context(self):
-        super().validate_context()
-        assert self.train_loader and len(self.train_loader) > 0, 'failed to load train data'
-        logger.info(f'There are {len(self.train_loader.dataset)} samples for training.')
-        assert self.test_loader and len(self.test_loader) > 0, 'failed to load test data'
-        logger.info(f'There are {len(self.test_loader.dataset)} samples for testing.')
-
-    def train_an_epoch(self) -> None:
-        self.model.train()
-        for data, labels in self.train_loader:
-            data: torch.Tensor
-            labels: torch.Tensor
-            data, labels = data.to(self.device), labels.to(self.device)
-            self.optimizer.zero_grad()
-            output = self.model(data)
-            loss = F.nll_loss(output, labels)
-            loss.backward()
-            self.optimizer.step()
-
-    def run_test(self):
+    def run_test(self,
+                 batched_feature_projections: List[torch.Tensor],
+                 batched_labels: List[torch.Tensor]):
         start = time()
-        self.model.eval()
         test_loss = 0
         correct = 0
-        with torch.no_grad():
-            for data, labels in self.test_loader:
-                data: torch.Tensor
-                labels: torch.Tensor
-                data, labels = data.to(self.device), labels.to(self.device)
-                output: torch.Tensor = self.model(data)
-                test_loss += F.nll_loss(output, labels, reduction='sum').item()
-                pred = output.max(1, keepdim=True)[1]
-                correct += pred.eq(labels.view_as(pred)).sum().item()
+        for _feature_projection, _lables in zip(batched_feature_projections, batched_labels):
+            fusion_tensor = torch.concat((_feature_projection['demo_host'],
+                                          _feature_projection['demo_collaborator']), dim=1)
+            out: torch.Tensor = self.infer_model(fusion_tensor)
+            test_loss += F.nll_loss(out, _lables)
+            pred = out.max(1, keepdim=True)[1]
+            correct += pred.eq(_lables.view_as(pred)).sum().item()
 
         test_loss /= len(self.test_loader.dataset)
         accuracy = correct / len(self.test_loader.dataset)
         correct_rate = 100. * accuracy
         logger.info(f'Test set: Average loss: {test_loss:.4f}')
         logger.info(
             f'Test set: Accuracy: {accuracy} ({correct_rate:.2f}%)'
@@ -155,388 +190,392 @@
 
         self.tb_writer.add_scalar('timer/run_time', end - start, self.current_round)
         self.tb_writer.add_scalar('test_results/average_loss', test_loss, self.current_round)
         self.tb_writer.add_scalar('test_results/accuracy', accuracy, self.current_round)
         self.tb_writer.add_scalar('test_results/correct_rate', correct_rate, self.current_round)
 
 
-class DemoSGD(FedSGDScheduler):
+class DemoHeteroCollaborator(HeteroNNCollaboratorScheduler):
 
     def __init__(self,
+                 feature_key: str,
+                 batch_size: int,
+                 data_dir: str,
+                 schedule_timeout: int = 30,
+                 is_feature_trainable: bool = True) -> None:
+        super().__init__(feature_key=feature_key,
+                         schedule_timeout=schedule_timeout,
+                         is_feature_trainable=is_feature_trainable)
+        self.batch_size = batch_size
+        self.data_dir = data_dir
+
+    def load_local_ids(self) -> List[str]:
+        train_ids = [str(i) for i in range(10000, 30000)]
+        test_ids = [str(i) for i in range(103000, 107000)]
+        return train_ids + test_ids
+
+    def split_dataset(self, id_intersection: Set[str]) -> Tuple[Set[str], Set[str]]:
+        ids = [int(_id) for _id in id_intersection]
+        ids.sort()
+        train_ids = ids[:10000]
+        test_ids = ids[10000:]
+
+        logger.info(f'Got {len(train_ids)} intersecting samples for training.')
+        logger.info(f'Got {len(test_ids)} intersecting samples for testing.')
+
+        return set(train_ids), set(test_ids)
+
+    def build_feature_model(self) -> nn.Module:
+        return ConvNet()
+
+    def build_feature_optimizer(self, feature_model: nn.Module) -> optim.Optimizer:
+        return optim.SGD(feature_model.parameters(), lr=0.01, momentum=0.9)
+
+    def _erase_left(self, _image: torch.Tensor) -> torch.Tensor:
+        return _image[:, :, :, 14:]
+
+    def iterate_train_feature(self,
+                              feature_model: nn.Module,
+                              train_ids: Set[str]) -> torch.Tensor:
+        train_dataset = torchvision.datasets.MNIST(
+            self.data_dir,
+            train=True,
+            download=True,
+            transform=torchvision.transforms.Compose([
+                torchvision.transforms.ToTensor(),
+                torchvision.transforms.Normalize((0.1307,), (0.3081,))
+            ])
+        )
+        train_ids: List = list(train_ids)
+        train_ids.sort(key=lambda x: md5(bytes(x + self.current_round)).digest())
+
+        train_dataset = Subset(train_dataset, train_ids)
+        self.train_loader = DataLoader(train_dataset,
+                                       batch_size=self.batch_size,
+                                       shuffle=False)
+
+        for _data, _ in self.train_loader:
+            _data = self._erase_left(_data)
+            yield feature_model(_data)
+
+    def iterate_test_feature(self,
+                             feature_model: nn.Module,
+                             test_ids: Set[str]) -> torch.Tensor:
+        test_dataset = torchvision.datasets.MNIST(
+            self.data_dir,
+            train=False,
+            download=True,
+            transform=torchvision.transforms.Compose([
+                torchvision.transforms.ToTensor(),
+                torchvision.transforms.Normalize((0.1307,), (0.3081,))
+            ])
+        )
+        test_ids = [(i - 100000) for i in test_ids]
+        test_dataset = Subset(test_dataset, test_ids)
+        self.test_loader = DataLoader(test_dataset,
+                                      batch_size=self.batch_size,
+                                      shuffle=False)
+
+        for _data, _ in self.test_loader:
+            _data = self._erase_left(_data)
+            yield feature_model(_data)
+
+
+class DemoSecureHeteroHost(SecureHeteroNNHostScheduler):
+
+    def __init__(self,
+                 feature_key: str,
+                 project_layer_config: List[Tuple[str, int, int]],
+                 project_layer_lr: float,
+                 batch_size: int,
+                 data_dir: str,
                  max_rounds: int = 0,
                  calculation_timeout: int = 300,
+                 schedule_timeout: int = 30,
                  log_rounds: int = 0,
-                 learning_rate: float = 0.01,
-                 momentum: float = 0.9) -> None:
-        super().__init__(max_rounds=max_rounds,
+                 is_feature_trainable: bool = True) -> None:
+        super().__init__(feature_key=feature_key,
+                         project_layer_config=project_layer_config,
+                         project_layer_lr=project_layer_lr,
+                         max_rounds=max_rounds,
                          calculation_timeout=calculation_timeout,
-                         log_rounds=log_rounds)
-        self.learning_rate = learning_rate
-        self.momentum = momentum
+                         schedule_timeout=schedule_timeout,
+                         log_rounds=log_rounds,
+                         is_feature_trainable=is_feature_trainable)
+        self.batch_size = batch_size
+        self.data_dir = data_dir
 
-        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
-        self.seed = 42
-        torch.manual_seed(self.seed)
-
-    def build_model(self) -> nn.Module:
-        model = ConvNet()
-        return model.to(self.device)
-
-    def build_optimizer(self, model: nn.Module) -> optim.Optimizer:
-        assert self.model, 'must initialize model first'
-        return optim.SGD(model.parameters(),
-                         lr=self.learning_rate,
-                         momentum=self.momentum)
-
-    def build_train_dataloader(self) -> DataLoader:
-        dataset = torchvision.datasets.MNIST(
-            get_dataset_dir(self.task_id),
+    def load_local_ids(self) -> List[str]:
+        train_ids = [str(i) for i in range(0, 20000)]
+        test_ids = [str(i) for i in range(100000, 105000)]
+        return train_ids + test_ids
+
+    def split_dataset(self, id_intersection: Set[str]) -> Tuple[Set[str], Set[str]]:
+        ids = [int(_id) for _id in id_intersection]
+        ids.sort()
+        train_ids = ids[:10000]
+        test_ids = ids[10000:]
+
+        logger.info(f'Got {len(train_ids)} intersecting samples for training.')
+        logger.info(f'Got {len(test_ids)} intersecting samples for testing.')
+
+        return set(train_ids), set(test_ids)
+
+    def build_feature_model(self) -> nn.Module:
+        return ConvNet()
+
+    def build_feature_optimizer(self, feature_model: nn.Module) -> optim.Optimizer:
+        return optim.SGD(feature_model.parameters(), lr=0.01, momentum=0.9)
+
+    def _erase_right(self, _image: torch.Tensor) -> torch.Tensor:
+        return _image[:, :, :, :14]
+
+    def iterate_train_feature(self,
+                              feature_model: nn.Module,
+                              train_ids: Set[str]) -> Tuple[torch.Tensor, torch.Tensor]:
+        train_dataset = torchvision.datasets.MNIST(
+            self.data_dir,
             train=True,
             download=True,
             transform=torchvision.transforms.Compose([
                 torchvision.transforms.ToTensor(),
                 torchvision.transforms.Normalize((0.1307,), (0.3081,))
             ])
         )
-        return DataLoader(dataset=dataset, batch_size=len(dataset), shuffle=True)
-
-    def build_test_dataloader(self) -> DataLoader:
-        return DataLoader(
-            torchvision.datasets.MNIST(
-                get_dataset_dir(self.task_id),
-                train=False,
-                download=True,
-                transform=torchvision.transforms.Compose([
-                    torchvision.transforms.ToTensor(),
-                    torchvision.transforms.Normalize((0.1307,), (0.3081,))
-                ])
-            ),
-            batch_size=64,  # no need be total number in test phrase
-            shuffle=False
+        train_ids: List = list(train_ids)
+        train_ids.sort(key=lambda x: md5(bytes(x + self.current_round)).digest())
+        train_dataset = Subset(train_dataset, train_ids)
+        self.train_loader = DataLoader(train_dataset,
+                                       batch_size=self.batch_size,
+                                       shuffle=False,
+                                       drop_last=True)
+
+        for _data, _labels in self.train_loader:
+            _data = self._erase_right(_data)
+            yield feature_model(_data), _labels
+
+    def iterate_test_feature(self,
+                             feature_model: nn.Module,
+                             test_ids: Set[str]) -> Tuple[torch.Tensor, torch.Tensor]:
+        test_dataset = torchvision.datasets.MNIST(
+            self.data_dir,
+            train=False,
+            download=True,
+            transform=torchvision.transforms.Compose([
+                torchvision.transforms.ToTensor(),
+                torchvision.transforms.Normalize((0.1307,), (0.3081,))
+            ])
         )
+        test_ids = [(i - 100000) for i in test_ids]
+        test_dataset = Subset(test_dataset, test_ids)
+        self.test_loader = DataLoader(test_dataset,
+                                      batch_size=self.batch_size,
+                                      shuffle=False,
+                                      drop_last=True)
+
+        for _data, _labels in self.test_loader:
+            _data = self._erase_right(_data)
+            yield feature_model(_data), _labels
+
+    def build_infer_model(self) -> nn.Module:
+        return InferModule()
+
+    def build_infer_optimizer(self, infer_model: nn.Module) -> optim.Optimizer:
+        return optim.SGD(infer_model.parameters(), lr=0.01, momentum=0.9)
+
+    def train_a_batch(self, feature_projection: Dict[str, torch.Tensor], labels: torch.Tensor):
+        fusion_tensor = torch.concat((feature_projection['demo_host'],
+                                      feature_projection['demo_collaborator']), dim=1)
+        self.optimizer.zero_grad()
+        out = self.infer_model(fusion_tensor)
+        loss = F.nll_loss(out, labels)
+        loss.backward()
+        self.optimizer.step()
 
-    def validate_context(self):
-        super().validate_context()
-        assert self.train_loader and len(self.train_loader) > 0, 'failed to load train data'
-        self.push_log(f'There are {len(self.train_loader.dataset)} samples for training.')
-        assert self.test_loader and len(self.test_loader) > 0, 'failed to load test data'
-        self.push_log(f'There are {len(self.test_loader.dataset)} samples for testing.')
-
-    def train_an_epoch(self) -> None:
-        self.model.train()
-        for data, labels in self.train_loader:
-            data: torch.Tensor
-            labels: torch.Tensor
-            data, labels = data.to(self.device), labels.to(self.device)
-            self.optimizer.zero_grad()
-            output = self.model(data)
-            loss = F.nll_loss(output, labels)
-            loss.backward()
-            self.optimizer.step()
-
-    def run_test(self):
+    def run_test(self,
+                 batched_feature_projections: List[torch.Tensor],
+                 batched_labels: List[torch.Tensor]):
         start = time()
-        self.model.eval()
         test_loss = 0
         correct = 0
-        with torch.no_grad():
-            test_loader = self.build_test_dataloader()
-            for data, labels in test_loader:
-                data: torch.Tensor
-                labels: torch.Tensor
-                data, labels = data.to(self.device), labels.to(self.device)
-                output: torch.Tensor = self.model(data)
-                test_loss += F.nll_loss(output, labels, reduction='sum').item()
-                pred = output.max(1, keepdim=True)[1]
-                correct += pred.eq(labels.view_as(pred)).sum().item()
+        for _feature_projection, _lables in zip(batched_feature_projections, batched_labels):
+            fusion_tensor = torch.concat((_feature_projection['demo_host'],
+                                          _feature_projection['demo_collaborator']), dim=1)
+            out: torch.Tensor = self.infer_model(fusion_tensor)
+            test_loss += F.nll_loss(out, _lables)
+            pred = out.max(1, keepdim=True)[1]
+            correct += pred.eq(_lables.view_as(pred)).sum().item()
 
-        test_loss /= len(test_loader.dataset)
-        accuracy = correct / len(test_loader.dataset)
+        test_loss /= len(self.test_loader.dataset)
+        accuracy = correct / len(self.test_loader.dataset)
         correct_rate = 100. * accuracy
         logger.info(f'Test set: Average loss: {test_loss:.4f}')
         logger.info(
             f'Test set: Accuracy: {accuracy} ({correct_rate:.2f}%)'
         )
 
         end = time()
 
         self.tb_writer.add_scalar('timer/run_time', end - start, self.current_round)
         self.tb_writer.add_scalar('test_results/average_loss', test_loss, self.current_round)
         self.tb_writer.add_scalar('test_results/accuracy', accuracy, self.current_round)
         self.tb_writer.add_scalar('test_results/correct_rate', correct_rate, self.current_round)
 
 
-class DemoSecure(SecureFedAvgScheduler):
+class DemoSecureHeteroCollaborator(SecureHeteroNNCollaboratorScheduler):
 
     def __init__(self,
-                 t: int,
-                 max_rounds: int = 0,
-                 merge_epochs: int = 1,
-                 calculation_timeout: int = 300,
-                 log_rounds: int = 0) -> None:
-        super().__init__(t=t,
-                         max_rounds=max_rounds,
-                         merge_epochs=merge_epochs,
-                         calculation_timeout=calculation_timeout,
-                         log_rounds=log_rounds)
-        self.batch_size = 64
-        self.learning_rate = 0.01
-        self.momentum = 0.5
-        self.random_seed = 42
-
-        torch.manual_seed(self.random_seed)
-        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
-
-    def build_model(self) -> nn.Module:
-        model = ConvNet()
-        return model.to(self.device)
-
-    def build_optimizer(self, model: nn.Module) -> optim.Optimizer:
-        return optim.SGD(model.parameters(),
-                         lr=self.learning_rate,
-                         momentum=self.momentum)
-
-    def build_train_dataloader(self) -> DataLoader:
-        return DataLoader(
-            torchvision.datasets.MNIST(
-                get_dataset_dir(self.task_id),
-                train=True,
-                download=True,
-                transform=torchvision.transforms.Compose([
-                    torchvision.transforms.ToTensor(),
-                    torchvision.transforms.Normalize((0.1307,), (0.3081,))
-                ])
-            ),
-            batch_size=self.batch_size,
-            shuffle=True
-        )
+                 feature_key: str,
+                 project_layer_lr: int,
+                 batch_size: int,
+                 data_dir: str,
+                 schedule_timeout: int = 30,
+                 is_feature_trainable: bool = True) -> None:
+        super().__init__(feature_key=feature_key,
+                         project_layer_lr=project_layer_lr,
+                         schedule_timeout=schedule_timeout,
+                         is_feature_trainable=is_feature_trainable)
+        self.batch_size = batch_size
+        self.data_dir = data_dir
 
-    def build_test_dataloader(self) -> DataLoader:
-        return DataLoader(
-            torchvision.datasets.MNIST(
-                get_dataset_dir(self.task_id),
-                train=False,
-                download=True,
-                transform=torchvision.transforms.Compose([
-                    torchvision.transforms.ToTensor(),
-                    torchvision.transforms.Normalize((0.1307,), (0.3081,))
-                ])
-            ),
-            batch_size=self.batch_size,
-            shuffle=False
+    def load_local_ids(self) -> List[str]:
+        train_ids = [str(i) for i in range(10000, 30000)]
+        test_ids = [str(i) for i in range(103000, 107000)]
+        return train_ids + test_ids
+
+    def split_dataset(self, id_intersection: Set[str]) -> Tuple[Set[str], Set[str]]:
+        ids = [int(_id) for _id in id_intersection]
+        ids.sort()
+        train_ids = ids[:10000]
+        test_ids = ids[10000:]
+
+        logger.info(f'Got {len(train_ids)} intersecting samples for training.')
+        logger.info(f'Got {len(test_ids)} intersecting samples for testing.')
+
+        return set(train_ids), set(test_ids)
+
+    def build_feature_model(self) -> nn.Module:
+        return ConvNet()
+
+    def build_feature_optimizer(self, feature_model: nn.Module) -> optim.Optimizer:
+        return optim.SGD(feature_model.parameters(), lr=0.01, momentum=0.9)
+
+    def _erase_left(self, _image: torch.Tensor) -> torch.Tensor:
+        return _image[:, :, :, 14:]
+
+    def iterate_train_feature(self,
+                              feature_model: nn.Module,
+                              train_ids: Set[str]) -> torch.Tensor:
+        train_dataset = torchvision.datasets.MNIST(
+            self.data_dir,
+            train=True,
+            download=True,
+            transform=torchvision.transforms.Compose([
+                torchvision.transforms.ToTensor(),
+                torchvision.transforms.Normalize((0.1307,), (0.3081,))
+            ])
         )
-
-    def validate_context(self):
-        super().validate_context()
-        assert self.train_loader and len(self.train_loader) > 0, 'failed to load train data'
-        self.push_log(f'There are {len(self.train_loader.dataset)} samples for training.')
-        assert self.test_loader and len(self.test_loader) > 0, 'failed to load test data'
-        self.push_log(f'There are {len(self.test_loader.dataset)} samples for testing.')
-
-    def train_an_epoch(self) -> None:
-        self.model.train()
-        for data, labels in self.train_loader:
-            data: torch.Tensor
-            labels: torch.Tensor
-            data, labels = data.to(self.device), labels.to(self.device)
-            self.optimizer.zero_grad()
-            output = self.model(data)
-            loss = F.nll_loss(output, labels)
-            loss.backward()
-            self.optimizer.step()
-
-    def run_test(self):
-        self.model.eval()
-        test_loss = 0
-        correct = 0
-        with torch.no_grad():
-            test_loader = self.build_test_dataloader()
-            for data, labels in test_loader:
-                data: torch.Tensor
-                labels: torch.Tensor
-                data, labels = data.to(self.device), labels.to(self.device)
-                output: torch.Tensor = self.model(data)
-                test_loss += F.nll_loss(output, labels, reduction='sum').item()
-                pred = output.max(1, keepdim=True)[1]
-                correct += pred.eq(labels.view_as(pred)).sum().item()
-
-        test_loss /= len(test_loader.dataset)
-        correct_rate = 100. * correct / len(test_loader.dataset)
-        logger.info(f'Test set: Average loss: {test_loss:.4f}')
-        logger.info(
-            f'Test set: Accuracy: {correct}/{len(test_loader.dataset)} ({correct_rate:.2f}%)'
+        train_ids: List = list(train_ids)
+        train_ids.sort(key=lambda x: md5(bytes(x + self.current_round)).digest())
+        train_dataset = Subset(train_dataset, train_ids)
+        self.train_loader = DataLoader(train_dataset,
+                                       batch_size=self.batch_size,
+                                       shuffle=False,
+                                       drop_last=True)
+
+        for _data, _ in self.train_loader:
+            _data = self._erase_left(_data)
+            yield feature_model(_data)
+
+    def iterate_test_feature(self,
+                             feature_model: nn.Module,
+                             test_ids: Set[str]) -> torch.Tensor:
+        test_dataset = torchvision.datasets.MNIST(
+            self.data_dir,
+            train=False,
+            download=True,
+            transform=torchvision.transforms.Compose([
+                torchvision.transforms.ToTensor(),
+                torchvision.transforms.Normalize((0.1307,), (0.3081,))
+            ])
         )
+        test_ids = [(i - 100000) for i in test_ids]
+        test_dataset = Subset(test_dataset, test_ids)
+        self.test_loader = DataLoader(test_dataset,
+                                      batch_size=self.batch_size,
+                                      shuffle=False,
+                                      drop_last=True)
+
+        for _data, _ in self.test_loader:
+            _data = self._erase_left(_data)
+            yield feature_model(_data)
 
-        self.tb_writer.add_scalar('test_results/average_loss', test_loss, self.current_round)
-        self.tb_writer.add_scalar('test_results/correct_rate', correct_rate, self.current_round)
 
+def get_task_id() -> str:
+    return DEV_TASK_ID
 
-class DemoDP(DPFedAvgScheduler):
-
-    def __init__(self,
-                 w_cap: int,
-                 q: float,
-                 S: float,
-                 z: float,
-                 max_rounds: int = 0,
-                 merge_epochs: int = 1,
-                 calculation_timeout: int = 300,
-                 log_rounds: int = 0,
-                 involve_aggregator: bool = False) -> None:
-        super().__init__(w_cap=w_cap,
-                         q=q,
-                         S=S,
-                         z=z,
-                         max_rounds=max_rounds,
-                         merge_epochs=merge_epochs,
-                         calculation_timeout=calculation_timeout,
-                         log_rounds=log_rounds,
-                         involve_aggregator=involve_aggregator)
-        self.batch_size = 64
-        self.learning_rate = 0.01
-        self.momentum = 0.5
-        self.random_seed = 42
-
-        torch.manual_seed(self.random_seed)
-        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
-
-    def build_model(self) -> nn.Module:
-        model = ConvNet()
-        return model.to(self.device)
-
-    def build_optimizer(self, model: nn.Module) -> optim.Optimizer:
-        return optim.SGD(model.parameters(),
-                         lr=self.learning_rate,
-                         momentum=self.momentum)
-
-    def build_train_dataloader(self) -> DataLoader:
-        return DataLoader(
-            torchvision.datasets.MNIST(
-                get_dataset_dir(self.task_id),
-                train=True,
-                download=True,
-                transform=torchvision.transforms.Compose([
-                    torchvision.transforms.ToTensor(),
-                    torchvision.transforms.Normalize((0.1307,), (0.3081,))
-                ])
-            ),
-            batch_size=self.batch_size,
-            shuffle=True
-        )
-
-    def build_test_dataloader(self) -> DataLoader:
-        return DataLoader(
-            torchvision.datasets.MNIST(
-                get_dataset_dir(self.task_id),
-                train=False,
-                download=True,
-                transform=torchvision.transforms.Compose([
-                    torchvision.transforms.ToTensor(),
-                    torchvision.transforms.Normalize((0.1307,), (0.3081,))
-                ])
-            ),
-            batch_size=self.batch_size,
-            shuffle=False
-        )
 
-    def validate_context(self):
-        super().validate_context()
-        assert self.train_loader and len(self.train_loader) > 0, 'failed to load train data'
-        self.push_log(f'There are {len(self.train_loader.dataset)} samples for training.')
-        assert self.test_loader and len(self.test_loader) > 0, 'failed to load test data'
-        self.push_log(f'There are {len(self.test_loader.dataset)} samples for testing.')
-
-    def train_a_batch(self, *batch_train_data):
-        data: torch.Tensor
-        labels: torch.Tensor
-        data, labels = batch_train_data
-        data, labels = data.to(self.device), labels.to(self.device)
-        self.optimizer.zero_grad()
-        output = self.model(data)
-        loss = F.nll_loss(output, labels)
-        loss.backward()
-        self.optimizer.step()
+def get_host(mode: str = VANILLA) -> Union[DemoHeteroHost, DemoSecureHeteroHost]:
+    assert mode in (VANILLA, SECURE), f'unknown mode: {mode}'
 
-    def run_test(self):
-        self.model.eval()
-        test_loss = 0
-        correct = 0
-        with torch.no_grad():
-            test_loader = self.build_test_dataloader()
-            for data, labels in test_loader:
-                data: torch.Tensor
-                labels: torch.Tensor
-                data, labels = data.to(self.device), labels.to(self.device)
-                output: torch.Tensor = self.model(data)
-                test_loss += F.nll_loss(output, labels, reduction='sum').item()
-                pred = output.max(1, keepdim=True)[1]
-                correct += pred.eq(labels.view_as(pred)).sum().item()
+    pickle_file = './scheduler_host.pickle'
 
-        test_loss /= len(test_loader.dataset)
-        correct_rate = 100. * correct / len(test_loader.dataset)
-        logger.info(f'Test set: Average loss: {test_loss:.4f}')
-        logger.info(
-            f'Test set: Accuracy: {correct}/{len(test_loader.dataset)} ({correct_rate:.2f}%)'
-        )
+    if os.path.exists(pickle_file):
+        os.remove(pickle_file)
 
-        self.tb_writer.add_scalar('test_results/average_loss', test_loss, self.current_round)
-        self.tb_writer.add_scalar('test_results/correct_rate', correct_rate, self.current_round)
+    if mode == VANILLA:
+        scheduler = DemoHeteroHost(feature_key='demo_host',
+                                   batch_size=128,
+                                   data_dir=_DATA_DIR,
+                                   max_rounds=5,
+                                   calculation_timeout=60,
+                                   log_rounds=1)
+    else:
+        project_layer_config = [
+            ('demo_host', 10, 10),
+            ('demo_collaborator', 10, 10)
+        ]
+        # Too big batch size could kill the server
+        scheduler = DemoSecureHeteroHost(feature_key='demo_host',
+                                         project_layer_config=project_layer_config,
+                                         project_layer_lr=0.01,
+                                         batch_size=128,
+                                         data_dir=_DATA_DIR,
+                                         max_rounds=10,
+                                         calculation_timeout=60,
+                                         log_rounds=1)
 
+    with open(pickle_file, 'w+b') as pf:
+        pickle.dump(scheduler, pf)
 
-def get_task_id() -> str:
-    return DEV_TASK_ID
+    with open(pickle_file, 'rb') as f:
+        scheduler = pickle.load(f)
+        return scheduler
 
 
-def get_scheduler(mode: str = VANILLA) -> FedAvgScheduler:
-    assert mode in (VANILLA, SGD, SECURE, DP, FED_IRM), f'unknown mode: {mode}'
+def get_collaborator(mode: str = VANILLA) -> Union[DemoHeteroCollaborator,
+                                                   DemoSecureHeteroCollaborator]:
+    assert mode in (VANILLA, SECURE), f'unknown mode: {mode}'
 
-    pickle_file = './scheduler.pickle'
-    import cloudpickle as pickle
+    pickle_file = './scheduler_collaborator.pickle'
 
     if os.path.exists(pickle_file):
         os.remove(pickle_file)
 
     if mode == VANILLA:
-        scheduler = DemoAvg(max_rounds=5,
-                            log_rounds=1,
-                            calculation_timeout=60,
-                            involve_aggregator=True)
-
-    elif mode == SGD:
-        scheduler = DemoSGD(max_rounds=200,
-                            log_rounds=1,
-                            calculation_timeout=60)
-
-    elif mode == DP:
-        scheduler = DemoDP(w_cap=20000,
-                           q=0.9,
-                           S=1,
-                           z=0.1,
-                           max_rounds=5,
-                           log_rounds=1,
-                           calculation_timeout=60,
-                           involve_aggregator=True)
-
-    elif mode == SECURE:
-        scheduler = DemoSecure(t=2,
-                               max_rounds=5,
-                               log_rounds=1,
-                               calculation_timeout=120)
-
-    elif mode == FED_IRM:
-        root_dir = '/data/alphamed/alphamed-dataset/tutorials/FedIRM/'
-        scheduler = DemoFedIRM(
-            root_path=os.path.join(root_dir, 'gtr21/ISIN-2018/train_image_224'),
-            csv_file_train=os.path.join(root_dir, 'train.csv'),
-            csv_file_test=os.path.join(root_dir, 'test.csv'),
-            max_rounds=50,
-            log_rounds=5,
-            calculation_timeout=3600,
-            involve_aggregator=True
-        )
+        scheduler = DemoHeteroCollaborator(feature_key='demo_collaborator',
+                                           batch_size=128,
+                                           data_dir=_DATA_DIR)
+
+    else:
+        # Too big batch size could kill the server
+        scheduler = DemoSecureHeteroCollaborator(feature_key='demo_collaborator',
+                                                 project_layer_lr=0.01,
+                                                 batch_size=128,
+                                                 data_dir=_DATA_DIR)
 
     with open(pickle_file, 'w+b') as pf:
         pickle.dump(scheduler, pf)
 
     with open(pickle_file, 'rb') as f:
         scheduler = pickle.load(f)
         return scheduler
```

### Comparing `alphamed-federated-0.4.7/src/alphafed/examples/fed_avg/model/my_scheduler.py` & `alphamed-federated-0.4.9/src/alphafed/examples/fed_avg/model/my_scheduler.py`

 * *Ordering differences only*

 * *Files 14% similar despite different names*

```diff
@@ -1,134 +1,134 @@
-from time import time
-from typing import Dict
-
-import torch
-import torch.nn as nn
-import torch.nn.functional as F
-import torchvision
-from torch import optim
-from torch.utils.data import DataLoader
-
-from alphafed import logger
-from alphafed.fed_avg import FedAvgScheduler
-from alphafed.fs import get_dataset_dir
-
-from net import ConvNet
-
-
-class DemoFedAvg(FedAvgScheduler):
-
-    def __init__(self,
-                 max_rounds: int = 0,
-                 merge_epochs: int = 1,
-                 calculation_timeout: int = 300,
-                 log_rounds: int = 0,
-                 involve_aggregator: bool = False,
-                 batch_size: int = 64,
-                 learning_rate: float = 0.01,
-                 momentum: float = 0.5) -> None:
-        super().__init__(max_rounds=max_rounds,
-                         merge_epochs=merge_epochs,
-                         calculation_timeout=calculation_timeout,
-                         log_rounds=log_rounds,
-                         involve_aggregator=involve_aggregator)
-        self.batch_size = batch_size
-        self.learning_rate = learning_rate
-        self.momentum = momentum
-
-        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
-        self.seed = 42
-        torch.manual_seed(self.seed)
-
-    def build_model(self) -> nn.Module:
-        model = ConvNet()
-        return model.to(self.device)
-
-    def build_optimizer(self, model: nn.Module) -> optim.Optimizer:
-        return optim.SGD(model.parameters(),
-                         lr=self.learning_rate,
-                         momentum=self.momentum)
-
-    def build_train_dataloader(self) -> DataLoader:
-        return DataLoader(
-            torchvision.datasets.MNIST(
-                get_dataset_dir(self.task_id),
-                train=True,
-                download=True,
-                transform=torchvision.transforms.Compose([
-                    torchvision.transforms.ToTensor(),
-                    torchvision.transforms.Normalize((0.1307,), (0.3081,))
-                ])
-            ),
-            batch_size=self.batch_size,
-            shuffle=True
-        )
-
-    def build_test_dataloader(self) -> DataLoader:
-        return DataLoader(
-            torchvision.datasets.MNIST(
-                get_dataset_dir(self.task_id),
-                train=False,
-                download=True,
-                transform=torchvision.transforms.Compose([
-                    torchvision.transforms.ToTensor(),
-                    torchvision.transforms.Normalize((0.1307,), (0.3081,))
-                ])
-            ),
-            batch_size=self.batch_size,
-            shuffle=False
-        )
-
-    def state_dict(self) -> Dict[str, torch.Tensor]:
-        return self.model.state_dict()
-
-    def load_state_dict(self, state_dict: Dict[str, torch.Tensor]):
-        self.model.load_state_dict(state_dict)
-
-    def validate_context(self):
-        super().validate_context()
-        assert self.train_loader and len(self.train_loader) > 0, 'failed to load train data'
-        logger.info(f'There are {len(self.train_loader.dataset)} samples for training.')
-        assert self.test_loader and len(self.test_loader) > 0, 'failed to load test data'
-        logger.info(f'There are {len(self.test_loader.dataset)} samples for testing.')
-
-    def train_an_epoch(self) -> None:
-        self.model.train()
-        for data, labels in self.train_loader:
-            data: torch.Tensor
-            labels: torch.Tensor
-            data, labels = data.to(self.device), labels.to(self.device)
-            self.optimizer.zero_grad()
-            output = self.model(data)
-            loss = F.nll_loss(output, labels)
-            loss.backward()
-            self.optimizer.step()
-
-    def run_test(self):
-        start = time()
-        self.model.eval()
-        test_loss = 0
-        correct = 0
-        with torch.no_grad():
-            for data, labels in self.test_loader:
-                data: torch.Tensor
-                labels: torch.Tensor
-                data, labels = data.to(self.device), labels.to(self.device)
-                output: torch.Tensor = self.model(data)
-                test_loss += F.nll_loss(output, labels, reduction='sum').item()
-                pred = output.max(1, keepdim=True)[1]
-                correct += pred.eq(labels.view_as(pred)).sum().item()
-
-        test_loss /= len(self.test_loader.dataset)
-        accuracy = correct / len(self.test_loader.dataset)
-        correct_rate = 100. * accuracy
-        logger.info(f'Test set: Average loss: {test_loss:.4f}')
-        logger.info(
-            f'Test set: Accuracy: {accuracy} ({correct_rate:.2f}%)'
-        )
-
-        end = time()
-
-        self.tb_writer.add_scalar('timer/run_time', end - start, self.current_round)
-        self.tb_writer.add_scalar('test_results/average_loss', test_loss, self.current_round)
-        self.tb_writer.add_scalar('test_results/accuracy', accuracy, self.current_round)
-        self.tb_writer.add_scalar('test_results/correct_rate', correct_rate, self.current_round)
+from time import time
+from typing import Dict
+
+import torch
+import torch.nn as nn
+import torch.nn.functional as F
+import torchvision
+from torch import optim
+from torch.utils.data import DataLoader
+
+from alphafed import logger
+from alphafed.fed_avg import FedAvgScheduler
+from alphafed.fs import get_dataset_dir
+
+from net import ConvNet
+
+
+class DemoFedAvg(FedAvgScheduler):
+
+    def __init__(self,
+                 max_rounds: int = 0,
+                 merge_epochs: int = 1,
+                 calculation_timeout: int = 300,
+                 log_rounds: int = 0,
+                 involve_aggregator: bool = False,
+                 batch_size: int = 64,
+                 learning_rate: float = 0.01,
+                 momentum: float = 0.5) -> None:
+        super().__init__(max_rounds=max_rounds,
+                         merge_epochs=merge_epochs,
+                         calculation_timeout=calculation_timeout,
+                         log_rounds=log_rounds,
+                         involve_aggregator=involve_aggregator)
+        self.batch_size = batch_size
+        self.learning_rate = learning_rate
+        self.momentum = momentum
+
+        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
+        self.seed = 42
+        torch.manual_seed(self.seed)
+
+    def build_model(self) -> nn.Module:
+        model = ConvNet()
+        return model.to(self.device)
+
+    def build_optimizer(self, model: nn.Module) -> optim.Optimizer:
+        return optim.SGD(model.parameters(),
+                         lr=self.learning_rate,
+                         momentum=self.momentum)
+
+    def build_train_dataloader(self) -> DataLoader:
+        return DataLoader(
+            torchvision.datasets.MNIST(
+                get_dataset_dir(self.task_id),
+                train=True,
+                download=True,
+                transform=torchvision.transforms.Compose([
+                    torchvision.transforms.ToTensor(),
+                    torchvision.transforms.Normalize((0.1307,), (0.3081,))
+                ])
+            ),
+            batch_size=self.batch_size,
+            shuffle=True
+        )
+
+    def build_test_dataloader(self) -> DataLoader:
+        return DataLoader(
+            torchvision.datasets.MNIST(
+                get_dataset_dir(self.task_id),
+                train=False,
+                download=True,
+                transform=torchvision.transforms.Compose([
+                    torchvision.transforms.ToTensor(),
+                    torchvision.transforms.Normalize((0.1307,), (0.3081,))
+                ])
+            ),
+            batch_size=self.batch_size,
+            shuffle=False
+        )
+
+    def state_dict(self) -> Dict[str, torch.Tensor]:
+        return self.model.state_dict()
+
+    def load_state_dict(self, state_dict: Dict[str, torch.Tensor]):
+        self.model.load_state_dict(state_dict)
+
+    def validate_context(self):
+        super().validate_context()
+        assert self.train_loader and len(self.train_loader) > 0, 'failed to load train data'
+        logger.info(f'There are {len(self.train_loader.dataset)} samples for training.')
+        assert self.test_loader and len(self.test_loader) > 0, 'failed to load test data'
+        logger.info(f'There are {len(self.test_loader.dataset)} samples for testing.')
+
+    def train_an_epoch(self) -> None:
+        self.model.train()
+        for data, labels in self.train_loader:
+            data: torch.Tensor
+            labels: torch.Tensor
+            data, labels = data.to(self.device), labels.to(self.device)
+            self.optimizer.zero_grad()
+            output = self.model(data)
+            loss = F.nll_loss(output, labels)
+            loss.backward()
+            self.optimizer.step()
+
+    def run_test(self):
+        start = time()
+        self.model.eval()
+        test_loss = 0
+        correct = 0
+        with torch.no_grad():
+            for data, labels in self.test_loader:
+                data: torch.Tensor
+                labels: torch.Tensor
+                data, labels = data.to(self.device), labels.to(self.device)
+                output: torch.Tensor = self.model(data)
+                test_loss += F.nll_loss(output, labels, reduction='sum').item()
+                pred = output.max(1, keepdim=True)[1]
+                correct += pred.eq(labels.view_as(pred)).sum().item()
+
+        test_loss /= len(self.test_loader.dataset)
+        accuracy = correct / len(self.test_loader.dataset)
+        correct_rate = 100. * accuracy
+        logger.info(f'Test set: Average loss: {test_loss:.4f}')
+        logger.info(
+            f'Test set: Accuracy: {accuracy} ({correct_rate:.2f}%)'
+        )
+
+        end = time()
+
+        self.tb_writer.add_scalar('timer/run_time', end - start, self.current_round)
+        self.tb_writer.add_scalar('test_results/average_loss', test_loss, self.current_round)
+        self.tb_writer.add_scalar('test_results/accuracy', accuracy, self.current_round)
+        self.tb_writer.add_scalar('test_results/correct_rate', correct_rate, self.current_round)
```

### Comparing `alphamed-federated-0.4.7/src/alphafed/examples/fed_avg/model/net.py` & `alphamed-federated-0.4.9/src/alphafed/examples/fed_avg/model/net.py`

 * *Ordering differences only*

 * *Files 10% similar despite different names*

```diff
@@ -1,21 +1,21 @@
-from torch import nn
-import torch.nn.functional as F
-
-
-class ConvNet(nn.Module):
-    def __init__(self) -> None:
-        super().__init__()
-        self.conv1 = nn.Conv2d(in_channels=1, out_channels=10, kernel_size=5)
-        self.conv2 = nn.Conv2d(in_channels=10, out_channels=20, kernel_size=5)
-        self.conv2_drop = nn.Dropout2d()
-        self.fc1 = nn.Linear(in_features=320, out_features=50)
-        self.fc2 = nn.Linear(in_features=50, out_features=10)
-
-    def forward(self, x):
-        x = F.relu(F.max_pool2d(self.conv1(x), 2))
-        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))
-        x = x.view(-1, 320)
-        x = F.relu(self.fc1(x))
-        x = F.dropout(x, training=self.training)
-        x = self.fc2(x)
-        return F.log_softmax(x, dim=-1)
+from torch import nn
+import torch.nn.functional as F
+
+
+class ConvNet(nn.Module):
+    def __init__(self) -> None:
+        super().__init__()
+        self.conv1 = nn.Conv2d(in_channels=1, out_channels=10, kernel_size=5)
+        self.conv2 = nn.Conv2d(in_channels=10, out_channels=20, kernel_size=5)
+        self.conv2_drop = nn.Dropout2d()
+        self.fc1 = nn.Linear(in_features=320, out_features=50)
+        self.fc2 = nn.Linear(in_features=50, out_features=10)
+
+    def forward(self, x):
+        x = F.relu(F.max_pool2d(self.conv1(x), 2))
+        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))
+        x = x.view(-1, 320)
+        x = F.relu(self.fc1(x))
+        x = F.dropout(x, training=self.training)
+        x = self.fc2(x)
+        return F.log_softmax(x, dim=-1)
```

### Comparing `alphamed-federated-0.4.7/src/alphafed/examples/fed_avg/run_aggregator.py` & `alphamed-federated-0.4.9/src/alphafed/examples/fed_avg/run_aggregator.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/examples/fed_avg/run_data_owner_2.py` & `alphamed-federated-0.4.9/src/alphafed/examples/fed_avg/run_data_owner_2.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/examples/fed_avg/run_data_owner_3.py` & `alphamed-federated-0.4.9/src/alphafed/examples/fed_avg/run_data_owner_3.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/examples/fed_avg/run_data_owner_4.py` & `alphamed-federated-0.4.9/src/alphafed/examples/fed_avg/run_data_owner_4.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/examples/fed_avg/run_data_owner_5.py` & `alphamed-federated-0.4.9/src/alphafed/examples/fed_avg/run_data_owner_5.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/examples/fed_md/__init__.py` & `alphamed-federated-0.4.9/src/alphafed/examples/fed_md/__init__.py`

 * *Ordering differences only*

 * *Files 12% similar despite different names*

```diff
@@ -1,16 +1,16 @@
-# CPU mode
-DEV_TASK_ID = 'd041d19f-59d0-467f-bc6c-7f5cf42436c2'
-
-AGGREGATOR_ID = 'QmXLxxW7W1cxdU7eeeq5yRXte53zekxiTRApSWxxssdzQP'
-DATA_OWNER_2_ID = 'QmUXV1ds7mNfZ5udaLauubMC5ve4mGpuwS6sTy6Keh2VJN'
-DATA_OWNER_3_ID = 'QmXG7aTnKk1AcLhKmauCkYpYafoxj1dG5xLBnCQNniuaeF'
-DATA_OWNER_4_ID = 'QmfFQ1CDXU8kYGMSkqPGqMw7NfnjGsfr3jPU9GbSBY4P3J'
-DATA_OWNER_5_ID = 'QmYX5KatFyFve3xVjadX2h7fEt1SzpdA8wnQsQ4v9muCyR'
-
-# GPU mode
-# DEV_TASK_ID = '45b0eb180eb34ba7a77f6df36fbf9e1b'
-
-# AGGREGATOR_ID = 'QmQERKLbhy2bbhWA6eSd4ENpr37BA7G3xzbm6BJqsERJ58'
-# DATA_OWNER_3_ID = 'QmPUhKyCbQ7V73gMNVUaGVnqsVbkNFxSotS7pEEFD8X1SP'
-# DATA_OWNER_4_ID = 'QmScck6og9ZRqeSKTqUpe4Phub45mxFeUHGysV2DWCouEg'
-# DATA_OWNER_5_ID = 'QmNwzJAbWSkcjdi2PS1wGCgbnZAxEdiwDtF8ZPVBn9EFGq'
+# CPU mode
+DEV_TASK_ID = 'd041d19f-59d0-467f-bc6c-7f5cf42436c2'
+
+AGGREGATOR_ID = 'QmXLxxW7W1cxdU7eeeq5yRXte53zekxiTRApSWxxssdzQP'
+DATA_OWNER_2_ID = 'QmUXV1ds7mNfZ5udaLauubMC5ve4mGpuwS6sTy6Keh2VJN'
+DATA_OWNER_3_ID = 'QmXG7aTnKk1AcLhKmauCkYpYafoxj1dG5xLBnCQNniuaeF'
+DATA_OWNER_4_ID = 'QmfFQ1CDXU8kYGMSkqPGqMw7NfnjGsfr3jPU9GbSBY4P3J'
+DATA_OWNER_5_ID = 'QmYX5KatFyFve3xVjadX2h7fEt1SzpdA8wnQsQ4v9muCyR'
+
+# GPU mode
+# DEV_TASK_ID = '45b0eb180eb34ba7a77f6df36fbf9e1b'
+
+# AGGREGATOR_ID = 'QmQERKLbhy2bbhWA6eSd4ENpr37BA7G3xzbm6BJqsERJ58'
+# DATA_OWNER_3_ID = 'QmPUhKyCbQ7V73gMNVUaGVnqsVbkNFxSotS7pEEFD8X1SP'
+# DATA_OWNER_4_ID = 'QmScck6og9ZRqeSKTqUpe4Phub45mxFeUHGysV2DWCouEg'
+# DATA_OWNER_5_ID = 'QmNwzJAbWSkcjdi2PS1wGCgbnZAxEdiwDtF8ZPVBn9EFGq'
```

### Comparing `alphamed-federated-0.4.7/src/alphafed/examples/fed_md/demos.py` & `alphamed-federated-0.4.9/src/alphafed/examples/fed_md/demos.py`

 * *Ordering differences only*

 * *Files 17% similar despite different names*

```diff
@@ -1,214 +1,214 @@
-"""Process demo."""
-
-import math
-import os
-from time import time
-
-import torch
-import torch.nn.functional as F
-from torch import Tensor
-from torch.nn import Module
-from torch.optim import SGD, Optimizer
-from torch.utils.data import DataLoader, Subset
-from torchvision import transforms
-from torchvision.datasets import MNIST
-
-from ... import get_dataset_dir, logger
-from . import DEV_TASK_ID
-from .model.loss import loss_kd
-from .model.net import ConvNet
-from .model.scheduler import HomoFedMDScheduler
-
-CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
-
-
-class DemoHomoFedMDScheduler(HomoFedMDScheduler):
-
-    def __init__(self,
-                 max_rounds: int,
-                 pretrain_public_epochs: int,
-                 pretrain_private_epochs: int,
-                 align_epochs: int,
-                 fine_tune_epochs: int,
-                 calculation_timeout: int = 300,
-                 schedule_timeout: int = 30,
-                 log_rounds: int = 0):
-        super().__init__(max_rounds=max_rounds,
-                         pretrain_public_epochs=pretrain_public_epochs,
-                         pretrain_private_epochs=pretrain_private_epochs,
-                         align_epochs=align_epochs,
-                         fine_tune_epochs=fine_tune_epochs,
-                         calculation_timeout=calculation_timeout,
-                         schedule_timeout=schedule_timeout,
-                         log_rounds=log_rounds)
-        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
-        self.seed = 42
-        torch.manual_seed(self.seed)
-        self.batch_size = 128
-
-    def build_model(self) -> Module:
-        net = ConvNet()
-        return net.to(self.device)
-
-    def build_optimizer(self, model: Module) -> Optimizer:
-        learning_rate = 0.01
-        momentum = 0.9
-        return SGD(model.parameters(), lr=learning_rate, momentum=momentum)
-    
-    def build_public_train_dataloader(self) -> DataLoader:
-        dataset = MNIST(
-            get_dataset_dir(self.task_id),
-            train=True,
-            download=True,
-            transform=transforms.Compose([
-                transforms.ToTensor(),
-                transforms.Normalize((0.1307,), (0.3081,))
-            ])
-        )
-        return DataLoader(
-            Subset(dataset=dataset, indices=list(range(50000))),
-            batch_size=self.batch_size,
-            shuffle=False
-        )
-    
-    def build_private_train_dataloader(self) -> DataLoader:
-        dataset = MNIST(
-            get_dataset_dir(self.task_id),
-            train=True,
-            download=True,
-            transform=transforms.Compose([
-                transforms.ToTensor(),
-                transforms.Normalize((0.1307,), (0.3081,))
-            ])
-        )
-        return DataLoader(
-            Subset(dataset=dataset, indices=list(range(50000, 60000))),
-            batch_size=self.batch_size,
-            shuffle=True
-        )
-    
-    def build_test_dataloader(self) -> DataLoader:
-        return DataLoader(
-            MNIST(
-                get_dataset_dir(self.task_id),
-                train=False,
-                download=True,
-                transform=transforms.Compose([
-                    transforms.ToTensor(),
-                    transforms.Normalize((0.1307,), (0.3081,))
-                ])
-            ),
-            batch_size=self.batch_size,
-            shuffle=False
-        )
-
-    @torch.no_grad()
-    def calc_local_logits(self) -> Tensor:
-        logits = []
-        self.model.eval()
-        for data, _ in self.public_train_loader:
-            data: Tensor
-            data = data.to(self.device)
-            logits.append(self.model(data))
-        return torch.cat(logits, dim=0)
-
-    def pretrain_an_epoch_on_public_data(self):
-        self.model.train()
-        for data, labels in self.public_train_loader:
-            data: Tensor
-            labels: Tensor
-            data, labels = data.to(self.device), labels.to(self.device)
-            self.optimizer.zero_grad()
-            output = self.model(data)
-            loss = F.nll_loss(output, labels)
-            loss.backward()
-            self.optimizer.step()
-
-    def pretrain_an_epoch_on_private_data(self):
-        self.model.train()
-        for data, labels in self.private_train_loader:
-            data: Tensor
-            labels: Tensor
-            data, labels = data.to(self.device), labels.to(self.device)
-            self.optimizer.zero_grad()
-            output = self.model(data)
-            loss = F.nll_loss(output, labels)
-            loss.backward()
-            self.optimizer.step()
-
-    def align_train_an_epoch(self, global_logits: Tensor):
-        self.model.train()
-        
-        # re-organize global_logits into batches
-        chunks = math.ceil(len(global_logits) / self.batch_size)
-        logits_batches = torch.chunk(input=global_logits, chunks=chunks, dim=0)
-        
-        for (data, labels), teacher_logits in zip(self.public_train_loader, logits_batches):
-            data: Tensor
-            labels: Tensor
-            data, labels = data.to(self.device), labels.to(self.device)
-            teacher_logits = teacher_logits.to(self.device)
-            self.optimizer.zero_grad()
-            output = self.model(data)            
-            loss = loss_kd(output, labels, teacher_logits)
-            loss.backward()
-            self.optimizer.step()
-
-    def fine_tune_an_epoch(self):
-        self.pretrain_an_epoch_on_private_data()
-
-    def run_test(self):
-        start = time()
-        self.model.eval()
-        test_loss = 0
-        correct = 0
-        with torch.no_grad():
-            for data, labels in self.test_loader:
-                data: torch.Tensor
-                labels: torch.Tensor
-                data, labels = data.to(self.device), labels.to(self.device)
-                output: torch.Tensor = self.model(data)
-                test_loss += F.nll_loss(output, labels, reduction='sum').item()
-                pred = output.max(1, keepdim=True)[1]
-                correct += pred.eq(labels.view_as(pred)).sum().item()
-
-        test_loss /= len(self.test_loader.dataset)
-        accuracy = correct / len(self.test_loader.dataset)
-        correct_rate = 100. * accuracy
-        logger.info(f'Test set: Average loss: {test_loss:.4f}')
-        logger.info(
-            f'Test set: Accuracy: {accuracy} ({correct_rate:.2f}%)'
-        )
-
-        end = time()
-
-        self.tb_writer.add_scalar('timer/run_time', end - start, self.current_round)
-        self.tb_writer.add_scalar('test_results/average_loss', test_loss, self.current_round)
-        self.tb_writer.add_scalar('test_results/accuracy', accuracy, self.current_round)
-        self.tb_writer.add_scalar('test_results/correct_rate', correct_rate, self.current_round)
-
-
-def get_task_id() -> str:
-    return DEV_TASK_ID
-
-
-def get_scheduler() -> DemoHomoFedMDScheduler:
-    pickle_file = './scheduler.pickle'
-    import cloudpickle as pickle
-
-    if os.path.exists(pickle_file):
-        os.remove(pickle_file)
-
-    scheduler = DemoHomoFedMDScheduler(max_rounds=3,
-                                       pretrain_public_epochs=1,
-                                       pretrain_private_epochs=2,
-                                       align_epochs=1,
-                                       fine_tune_epochs=2,
-                                       log_rounds=1)
-
-    with open(pickle_file, 'wb') as pf:
-        pickle.dump(scheduler, pf)
-
-    with open(pickle_file, 'rb') as f:
-        scheduler = pickle.load(f)
-        return scheduler
+"""Process demo."""
+
+import math
+import os
+from time import time
+
+import torch
+import torch.nn.functional as F
+from torch import Tensor
+from torch.nn import Module
+from torch.optim import SGD, Optimizer
+from torch.utils.data import DataLoader, Subset
+from torchvision import transforms
+from torchvision.datasets import MNIST
+
+from ... import get_dataset_dir, logger
+from . import DEV_TASK_ID
+from .model.loss import loss_kd
+from .model.net import ConvNet
+from .model.scheduler import HomoFedMDScheduler
+
+CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
+
+
+class DemoHomoFedMDScheduler(HomoFedMDScheduler):
+
+    def __init__(self,
+                 max_rounds: int,
+                 pretrain_public_epochs: int,
+                 pretrain_private_epochs: int,
+                 align_epochs: int,
+                 fine_tune_epochs: int,
+                 calculation_timeout: int = 300,
+                 schedule_timeout: int = 30,
+                 log_rounds: int = 0):
+        super().__init__(max_rounds=max_rounds,
+                         pretrain_public_epochs=pretrain_public_epochs,
+                         pretrain_private_epochs=pretrain_private_epochs,
+                         align_epochs=align_epochs,
+                         fine_tune_epochs=fine_tune_epochs,
+                         calculation_timeout=calculation_timeout,
+                         schedule_timeout=schedule_timeout,
+                         log_rounds=log_rounds)
+        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
+        self.seed = 42
+        torch.manual_seed(self.seed)
+        self.batch_size = 128
+
+    def build_model(self) -> Module:
+        net = ConvNet()
+        return net.to(self.device)
+
+    def build_optimizer(self, model: Module) -> Optimizer:
+        learning_rate = 0.01
+        momentum = 0.9
+        return SGD(model.parameters(), lr=learning_rate, momentum=momentum)
+    
+    def build_public_train_dataloader(self) -> DataLoader:
+        dataset = MNIST(
+            get_dataset_dir(self.task_id),
+            train=True,
+            download=True,
+            transform=transforms.Compose([
+                transforms.ToTensor(),
+                transforms.Normalize((0.1307,), (0.3081,))
+            ])
+        )
+        return DataLoader(
+            Subset(dataset=dataset, indices=list(range(50000))),
+            batch_size=self.batch_size,
+            shuffle=False
+        )
+    
+    def build_private_train_dataloader(self) -> DataLoader:
+        dataset = MNIST(
+            get_dataset_dir(self.task_id),
+            train=True,
+            download=True,
+            transform=transforms.Compose([
+                transforms.ToTensor(),
+                transforms.Normalize((0.1307,), (0.3081,))
+            ])
+        )
+        return DataLoader(
+            Subset(dataset=dataset, indices=list(range(50000, 60000))),
+            batch_size=self.batch_size,
+            shuffle=True
+        )
+    
+    def build_test_dataloader(self) -> DataLoader:
+        return DataLoader(
+            MNIST(
+                get_dataset_dir(self.task_id),
+                train=False,
+                download=True,
+                transform=transforms.Compose([
+                    transforms.ToTensor(),
+                    transforms.Normalize((0.1307,), (0.3081,))
+                ])
+            ),
+            batch_size=self.batch_size,
+            shuffle=False
+        )
+
+    @torch.no_grad()
+    def calc_local_logits(self) -> Tensor:
+        logits = []
+        self.model.eval()
+        for data, _ in self.public_train_loader:
+            data: Tensor
+            data = data.to(self.device)
+            logits.append(self.model(data))
+        return torch.cat(logits, dim=0)
+
+    def pretrain_an_epoch_on_public_data(self):
+        self.model.train()
+        for data, labels in self.public_train_loader:
+            data: Tensor
+            labels: Tensor
+            data, labels = data.to(self.device), labels.to(self.device)
+            self.optimizer.zero_grad()
+            output = self.model(data)
+            loss = F.nll_loss(output, labels)
+            loss.backward()
+            self.optimizer.step()
+
+    def pretrain_an_epoch_on_private_data(self):
+        self.model.train()
+        for data, labels in self.private_train_loader:
+            data: Tensor
+            labels: Tensor
+            data, labels = data.to(self.device), labels.to(self.device)
+            self.optimizer.zero_grad()
+            output = self.model(data)
+            loss = F.nll_loss(output, labels)
+            loss.backward()
+            self.optimizer.step()
+
+    def align_train_an_epoch(self, global_logits: Tensor):
+        self.model.train()
+        
+        # re-organize global_logits into batches
+        chunks = math.ceil(len(global_logits) / self.batch_size)
+        logits_batches = torch.chunk(input=global_logits, chunks=chunks, dim=0)
+        
+        for (data, labels), teacher_logits in zip(self.public_train_loader, logits_batches):
+            data: Tensor
+            labels: Tensor
+            data, labels = data.to(self.device), labels.to(self.device)
+            teacher_logits = teacher_logits.to(self.device)
+            self.optimizer.zero_grad()
+            output = self.model(data)            
+            loss = loss_kd(output, labels, teacher_logits)
+            loss.backward()
+            self.optimizer.step()
+
+    def fine_tune_an_epoch(self):
+        self.pretrain_an_epoch_on_private_data()
+
+    def run_test(self):
+        start = time()
+        self.model.eval()
+        test_loss = 0
+        correct = 0
+        with torch.no_grad():
+            for data, labels in self.test_loader:
+                data: torch.Tensor
+                labels: torch.Tensor
+                data, labels = data.to(self.device), labels.to(self.device)
+                output: torch.Tensor = self.model(data)
+                test_loss += F.nll_loss(output, labels, reduction='sum').item()
+                pred = output.max(1, keepdim=True)[1]
+                correct += pred.eq(labels.view_as(pred)).sum().item()
+
+        test_loss /= len(self.test_loader.dataset)
+        accuracy = correct / len(self.test_loader.dataset)
+        correct_rate = 100. * accuracy
+        logger.info(f'Test set: Average loss: {test_loss:.4f}')
+        logger.info(
+            f'Test set: Accuracy: {accuracy} ({correct_rate:.2f}%)'
+        )
+
+        end = time()
+
+        self.tb_writer.add_scalar('timer/run_time', end - start, self.current_round)
+        self.tb_writer.add_scalar('test_results/average_loss', test_loss, self.current_round)
+        self.tb_writer.add_scalar('test_results/accuracy', accuracy, self.current_round)
+        self.tb_writer.add_scalar('test_results/correct_rate', correct_rate, self.current_round)
+
+
+def get_task_id() -> str:
+    return DEV_TASK_ID
+
+
+def get_scheduler() -> DemoHomoFedMDScheduler:
+    pickle_file = './scheduler.pickle'
+    import cloudpickle as pickle
+
+    if os.path.exists(pickle_file):
+        os.remove(pickle_file)
+
+    scheduler = DemoHomoFedMDScheduler(max_rounds=3,
+                                       pretrain_public_epochs=1,
+                                       pretrain_private_epochs=2,
+                                       align_epochs=1,
+                                       fine_tune_epochs=2,
+                                       log_rounds=1)
+
+    with open(pickle_file, 'wb') as pf:
+        pickle.dump(scheduler, pf)
+
+    with open(pickle_file, 'rb') as f:
+        scheduler = pickle.load(f)
+        return scheduler
```

### Comparing `alphamed-federated-0.4.7/src/alphafed/examples/fed_md/model/contractor.py` & `alphamed-federated-0.4.9/src/alphafed/examples/fed_md/model/contractor.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/examples/fed_md/model/my_homo_fed_md_impl.py` & `alphamed-federated-0.4.9/src/alphafed/examples/fed_md/model/my_homo_fed_md_impl.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/examples/fed_md/model/net.py` & `alphamed-federated-0.4.9/src/alphafed/examples/fed_md/model/net.py`

 * *Ordering differences only*

 * *Files 10% similar despite different names*

```diff
@@ -1,21 +1,21 @@
-from torch import nn
-import torch.nn.functional as F
-
-
-class ConvNet(nn.Module):
-    def __init__(self) -> None:
-        super().__init__()
-        self.conv1 = nn.Conv2d(in_channels=1, out_channels=10, kernel_size=5)
-        self.conv2 = nn.Conv2d(in_channels=10, out_channels=20, kernel_size=5)
-        self.conv2_drop = nn.Dropout2d()
-        self.fc1 = nn.Linear(in_features=320, out_features=50)
-        self.fc2 = nn.Linear(in_features=50, out_features=10)
-
-    def forward(self, x):
-        x = F.relu(F.max_pool2d(self.conv1(x), 2))
-        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))
-        x = x.view(-1, 320)
-        x = F.relu(self.fc1(x))
-        x = F.dropout(x, training=self.training)
-        x = self.fc2(x)
-        return F.log_softmax(x, dim=-1)
+from torch import nn
+import torch.nn.functional as F
+
+
+class ConvNet(nn.Module):
+    def __init__(self) -> None:
+        super().__init__()
+        self.conv1 = nn.Conv2d(in_channels=1, out_channels=10, kernel_size=5)
+        self.conv2 = nn.Conv2d(in_channels=10, out_channels=20, kernel_size=5)
+        self.conv2_drop = nn.Dropout2d()
+        self.fc1 = nn.Linear(in_features=320, out_features=50)
+        self.fc2 = nn.Linear(in_features=50, out_features=10)
+
+    def forward(self, x):
+        x = F.relu(F.max_pool2d(self.conv1(x), 2))
+        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))
+        x = x.view(-1, 320)
+        x = F.relu(self.fc1(x))
+        x = F.dropout(x, training=self.training)
+        x = self.fc2(x)
+        return F.log_softmax(x, dim=-1)
```

### Comparing `alphamed-federated-0.4.7/src/alphafed/examples/fed_md/model/scheduler.py` & `alphamed-federated-0.4.9/src/alphafed/examples/fed_md/model/scheduler.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/examples/fed_md/run_aggregator.py` & `alphamed-federated-0.4.9/src/alphafed/examples/fed_md/run_aggregator.py`

 * *Ordering differences only*

 * *Files 24% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-import os
-import sys
-
-CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
-PYTHONPATH = os.path.join(CURRENT_DIR, os.pardir, os.pardir, os.pardir)
-sys.path.insert(0, PYTHONPATH)
-
-if True:
-    from alphafed import logger
-    from alphafed.examples.fed_md import AGGREGATOR_ID
-    from alphafed.examples.fed_md.demos import (get_scheduler, get_task_id)
-
-
-task_id = get_task_id()
-scheduler = get_scheduler()
-logger.debug(f'{type(scheduler)=}')
-scheduler._run(id=AGGREGATOR_ID, task_id=task_id, is_initiator=True)
+import os
+import sys
+
+CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
+PYTHONPATH = os.path.join(CURRENT_DIR, os.pardir, os.pardir, os.pardir)
+sys.path.insert(0, PYTHONPATH)
+
+if True:
+    from alphafed import logger
+    from alphafed.examples.fed_md import AGGREGATOR_ID
+    from alphafed.examples.fed_md.demos import (get_scheduler, get_task_id)
+
+
+task_id = get_task_id()
+scheduler = get_scheduler()
+logger.debug(f'{type(scheduler)=}')
+scheduler._run(id=AGGREGATOR_ID, task_id=task_id, is_initiator=True)
```

### Comparing `alphamed-federated-0.4.7/src/alphafed/examples/fed_per/__init__.py` & `alphamed-federated-0.4.9/src/alphafed/examples/fed_per/__init__.py`

 * *Ordering differences only*

 * *Files 12% similar despite different names*

```diff
@@ -1,16 +1,16 @@
-# CPU mode
-DEV_TASK_ID = 'd041d19f-59d0-467f-bc6c-7f5cf42436c2'
-
-AGGREGATOR_ID = 'QmXLxxW7W1cxdU7eeeq5yRXte53zekxiTRApSWxxssdzQP'
-DATA_OWNER_2_ID = 'QmUXV1ds7mNfZ5udaLauubMC5ve4mGpuwS6sTy6Keh2VJN'
-DATA_OWNER_3_ID = 'QmXG7aTnKk1AcLhKmauCkYpYafoxj1dG5xLBnCQNniuaeF'
-DATA_OWNER_4_ID = 'QmfFQ1CDXU8kYGMSkqPGqMw7NfnjGsfr3jPU9GbSBY4P3J'
-DATA_OWNER_5_ID = 'QmYX5KatFyFve3xVjadX2h7fEt1SzpdA8wnQsQ4v9muCyR'
-
-# GPU mode
-# DEV_TASK_ID = '45b0eb180eb34ba7a77f6df36fbf9e1b'
-
-# AGGREGATOR_ID = 'QmQERKLbhy2bbhWA6eSd4ENpr37BA7G3xzbm6BJqsERJ58'
-# DATA_OWNER_3_ID = 'QmPUhKyCbQ7V73gMNVUaGVnqsVbkNFxSotS7pEEFD8X1SP'
-# DATA_OWNER_4_ID = 'QmScck6og9ZRqeSKTqUpe4Phub45mxFeUHGysV2DWCouEg'
-# DATA_OWNER_5_ID = 'QmNwzJAbWSkcjdi2PS1wGCgbnZAxEdiwDtF8ZPVBn9EFGq'
+# CPU mode
+DEV_TASK_ID = 'd041d19f-59d0-467f-bc6c-7f5cf42436c2'
+
+AGGREGATOR_ID = 'QmXLxxW7W1cxdU7eeeq5yRXte53zekxiTRApSWxxssdzQP'
+DATA_OWNER_2_ID = 'QmUXV1ds7mNfZ5udaLauubMC5ve4mGpuwS6sTy6Keh2VJN'
+DATA_OWNER_3_ID = 'QmXG7aTnKk1AcLhKmauCkYpYafoxj1dG5xLBnCQNniuaeF'
+DATA_OWNER_4_ID = 'QmfFQ1CDXU8kYGMSkqPGqMw7NfnjGsfr3jPU9GbSBY4P3J'
+DATA_OWNER_5_ID = 'QmYX5KatFyFve3xVjadX2h7fEt1SzpdA8wnQsQ4v9muCyR'
+
+# GPU mode
+# DEV_TASK_ID = '45b0eb180eb34ba7a77f6df36fbf9e1b'
+
+# AGGREGATOR_ID = 'QmQERKLbhy2bbhWA6eSd4ENpr37BA7G3xzbm6BJqsERJ58'
+# DATA_OWNER_3_ID = 'QmPUhKyCbQ7V73gMNVUaGVnqsVbkNFxSotS7pEEFD8X1SP'
+# DATA_OWNER_4_ID = 'QmScck6og9ZRqeSKTqUpe4Phub45mxFeUHGysV2DWCouEg'
+# DATA_OWNER_5_ID = 'QmNwzJAbWSkcjdi2PS1wGCgbnZAxEdiwDtF8ZPVBn9EFGq'
```

### Comparing `alphamed-federated-0.4.7/src/alphafed/examples/fed_per/demos.py` & `alphamed-federated-0.4.9/src/alphafed/examples/fed_per/demos.py`

 * *Ordering differences only*

 * *Files 18% similar despite different names*

```diff
@@ -1,160 +1,160 @@
-"""Process demo."""
-
-import os
-from time import time
-
-import torch
-import torch.nn as nn
-import torch.nn.functional as F
-import torchvision
-from torch import optim
-from torch.utils.data import DataLoader
-
-from ... import get_dataset_dir, logger
-from .model.scheduler import HomoFedPerScheduler
-from .model.net import GlobalNet, PersonalizedLayer
-from . import DEV_TASK_ID
-
-CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
-
-
-class DemoHomoFedPerScheduler(HomoFedPerScheduler):
-
-    def __init__(self,
-                 max_rounds: int = 0,
-                 merge_epochs: int = 1,
-                 batch_size: int = 64,
-                 learning_rate: float = 0.01,
-                 momentum: float = 0.5,
-                 schedule_timeout: int = 30,
-                 calculation_timeout: int = 300,
-                 log_rounds: int = 0) -> None:
-        super().__init__(max_rounds=max_rounds,
-                         merge_epochs=merge_epochs,
-                         schedule_timeout=schedule_timeout,
-                         calculation_timeout=calculation_timeout,
-                         log_rounds=log_rounds)
-        self.batch_size = batch_size
-        self.learning_rate = learning_rate
-        self.momentum = momentum
-
-        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
-        self.seed = 42
-        torch.manual_seed(self.seed)
-
-    def build_global_model(self) -> nn.Module:
-        model = GlobalNet()
-        return model.to(self.device)
-    
-    def build_personalized_layer(self) -> nn.Module:
-        model = PersonalizedLayer()
-        return model.to(self.device)
-
-    def build_optimizer(self, model: nn.Module) -> optim.Optimizer:
-        return optim.SGD(model.parameters(),
-                         lr=self.learning_rate,
-                         momentum=self.momentum)
-
-    def build_train_dataloader(self) -> DataLoader:
-        return DataLoader(
-            torchvision.datasets.MNIST(
-                get_dataset_dir(self.task_id),
-                train=True,
-                download=True,
-                transform=torchvision.transforms.Compose([
-                    torchvision.transforms.ToTensor(),
-                    torchvision.transforms.Normalize((0.1307,), (0.3081,))
-                ])
-            ),
-            batch_size=self.batch_size,
-            shuffle=True
-        )
-
-    def build_test_dataloader(self) -> DataLoader:
-        return DataLoader(
-            torchvision.datasets.MNIST(
-                get_dataset_dir(self.task_id),
-                train=False,
-                download=True,
-                transform=torchvision.transforms.Compose([
-                    torchvision.transforms.ToTensor(),
-                    torchvision.transforms.Normalize((0.1307,), (0.3081,))
-                ])
-            ),
-            batch_size=self.batch_size,
-            shuffle=False
-        )
-
-    def validate_context(self):
-        super().validate_context()
-        assert self.train_loader and len(self.train_loader) > 0, 'failed to load train data'
-        logger.info(f'There are {len(self.train_loader.dataset)} samples for training.')
-        assert self.test_loader and len(self.test_loader) > 0, 'failed to load test data'
-        logger.info(f'There are {len(self.test_loader.dataset)} samples for testing.')
-
-    def train_an_epoch(self) -> None:
-        self.model.train()
-        for data, labels in self.train_loader:
-            data: torch.Tensor
-            labels: torch.Tensor
-            data, labels = data.to(self.device), labels.to(self.device)
-            self.optimizer.zero_grad()
-            output = self.model(data)
-            loss = F.nll_loss(output, labels)
-            loss.backward()
-            self.optimizer.step()
-
-    def run_test(self):
-        start = time()
-        self.model.eval()
-        test_loss = 0
-        correct = 0
-        with torch.no_grad():
-            for data, labels in self.test_loader:
-                data: torch.Tensor
-                labels: torch.Tensor
-                data, labels = data.to(self.device), labels.to(self.device)
-                output: torch.Tensor = self.model(data)
-                test_loss += F.nll_loss(output, labels, reduction='sum').item()
-                pred = output.max(1, keepdim=True)[1]
-                correct += pred.eq(labels.view_as(pred)).sum().item()
-
-        test_loss /= len(self.test_loader.dataset)
-        accuracy = correct / len(self.test_loader.dataset)
-        correct_rate = 100. * accuracy
-        logger.info(f'Test set: Average loss: {test_loss:.4f}')
-        logger.info(
-            f'Test set: Accuracy: {accuracy} ({correct_rate:.2f}%)'
-        )
-
-        end = time()
-
-        self.tb_writer.add_scalar('timer/run_time', end - start, self.current_round)
-        self.tb_writer.add_scalar('test_results/average_loss', test_loss, self.current_round)
-        self.tb_writer.add_scalar('test_results/accuracy', accuracy, self.current_round)
-        self.tb_writer.add_scalar('test_results/correct_rate', correct_rate, self.current_round)
-
-
-def get_task_id() -> str:
-    return DEV_TASK_ID
-
-
-def get_scheduler() -> HomoFedPerScheduler:
-    pickle_file = './scheduler.pickle'
-    import cloudpickle as pickle
-
-    if os.path.exists(pickle_file):
-        os.remove(pickle_file)
-
-    scheduler = DemoHomoFedPerScheduler(max_rounds=5,
-                                        merge_epochs=1,
-                                        batch_size=128,
-                                        learning_rate=0.01,
-                                        momentum=0.9)
-
-    with open(pickle_file, 'wb') as pf:
-        pickle.dump(scheduler, pf)
-
-    with open(pickle_file, 'rb') as f:
-        scheduler = pickle.load(f)
-        return scheduler
+"""Process demo."""
+
+import os
+from time import time
+
+import torch
+import torch.nn as nn
+import torch.nn.functional as F
+import torchvision
+from torch import optim
+from torch.utils.data import DataLoader
+
+from ... import get_dataset_dir, logger
+from .model.scheduler import HomoFedPerScheduler
+from .model.net import GlobalNet, PersonalizedLayer
+from . import DEV_TASK_ID
+
+CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
+
+
+class DemoHomoFedPerScheduler(HomoFedPerScheduler):
+
+    def __init__(self,
+                 max_rounds: int = 0,
+                 merge_epochs: int = 1,
+                 batch_size: int = 64,
+                 learning_rate: float = 0.01,
+                 momentum: float = 0.5,
+                 schedule_timeout: int = 30,
+                 calculation_timeout: int = 300,
+                 log_rounds: int = 0) -> None:
+        super().__init__(max_rounds=max_rounds,
+                         merge_epochs=merge_epochs,
+                         schedule_timeout=schedule_timeout,
+                         calculation_timeout=calculation_timeout,
+                         log_rounds=log_rounds)
+        self.batch_size = batch_size
+        self.learning_rate = learning_rate
+        self.momentum = momentum
+
+        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
+        self.seed = 42
+        torch.manual_seed(self.seed)
+
+    def build_global_model(self) -> nn.Module:
+        model = GlobalNet()
+        return model.to(self.device)
+    
+    def build_personalized_layer(self) -> nn.Module:
+        model = PersonalizedLayer()
+        return model.to(self.device)
+
+    def build_optimizer(self, model: nn.Module) -> optim.Optimizer:
+        return optim.SGD(model.parameters(),
+                         lr=self.learning_rate,
+                         momentum=self.momentum)
+
+    def build_train_dataloader(self) -> DataLoader:
+        return DataLoader(
+            torchvision.datasets.MNIST(
+                get_dataset_dir(self.task_id),
+                train=True,
+                download=True,
+                transform=torchvision.transforms.Compose([
+                    torchvision.transforms.ToTensor(),
+                    torchvision.transforms.Normalize((0.1307,), (0.3081,))
+                ])
+            ),
+            batch_size=self.batch_size,
+            shuffle=True
+        )
+
+    def build_test_dataloader(self) -> DataLoader:
+        return DataLoader(
+            torchvision.datasets.MNIST(
+                get_dataset_dir(self.task_id),
+                train=False,
+                download=True,
+                transform=torchvision.transforms.Compose([
+                    torchvision.transforms.ToTensor(),
+                    torchvision.transforms.Normalize((0.1307,), (0.3081,))
+                ])
+            ),
+            batch_size=self.batch_size,
+            shuffle=False
+        )
+
+    def validate_context(self):
+        super().validate_context()
+        assert self.train_loader and len(self.train_loader) > 0, 'failed to load train data'
+        logger.info(f'There are {len(self.train_loader.dataset)} samples for training.')
+        assert self.test_loader and len(self.test_loader) > 0, 'failed to load test data'
+        logger.info(f'There are {len(self.test_loader.dataset)} samples for testing.')
+
+    def train_an_epoch(self) -> None:
+        self.model.train()
+        for data, labels in self.train_loader:
+            data: torch.Tensor
+            labels: torch.Tensor
+            data, labels = data.to(self.device), labels.to(self.device)
+            self.optimizer.zero_grad()
+            output = self.model(data)
+            loss = F.nll_loss(output, labels)
+            loss.backward()
+            self.optimizer.step()
+
+    def run_test(self):
+        start = time()
+        self.model.eval()
+        test_loss = 0
+        correct = 0
+        with torch.no_grad():
+            for data, labels in self.test_loader:
+                data: torch.Tensor
+                labels: torch.Tensor
+                data, labels = data.to(self.device), labels.to(self.device)
+                output: torch.Tensor = self.model(data)
+                test_loss += F.nll_loss(output, labels, reduction='sum').item()
+                pred = output.max(1, keepdim=True)[1]
+                correct += pred.eq(labels.view_as(pred)).sum().item()
+
+        test_loss /= len(self.test_loader.dataset)
+        accuracy = correct / len(self.test_loader.dataset)
+        correct_rate = 100. * accuracy
+        logger.info(f'Test set: Average loss: {test_loss:.4f}')
+        logger.info(
+            f'Test set: Accuracy: {accuracy} ({correct_rate:.2f}%)'
+        )
+
+        end = time()
+
+        self.tb_writer.add_scalar('timer/run_time', end - start, self.current_round)
+        self.tb_writer.add_scalar('test_results/average_loss', test_loss, self.current_round)
+        self.tb_writer.add_scalar('test_results/accuracy', accuracy, self.current_round)
+        self.tb_writer.add_scalar('test_results/correct_rate', correct_rate, self.current_round)
+
+
+def get_task_id() -> str:
+    return DEV_TASK_ID
+
+
+def get_scheduler() -> HomoFedPerScheduler:
+    pickle_file = './scheduler.pickle'
+    import cloudpickle as pickle
+
+    if os.path.exists(pickle_file):
+        os.remove(pickle_file)
+
+    scheduler = DemoHomoFedPerScheduler(max_rounds=5,
+                                        merge_epochs=1,
+                                        batch_size=128,
+                                        learning_rate=0.01,
+                                        momentum=0.9)
+
+    with open(pickle_file, 'wb') as pf:
+        pickle.dump(scheduler, pf)
+
+    with open(pickle_file, 'rb') as f:
+        scheduler = pickle.load(f)
+        return scheduler
```

### Comparing `alphamed-federated-0.4.7/src/alphafed/examples/fed_per/model/contractor.py` & `alphamed-federated-0.4.9/src/alphafed/examples/fed_per/model/contractor.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/examples/fed_per/model/my_homo_fed_per_impl.py` & `alphamed-federated-0.4.9/src/alphafed/examples/fed_per/model/my_homo_fed_per_impl.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/examples/fed_per/model/net.py` & `alphamed-federated-0.4.9/src/alphafed/examples/fed_per/model/net.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/examples/fed_per/model/scheduler.py` & `alphamed-federated-0.4.9/src/alphafed/examples/fed_per/model/scheduler.py`

 * *Ordering differences only*

 * *Files 21% similar despite different names*

```diff
@@ -1,275 +1,275 @@
-"""HomoFedPer Scheduler."""
-import io
-import json
-import os
-import sys
-import traceback
-from abc import abstractmethod
-from typing import Dict, Tuple, final
-from zipfile import ZipFile
-
-import torch
-from torch.nn import Module, Sequential
-
-from alphafed import logger
-from alphafed.fed_avg import FedAvgScheduler
-from alphafed.fed_avg.fed_avg import ResetRound, SkipRound
-from alphafed.scheduler import TaskComplete, TaskFailed
-
-from .contractor import CollaboratorCompleteEvent, HomoFedPerContractor
-
-
-class HomoFedPerScheduler(FedAvgScheduler):
-
-    _FINISHED = 'finished'
-
-    def __init__(self,
-                 max_rounds: int = 0,
-                 merge_epochs: int = 1,
-                 calculation_timeout: int = 300,
-                 schedule_timeout: int = 30,
-                 log_rounds: int = 0):
-        super().__init__(max_rounds=max_rounds,
-                         merge_epochs=merge_epochs,
-                         calculation_timeout=calculation_timeout,
-                         schedule_timeout=schedule_timeout,
-                         log_rounds=log_rounds,
-                         involve_aggregator=False)
-
-    def _init_contractor(self) -> HomoFedPerContractor:
-        return HomoFedPerContractor(task_id=self.task_id)
-
-    @abstractmethod
-    def build_global_model(self) -> Module:
-        """Return a global model object which will be used for training."""
-
-    @final
-    @property
-    def global_model(self) -> Module:
-        """Get the model object which is used for training."""
-        if not hasattr(self, '_global_model'):
-            self._global_model = self.build_global_model()
-        return self._global_model
-
-    @abstractmethod
-    def build_personalized_layer(self) -> Module:
-        """Return a personalized layer object which will be used for training."""
-
-    @final
-    @property
-    def personalized_layer(self) -> Module:
-        """Get the model object which is used for training."""
-        if not hasattr(self, '_personalized_layer'):
-            self._personalized_layer = self.build_personalized_layer()
-        return self._personalized_layer
-
-    @final
-    def build_model(self) -> Module:
-        if self.is_aggregator:
-            return self.global_model
-        else:
-            return Sequential(
-                self.global_model,
-                self.personalized_layer
-            )
-
-    def state_dict(self) -> Dict[str, torch.Tensor]:
-        return self.global_model.state_dict()
-
-    def load_state_dict(self, state_dict: Dict[str, torch.Tensor]):
-        return self.global_model.load_state_dict(state_dict)
-
-    def _run(self, id: str, task_id: str, is_initiator: bool = False, recover: bool = False):
-        self._setup_context(id=id, task_id=task_id, is_initiator=is_initiator)
-        self.push_log(message='Local context is ready.')
-        try:
-            if recover:
-                self._recover_progress()
-            else:
-                self._clean_progress()
-            self._launch_process()
-        except Exception:
-            err_stack = '\n'.join(traceback.format_exception(*sys.exc_info()))
-            self.push_log(err_stack)
-
-    def _recover_progress(self):
-        """Try to recover and continue from last running."""
-        if not os.path.isfile(self._context_file):
-            raise TaskFailed('Failed to recover progress: missing cached context.')
-
-        with open(self._context_file, 'r') as f:
-            context_info: dict = json.load(f)
-        round = context_info.get('round')
-        ckpt_file = context_info.get('ckpt_file')
-        assert round and isinstance(round, int) and round > 0, f'Invalid round: {round} .'
-        assert ckpt_file and isinstance(ckpt_file, str), f'Invalid ckpt_file: {ckpt_file} .'
-        if not os.path.isfile(ckpt_file):
-            raise TaskFailed('Failed to recover progress: missing checkpoint parameters.')
-
-        self.current_round = round
-        with open(ckpt_file, 'rb') as f:
-            state_dict = torch.load(f)
-            if self.is_aggregator:
-                self.global_model.load_state_dict(state_dict)
-            else:
-                self.model.load_state_dict(state_dict)
-
-    def _save_model(self):
-        """Save latest model state."""
-        with open(self._ckpt_file, 'wb') as f:
-            if self.is_aggregator:
-                torch.save(self.global_model.state_dict(), f)
-            else:
-                torch.save(self.model.state_dict(), f)
-        self.push_log('Saved latest parameters locally.')
-
-    def _launch_process(self):
-        try:
-            assert self.status == self._INIT, 'must begin from initial status'
-            self.push_log(f'Node {self.id} is up.')
-
-            self._switch_status(self._GETHORING)
-            self._check_in()
-
-            self._switch_status(self._READY)
-            while self.status == self._READY:
-                try:
-                    self._switch_status(self._SYNCHRONIZING)
-                    self._sync_state()
-
-                    self._switch_status(self._IN_A_ROUND)
-                    self._run_a_round()
-                    self._persistent_running_context()
-                    self._switch_status(self._READY)
-                except ResetRound:
-                    self.push_log('WARNING: Reset runtime context, there might be an error raised.')
-                    self._switch_status(self._READY)
-                    continue
-
-                if self.is_aggregator:
-                    is_finished = self.is_task_finished()
-                    self._switch_status(self._READY)
-                    self.current_round += 1
-                    if is_finished:
-                        self.push_log(f'Obtained the final results of task {self.task_id}')
-                        self._switch_status(self._FINISHING)
-                        self._close_task()  # 聚合方退出
-
-        except TaskComplete:
-            self._close_task()  # 数据持有方退出
-            logger.info('training task complete')
-
-    def _check_and_run_test(self):
-        """Run test if match configured conditions."""
-        if self.is_aggregator:
-            return
-        if (
-            self.current_round == 1
-            or (self.log_rounds > 0 and self.current_round % self.log_rounds == 0)
-            or self.current_round == self.max_rounds
-        ):
-            self.push_log('Begin to make a model test.')
-            self.run_test()
-            self.push_log('Finished a round of test.')
-
-    def _close_task(self):
-        """Close the FedAvg calculation.
-
-        As an aggregator, broadcasts the finish task event to all participants,
-        uploads the final parameters and tells L1 task manager the task is complete.
-        As a participant, do nothing.
-        """
-        self.push_log(f'Closing task {self.task_id} ...')
-        self.contractor: HomoFedPerContractor
-        if self.is_aggregator:
-            # 任务成功结束，聚合方处理
-            self.contractor.finish_task()
-            _, model_file_path = self._prepare_task_output()
-            # 报告上传和模型上传
-            self.contractor.upload_metric_report(receivers=[self.id])
-            self.contractor.upload_model(receivers=[self.id],
-                                         model_file=model_file_path)
-            self._wait_for_all_complete()
-            self.contractor.notify_task_completion(result=True)
-
-        else:  # 数据持有方
-            report_file_path, model_file_path = self._prepare_task_output()
-            # 报告上传和模型上传
-            self.contractor.upload_metric_report(receivers=[self.id],
-                                                 report_file=report_file_path)
-            self.contractor.upload_model(receivers=[self.id],
-                                         model_file=model_file_path)
-            self.contractor.notify_collaborator_complete(peer_id=self.id, host=self._aggregator)
-        self._switch_status(self._FINISHED)
-        self.push_log(f'Task {self.task_id} closed. Byebye!')
-
-    def _prepare_task_output(self) -> Tuple[str, str]:
-        """Generate final output files of the task.
-
-        Return:
-            Local paths of the report file and model file.
-        """
-        self.push_log('Uploading task achievement and closing task ...')
-
-        report_file_path = None
-        if not self.is_aggregator:
-            report_file = os.path.join(self._result_dir, "report.zip")
-            with ZipFile(report_file, 'w') as report_zip:
-                for path, _, filenames in os.walk(self._log_dir):
-                    rel_dir = os.path.relpath(path=path, start=self._result_dir)
-                    rel_dir = rel_dir.lstrip('.')  # ./file => file
-                    for _file in filenames:
-                        rel_path = os.path.join(rel_dir, _file)
-                        report_zip.write(os.path.join(path, _file), rel_path)
-            report_file_path = os.path.abspath(report_file)
-
-        model_file = os.path.join(
-            self._result_dir,
-            "global_model.pt" if self.is_aggregator else "personalized_model.pt"
-        )
-        with open(model_file, 'wb') as f:
-            torch.save(self.global_model.state_dict() if self.is_aggregator else self.model.state_dict(), f)
-        model_file_path = os.path.abspath(model_file)
-
-        self.push_log('Task achievement files are ready.')
-        return report_file_path, model_file_path
-
-    def _wait_for_all_complete(self):
-        """Wait for all collaborators complete their tasks."""
-        self.push_log('Waiting for all collaborators complete their tasks ...')
-        results = {_peer_id: False for _peer_id in self.participants if _peer_id != self.id}
-        for _event in self.contractor.contract_events():
-            if isinstance(_event, CollaboratorCompleteEvent):
-                results[_event.peer_id] = True
-                if all(results.values()):
-                    break
-        self.push_log('All collaborators have completed their tasks.')
-
-    def _run_as_data_owner(self):
-        try:
-            self._wait_for_starting_round()
-            self._switch_status(self._UPDATING)
-            self._wait_for_updating_model()
-            self._save_model()
-            self._switch_status(self._CALCULATING)
-            self.push_log('Begin to run calculation ...')
-            self._execute_training()
-            self.push_log('Local calculation complete.')
-
-            self._wait_for_uploading_model()
-            buffer = io.BytesIO()
-            torch.save(self.state_dict(), buffer)
-            self.push_log('Pushing local update to the aggregator ...')
-            self.data_channel.send_stream(source=self.id,
-                                          target=self._aggregator,
-                                          data_stream=buffer.getvalue())
-            self.push_log('Successfully pushed local update to the aggregator.')
-
-            self._check_and_run_test()
-
-            self._switch_status(self._CLOSING_ROUND)
-            self._wait_for_closing_round()
-        except SkipRound:
-            pass
-
-        self.push_log(f'ID: {self.id} finished training task of round {self.current_round}.')
+"""HomoFedPer Scheduler."""
+import io
+import json
+import os
+import sys
+import traceback
+from abc import abstractmethod
+from typing import Dict, Tuple, final
+from zipfile import ZipFile
+
+import torch
+from torch.nn import Module, Sequential
+
+from alphafed import logger
+from alphafed.fed_avg import FedAvgScheduler
+from alphafed.fed_avg.fed_avg import ResetRound, SkipRound
+from alphafed.scheduler import TaskComplete, TaskFailed
+
+from .contractor import CollaboratorCompleteEvent, HomoFedPerContractor
+
+
+class HomoFedPerScheduler(FedAvgScheduler):
+
+    _FINISHED = 'finished'
+
+    def __init__(self,
+                 max_rounds: int = 0,
+                 merge_epochs: int = 1,
+                 calculation_timeout: int = 300,
+                 schedule_timeout: int = 30,
+                 log_rounds: int = 0):
+        super().__init__(max_rounds=max_rounds,
+                         merge_epochs=merge_epochs,
+                         calculation_timeout=calculation_timeout,
+                         schedule_timeout=schedule_timeout,
+                         log_rounds=log_rounds,
+                         involve_aggregator=False)
+
+    def _init_contractor(self) -> HomoFedPerContractor:
+        return HomoFedPerContractor(task_id=self.task_id)
+
+    @abstractmethod
+    def build_global_model(self) -> Module:
+        """Return a global model object which will be used for training."""
+
+    @final
+    @property
+    def global_model(self) -> Module:
+        """Get the model object which is used for training."""
+        if not hasattr(self, '_global_model'):
+            self._global_model = self.build_global_model()
+        return self._global_model
+
+    @abstractmethod
+    def build_personalized_layer(self) -> Module:
+        """Return a personalized layer object which will be used for training."""
+
+    @final
+    @property
+    def personalized_layer(self) -> Module:
+        """Get the model object which is used for training."""
+        if not hasattr(self, '_personalized_layer'):
+            self._personalized_layer = self.build_personalized_layer()
+        return self._personalized_layer
+
+    @final
+    def build_model(self) -> Module:
+        if self.is_aggregator:
+            return self.global_model
+        else:
+            return Sequential(
+                self.global_model,
+                self.personalized_layer
+            )
+
+    def state_dict(self) -> Dict[str, torch.Tensor]:
+        return self.global_model.state_dict()
+
+    def load_state_dict(self, state_dict: Dict[str, torch.Tensor]):
+        return self.global_model.load_state_dict(state_dict)
+
+    def _run(self, id: str, task_id: str, is_initiator: bool = False, recover: bool = False):
+        self._setup_context(id=id, task_id=task_id, is_initiator=is_initiator)
+        self.push_log(message='Local context is ready.')
+        try:
+            if recover:
+                self._recover_progress()
+            else:
+                self._clean_progress()
+            self._launch_process()
+        except Exception:
+            err_stack = '\n'.join(traceback.format_exception(*sys.exc_info()))
+            self.push_log(err_stack)
+
+    def _recover_progress(self):
+        """Try to recover and continue from last running."""
+        if not os.path.isfile(self._context_file):
+            raise TaskFailed('Failed to recover progress: missing cached context.')
+
+        with open(self._context_file, 'r') as f:
+            context_info: dict = json.load(f)
+        round = context_info.get('round')
+        ckpt_file = context_info.get('ckpt_file')
+        assert round and isinstance(round, int) and round > 0, f'Invalid round: {round} .'
+        assert ckpt_file and isinstance(ckpt_file, str), f'Invalid ckpt_file: {ckpt_file} .'
+        if not os.path.isfile(ckpt_file):
+            raise TaskFailed('Failed to recover progress: missing checkpoint parameters.')
+
+        self.current_round = round
+        with open(ckpt_file, 'rb') as f:
+            state_dict = torch.load(f)
+            if self.is_aggregator:
+                self.global_model.load_state_dict(state_dict)
+            else:
+                self.model.load_state_dict(state_dict)
+
+    def _save_model(self):
+        """Save latest model state."""
+        with open(self._ckpt_file, 'wb') as f:
+            if self.is_aggregator:
+                torch.save(self.global_model.state_dict(), f)
+            else:
+                torch.save(self.model.state_dict(), f)
+        self.push_log('Saved latest parameters locally.')
+
+    def _launch_process(self):
+        try:
+            assert self.status == self._INIT, 'must begin from initial status'
+            self.push_log(f'Node {self.id} is up.')
+
+            self._switch_status(self._GETHORING)
+            self._check_in()
+
+            self._switch_status(self._READY)
+            while self.status == self._READY:
+                try:
+                    self._switch_status(self._SYNCHRONIZING)
+                    self._sync_state()
+
+                    self._switch_status(self._IN_A_ROUND)
+                    self._run_a_round()
+                    self._persistent_running_context()
+                    self._switch_status(self._READY)
+                except ResetRound:
+                    self.push_log('WARNING: Reset runtime context, there might be an error raised.')
+                    self._switch_status(self._READY)
+                    continue
+
+                if self.is_aggregator:
+                    is_finished = self.is_task_finished()
+                    self._switch_status(self._READY)
+                    self.current_round += 1
+                    if is_finished:
+                        self.push_log(f'Obtained the final results of task {self.task_id}')
+                        self._switch_status(self._FINISHING)
+                        self._close_task()  # 聚合方退出
+
+        except TaskComplete:
+            self._close_task()  # 数据持有方退出
+            logger.info('training task complete')
+
+    def _check_and_run_test(self):
+        """Run test if match configured conditions."""
+        if self.is_aggregator:
+            return
+        if (
+            self.current_round == 1
+            or (self.log_rounds > 0 and self.current_round % self.log_rounds == 0)
+            or self.current_round == self.max_rounds
+        ):
+            self.push_log('Begin to make a model test.')
+            self.run_test()
+            self.push_log('Finished a round of test.')
+
+    def _close_task(self):
+        """Close the FedAvg calculation.
+
+        As an aggregator, broadcasts the finish task event to all participants,
+        uploads the final parameters and tells L1 task manager the task is complete.
+        As a participant, do nothing.
+        """
+        self.push_log(f'Closing task {self.task_id} ...')
+        self.contractor: HomoFedPerContractor
+        if self.is_aggregator:
+            # 任务成功结束，聚合方处理
+            self.contractor.finish_task()
+            _, model_file_path = self._prepare_task_output()
+            # 报告上传和模型上传
+            self.contractor.upload_metric_report(receivers=[self.id])
+            self.contractor.upload_model(receivers=[self.id],
+                                         model_file=model_file_path)
+            self._wait_for_all_complete()
+            self.contractor.notify_task_completion(result=True)
+
+        else:  # 数据持有方
+            report_file_path, model_file_path = self._prepare_task_output()
+            # 报告上传和模型上传
+            self.contractor.upload_metric_report(receivers=[self.id],
+                                                 report_file=report_file_path)
+            self.contractor.upload_model(receivers=[self.id],
+                                         model_file=model_file_path)
+            self.contractor.notify_collaborator_complete(peer_id=self.id, host=self._aggregator)
+        self._switch_status(self._FINISHED)
+        self.push_log(f'Task {self.task_id} closed. Byebye!')
+
+    def _prepare_task_output(self) -> Tuple[str, str]:
+        """Generate final output files of the task.
+
+        Return:
+            Local paths of the report file and model file.
+        """
+        self.push_log('Uploading task achievement and closing task ...')
+
+        report_file_path = None
+        if not self.is_aggregator:
+            report_file = os.path.join(self._result_dir, "report.zip")
+            with ZipFile(report_file, 'w') as report_zip:
+                for path, _, filenames in os.walk(self._log_dir):
+                    rel_dir = os.path.relpath(path=path, start=self._result_dir)
+                    rel_dir = rel_dir.lstrip('.')  # ./file => file
+                    for _file in filenames:
+                        rel_path = os.path.join(rel_dir, _file)
+                        report_zip.write(os.path.join(path, _file), rel_path)
+            report_file_path = os.path.abspath(report_file)
+
+        model_file = os.path.join(
+            self._result_dir,
+            "global_model.pt" if self.is_aggregator else "personalized_model.pt"
+        )
+        with open(model_file, 'wb') as f:
+            torch.save(self.global_model.state_dict() if self.is_aggregator else self.model.state_dict(), f)
+        model_file_path = os.path.abspath(model_file)
+
+        self.push_log('Task achievement files are ready.')
+        return report_file_path, model_file_path
+
+    def _wait_for_all_complete(self):
+        """Wait for all collaborators complete their tasks."""
+        self.push_log('Waiting for all collaborators complete their tasks ...')
+        results = {_peer_id: False for _peer_id in self.participants if _peer_id != self.id}
+        for _event in self.contractor.contract_events():
+            if isinstance(_event, CollaboratorCompleteEvent):
+                results[_event.peer_id] = True
+                if all(results.values()):
+                    break
+        self.push_log('All collaborators have completed their tasks.')
+
+    def _run_as_data_owner(self):
+        try:
+            self._wait_for_starting_round()
+            self._switch_status(self._UPDATING)
+            self._wait_for_updating_model()
+            self._save_model()
+            self._switch_status(self._CALCULATING)
+            self.push_log('Begin to run calculation ...')
+            self._execute_training()
+            self.push_log('Local calculation complete.')
+
+            self._wait_for_uploading_model()
+            buffer = io.BytesIO()
+            torch.save(self.state_dict(), buffer)
+            self.push_log('Pushing local update to the aggregator ...')
+            self.data_channel.send_stream(source=self.id,
+                                          target=self._aggregator,
+                                          data_stream=buffer.getvalue())
+            self.push_log('Successfully pushed local update to the aggregator.')
+
+            self._check_and_run_test()
+
+            self._switch_status(self._CLOSING_ROUND)
+            self._wait_for_closing_round()
+        except SkipRound:
+            pass
+
+        self.push_log(f'ID: {self.id} finished training task of round {self.current_round}.')
```

### Comparing `alphamed-federated-0.4.7/src/alphafed/examples/fed_per/run_aggregator.py` & `alphamed-federated-0.4.9/src/alphafed/examples/fed_per/run_data_owner_2.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-import os
-import sys
-
-CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
-PYTHONPATH = os.path.join(CURRENT_DIR, os.pardir, os.pardir, os.pardir)
-sys.path.insert(0, PYTHONPATH)
-
-if True:
-    from alphafed import logger
-    from alphafed.examples.fed_per import AGGREGATOR_ID
-    from alphafed.examples.fed_per.demos import (get_scheduler, get_task_id)
-
-
-task_id = get_task_id()
-scheduler = get_scheduler()
-logger.debug(f'{type(scheduler)=}')
-scheduler._run(id=AGGREGATOR_ID, task_id=task_id, is_initiator=True)
+import os
+import sys
+
+CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
+PYTHONPATH = os.path.join(CURRENT_DIR, os.pardir, os.pardir, os.pardir)
+sys.path.insert(0, PYTHONPATH)
+
+if True:
+    from alphafed import logger
+    from alphafed.examples.fed_per import DATA_OWNER_2_ID
+    from alphafed.examples.fed_per.demos import (get_scheduler, get_task_id)
+
+
+task_id = get_task_id()
+scheduler = get_scheduler()
+logger.debug(f'{type(scheduler)=}')
+scheduler._run(id=DATA_OWNER_2_ID, task_id=task_id)
```

### Comparing `alphamed-federated-0.4.7/src/alphafed/examples/fed_prox/__init__.py` & `alphamed-federated-0.4.9/src/alphafed/examples/fed_prox/__init__.py`

 * *Ordering differences only*

 * *Files 12% similar despite different names*

```diff
@@ -1,16 +1,16 @@
-# CPU mode
-DEV_TASK_ID = 'd041d19f-59d0-467f-bc6c-7f5cf42436c2'
-
-AGGREGATOR_ID = 'QmXLxxW7W1cxdU7eeeq5yRXte53zekxiTRApSWxxssdzQP'
-DATA_OWNER_2_ID = 'QmUXV1ds7mNfZ5udaLauubMC5ve4mGpuwS6sTy6Keh2VJN'
-DATA_OWNER_3_ID = 'QmXG7aTnKk1AcLhKmauCkYpYafoxj1dG5xLBnCQNniuaeF'
-DATA_OWNER_4_ID = 'QmfFQ1CDXU8kYGMSkqPGqMw7NfnjGsfr3jPU9GbSBY4P3J'
-DATA_OWNER_5_ID = 'QmYX5KatFyFve3xVjadX2h7fEt1SzpdA8wnQsQ4v9muCyR'
-
-# GPU mode
-# DEV_TASK_ID = '45b0eb180eb34ba7a77f6df36fbf9e1b'
-
-# AGGREGATOR_ID = 'QmQERKLbhy2bbhWA6eSd4ENpr37BA7G3xzbm6BJqsERJ58'
-# DATA_OWNER_3_ID = 'QmPUhKyCbQ7V73gMNVUaGVnqsVbkNFxSotS7pEEFD8X1SP'
-# DATA_OWNER_4_ID = 'QmScck6og9ZRqeSKTqUpe4Phub45mxFeUHGysV2DWCouEg'
-# DATA_OWNER_5_ID = 'QmNwzJAbWSkcjdi2PS1wGCgbnZAxEdiwDtF8ZPVBn9EFGq'
+# CPU mode
+DEV_TASK_ID = 'd041d19f-59d0-467f-bc6c-7f5cf42436c2'
+
+AGGREGATOR_ID = 'QmXLxxW7W1cxdU7eeeq5yRXte53zekxiTRApSWxxssdzQP'
+DATA_OWNER_2_ID = 'QmUXV1ds7mNfZ5udaLauubMC5ve4mGpuwS6sTy6Keh2VJN'
+DATA_OWNER_3_ID = 'QmXG7aTnKk1AcLhKmauCkYpYafoxj1dG5xLBnCQNniuaeF'
+DATA_OWNER_4_ID = 'QmfFQ1CDXU8kYGMSkqPGqMw7NfnjGsfr3jPU9GbSBY4P3J'
+DATA_OWNER_5_ID = 'QmYX5KatFyFve3xVjadX2h7fEt1SzpdA8wnQsQ4v9muCyR'
+
+# GPU mode
+# DEV_TASK_ID = '45b0eb180eb34ba7a77f6df36fbf9e1b'
+
+# AGGREGATOR_ID = 'QmQERKLbhy2bbhWA6eSd4ENpr37BA7G3xzbm6BJqsERJ58'
+# DATA_OWNER_3_ID = 'QmPUhKyCbQ7V73gMNVUaGVnqsVbkNFxSotS7pEEFD8X1SP'
+# DATA_OWNER_4_ID = 'QmScck6og9ZRqeSKTqUpe4Phub45mxFeUHGysV2DWCouEg'
+# DATA_OWNER_5_ID = 'QmNwzJAbWSkcjdi2PS1wGCgbnZAxEdiwDtF8ZPVBn9EFGq'
```

### Comparing `alphamed-federated-0.4.7/src/alphafed/examples/fed_prox/model/my_fed_prox_impl.py` & `alphamed-federated-0.4.9/src/alphafed/examples/fed_prox/model/my_fed_prox_impl.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/examples/fed_prox/model/net.py` & `alphamed-federated-0.4.9/src/alphafed/examples/fed_prox/model/net.py`

 * *Ordering differences only*

 * *Files 10% similar despite different names*

```diff
@@ -1,21 +1,21 @@
-from torch import nn
-import torch.nn.functional as F
-
-
-class ConvNet(nn.Module):
-    def __init__(self) -> None:
-        super().__init__()
-        self.conv1 = nn.Conv2d(in_channels=1, out_channels=10, kernel_size=5)
-        self.conv2 = nn.Conv2d(in_channels=10, out_channels=20, kernel_size=5)
-        self.conv2_drop = nn.Dropout2d()
-        self.fc1 = nn.Linear(in_features=320, out_features=50)
-        self.fc2 = nn.Linear(in_features=50, out_features=10)
-
-    def forward(self, x):
-        x = F.relu(F.max_pool2d(self.conv1(x), 2))
-        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))
-        x = x.view(-1, 320)
-        x = F.relu(self.fc1(x))
-        x = F.dropout(x, training=self.training)
-        x = self.fc2(x)
-        return F.log_softmax(x, dim=-1)
+from torch import nn
+import torch.nn.functional as F
+
+
+class ConvNet(nn.Module):
+    def __init__(self) -> None:
+        super().__init__()
+        self.conv1 = nn.Conv2d(in_channels=1, out_channels=10, kernel_size=5)
+        self.conv2 = nn.Conv2d(in_channels=10, out_channels=20, kernel_size=5)
+        self.conv2_drop = nn.Dropout2d()
+        self.fc1 = nn.Linear(in_features=320, out_features=50)
+        self.fc2 = nn.Linear(in_features=50, out_features=10)
+
+    def forward(self, x):
+        x = F.relu(F.max_pool2d(self.conv1(x), 2))
+        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))
+        x = x.view(-1, 320)
+        x = F.relu(self.fc1(x))
+        x = F.dropout(x, training=self.training)
+        x = self.fc2(x)
+        return F.log_softmax(x, dim=-1)
```

### Comparing `alphamed-federated-0.4.7/src/alphafed/examples/fed_prox/model/scheduler.py` & `alphamed-federated-0.4.9/src/alphafed/examples/fed_prox/model/scheduler.py`

 * *Ordering differences only*

 * *Files 18% similar despite different names*

```diff
@@ -1,60 +1,60 @@
-"""FedProx Scheduler."""
-from copy import deepcopy
-import io
-from typing import Callable
-from torch.nn import Module
-import torch
-from alphafed.contractor.common import ContractEvent
-
-from alphafed.fed_avg import FedAvgScheduler
-from alphafed.fed_avg.contractor import FinishTaskEvent, ResetRoundEvent
-from alphafed.fed_avg.fed_avg import ResetRound
-from alphafed.scheduler import TaskComplete
-from alphafed import logger
-
-
-class FedProxScheduler(FedAvgScheduler):
-
-    def __init__(self,
-                 max_rounds: int = 0,
-                 merge_epochs: int = 1,
-                 mu: float = 0.01,
-                 calculation_timeout: int = 300,
-                 schedule_timeout: int = 30,
-                 log_rounds: int = 0,
-                 involve_aggregator: bool = False):
-        super().__init__(max_rounds=max_rounds,
-                         merge_epochs=merge_epochs,
-                         calculation_timeout=calculation_timeout,
-                         schedule_timeout=schedule_timeout,
-                         log_rounds=log_rounds,
-                         involve_aggregator=involve_aggregator)
-        self.mu = mu
-        self.global_model: Module = None
-
-    def _wait_for_updating_model(self):
-        """Wait for receiving latest parameters from aggregator."""
-        def _complementary_handler(event: ContractEvent):
-            if isinstance(event, FinishTaskEvent):
-                raise TaskComplete()
-            elif isinstance(event, ResetRoundEvent):
-                raise ResetRound()
-
-        self.push_log('Waiting for receiving latest parameters from the aggregator ...')
-        _, parameters = self.data_channel.receive_stream(
-            receiver=self.id,
-            complementary_handler=_complementary_handler,
-            source=self._aggregator
-        )
-        buffer = io.BytesIO(parameters)
-        new_state_dict = torch.load(buffer)
-        self.load_state_dict(new_state_dict)
-        self.global_model = deepcopy(self.model)
-        self.push_log('Successfully received latest parameters.')
-    
-    def calc_prox_loss(self, origin_loss_func: Callable, *args, **kwargs) -> torch.Tensor:
-        origin_loss = origin_loss_func(*args, **kwargs)
-        proximal_term = 0.0
-        for w, w_t in zip(self.model.parameters(), self.global_model.parameters()):
-            proximal_term += (w - w_t).norm(2)
-        return origin_loss + (self.mu / 2) * proximal_term
+"""FedProx Scheduler."""
+from copy import deepcopy
+import io
+from typing import Callable
+from torch.nn import Module
+import torch
+from alphafed.contractor.common import ContractEvent
+
+from alphafed.fed_avg import FedAvgScheduler
+from alphafed.fed_avg.contractor import FinishTaskEvent, ResetRoundEvent
+from alphafed.fed_avg.fed_avg import ResetRound
+from alphafed.scheduler import TaskComplete
+from alphafed import logger
+
+
+class FedProxScheduler(FedAvgScheduler):
+
+    def __init__(self,
+                 max_rounds: int = 0,
+                 merge_epochs: int = 1,
+                 mu: float = 0.01,
+                 calculation_timeout: int = 300,
+                 schedule_timeout: int = 30,
+                 log_rounds: int = 0,
+                 involve_aggregator: bool = False):
+        super().__init__(max_rounds=max_rounds,
+                         merge_epochs=merge_epochs,
+                         calculation_timeout=calculation_timeout,
+                         schedule_timeout=schedule_timeout,
+                         log_rounds=log_rounds,
+                         involve_aggregator=involve_aggregator)
+        self.mu = mu
+        self.global_model: Module = None
+
+    def _wait_for_updating_model(self):
+        """Wait for receiving latest parameters from aggregator."""
+        def _complementary_handler(event: ContractEvent):
+            if isinstance(event, FinishTaskEvent):
+                raise TaskComplete()
+            elif isinstance(event, ResetRoundEvent):
+                raise ResetRound()
+
+        self.push_log('Waiting for receiving latest parameters from the aggregator ...')
+        _, parameters = self.data_channel.receive_stream(
+            receiver=self.id,
+            complementary_handler=_complementary_handler,
+            source=self._aggregator
+        )
+        buffer = io.BytesIO(parameters)
+        new_state_dict = torch.load(buffer)
+        self.load_state_dict(new_state_dict)
+        self.global_model = deepcopy(self.model)
+        self.push_log('Successfully received latest parameters.')
+    
+    def calc_prox_loss(self, origin_loss_func: Callable, *args, **kwargs) -> torch.Tensor:
+        origin_loss = origin_loss_func(*args, **kwargs)
+        proximal_term = 0.0
+        for w, w_t in zip(self.model.parameters(), self.global_model.parameters()):
+            proximal_term += (w - w_t).norm(2)
+        return origin_loss + (self.mu / 2) * proximal_term
```

### Comparing `alphamed-federated-0.4.7/src/alphafed/examples/hetero_nn/hetero_fed_irm/collaborator_scheduler.py` & `alphamed-federated-0.4.9/src/alphafed/examples/hetero_nn/hetero_fed_irm/collaborator_scheduler.py`

 * *Files 20% similar despite different names*

```diff
@@ -5,17 +5,16 @@
 from typing import List, Set, Tuple
 
 import pandas as pd
 import torch
 import torch.backends.cudnn
 import torch.nn.functional as F
 from PIL import Image
-from res_net import ResNet18
 from torch import nn
-from torch.optim import SGD, Adam, Optimizer
+from torch.optim import Adam, Optimizer
 from torch.utils.data import DataLoader, Dataset, Subset
 from torchvision import transforms
 
 from alphafed import logger
 from alphafed.hetero_nn import HeteroNNCollaboratorScheduler
 
 
@@ -122,31 +121,24 @@
     def load_local_ids(self) -> List[str]:
         return list(self.dataset.images)
 
     def split_dataset(self, id_intersection: Set[str]) -> Tuple[Set[str], Set[str]]:
         ids = list(id_intersection)
         # 模拟随机拆分训练集和测试集
         ids.sort(key=lambda x: md5(bytes(x.encode())).digest())
-        train_num = round(len(ids) * 0.5)
-        train_ids = ids
+        train_num = round(len(ids) * 0.8)
+        train_ids = ids[:train_num]
         test_ids = ids[train_num:]
 
         logger.info(f'Got {len(train_ids)} intersecting samples for training.')
         logger.info(f'Got {len(test_ids)} intersecting samples for testing.')
 
         return set(train_ids), set(test_ids)
 
     def build_feature_model(self) -> nn.Module:
-        # model = ResNet18(num_classes=7)
-        # param_file = os.path.join(self.data_dir, self.param_file)
-        # with open(param_file, 'rb') as f:
-        #     state_dict = torch.load(f)
-        #     model.load_state_dict(state_dict, strict=False)
-        # # 替换分类层
-        # model.fc = nn.Linear(model.layer1[0].expansion * 512, 25)
         model = CollaboratorConvNet()
         return model.cuda() if torch.cuda.is_available() else model
 
     def build_feature_optimizer(self, feature_model: nn.Module) -> Optimizer:
         return Adam(feature_model.parameters(),
                     lr=1e-4,
                     betas=(0.9, 0.999),
```

### Comparing `alphamed-federated-0.4.7/src/alphafed/examples/hetero_nn/hetero_fed_irm/data_checker.py` & `alphamed-federated-0.4.9/src/alphafed/examples/hetero_nn/hetero_fed_irm/data_checker.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/examples/hetero_nn/hetero_fed_irm/host_scheduler.py` & `alphamed-federated-0.4.9/src/alphafed/examples/hetero_nn/hetero_fed_irm/host_scheduler.py`

 * *Files 1% similar despite different names*

```diff
@@ -170,16 +170,16 @@
     def load_local_ids(self) -> List[str]:
         return list(self.dataset.images)
 
     def split_dataset(self, id_intersection: Set[str]) -> Tuple[Set[str], Set[str]]:
         ids = list(id_intersection)
         # 模拟随机拆分训练集和测试集
         ids.sort(key=lambda x: md5(bytes(x.encode())).digest())
-        train_num = round(len(ids) * 0.5)
-        train_ids = ids
+        train_num = round(len(ids) * 0.8)
+        train_ids = ids[:train_num]
         test_ids = ids[train_num:]
 
         logger.info(f'Got {len(train_ids)} intersecting samples for training.')
         logger.info(f'Got {len(test_ids)} intersecting samples for testing.')
 
         return set(train_ids), set(test_ids)
```

### Comparing `alphamed-federated-0.4.7/src/alphafed/examples/hetero_nn/psi/demos.py` & `alphamed-federated-0.4.9/src/alphafed/examples/hetero_nn/psi/demos.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/examples/hetero_nn/psi/run_collaborator_2.py` & `alphamed-federated-0.4.9/src/alphafed/examples/hetero_nn/psi/run_collaborator_2.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/examples/hetero_nn/psi/run_collaborator_3.py` & `alphamed-federated-0.4.9/src/alphafed/examples/hetero_nn/psi/run_collaborator_3.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/examples/hetero_nn/psi/run_collaborator_4.py` & `alphamed-federated-0.4.9/src/alphafed/examples/hetero_nn/psi/run_collaborator_4.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/examples/hetero_nn/psi/run_collaborator_5.py` & `alphamed-federated-0.4.9/src/alphafed/examples/hetero_nn/psi/run_collaborator_5.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/examples/hetero_nn/psi/run_initiator.py` & `alphamed-federated-0.4.9/src/alphafed/examples/hetero_nn/psi/run_initiator.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/examples/hetero_nn/run_collaborater.py` & `alphamed-federated-0.4.9/src/alphafed/examples/hetero_nn/run_collaborater.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/examples/hetero_nn/run_host.py` & `alphamed-federated-0.4.9/src/alphafed/examples/hetero_nn/run_host.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/fed_avg/contractor.py` & `alphamed-federated-0.4.9/src/alphafed/fed_avg/contractor.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/fed_avg/dp_contractor.py` & `alphamed-federated-0.4.9/src/alphafed/fed_avg/dp_contractor.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/fed_avg/dp_fed_avg.py` & `alphamed-federated-0.4.9/src/alphafed/fed_avg/dp_fed_avg.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/fed_avg/fed_avg.py` & `alphamed-federated-0.4.9/src/alphafed/fed_avg/fed_avg.py`

 * *Ordering differences only*

 * *Files 18% similar despite different names*

```diff
@@ -1,804 +1,804 @@
-"""FedAvg scheduler."""
-
-import io
-import json
-import os
-import shutil
-import sys
-import traceback
-from abc import ABCMeta, abstractmethod
-from typing import Any, Dict, List, Tuple, final
-from zipfile import ZipFile
-
-import torch
-from torch.nn import Module
-from torch.optim import Optimizer
-from torch.utils.data import DataLoader
-from torch.utils.tensorboard import SummaryWriter
-
-from .. import get_result_dir, get_runtime_dir, logger
-from ..data_channel import SharedFileDataChannel
-from ..scheduler import ConfigError, Scheduler, TaskComplete, TaskFailed
-from .contractor import (CheckinEvent, CheckinResponseEvent, CloseRoundEvent,
-                         ContractEvent, FedAvgContractor,
-                         FinishTaskEvent, ReadyForAggregationEvent,
-                         ResetRoundEvent, StartRoundEvent, SyncStateEvent,
-                         SyncStateResponseEvent)
-
-__all__ = [
-    'FedAvgScheduler',
-    'FedSGDScheduler'
-]
-
-
-class AggregationError(Exception):
-    ...
-
-
-class SkipRound(Exception):
-    ...
-
-
-class ResetRound(Exception):
-    ...
-
-
-class FedAvgScheduler(Scheduler, metaclass=ABCMeta):
-    """Implementation of FedAvg."""
-
-    _INIT = 'init'
-    _GETHORING = 'gethering'
-    _READY = 'ready'
-    _SYNCHRONIZING = 'synchronizing'
-    _IN_A_ROUND = 'in_a_round'
-    _UPDATING = 'updating'
-    _CALCULATING = 'calculating'
-    _WAIT_FOR_AGGR = 'wait_4_aggr'
-    _AGGREGATING = 'aggregating'
-    _PERSISTING = 'persisting'
-    _CLOSING_ROUND = 'closing_round'
-    _FINISHING = 'finishing'
-
-    def __init__(self,
-                 max_rounds: int = 0,
-                 merge_epochs: int = 1,
-                 calculation_timeout: int = 300,
-                 schedule_timeout: int = 30,
-                 log_rounds: int = 0,
-                 involve_aggregator: bool = False):
-        """Init.
-
-        Args:
-            max_rounds:
-                Maximal number of training rounds.
-            merge_epochs:
-                The number of epochs to run before aggregation is performed.
-            calculation_timeout:
-                Seconds to timeout for calculation in a round. Takeing off timeout
-                by setting its value to 0.
-            schedule_timeout:
-                Seconds to timeout for process scheduling. Takeing off timeout
-                by setting its value to 0.
-            log_rounds:
-                The number of rounds to run testing and log the result. Skip it
-                by setting its value to 0.
-            involve_aggregator:
-                If set true, the aggregator should have its local data and conduct
-                training other than merely schedule and aggregate.
-        """
-        super().__init__()
-        self._switch_status(self._INIT)
-
-        self.max_rounds = max_rounds
-        self.merge_epochs = merge_epochs
-        self.calculation_timeout = calculation_timeout
-        self.schedule_timeout = schedule_timeout
-        self.log_rounds = log_rounds
-        self.involve_aggregator = involve_aggregator
-
-        self._validate_config()
-        self.current_round = 1
-
-        self.participants: List[str] = []
-        self.gethered: List[str] = []
-        self.is_gathering_complete = False
-
-    def _validate_config(self):
-        if self.merge_epochs <= 0:
-            raise ConfigError('merge_epochs must be a positive integer')
-
-    @abstractmethod
-    def build_model(self) -> Module:
-        """Return a model object which will be used for training."""
-
-    @final
-    @property
-    def model(self) -> Module:
-        """Get the model object which is used for training."""
-        if not hasattr(self, '_model'):
-            self._model = self.build_model()
-        return self._model
-
-    @abstractmethod
-    def build_optimizer(self, model: Module) -> Optimizer:
-        """Return a optimizer object which will be used for training.
-
-        Args:
-            model:
-                The model object which is used for training.
-        """
-
-    @final
-    @property
-    def optimizer(self) -> Optimizer:
-        """Get the optimizer object which is used for training."""
-        if not hasattr(self, '_optimizer'):
-            self._optimizer = self.build_optimizer(model=self.model)
-        return self._optimizer
-
-    @abstractmethod
-    def build_train_dataloader(self) -> DataLoader:
-        """Define the training dataloader.
-
-        You can transform the dataset, do some preprocess to the dataset.
-
-        Return:
-            training dataloader
-        """
-
-    @final
-    @property
-    def train_loader(self) -> DataLoader:
-        """Get the training dataloader object."""
-        if not hasattr(self, '_train_loader'):
-            self._train_loader = self.build_train_dataloader()
-        return self._train_loader
-
-    def build_validation_dataloader(self) -> DataLoader:
-        """Define the validation dataloader if needed.
-
-        You can transform the dataset, do some preprocess to the dataset.
-
-        Return:
-            validation dataloader
-        """
-        raise NotImplementedError()
-
-    @final
-    @property
-    def validation_loader(self) -> DataLoader:
-        """Get the validation dataloader object if needed."""
-        if not hasattr(self, '_validation_loader'):
-            self._validation_loader = self.build_validation_dataloader()
-        return self._validation_loader
-
-    @abstractmethod
-    def build_test_dataloader(self) -> DataLoader:
-        """Define the testing dataloader.
-
-        You can transform the dataset, do some preprocess to the dataset. If you do not
-        want to do testing after training, simply make it return None.
-
-        Args:
-            dataset:
-                training dataset
-        Return:
-            testing dataloader
-        """
-
-    @final
-    @property
-    def test_loader(self) -> DataLoader:
-        """Get the testing dataloader object."""
-        if not hasattr(self, '_test_loader'):
-            self._test_loader = self.build_test_dataloader()
-        return self._test_loader
-
-    def state_dict(self) -> Dict[str, torch.Tensor]:
-        """Get the params that need to train and update.
-
-        Only the params returned by this function will be updated and saved during aggregation.
-        Return self.model.state_dict() by default.
-
-        Return:
-            List[torch.Tensor], The list of model params.
-        """
-        return self.model.state_dict()
-
-    def load_state_dict(self, state_dict: Dict[str, torch.Tensor]):
-        """Load the params that trained and updated.
-
-        Only the params returned by state_dict() should be loaded by this function.
-        Execute self.model.load_state_dict(state_dict) by default.
-        """
-        self.model.load_state_dict(state_dict)
-
-    def validate_context(self):
-        """Validate if the local running context is ready.
-
-        For example: check if train and test dataset could be loaded successfully.
-        """
-        if self.model is None:
-            raise ConfigError('Must specify a model to train')
-        if not isinstance(self.model, Module):
-            raise ConfigError('Support torch.Module only')
-        if self.optimizer is None:
-            raise ConfigError('Must specify an optimizer to train')
-        if not isinstance(self.optimizer, Optimizer):
-            raise ConfigError('Support torch.optim.Optimizer only')
-
-    @abstractmethod
-    def train_an_epoch(self) -> Any:
-        """Define the training steps in an epoch."""
-
-    @abstractmethod
-    def run_test(self) -> Any:
-        """Define the testing steps.
-
-        If you do not want to do testing after training, simply make it pass.
-        """
-
-    def is_task_finished(self) -> bool:
-        """By default true if reach the max rounds configured."""
-        return self._is_reach_max_rounds()
-
-    def _run(self, id: str, task_id: str, is_initiator: bool = False, recover: bool = False):
-        self._setup_context(id=id, task_id=task_id, is_initiator=is_initiator)
-        self.push_log(message='Local context is ready.')
-        try:
-            if self.is_aggregator and recover:
-                self._recover_progress()
-            else:
-                self._clean_progress()
-            self._launch_process()
-        except Exception:
-            err_stack = '\n'.join(traceback.format_exception(*sys.exc_info()))
-            self.push_log(err_stack)
-
-    def _setup_context(self, id: str, task_id: str, is_initiator: bool = False):
-        assert id, 'must specify a unique id for every participant'
-        assert task_id, 'must specify a task_id for every participant'
-
-        self.id = id
-        self.task_id = task_id
-        self._runtime_dir = get_runtime_dir(self.task_id)
-        self._context_file = os.path.join(self._runtime_dir, ".context.json")
-        self._checkpoint_dir = os.path.join(self._runtime_dir, 'checkpoint')
-        self._ckpt_file = os.path.join(self._checkpoint_dir, "model_ckpt.pt")
-        self._result_dir = get_result_dir(self.task_id)
-        self._log_dir = os.path.join(self._result_dir, 'tb_logs')
-        self.tb_writer = SummaryWriter(log_dir=self._log_dir)
-
-        self.is_initiator = is_initiator
-        self.is_aggregator = self.is_initiator
-
-        self.contractor = self._init_contractor()
-        self.data_channel = SharedFileDataChannel(self.contractor)
-        self.model
-        self.optimizer
-
-        if self.is_initiator:
-            self.participants = self.contractor.query_nodes()
-            if len(self.participants) < 2:
-                raise TaskFailed('Failed to get participants list.')
-
-        self.push_log(message='Begin to validate local context.')
-        self.validate_context()
-
-    def _init_contractor(self):
-        return FedAvgContractor(task_id=self.task_id)
-
-    def _recover_progress(self):
-        """Try to recover and continue from last running."""
-        if not os.path.isfile(self._context_file):
-            raise TaskFailed('Failed to recover progress: missing cached context.')
-
-        with open(self._context_file, 'r') as f:
-            context_info: dict = json.load(f)
-        round = context_info.get('round')
-        ckpt_file = context_info.get('ckpt_file')
-        assert round and isinstance(round, int) and round > 0, f'Invalid round: {round} .'
-        assert ckpt_file and isinstance(ckpt_file, str), f'Invalid ckpt_file: {ckpt_file} .'
-        if not os.path.isfile(ckpt_file):
-            raise TaskFailed('Failed to recover progress: missing checkpoint parameters.')
-
-        self.current_round = round
-        with open(ckpt_file, 'rb') as f:
-            state_dict = torch.load(f)
-            self.load_state_dict(state_dict)
-
-    def _clean_progress(self):
-        """Clean existing progress data."""
-        shutil.rmtree(self._runtime_dir, ignore_errors=True)
-        shutil.rmtree(self._result_dir, ignore_errors=True)
-        os.makedirs(self._runtime_dir, exist_ok=True)
-        os.makedirs(self._checkpoint_dir, exist_ok=True)
-        os.makedirs(self._result_dir, exist_ok=True)
-        os.makedirs(self._log_dir, exist_ok=True)
-
-    def _launch_process(self):
-        try:
-            assert self.status == self._INIT, 'must begin from initial status'
-            self.push_log(f'Node {self.id} is up.')
-
-            self._switch_status(self._GETHORING)
-            self._check_in()
-
-            self._switch_status(self._READY)
-            while self.status == self._READY:
-                try:
-                    self._switch_status(self._SYNCHRONIZING)
-                    self._sync_state()
-
-                    self._switch_status(self._IN_A_ROUND)
-                    self._run_a_round()
-                    self._switch_status(self._READY)
-                except ResetRound:
-                    self.push_log('WARNING: Reset runtime context, there might be an error raised.')
-                    self._switch_status(self._READY)
-                    continue
-
-                if self.is_aggregator:
-                    is_finished = self.is_task_finished()
-                    self._persistent_running_context()
-                    self._switch_status(self._READY)
-                    self.current_round += 1
-                    if is_finished:
-                        self.push_log(f'Obtained the final results of task {self.task_id}')
-                        self._switch_status(self._FINISHING)
-                        self._close_task()
-
-        except TaskComplete:
-            logger.info('training task complete')
-
-    def _check_in(self):
-        """Check in task and get ready.
-
-        As an initiator (and default the first aggregator), records each participants
-        and launches election or training process accordingly.
-        As a participant, checkins and gets ready for election or training.
-        """
-        if self.is_initiator:
-            self.push_log('Waiting for participants taking part in ...')
-            self._wait_for_gathering()
-            self.is_gathering_complete = True
-        else:
-            is_checked_in = False
-            # the aggregator may be in special state so can not response
-            # correctly nor in time, then retry periodically
-            self.push_log('Checking in the task ...')
-            while not is_checked_in:
-                is_checked_in = self._check_in_task()
-            self.push_log(f'Node {self.id} have taken part in the task.')
-
-    def _sync_state(self):
-        """Synchronize state before each round, so it's easier to manage the process.
-
-        As an aggregator, iterates round, broadcasts and resets context of the new round.
-        As a participant, synchronizes state and gives a response.
-        """
-        self.push_log('Synchronizing round state ...')
-        if self.is_aggregator:
-            self.push_log(f'Initiate state synchronization of round {self.current_round}.')
-            self.contractor.sync_state(round=self.current_round, aggregator=self.id)
-            self._wait_for_sync_response()
-        else:
-            self._wait_for_sync_state()
-        self.push_log(f'Successfully synchronized state in round {self.current_round}')
-
-    def _run_a_round(self):
-        """Perform a round of FedAvg calculation.
-
-        As an aggregator, selects a part of participants as actual calculators
-        in the round, distributes latest parameters to them, collects update and
-        makes aggregation.
-        As a participant, if is selected as a calculator, calculates and uploads
-        parameter update.
-        """
-        if self.is_aggregator:
-            try:
-                self._run_as_aggregator()
-            except AggregationError as err:
-                err_stack = '\n'.join(traceback.format_exception(*sys.exc_info()))
-                self.push_log(err_stack)
-                self.contractor.reset_round()
-                raise ResetRound(err)
-        else:
-            self._run_as_data_owner()
-
-    def _close_task(self, is_succ: bool = True):
-        """Close the FedAvg calculation.
-
-        As an aggregator, broadcasts the finish task event to all participants,
-        uploads the final parameters and tells L1 task manager the task is complete.
-        As a participant, do nothing.
-        """
-        self.push_log(f'Closing task {self.task_id} ...')
-        if is_succ and self.is_aggregator:
-            self._switch_status(self._FINISHING)
-            self.contractor.finish_task()
-            report_file_path, model_file_path = self._prepare_task_output()
-            self.contractor.upload_metric_report(receivers=self.contractor.EVERYONE,
-                                                 report_file=report_file_path)
-            self.contractor.upload_model(receivers=self.contractor.EVERYONE,
-                                         model_file=model_file_path)
-            self.contractor.notify_task_completion(result=True)
-        elif self.is_aggregator:
-            self.contractor.finish_task()
-            self.contractor.notify_task_completion(result=False)
-        self.push_log(f'Task {self.task_id} closed. Byebye!')
-
-    def _wait_for_gathering(self):
-        """Wait for participants gethering."""
-        logger.debug('_wait_for_gathering ...')
-        for _event in self.contractor.contract_events():
-            if isinstance(_event, CheckinEvent):
-                self._handle_check_in(_event)
-                if len(self.gethered) == len(self.participants) - 1:
-                    return
-
-    def _handle_check_in(self, _event: CheckinEvent):
-        if _event.peer_id not in self.gethered:
-            self.gethered.append(_event.peer_id)
-            self.push_log(f'Welcome a new participant ID: {_event.peer_id}.')
-            self.push_log(f'There are {len(self.gethered) + 1} participants now.')
-        self.contractor.respond_check_in(round=self.current_round,
-                                         aggregator=self.id,
-                                         nonce=_event.nonce,
-                                         requester_id=_event.peer_id)
-        if self.is_gathering_complete:
-            self.contractor.sync_state(round=self.current_round, aggregator=self.id)
-
-    def _wait_for_sync_response(self):
-        """Wait for participants' synchronizing state response."""
-        self.push_log('Waiting for synchronization responses ...')
-        synced = set()
-        for _event in self.contractor.contract_events(timeout=0):
-            if isinstance(_event, SyncStateResponseEvent):
-                if _event.round != self.current_round:
-                    continue
-                synced.add(_event.peer_id)
-                self.push_log(f'Successfully synchronized state with ID: {_event.peer_id}.')
-                self.push_log(f'Successfully synchronized with {len(synced)} participants.')
-                if len(synced) == len(self.gethered):
-                    return
-
-            elif isinstance(_event, CheckinEvent):
-                self._handle_check_in(_event)
-
-    def _check_in_task(self) -> bool:
-        """Try to check in the task."""
-        nonce = self.contractor.checkin(peer_id=self.id)
-        return self._wait_for_check_in_response(nonce=nonce,
-                                                timeout=self.schedule_timeout)
-
-    def _wait_for_check_in_response(self, nonce: str, timeout: int = 0) -> bool:
-        """Wait for checkin response.
-
-        Return True if received response successfully otherwise False.
-        """
-        logger.debug('_wait_for_check_in_response ...')
-        for _event in self.contractor.contract_events(timeout=timeout):
-            if isinstance(_event, CheckinResponseEvent):
-                if _event.nonce != nonce:
-                    continue
-                self.current_round = _event.round
-                return True
-            elif isinstance(_event, FinishTaskEvent):
-                raise TaskComplete()
-        return False
-
-    def _wait_for_sync_state(self, timeout: int = 0) -> bool:
-        """Wait for synchronising latest task state.
-
-        Return True if synchronising successfully otherwise False.
-        """
-        self.push_log('Waiting for synchronizing state with the aggregator ...')
-        for _event in self.contractor.contract_events(timeout=timeout):
-            if isinstance(_event, SyncStateEvent):
-                self.current_round = _event.round
-                self.contractor.respond_sync_state(round=self.current_round,
-                                                   peer_id=self.id,
-                                                   aggregator=_event.aggregator)
-                self.push_log('Successfully synchronized state with the aggregator.')
-                return
-            elif isinstance(_event, FinishTaskEvent):
-                raise TaskComplete()
-
-    def _run_as_aggregator(self):
-        self._start_round()
-        self._distribute_model()
-
-        self._process_aggregation()
-
-        self._check_and_run_test()
-        self._close_round()
-
-    def _close_round(self):
-        """Close current round when finished."""
-        self._switch_status(self._CLOSING_ROUND)
-        self.contractor.close_round(round=self.current_round)
-        self.push_log(f'The training of Round {self.current_round} complete.')
-
-    def _start_round(self):
-        """Prepare and start calculation of a round."""
-        self.push_log(f'Begin the training of round {self.current_round}.')
-        self.contractor.start_round(round=self.current_round,
-                                    calculators=self.gethered,
-                                    aggregator=self.id)
-        self.push_log(f'Calculation of round {self.current_round} is started.')
-
-    def _distribute_model(self):
-        buffer = io.BytesIO()
-        torch.save(self.state_dict(), buffer)
-        self.push_log('Distributing parameters ...')
-        results = {_target: False for _target in self.gethered}
-        accept_list = self.data_channel.batch_send_stream(source=self.id,
-                                                          target=list(results.keys()),
-                                                          data_stream=buffer.getvalue())
-        self.push_log(f'Successfully distributed parameters to: {accept_list}')
-        if len(results.keys()) != len(accept_list):
-            reject_list = [_target for _target in results.keys()
-                           if _target not in accept_list]
-            self.push_log(f'Failed to distribute parameters to: {reject_list}')
-        results.update({_target: True for _target in accept_list})
-
-        if sum(results.values()) < len(self.gethered):
-            self.push_log('Task failed because of too few calculators getting ready')
-            raise AggregationError(f'Too few calculators getting ready: {results}.')
-        self.push_log(f'Distributed parameters to {sum(results.values())} calculators.')
-
-    def _process_aggregation(self):
-        """Process aggregation depending on specific algorithm."""
-        # run training if necessary or zeroize parameters
-        if self.involve_aggregator:
-            self._execute_training()
-            self.push_log(f'The aggregator ID: {self.id} obtained its calculation results.')
-        else:
-            for _param in self.state_dict().values():
-                if isinstance(_param, torch.Tensor):
-                    _param.zero_()
-        # collect participants' results
-        self._switch_status(self._WAIT_FOR_AGGR)
-        self.contractor.notify_ready_for_aggregation(round=self.current_round)
-        self.push_log('Now waiting for executing calculation ...')
-        accum_result, result_count = self._wait_for_calculation()
-        if result_count < len(self.gethered) + int(self.involve_aggregator):
-            self.push_log('Task failed because of too few calculation results gathered.')
-            raise AggregationError(f'Too few results gathered: {result_count} copies.')
-        self.push_log(f'Received {result_count} copies of calculation results.')
-
-        self._switch_status(self._AGGREGATING)
-        self.push_log('Begin to aggregate and update parameters.')
-        for _key in accum_result.keys():
-            if accum_result[_key].dtype in (
-                torch.uint8, torch.int8, torch.int16, torch.int32, torch.int64
-            ):
-                logger.warn(f'average a int value may lose precision: {_key=}')
-                accum_result[_key].div_(result_count, rounding_mode='trunc')
-            else:
-                accum_result[_key].div_(result_count)
-        self.load_state_dict(accum_result)
-        self.push_log('Obtained a new version of parameters.')
-
-    def _persistent_running_context(self):
-        self._switch_status(self._PERSISTING)
-        self._save_model()
-        self._save_runtime_context()
-
-    def _check_and_run_test(self):
-        """Run test if match configured conditions."""
-        if (
-            self.current_round == 1
-            or (self.log_rounds > 0 and self.current_round % self.log_rounds == 0)
-            or self.current_round == self.max_rounds
-        ):
-            self.push_log('Begin to make a model test.')
-            self.run_test()
-            self.push_log('Finished a round of test.')
-
-    def _wait_for_calculation(self) -> Tuple[Dict[str, torch.Tensor], int]:
-        """Wait for every calculator finish its task or timeout."""
-        result_count = int(self.involve_aggregator)
-        accum_result = self.state_dict()
-
-        self.push_log('Waiting for training results ...')
-        training_results = self.data_channel.batch_receive_stream(
-            receiver=self.id,
-            source_list=self.gethered,
-            timeout=self.calculation_timeout
-        )
-        for _source, _result in training_results.items():
-            buffer = io.BytesIO(_result)
-            _new_state_dict = torch.load(buffer)
-            for _key in accum_result.keys():
-                accum_result[_key].add_(_new_state_dict[_key])
-            result_count += 1
-            self.push_log(f'Received calculation results from ID: {_source}')
-
-        return accum_result, result_count
-
-    def _is_reach_max_rounds(self) -> bool:
-        """Is the max rounds configuration reached."""
-        return self.current_round >= self.max_rounds
-
-    def _save_model(self):
-        """Save latest model state."""
-        with open(self._ckpt_file, 'wb') as f:
-            torch.save(self.state_dict(), f)
-        self.push_log('Saved latest parameters locally.')
-
-    def _save_runtime_context(self):
-        """Save runtime context information in case of restoring."""
-        context_info = {
-            'round': self.current_round,
-            'ckpt_file': self._ckpt_file
-        }
-        with open(self._context_file, 'w') as f:
-            f.write(json.dumps(context_info, ensure_ascii=False))
-        self.push_log('Saved latest runtime context.')
-
-    def _prepare_task_output(self) -> Tuple[str, str]:
-        """Generate final output files of the task.
-
-        Return:
-            Local paths of the report file and model file.
-        """
-        self.push_log('Uploading task achievement and closing task ...')
-
-        report_file = os.path.join(self._result_dir, "report.zip")
-        with ZipFile(report_file, 'w') as report_zip:
-            for path, _, filenames in os.walk(self._log_dir):
-                rel_dir = os.path.relpath(path=path, start=self._result_dir)
-                rel_dir = rel_dir.lstrip('.')  # ./file => file
-                for _file in filenames:
-                    rel_path = os.path.join(rel_dir, _file)
-                    report_zip.write(os.path.join(path, _file), rel_path)
-        report_file_path = os.path.abspath(report_file)
-
-        model_file = os.path.join(self._result_dir, "model.pt")
-        with open(model_file, 'wb') as f:
-            torch.save(self.state_dict(), f)
-        model_file_path = os.path.abspath(model_file)
-
-        self.push_log('Task achievement files are ready.')
-        return report_file_path, model_file_path
-
-    def _run_as_data_owner(self):
-        try:
-            self._wait_for_starting_round()
-            self._switch_status(self._UPDATING)
-            self._wait_for_updating_model()
-            self._save_model()
-            self._switch_status(self._CALCULATING)
-            self.push_log('Begin to run calculation ...')
-            self._execute_training()
-            self.push_log('Local calculation complete.')
-
-            self._wait_for_uploading_model()
-            buffer = io.BytesIO()
-            torch.save(self.state_dict(), buffer)
-            self.push_log('Pushing local update to the aggregator ...')
-            self.data_channel.send_stream(source=self.id,
-                                          target=self._aggregator,
-                                          data_stream=buffer.getvalue())
-            self.push_log('Successfully pushed local update to the aggregator.')
-            self._switch_status(self._CLOSING_ROUND)
-            self._wait_for_closing_round()
-        except SkipRound:
-            pass
-
-        self.push_log(f'ID: {self.id} finished training task of round {self.current_round}.')
-
-    def _execute_training(self):
-        for _ in range(self.merge_epochs):
-            self.train_an_epoch()
-
-    def _wait_for_starting_round(self):
-        """Wait for starting a new round of training."""
-        self.push_log(f'Waiting for training of round {self.current_round} begin ...')
-        for _event in self.contractor.contract_events():
-            if isinstance(_event, StartRoundEvent):
-                if _event.round != self.current_round:
-                    continue
-                if self.id not in _event.calculators:
-                    raise SkipRound()
-                self._aggregator = _event.aggregator
-                self.push_log(f'Training of round {self.current_round} begins.')
-                return
-            elif isinstance(_event, FinishTaskEvent):
-                raise TaskComplete()
-            elif isinstance(_event, ResetRoundEvent):
-                raise ResetRound()
-
-    def _wait_for_updating_model(self):
-        """Wait for receiving latest parameters from aggregator."""
-        def _complementary_handler(event: ContractEvent):
-            if isinstance(event, FinishTaskEvent):
-                raise TaskComplete()
-            elif isinstance(event, ResetRoundEvent):
-                raise ResetRound()
-
-        self.push_log('Waiting for receiving latest parameters from the aggregator ...')
-        _, parameters = self.data_channel.receive_stream(
-            receiver=self.id,
-            complementary_handler=_complementary_handler,
-            source=self._aggregator
-        )
-        buffer = io.BytesIO(parameters)
-        new_state_dict = torch.load(buffer)
-        self.load_state_dict(new_state_dict)
-        self.push_log('Successfully received latest parameters.')
-
-    def _wait_for_uploading_model(self):
-        """Wait for uploading trained parameters to aggregator."""
-        self.push_log('Waiting for aggregation begin ...')
-        for _event in self.contractor.contract_events():
-            if isinstance(_event, ReadyForAggregationEvent):
-                if _event.round != self.current_round:
-                    continue
-                return
-            elif isinstance(_event, FinishTaskEvent):
-                raise TaskComplete()
-            elif isinstance(_event, ResetRoundEvent):
-                raise ResetRound()
-
-    def _wait_for_closing_round(self):
-        """Wait for closing current round of training."""
-        self.push_log(f'Waiting for closing signal of training round {self.current_round} ...')
-        for _event in self.contractor.contract_events():
-            if isinstance(_event, CloseRoundEvent):
-                if _event.round != self.current_round:
-                    continue
-                return
-            elif isinstance(_event, FinishTaskEvent):
-                raise TaskComplete()
-            elif isinstance(_event, ResetRoundEvent):
-                raise ResetRound()
-
-
-class FedSGDScheduler(FedAvgScheduler):
-    """Implementation of FedSGD."""
-
-    def __init__(self,
-                 max_rounds: int = 0,
-                 calculation_timeout: int = 300,
-                 schedule_timeout: int = 30,
-                 log_rounds: int = 0):
-        """Init.
-
-        By now, IterableDataset with no length is not supported.
-
-        Args:
-            max_rounds:
-                Maximal number of training rounds.
-            calculation_timeout:
-                Seconds to timeout for calculation in a round. Takeing off timeout
-                by setting its value to 0.
-            schedule_timeout:
-                Seconds to timeout for process scheduling. Takeing off timeout
-                by setting its value to 0.
-            log_rounds:
-                The number of rounds to run testing and log the result. Skip it
-                by setting its value to 0.
-        """
-        super().__init__(max_rounds=max_rounds,
-                         merge_epochs=1,
-                         calculation_timeout=calculation_timeout,
-                         schedule_timeout=schedule_timeout,
-                         log_rounds=log_rounds)
-
-    def _setup_context(self, id: str, task_id: str, is_initiator: bool = False):
-        super()._setup_context(id=id, task_id=task_id, is_initiator=is_initiator)
-        # Since build_train_dataloader is implemented by the user, and DataLoader base
-        # implementation does not allow to modify batch_size after initialization,
-        # there is no way to mandatorily set batch size to the correct value.
-        # So a post check is used.
-        self.push_log(f'train batch size = {self.train_loader.batch_size}')
-        try:
-            num_samples = len(self.train_loader.dataset)
-            self.push_log(f'train examples = {num_samples}')
-            if self.train_loader.batch_size != num_samples:
-                raise ConfigError('batch size must be the total number of samples.')
-        except TypeError:
-            raise ConfigError('Does not support iterable dataset with no length.')
+"""FedAvg scheduler."""
+
+import io
+import json
+import os
+import shutil
+import sys
+import traceback
+from abc import ABCMeta, abstractmethod
+from typing import Any, Dict, List, Tuple, final
+from zipfile import ZipFile
+
+import torch
+from torch.nn import Module
+from torch.optim import Optimizer
+from torch.utils.data import DataLoader
+from torch.utils.tensorboard import SummaryWriter
+
+from .. import get_result_dir, get_runtime_dir, logger
+from ..data_channel import SharedFileDataChannel
+from ..scheduler import ConfigError, Scheduler, TaskComplete, TaskFailed
+from .contractor import (CheckinEvent, CheckinResponseEvent, CloseRoundEvent,
+                         ContractEvent, FedAvgContractor,
+                         FinishTaskEvent, ReadyForAggregationEvent,
+                         ResetRoundEvent, StartRoundEvent, SyncStateEvent,
+                         SyncStateResponseEvent)
+
+__all__ = [
+    'FedAvgScheduler',
+    'FedSGDScheduler'
+]
+
+
+class AggregationError(Exception):
+    ...
+
+
+class SkipRound(Exception):
+    ...
+
+
+class ResetRound(Exception):
+    ...
+
+
+class FedAvgScheduler(Scheduler, metaclass=ABCMeta):
+    """Implementation of FedAvg."""
+
+    _INIT = 'init'
+    _GETHORING = 'gethering'
+    _READY = 'ready'
+    _SYNCHRONIZING = 'synchronizing'
+    _IN_A_ROUND = 'in_a_round'
+    _UPDATING = 'updating'
+    _CALCULATING = 'calculating'
+    _WAIT_FOR_AGGR = 'wait_4_aggr'
+    _AGGREGATING = 'aggregating'
+    _PERSISTING = 'persisting'
+    _CLOSING_ROUND = 'closing_round'
+    _FINISHING = 'finishing'
+
+    def __init__(self,
+                 max_rounds: int = 0,
+                 merge_epochs: int = 1,
+                 calculation_timeout: int = 300,
+                 schedule_timeout: int = 30,
+                 log_rounds: int = 0,
+                 involve_aggregator: bool = False):
+        """Init.
+
+        Args:
+            max_rounds:
+                Maximal number of training rounds.
+            merge_epochs:
+                The number of epochs to run before aggregation is performed.
+            calculation_timeout:
+                Seconds to timeout for calculation in a round. Takeing off timeout
+                by setting its value to 0.
+            schedule_timeout:
+                Seconds to timeout for process scheduling. Takeing off timeout
+                by setting its value to 0.
+            log_rounds:
+                The number of rounds to run testing and log the result. Skip it
+                by setting its value to 0.
+            involve_aggregator:
+                If set true, the aggregator should have its local data and conduct
+                training other than merely schedule and aggregate.
+        """
+        super().__init__()
+        self._switch_status(self._INIT)
+
+        self.max_rounds = max_rounds
+        self.merge_epochs = merge_epochs
+        self.calculation_timeout = calculation_timeout
+        self.schedule_timeout = schedule_timeout
+        self.log_rounds = log_rounds
+        self.involve_aggregator = involve_aggregator
+
+        self._validate_config()
+        self.current_round = 1
+
+        self.participants: List[str] = []
+        self.gethered: List[str] = []
+        self.is_gathering_complete = False
+
+    def _validate_config(self):
+        if self.merge_epochs <= 0:
+            raise ConfigError('merge_epochs must be a positive integer')
+
+    @abstractmethod
+    def build_model(self) -> Module:
+        """Return a model object which will be used for training."""
+
+    @final
+    @property
+    def model(self) -> Module:
+        """Get the model object which is used for training."""
+        if not hasattr(self, '_model'):
+            self._model = self.build_model()
+        return self._model
+
+    @abstractmethod
+    def build_optimizer(self, model: Module) -> Optimizer:
+        """Return a optimizer object which will be used for training.
+
+        Args:
+            model:
+                The model object which is used for training.
+        """
+
+    @final
+    @property
+    def optimizer(self) -> Optimizer:
+        """Get the optimizer object which is used for training."""
+        if not hasattr(self, '_optimizer'):
+            self._optimizer = self.build_optimizer(model=self.model)
+        return self._optimizer
+
+    @abstractmethod
+    def build_train_dataloader(self) -> DataLoader:
+        """Define the training dataloader.
+
+        You can transform the dataset, do some preprocess to the dataset.
+
+        Return:
+            training dataloader
+        """
+
+    @final
+    @property
+    def train_loader(self) -> DataLoader:
+        """Get the training dataloader object."""
+        if not hasattr(self, '_train_loader'):
+            self._train_loader = self.build_train_dataloader()
+        return self._train_loader
+
+    def build_validation_dataloader(self) -> DataLoader:
+        """Define the validation dataloader if needed.
+
+        You can transform the dataset, do some preprocess to the dataset.
+
+        Return:
+            validation dataloader
+        """
+        raise NotImplementedError()
+
+    @final
+    @property
+    def validation_loader(self) -> DataLoader:
+        """Get the validation dataloader object if needed."""
+        if not hasattr(self, '_validation_loader'):
+            self._validation_loader = self.build_validation_dataloader()
+        return self._validation_loader
+
+    @abstractmethod
+    def build_test_dataloader(self) -> DataLoader:
+        """Define the testing dataloader.
+
+        You can transform the dataset, do some preprocess to the dataset. If you do not
+        want to do testing after training, simply make it return None.
+
+        Args:
+            dataset:
+                training dataset
+        Return:
+            testing dataloader
+        """
+
+    @final
+    @property
+    def test_loader(self) -> DataLoader:
+        """Get the testing dataloader object."""
+        if not hasattr(self, '_test_loader'):
+            self._test_loader = self.build_test_dataloader()
+        return self._test_loader
+
+    def state_dict(self) -> Dict[str, torch.Tensor]:
+        """Get the params that need to train and update.
+
+        Only the params returned by this function will be updated and saved during aggregation.
+        Return self.model.state_dict() by default.
+
+        Return:
+            List[torch.Tensor], The list of model params.
+        """
+        return self.model.state_dict()
+
+    def load_state_dict(self, state_dict: Dict[str, torch.Tensor]):
+        """Load the params that trained and updated.
+
+        Only the params returned by state_dict() should be loaded by this function.
+        Execute self.model.load_state_dict(state_dict) by default.
+        """
+        self.model.load_state_dict(state_dict)
+
+    def validate_context(self):
+        """Validate if the local running context is ready.
+
+        For example: check if train and test dataset could be loaded successfully.
+        """
+        if self.model is None:
+            raise ConfigError('Must specify a model to train')
+        if not isinstance(self.model, Module):
+            raise ConfigError('Support torch.Module only')
+        if self.optimizer is None:
+            raise ConfigError('Must specify an optimizer to train')
+        if not isinstance(self.optimizer, Optimizer):
+            raise ConfigError('Support torch.optim.Optimizer only')
+
+    @abstractmethod
+    def train_an_epoch(self) -> Any:
+        """Define the training steps in an epoch."""
+
+    @abstractmethod
+    def run_test(self) -> Any:
+        """Define the testing steps.
+
+        If you do not want to do testing after training, simply make it pass.
+        """
+
+    def is_task_finished(self) -> bool:
+        """By default true if reach the max rounds configured."""
+        return self._is_reach_max_rounds()
+
+    def _run(self, id: str, task_id: str, is_initiator: bool = False, recover: bool = False):
+        self._setup_context(id=id, task_id=task_id, is_initiator=is_initiator)
+        self.push_log(message='Local context is ready.')
+        try:
+            if self.is_aggregator and recover:
+                self._recover_progress()
+            else:
+                self._clean_progress()
+            self._launch_process()
+        except Exception:
+            err_stack = '\n'.join(traceback.format_exception(*sys.exc_info()))
+            self.push_log(err_stack)
+
+    def _setup_context(self, id: str, task_id: str, is_initiator: bool = False):
+        assert id, 'must specify a unique id for every participant'
+        assert task_id, 'must specify a task_id for every participant'
+
+        self.id = id
+        self.task_id = task_id
+        self._runtime_dir = get_runtime_dir(self.task_id)
+        self._context_file = os.path.join(self._runtime_dir, ".context.json")
+        self._checkpoint_dir = os.path.join(self._runtime_dir, 'checkpoint')
+        self._ckpt_file = os.path.join(self._checkpoint_dir, "model_ckpt.pt")
+        self._result_dir = get_result_dir(self.task_id)
+        self._log_dir = os.path.join(self._result_dir, 'tb_logs')
+        self.tb_writer = SummaryWriter(log_dir=self._log_dir)
+
+        self.is_initiator = is_initiator
+        self.is_aggregator = self.is_initiator
+
+        self.contractor = self._init_contractor()
+        self.data_channel = SharedFileDataChannel(self.contractor)
+        self.model
+        self.optimizer
+
+        if self.is_initiator:
+            self.participants = self.contractor.query_nodes()
+            if len(self.participants) < 2:
+                raise TaskFailed('Failed to get participants list.')
+
+        self.push_log(message='Begin to validate local context.')
+        self.validate_context()
+
+    def _init_contractor(self):
+        return FedAvgContractor(task_id=self.task_id)
+
+    def _recover_progress(self):
+        """Try to recover and continue from last running."""
+        if not os.path.isfile(self._context_file):
+            raise TaskFailed('Failed to recover progress: missing cached context.')
+
+        with open(self._context_file, 'r') as f:
+            context_info: dict = json.load(f)
+        round = context_info.get('round')
+        ckpt_file = context_info.get('ckpt_file')
+        assert round and isinstance(round, int) and round > 0, f'Invalid round: {round} .'
+        assert ckpt_file and isinstance(ckpt_file, str), f'Invalid ckpt_file: {ckpt_file} .'
+        if not os.path.isfile(ckpt_file):
+            raise TaskFailed('Failed to recover progress: missing checkpoint parameters.')
+
+        self.current_round = round
+        with open(ckpt_file, 'rb') as f:
+            state_dict = torch.load(f)
+            self.load_state_dict(state_dict)
+
+    def _clean_progress(self):
+        """Clean existing progress data."""
+        shutil.rmtree(self._runtime_dir, ignore_errors=True)
+        shutil.rmtree(self._result_dir, ignore_errors=True)
+        os.makedirs(self._runtime_dir, exist_ok=True)
+        os.makedirs(self._checkpoint_dir, exist_ok=True)
+        os.makedirs(self._result_dir, exist_ok=True)
+        os.makedirs(self._log_dir, exist_ok=True)
+
+    def _launch_process(self):
+        try:
+            assert self.status == self._INIT, 'must begin from initial status'
+            self.push_log(f'Node {self.id} is up.')
+
+            self._switch_status(self._GETHORING)
+            self._check_in()
+
+            self._switch_status(self._READY)
+            while self.status == self._READY:
+                try:
+                    self._switch_status(self._SYNCHRONIZING)
+                    self._sync_state()
+
+                    self._switch_status(self._IN_A_ROUND)
+                    self._run_a_round()
+                    self._switch_status(self._READY)
+                except ResetRound:
+                    self.push_log('WARNING: Reset runtime context, there might be an error raised.')
+                    self._switch_status(self._READY)
+                    continue
+
+                if self.is_aggregator:
+                    is_finished = self.is_task_finished()
+                    self._persistent_running_context()
+                    self._switch_status(self._READY)
+                    self.current_round += 1
+                    if is_finished:
+                        self.push_log(f'Obtained the final results of task {self.task_id}')
+                        self._switch_status(self._FINISHING)
+                        self._close_task()
+
+        except TaskComplete:
+            logger.info('training task complete')
+
+    def _check_in(self):
+        """Check in task and get ready.
+
+        As an initiator (and default the first aggregator), records each participants
+        and launches election or training process accordingly.
+        As a participant, checkins and gets ready for election or training.
+        """
+        if self.is_initiator:
+            self.push_log('Waiting for participants taking part in ...')
+            self._wait_for_gathering()
+            self.is_gathering_complete = True
+        else:
+            is_checked_in = False
+            # the aggregator may be in special state so can not response
+            # correctly nor in time, then retry periodically
+            self.push_log('Checking in the task ...')
+            while not is_checked_in:
+                is_checked_in = self._check_in_task()
+            self.push_log(f'Node {self.id} have taken part in the task.')
+
+    def _sync_state(self):
+        """Synchronize state before each round, so it's easier to manage the process.
+
+        As an aggregator, iterates round, broadcasts and resets context of the new round.
+        As a participant, synchronizes state and gives a response.
+        """
+        self.push_log('Synchronizing round state ...')
+        if self.is_aggregator:
+            self.push_log(f'Initiate state synchronization of round {self.current_round}.')
+            self.contractor.sync_state(round=self.current_round, aggregator=self.id)
+            self._wait_for_sync_response()
+        else:
+            self._wait_for_sync_state()
+        self.push_log(f'Successfully synchronized state in round {self.current_round}')
+
+    def _run_a_round(self):
+        """Perform a round of FedAvg calculation.
+
+        As an aggregator, selects a part of participants as actual calculators
+        in the round, distributes latest parameters to them, collects update and
+        makes aggregation.
+        As a participant, if is selected as a calculator, calculates and uploads
+        parameter update.
+        """
+        if self.is_aggregator:
+            try:
+                self._run_as_aggregator()
+            except AggregationError as err:
+                err_stack = '\n'.join(traceback.format_exception(*sys.exc_info()))
+                self.push_log(err_stack)
+                self.contractor.reset_round()
+                raise ResetRound(err)
+        else:
+            self._run_as_data_owner()
+
+    def _close_task(self, is_succ: bool = True):
+        """Close the FedAvg calculation.
+
+        As an aggregator, broadcasts the finish task event to all participants,
+        uploads the final parameters and tells L1 task manager the task is complete.
+        As a participant, do nothing.
+        """
+        self.push_log(f'Closing task {self.task_id} ...')
+        if is_succ and self.is_aggregator:
+            self._switch_status(self._FINISHING)
+            self.contractor.finish_task()
+            report_file_path, model_file_path = self._prepare_task_output()
+            self.contractor.upload_metric_report(receivers=self.contractor.EVERYONE,
+                                                 report_file=report_file_path)
+            self.contractor.upload_model(receivers=self.contractor.EVERYONE,
+                                         model_file=model_file_path)
+            self.contractor.notify_task_completion(result=True)
+        elif self.is_aggregator:
+            self.contractor.finish_task()
+            self.contractor.notify_task_completion(result=False)
+        self.push_log(f'Task {self.task_id} closed. Byebye!')
+
+    def _wait_for_gathering(self):
+        """Wait for participants gethering."""
+        logger.debug('_wait_for_gathering ...')
+        for _event in self.contractor.contract_events():
+            if isinstance(_event, CheckinEvent):
+                self._handle_check_in(_event)
+                if len(self.gethered) == len(self.participants) - 1:
+                    return
+
+    def _handle_check_in(self, _event: CheckinEvent):
+        if _event.peer_id not in self.gethered:
+            self.gethered.append(_event.peer_id)
+            self.push_log(f'Welcome a new participant ID: {_event.peer_id}.')
+            self.push_log(f'There are {len(self.gethered) + 1} participants now.')
+        self.contractor.respond_check_in(round=self.current_round,
+                                         aggregator=self.id,
+                                         nonce=_event.nonce,
+                                         requester_id=_event.peer_id)
+        if self.is_gathering_complete:
+            self.contractor.sync_state(round=self.current_round, aggregator=self.id)
+
+    def _wait_for_sync_response(self):
+        """Wait for participants' synchronizing state response."""
+        self.push_log('Waiting for synchronization responses ...')
+        synced = set()
+        for _event in self.contractor.contract_events(timeout=0):
+            if isinstance(_event, SyncStateResponseEvent):
+                if _event.round != self.current_round:
+                    continue
+                synced.add(_event.peer_id)
+                self.push_log(f'Successfully synchronized state with ID: {_event.peer_id}.')
+                self.push_log(f'Successfully synchronized with {len(synced)} participants.')
+                if len(synced) == len(self.gethered):
+                    return
+
+            elif isinstance(_event, CheckinEvent):
+                self._handle_check_in(_event)
+
+    def _check_in_task(self) -> bool:
+        """Try to check in the task."""
+        nonce = self.contractor.checkin(peer_id=self.id)
+        return self._wait_for_check_in_response(nonce=nonce,
+                                                timeout=self.schedule_timeout)
+
+    def _wait_for_check_in_response(self, nonce: str, timeout: int = 0) -> bool:
+        """Wait for checkin response.
+
+        Return True if received response successfully otherwise False.
+        """
+        logger.debug('_wait_for_check_in_response ...')
+        for _event in self.contractor.contract_events(timeout=timeout):
+            if isinstance(_event, CheckinResponseEvent):
+                if _event.nonce != nonce:
+                    continue
+                self.current_round = _event.round
+                return True
+            elif isinstance(_event, FinishTaskEvent):
+                raise TaskComplete()
+        return False
+
+    def _wait_for_sync_state(self, timeout: int = 0) -> bool:
+        """Wait for synchronising latest task state.
+
+        Return True if synchronising successfully otherwise False.
+        """
+        self.push_log('Waiting for synchronizing state with the aggregator ...')
+        for _event in self.contractor.contract_events(timeout=timeout):
+            if isinstance(_event, SyncStateEvent):
+                self.current_round = _event.round
+                self.contractor.respond_sync_state(round=self.current_round,
+                                                   peer_id=self.id,
+                                                   aggregator=_event.aggregator)
+                self.push_log('Successfully synchronized state with the aggregator.')
+                return
+            elif isinstance(_event, FinishTaskEvent):
+                raise TaskComplete()
+
+    def _run_as_aggregator(self):
+        self._start_round()
+        self._distribute_model()
+
+        self._process_aggregation()
+
+        self._check_and_run_test()
+        self._close_round()
+
+    def _close_round(self):
+        """Close current round when finished."""
+        self._switch_status(self._CLOSING_ROUND)
+        self.contractor.close_round(round=self.current_round)
+        self.push_log(f'The training of Round {self.current_round} complete.')
+
+    def _start_round(self):
+        """Prepare and start calculation of a round."""
+        self.push_log(f'Begin the training of round {self.current_round}.')
+        self.contractor.start_round(round=self.current_round,
+                                    calculators=self.gethered,
+                                    aggregator=self.id)
+        self.push_log(f'Calculation of round {self.current_round} is started.')
+
+    def _distribute_model(self):
+        buffer = io.BytesIO()
+        torch.save(self.state_dict(), buffer)
+        self.push_log('Distributing parameters ...')
+        results = {_target: False for _target in self.gethered}
+        accept_list = self.data_channel.batch_send_stream(source=self.id,
+                                                          target=list(results.keys()),
+                                                          data_stream=buffer.getvalue())
+        self.push_log(f'Successfully distributed parameters to: {accept_list}')
+        if len(results.keys()) != len(accept_list):
+            reject_list = [_target for _target in results.keys()
+                           if _target not in accept_list]
+            self.push_log(f'Failed to distribute parameters to: {reject_list}')
+        results.update({_target: True for _target in accept_list})
+
+        if sum(results.values()) < len(self.gethered):
+            self.push_log('Task failed because of too few calculators getting ready')
+            raise AggregationError(f'Too few calculators getting ready: {results}.')
+        self.push_log(f'Distributed parameters to {sum(results.values())} calculators.')
+
+    def _process_aggregation(self):
+        """Process aggregation depending on specific algorithm."""
+        # run training if necessary or zeroize parameters
+        if self.involve_aggregator:
+            self._execute_training()
+            self.push_log(f'The aggregator ID: {self.id} obtained its calculation results.')
+        else:
+            for _param in self.state_dict().values():
+                if isinstance(_param, torch.Tensor):
+                    _param.zero_()
+        # collect participants' results
+        self._switch_status(self._WAIT_FOR_AGGR)
+        self.contractor.notify_ready_for_aggregation(round=self.current_round)
+        self.push_log('Now waiting for executing calculation ...')
+        accum_result, result_count = self._wait_for_calculation()
+        if result_count < len(self.gethered) + int(self.involve_aggregator):
+            self.push_log('Task failed because of too few calculation results gathered.')
+            raise AggregationError(f'Too few results gathered: {result_count} copies.')
+        self.push_log(f'Received {result_count} copies of calculation results.')
+
+        self._switch_status(self._AGGREGATING)
+        self.push_log('Begin to aggregate and update parameters.')
+        for _key in accum_result.keys():
+            if accum_result[_key].dtype in (
+                torch.uint8, torch.int8, torch.int16, torch.int32, torch.int64
+            ):
+                logger.warn(f'average a int value may lose precision: {_key=}')
+                accum_result[_key].div_(result_count, rounding_mode='trunc')
+            else:
+                accum_result[_key].div_(result_count)
+        self.load_state_dict(accum_result)
+        self.push_log('Obtained a new version of parameters.')
+
+    def _persistent_running_context(self):
+        self._switch_status(self._PERSISTING)
+        self._save_model()
+        self._save_runtime_context()
+
+    def _check_and_run_test(self):
+        """Run test if match configured conditions."""
+        if (
+            self.current_round == 1
+            or (self.log_rounds > 0 and self.current_round % self.log_rounds == 0)
+            or self.current_round == self.max_rounds
+        ):
+            self.push_log('Begin to make a model test.')
+            self.run_test()
+            self.push_log('Finished a round of test.')
+
+    def _wait_for_calculation(self) -> Tuple[Dict[str, torch.Tensor], int]:
+        """Wait for every calculator finish its task or timeout."""
+        result_count = int(self.involve_aggregator)
+        accum_result = self.state_dict()
+
+        self.push_log('Waiting for training results ...')
+        training_results = self.data_channel.batch_receive_stream(
+            receiver=self.id,
+            source_list=self.gethered,
+            timeout=self.calculation_timeout
+        )
+        for _source, _result in training_results.items():
+            buffer = io.BytesIO(_result)
+            _new_state_dict = torch.load(buffer)
+            for _key in accum_result.keys():
+                accum_result[_key].add_(_new_state_dict[_key])
+            result_count += 1
+            self.push_log(f'Received calculation results from ID: {_source}')
+
+        return accum_result, result_count
+
+    def _is_reach_max_rounds(self) -> bool:
+        """Is the max rounds configuration reached."""
+        return self.current_round >= self.max_rounds
+
+    def _save_model(self):
+        """Save latest model state."""
+        with open(self._ckpt_file, 'wb') as f:
+            torch.save(self.state_dict(), f)
+        self.push_log('Saved latest parameters locally.')
+
+    def _save_runtime_context(self):
+        """Save runtime context information in case of restoring."""
+        context_info = {
+            'round': self.current_round,
+            'ckpt_file': self._ckpt_file
+        }
+        with open(self._context_file, 'w') as f:
+            f.write(json.dumps(context_info, ensure_ascii=False))
+        self.push_log('Saved latest runtime context.')
+
+    def _prepare_task_output(self) -> Tuple[str, str]:
+        """Generate final output files of the task.
+
+        Return:
+            Local paths of the report file and model file.
+        """
+        self.push_log('Uploading task achievement and closing task ...')
+
+        report_file = os.path.join(self._result_dir, "report.zip")
+        with ZipFile(report_file, 'w') as report_zip:
+            for path, _, filenames in os.walk(self._log_dir):
+                rel_dir = os.path.relpath(path=path, start=self._result_dir)
+                rel_dir = rel_dir.lstrip('.')  # ./file => file
+                for _file in filenames:
+                    rel_path = os.path.join(rel_dir, _file)
+                    report_zip.write(os.path.join(path, _file), rel_path)
+        report_file_path = os.path.abspath(report_file)
+
+        model_file = os.path.join(self._result_dir, "model.pt")
+        with open(model_file, 'wb') as f:
+            torch.save(self.state_dict(), f)
+        model_file_path = os.path.abspath(model_file)
+
+        self.push_log('Task achievement files are ready.')
+        return report_file_path, model_file_path
+
+    def _run_as_data_owner(self):
+        try:
+            self._wait_for_starting_round()
+            self._switch_status(self._UPDATING)
+            self._wait_for_updating_model()
+            self._save_model()
+            self._switch_status(self._CALCULATING)
+            self.push_log('Begin to run calculation ...')
+            self._execute_training()
+            self.push_log('Local calculation complete.')
+
+            self._wait_for_uploading_model()
+            buffer = io.BytesIO()
+            torch.save(self.state_dict(), buffer)
+            self.push_log('Pushing local update to the aggregator ...')
+            self.data_channel.send_stream(source=self.id,
+                                          target=self._aggregator,
+                                          data_stream=buffer.getvalue())
+            self.push_log('Successfully pushed local update to the aggregator.')
+            self._switch_status(self._CLOSING_ROUND)
+            self._wait_for_closing_round()
+        except SkipRound:
+            pass
+
+        self.push_log(f'ID: {self.id} finished training task of round {self.current_round}.')
+
+    def _execute_training(self):
+        for _ in range(self.merge_epochs):
+            self.train_an_epoch()
+
+    def _wait_for_starting_round(self):
+        """Wait for starting a new round of training."""
+        self.push_log(f'Waiting for training of round {self.current_round} begin ...')
+        for _event in self.contractor.contract_events():
+            if isinstance(_event, StartRoundEvent):
+                if _event.round != self.current_round:
+                    continue
+                if self.id not in _event.calculators:
+                    raise SkipRound()
+                self._aggregator = _event.aggregator
+                self.push_log(f'Training of round {self.current_round} begins.')
+                return
+            elif isinstance(_event, FinishTaskEvent):
+                raise TaskComplete()
+            elif isinstance(_event, ResetRoundEvent):
+                raise ResetRound()
+
+    def _wait_for_updating_model(self):
+        """Wait for receiving latest parameters from aggregator."""
+        def _complementary_handler(event: ContractEvent):
+            if isinstance(event, FinishTaskEvent):
+                raise TaskComplete()
+            elif isinstance(event, ResetRoundEvent):
+                raise ResetRound()
+
+        self.push_log('Waiting for receiving latest parameters from the aggregator ...')
+        _, parameters = self.data_channel.receive_stream(
+            receiver=self.id,
+            complementary_handler=_complementary_handler,
+            source=self._aggregator
+        )
+        buffer = io.BytesIO(parameters)
+        new_state_dict = torch.load(buffer)
+        self.load_state_dict(new_state_dict)
+        self.push_log('Successfully received latest parameters.')
+
+    def _wait_for_uploading_model(self):
+        """Wait for uploading trained parameters to aggregator."""
+        self.push_log('Waiting for aggregation begin ...')
+        for _event in self.contractor.contract_events():
+            if isinstance(_event, ReadyForAggregationEvent):
+                if _event.round != self.current_round:
+                    continue
+                return
+            elif isinstance(_event, FinishTaskEvent):
+                raise TaskComplete()
+            elif isinstance(_event, ResetRoundEvent):
+                raise ResetRound()
+
+    def _wait_for_closing_round(self):
+        """Wait for closing current round of training."""
+        self.push_log(f'Waiting for closing signal of training round {self.current_round} ...')
+        for _event in self.contractor.contract_events():
+            if isinstance(_event, CloseRoundEvent):
+                if _event.round != self.current_round:
+                    continue
+                return
+            elif isinstance(_event, FinishTaskEvent):
+                raise TaskComplete()
+            elif isinstance(_event, ResetRoundEvent):
+                raise ResetRound()
+
+
+class FedSGDScheduler(FedAvgScheduler):
+    """Implementation of FedSGD."""
+
+    def __init__(self,
+                 max_rounds: int = 0,
+                 calculation_timeout: int = 300,
+                 schedule_timeout: int = 30,
+                 log_rounds: int = 0):
+        """Init.
+
+        By now, IterableDataset with no length is not supported.
+
+        Args:
+            max_rounds:
+                Maximal number of training rounds.
+            calculation_timeout:
+                Seconds to timeout for calculation in a round. Takeing off timeout
+                by setting its value to 0.
+            schedule_timeout:
+                Seconds to timeout for process scheduling. Takeing off timeout
+                by setting its value to 0.
+            log_rounds:
+                The number of rounds to run testing and log the result. Skip it
+                by setting its value to 0.
+        """
+        super().__init__(max_rounds=max_rounds,
+                         merge_epochs=1,
+                         calculation_timeout=calculation_timeout,
+                         schedule_timeout=schedule_timeout,
+                         log_rounds=log_rounds)
+
+    def _setup_context(self, id: str, task_id: str, is_initiator: bool = False):
+        super()._setup_context(id=id, task_id=task_id, is_initiator=is_initiator)
+        # Since build_train_dataloader is implemented by the user, and DataLoader base
+        # implementation does not allow to modify batch_size after initialization,
+        # there is no way to mandatorily set batch size to the correct value.
+        # So a post check is used.
+        self.push_log(f'train batch size = {self.train_loader.batch_size}')
+        try:
+            num_samples = len(self.train_loader.dataset)
+            self.push_log(f'train examples = {num_samples}')
+            if self.train_loader.batch_size != num_samples:
+                raise ConfigError('batch size must be the total number of samples.')
+        except TypeError:
+            raise ConfigError('Does not support iterable dataset with no length.')
```

### Comparing `alphamed-federated-0.4.7/src/alphafed/fed_avg/secure_contractor.py` & `alphamed-federated-0.4.9/src/alphafed/fed_avg/secure_contractor.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/fed_avg/secure_fed_avg.py` & `alphamed-federated-0.4.9/src/alphafed/fed_avg/secure_fed_avg.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/fs.py` & `alphamed-federated-0.4.9/src/alphafed/fs.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/hetero_nn/contractor.py` & `alphamed-federated-0.4.9/src/alphafed/hetero_nn/contractor.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/hetero_nn/hetero_nn.py` & `alphamed-federated-0.4.9/src/alphafed/hetero_nn/hetero_nn.py`

 * *Ordering differences only*

 * *Files 15% similar despite different names*

```diff
@@ -1,1196 +1,1196 @@
-"""The host of a hetero_nn task.
-
-Reference: https://arxiv.org/pdf/2007.06849.pdf
-"""
-
-import io
-import json
-import os
-import shutil
-import sys
-import traceback
-from abc import ABC, ABCMeta, abstractmethod
-from tempfile import TemporaryFile
-from typing import Dict, List, Set, Tuple, final
-from zipfile import ZipFile
-
-import torch
-import torch.nn as nn
-import torch.optim as optim
-from torch.utils.tensorboard import SummaryWriter
-
-from .. import get_result_dir, get_runtime_dir, logger
-from ..data_channel import SharedFileDataChannel
-from ..scheduler import ConfigError, Scheduler, TaskComplete, TaskFailed
-from .contractor import (CheckinEvent, CheckinResponseEvent, CloseRoundEvent,
-                         CloseTestRoundEvent, CollaboratorCompleteEvent,
-                         CompleteTaskEvent, ContractEvent, FailTaskEvent,
-                         HeteroNNContractor, ReadyForFusionEvent,
-                         ResetRoundEvent, StartRoundEvent, StartTestRoundEvent,
-                         SyncStateEvent, SyncStateResponseEvent)
-from .psi import RSAPSICollaboratorScheduler, RSAPSIInitiatorScheduler
-
-__all__ = ['HeteroNNHostScheduler', 'HeteroNNCollaboratorScheduler']
-
-_FEATURE_KEY = str
-
-
-class ResetRound(Exception):
-    ...
-
-
-class _SimplifiedOptimizer(ABC):
-    """A simplified optimizer tool to facilitate update parameters."""
-
-    @abstractmethod
-    def zero_grad(self):
-        """To clean grad of parameters, as a normal PyTorch Optimizer."""
-
-    @abstractmethod
-    def step(self):
-        """To update parameters, as a normal PyTorch Optimizer."""
-
-
-class HeteroNNScheduler(Scheduler, metaclass=ABCMeta):
-    """Base scheduler for heteto_nn tasks."""
-
-    _INIT = 'init'
-    _GETHORING = 'gethoring'
-    _ID_INTERSECTION = 'id_intersection'
-    _READY = 'ready'
-    _SYNCHRONIZING = 'synchronizing'
-    _IN_A_ROUND = 'in_a_round'
-    _PROJECTING = 'projecting'
-    _FINISHING = 'finishing'
-    _UPDATING = 'updating'
-    _PERSISTING = 'persisting'
-    _TESTING = 'testing'
-    _CLOSING_ROUND = 'closing_round'
-
-    def __init__(self) -> None:
-        super().__init__()
-        self.feature_model
-        self.feature_optimizer
-
-        self._id_intersection = None
-        self._local_features: torch.Tensor = None
-        self._example_feature_inputs = None
-
-    @abstractmethod
-    def _setup_context(self, id: str, task_id: str, is_initiator: bool = False):
-        assert id, 'must specify a unique id for every participant'
-        assert task_id, 'must specify a task_id for every participant'
-
-        self.id = id
-        self.task_id = task_id
-        self.is_host = is_initiator
-        self._result_dir = get_result_dir(self.task_id)
-        self._log_dir = os.path.join(self._result_dir, 'tb_logs')
-        self.tb_writer = SummaryWriter(log_dir=self._log_dir)
-
-        self.contractor = HeteroNNContractor(task_id=task_id)
-        self.data_channel = SharedFileDataChannel(self.contractor)
-
-    @abstractmethod
-    def load_local_ids(self) -> List[str]:
-        """Load all local data IDs for PSI."""
-
-    @abstractmethod
-    def split_dataset(self, id_intersection: Set[str]) -> Tuple[Set[str], Set[str]]:
-        """Split dataset into train set and test set.
-
-        NOTE: Must make sure each node gets the same split results.
-
-        :return
-            A tuple of ID set of training dataset and of testing dataset:
-            (Set[train_ids], Set[test_ids]).
-        """
-
-    @abstractmethod
-    def build_feature_model(self) -> nn.Module:
-        """Return a model object to project input to features.
-
-        The output of feature model MUST be a (str_keyword, torch.Tensor) tuple, where
-        str_keyword is used by the host to distinguish features from collaborators
-        and Tensor is a two dimension (batch, feature_vector) tensor as the input
-        of projection layer.
-        """
-
-    @property
-    def feature_model(self) -> nn.Module:
-        if not hasattr(self, '_feature_model'):
-            self._feature_model = self.build_feature_model()
-        return self._feature_model
-
-    @abstractmethod
-    def build_feature_optimizer(self, feature_model: nn.Module) -> optim.Optimizer:
-        """Return a optimizer object to facilitate training feature model.
-
-        :args
-            :feature_model
-                The feature model object to train & test.
-        """
-
-    @final
-    @property
-    def feature_optimizer(self) -> optim.Optimizer:
-        if not hasattr(self, '_feature_optimizer'):
-            assert self.feature_model, 'Must initialize feature model at first.'
-            self._feature_optimizer = self.build_feature_optimizer(self.feature_model)
-        return self._feature_optimizer
-
-    @final
-    @property
-    def id_intersection(self) -> Set[str]:
-        """Return the intersection of whole dataset IDs."""
-        assert self._id_intersection is not None, 'Have not run ID intersection process.'
-        return self._id_intersection
-
-    @final
-    @property
-    def train_ids(self) -> Set[str]:
-        """Return the ID set of training dataset intersection."""
-        if not hasattr(self, '_train_ids'):
-            assert self.id_intersection, 'Must get the whole ID intersection at first.'
-            self._train_ids, self._test_ids = self.split_dataset(self.id_intersection.copy())
-        return self._train_ids
-
-    @final
-    @property
-    def test_ids(self) -> Set[str]:
-        """Return the ID set of testing dataset intersection."""
-        if not hasattr(self, '_test_ids'):
-            assert self.id_intersection, 'Must get the whole ID intersection at first.'
-            self._train_ids, self._test_ids = self.split_dataset(self.id_intersection.copy())
-        return self._test_ids
-
-    @abstractmethod
-    def _launch_process(self):
-        """Run the main process of the task."""
-
-    @abstractmethod
-    def _recover_progress():
-        """Try to recover progress from last running."""
-
-    @abstractmethod
-    def _clean_progress(self):
-        """Clean existing progress data."""
-
-    def _run(self, id: str, task_id: str, is_initiator: bool = False, recover: bool = False):
-        self._setup_context(id=id, task_id=task_id, is_initiator=is_initiator)
-        self.push_log(message='Local context is ready.')
-        try:
-            if recover:
-                self._recover_progress()
-            else:
-                self._clean_progress()
-            self._launch_process()
-        except Exception:
-            err_stack = '\n'.join(traceback.format_exception(*sys.exc_info()))
-            self.push_log(err_stack)
-
-
-class HeteroNNHostScheduler(HeteroNNScheduler):
-    """Schedule the process of the host in a hetero_nn task."""
-
-    _WAITING_FOR_FEATURES = 'wait_4_feature'
-    _GETTING_GRAD = 'calc_loss'
-    _DISTRIBUTING_FEATURE_GRAD = 'distribute_grad'
-
-    def __init__(self,
-                 feature_key: str,
-                 max_rounds: int = 0,
-                 calculation_timeout: int = 300,
-                 schedule_timeout: int = 30,
-                 log_rounds: int = 0,
-                 is_feature_trainable: bool = True) -> None:
-        r"""Init.
-
-        :args
-            :feature_key
-                A unique key of feature used by the host to distinguish features
-                from collaborators.
-            :max_rounds
-                Maximal number of training rounds.
-            :calculation_timeout
-                Seconds to timeout for calculation in a round. Takeing off timeout
-                by setting its value to 0.
-            :schedule_timeout
-                Seconds to timeout for process scheduling. Takeing off timeout
-                by setting its value to 0.
-            :log_rounds
-                The number of rounds to run testing and log the result. Skip it
-                by setting its value to 0.
-            :is_feature_trainable
-                Decide whether or not train the feature model
-        """
-        super().__init__()
-        self._switch_status(self._INIT)
-
-        self.feature_key = feature_key
-        self.max_rounds = max_rounds
-        self.calculation_timeout = calculation_timeout
-        self.schedule_timeout = schedule_timeout
-        self.log_rounds = log_rounds
-        self.is_feature_trainable = is_feature_trainable  # TODO 暂时不考虑
-
-        self._validate_config()
-
-        self.infer_model
-        self.infer_optimizer
-
-        self.current_round = 1
-        self._partners: List[str] = []
-
-        self._example_project_input = None
-        self._example_infer_input = None
-
-        self._alpha_map: Dict[str, Dict[_FEATURE_KEY, torch.Tensor]] = {}
-        self._feature_fusion_map: Dict[_FEATURE_KEY, torch.Tensor] = {}
-        self._batched_test_features: List[List[Dict[_FEATURE_KEY, torch.Tensor]]] = []
-
-    def _validate_config(self):
-        if not self.feature_key or not isinstance(self.feature_key, str):
-            raise ConfigError('Must specify a feature_key of type string.')
-
-    @abstractmethod
-    def build_infer_model(self) -> nn.Module:
-        """Return a model object to infer business results."""
-
-    @final
-    @property
-    def infer_model(self) -> nn.Module:
-        if not hasattr(self, '_infer_model'):
-            self._infer_model = self.build_infer_model()
-        return self._infer_model
-
-    @abstractmethod
-    def build_infer_optimizer(self, infer_model: nn.Module) -> optim.Optimizer:
-        """Return a optimizer object to facilitate training infer model.
-
-        :args
-            :infer_model
-                The infer model object to train & test.
-        """
-
-    @final
-    @property
-    def infer_optimizer(self) -> optim.Optimizer:
-        if not hasattr(self, '_infer_optimizer'):
-            self._infer_optimizer = self.build_infer_optimizer(self.infer_model)
-        return self._infer_optimizer
-
-    @final
-    @property
-    def optimizer(self) -> _SimplifiedOptimizer:
-        """Return a general optimizer to wrap the 3 (feature, project, infer) optimizers."""
-
-        class _OptimizerImpl(_SimplifiedOptimizer):
-
-            def __init__(self, host_obj: HeteroNNHostScheduler) -> None:
-                super().__init__()
-                self.host_obj = host_obj
-
-            def zero_grad(self):
-                self.host_obj.infer_optimizer.zero_grad()
-                self.host_obj.feature_optimizer.zero_grad()
-
-            def step(self):
-                self.host_obj.infer_optimizer.step()
-                self.host_obj.feature_optimizer.step()
-
-        if not hasattr(self, '_optimizer'):
-            self._optimizer = _OptimizerImpl(host_obj=self)
-        return self._optimizer
-
-    @abstractmethod
-    def iterate_train_feature(self,
-                              feature_model: nn.Module,
-                              train_ids: Set[str]) -> Tuple[torch.Tensor, torch.Tensor]:
-        """Iterate over train dataset and features a batch of data each time.
-
-        :args
-            :feature_model
-                The feature model object to train & test.
-            :train_ids
-                The ID set of train dataset.
-        :return
-            A tuple of a batch of train data and their labels. (train_data, labels)
-        """
-
-    @abstractmethod
-    def iterate_test_feature(self,
-                             feature_model: nn.Module,
-                             test_ids: Set[str]) -> Tuple[torch.Tensor, torch.Tensor]:
-        """Iterate over test dataset and features a batch of data each time.
-
-        :args
-            :feature_model
-                The feature model object to train & test.
-            :train_ids
-                The ID set of test dataset.
-        :return
-            A tuple of a batch of test data and their labels. (test_data, labels)
-        """
-
-    @abstractmethod
-    def train_a_batch(self, feature_projection: Dict[str, torch.Tensor], labels: torch.Tensor):
-        """Train a batch of data in infer model.
-
-        :args
-            :feature_projection
-                A map containing features from all nodes of type feature_key => feature_tensor.
-            :labels
-                Corresponding labels of the batch of data.
-        """
-
-    @abstractmethod
-    def run_test(self,
-                 batched_feature_projection: List[Dict[str, torch.Tensor]],
-                 batched_labels: List[torch.Tensor]):
-        """Define the testing steps.
-
-        If you do not want to do testing after training, simply make it pass.
-
-        :args
-            :batched_feature_projections
-                A list of feature projection grouped by batch of testing data. Each batch
-                is a map containing features from all nodes of type feature_key => feature_tensor.
-            :batched_labels
-                A list of labels grouped by batch of testing data.
-        """
-
-    def validate_context(self):
-        """Validate if the local running context is ready.
-
-        For example: check if train and test dataset could be loaded successfully.
-        """
-        if self.feature_model is None:
-            raise ConfigError('Failed to initialize a feature model.')
-        if not isinstance(self.feature_model, nn.Module):
-            err_msg = 'Support feature model of type torch.Module only.'
-            err_msg += f'Got a {type(self.feature_model)} object.'
-            raise ConfigError(err_msg)
-        if self.feature_optimizer is None:
-            raise ConfigError('Failed to initialize a feature optimizer.')
-        if not isinstance(self.feature_optimizer, optim.Optimizer):
-            err_msg = 'Support feature optimizer of type torch.optim.Optimizer only.'
-            err_msg += f'Got a {type(self.feature_optimizer)} object.'
-            raise ConfigError(err_msg)
-
-        if self.infer_model is None:
-            raise ConfigError('Failed to initialize a infer model.')
-        if not isinstance(self.infer_model, nn.Module):
-            err_msg = 'Support infer model of type torch.Module only.'
-            err_msg += f'Got a {type(self.infer_model)} object.'
-            raise ConfigError(err_msg)
-        if self.infer_optimizer is None:
-            raise ConfigError('Failed to initialize a infer optimizer.')
-        if not isinstance(self.infer_optimizer, optim.Optimizer):
-            err_msg = 'Support infer optimizer of type torch.optim.Optimizer only.'
-            err_msg += f'Got a {type(self.infer_optimizer)} object.'
-            raise ConfigError(err_msg)
-
-        if not self._partners:
-            raise TaskFailed('No partners.')
-
-    def is_task_finished(self) -> bool:
-        """By default true if reach the max rounds configured."""
-        return self._is_reach_max_rounds()
-
-    def _init_partners(self):
-        """Query and set all partners in this task."""
-        self._partners = self.contractor.query_partners()
-        self._partners.remove(self.id)
-
-    def _setup_context(self, id: str, task_id: str, is_initiator: bool = False):
-        super()._setup_context(id=id, task_id=task_id, is_initiator=is_initiator)
-
-        self._init_partners()
-        self._check_in_status = {_partner: False for _partner in self._partners}
-        self._is_gathering_complete = False
-
-        self._runtime_dir = get_runtime_dir(self.task_id)
-        self._context_file = os.path.join(self._runtime_dir, ".context.json")
-        self._checkpoint_dir = os.path.join(self._runtime_dir, 'checkpoint')
-        self._feature_ckpt_file = os.path.join(self._checkpoint_dir, 'feature_model_ckp.pt')
-        self._infer_ckpt_file = os.path.join(self._checkpoint_dir, 'infer_model_ckp.pt')
-
-        self.push_log(message='Begin to validate local context.')
-        self.validate_context()
-
-    def _recover_progress(self):
-        if not os.path.isfile(self._context_file):
-            raise TaskFailed('Failed to recover progress: missing cached context.')
-
-        with open(self._context_file, 'r') as f:
-            context_info = json.load(f)
-        round = context_info.get('round')
-        feature_ckpt_file = context_info.get('feature_ckpt_file')
-        infer_ckpt_file = context_info.get('infer_ckpt_file')
-        assert round and isinstance(round, int) and round > 0, f'Invalid round: {round} .'
-        assert (
-            feature_ckpt_file and isinstance(feature_ckpt_file, str)
-        ), f'Invalid feature_ckpt_file: {feature_ckpt_file} .'
-        assert (
-            infer_ckpt_file and isinstance(infer_ckpt_file, str)
-        ), f'Invalid infer_ckpt_file: {infer_ckpt_file} .'
-        if not os.path.isfile(feature_ckpt_file) or not os.path.isfile(infer_ckpt_file):
-            raise TaskFailed('Failed to recover progress: missing checkpoint parameters.')
-
-        self.current_round = round
-        with open(feature_ckpt_file, 'rb') as f:
-            state_dict = torch.load(f)
-            self.feature_model.load_state_dict(state_dict)
-        with open(infer_ckpt_file, 'rb') as f:
-            state_dict = torch.load(f)
-            self.infer_model.load_state_dict(state_dict)
-
-    def _clean_progress(self):
-        """Clean existing progress data."""
-        shutil.rmtree(self._runtime_dir, ignore_errors=True)
-        shutil.rmtree(self._result_dir, ignore_errors=True)
-        os.makedirs(self._runtime_dir, exist_ok=True)
-        os.makedirs(self._checkpoint_dir, exist_ok=True)
-        os.makedirs(self._result_dir, exist_ok=True)
-        os.makedirs(self._log_dir, exist_ok=True)
-
-    def _is_reach_max_rounds(self) -> bool:
-        """Is the max rounds configuration reached."""
-        return self.current_round >= self.max_rounds
-
-    def _validate_feature_dict(self, features: Dict[str, torch.Tensor]):
-        """Validate feature format."""
-        if not features or not isinstance(features, dict) or len(features) != 1:
-            self.push_log(f'Received invalid features: {features}')
-            err_msg = r'Invalid feature type. It must be a dict of {feature_key: feature tensor}.'
-            raise TaskFailed(err_msg)
-        _key, _val = features.copy().popitem()
-        if not _key or not isinstance(_key, str):
-            self.push_log(f'Received invalid feature key: {_key}')
-            raise TaskFailed('Invalid feature type. It must contain a keyword of string.')
-        if _val is None or not isinstance(_val, torch.Tensor) or _val.dim() != 2:
-            self.push_log(f'Received invalid feature value: {_val}')
-            raise TaskFailed('Invalid feature type. Its value must be a tensor of two dimension.')
-
-    def _launch_process(self):
-        try:
-            assert self.status == self._INIT, 'must begin from initial status'
-            self.push_log(f'Node {self.id} is up.')
-
-            self._switch_status(self._GETHORING)
-            self._check_in()
-
-            self._switch_status(self._READY)
-            while self.status == self._READY:
-                try:
-                    self._switch_status(self._SYNCHRONIZING)
-                    self._sync_state()
-
-                    if not self._id_intersection:
-                        self._switch_status(self._ID_INTERSECTION)
-                        self._make_id_intersection()
-
-                    self._switch_status(self._IN_A_ROUND)
-                    self._run_a_round()
-                    self._switch_status(self._READY)
-                    delattr(self, '_train_ids')
-                    delattr(self, '_test_ids')
-                except ResetRound:
-                    self.push_log('WARNING: Reset runtime context, there might be an error raised.')
-                    self._switch_status(self._READY)
-                    self._id_intersection = None
-                    delattr(self, '_train_ids')
-                    delattr(self, '_test_ids')
-                    continue
-
-                if self.is_task_finished():
-                    self.push_log(f'Obtained the final results of task {self.task_id}')
-                    self._switch_status(self._FINISHING)
-                    self._close_task(is_succ=True)
-
-                self.current_round += 1
-
-        except TaskFailed as err:
-            logger.exception(err)
-            self._close_task(is_succ=False)
-
-    def _check_in(self):
-        """Check in task and connect every partners."""
-        self.push_log('Waiting for participants taking part in ...')
-        for _event in self.contractor.contract_events():
-            if isinstance(_event, CheckinEvent):
-                self._handle_check_in(_event)
-                if all(self._check_in_status.values()):
-                    self._is_gathering_complete = True
-                    break
-        self.push_log('All partners have gethored.')
-
-    def _handle_check_in(self, _event: CheckinEvent):
-        self._check_in_status[_event.peer_id] = True
-        self.push_log(f'Welcome a new partner ID: {_event.peer_id}.')
-        self.push_log(f'There are {sum(self._check_in_status.values())} partners now.')
-        self.contractor.respond_check_in(round=self.current_round,
-                                         host=self.id,
-                                         nonce=_event.nonce,
-                                         requester_id=_event.peer_id)
-        if self._is_gathering_complete:
-            self.contractor.sync_state(round=self.current_round, host=self.id)
-
-    def _sync_state(self):
-        """Synchronize state before each round, so it's easier to manage the process.
-
-        As a host, iterates round, broadcasts and resets context of the new round.
-        """
-        self.push_log(f'Initiate state synchronization of round {self.current_round}.')
-        self.contractor.sync_state(round=self.current_round, host=self.id)
-
-        sync_status = {_partner: False for _partner in self._partners}
-        self.push_log('Waiting for synchronization responses ...')
-        for _event in self.contractor.contract_events(timeout=0):
-            if isinstance(_event, SyncStateResponseEvent):
-                if _event.round != self.current_round:
-                    continue
-                if sync_status.get(_event.peer_id) is False:
-                    sync_status[_event.peer_id] = True
-                    self.push_log(f'Successfully synchronized state with ID: {_event.peer_id}.')
-                if sum(sync_status.values()) == len(self._partners):
-                    break
-            elif isinstance(_event, CheckinEvent):
-                self._handle_check_in(_event)
-
-        self.push_log(f'Successfully synchronized state in round {self.current_round}')
-
-    def _make_id_intersection(self) -> List[str]:
-        """Make PSI and get id intersection for training."""
-        local_ids = self.load_local_ids()
-        psi_scheduler = RSAPSIInitiatorScheduler(
-            task_id=self.task_id,
-            initiator_id=self.id,
-            ids=local_ids,
-            collaborator_ids=self._partners,
-            contractor=self.contractor
-        )
-        self._id_intersection = psi_scheduler.make_intersection()
-
-    def _run_a_round(self):
-        try:
-            self._start_round()
-            self.infer_model.train()
-            self.feature_model.train()
-            for _feature_batch, _labels in self.iterate_train_feature(
-                self.feature_model, self.train_ids
-            ):
-                self.push_log('Featured a batch of data.')
-                self._local_features = _feature_batch
-                self._switch_status(self._WAITING_FOR_FEATURES)
-                self._collect_features()
-                self._switch_status(self._GETTING_GRAD)
-                self.train_a_batch(self._feature_fusion_map, _labels)
-                self._switch_status(self._DISTRIBUTING_FEATURE_GRAD)
-                self._distribute_feature_grad()
-
-            self._switch_status(self._PERSISTING)
-            self._save_model()
-            self._save_runtime_context()
-            self._switch_status(self._TESTING)
-            self._check_and_run_test()
-            self._switch_status(self._CLOSING_ROUND)
-            self._close_round()
-        except TaskFailed as err:
-            err_stack = '\n'.join(traceback.format_exception(*sys.exc_info()))
-            self.push_log(err_stack)
-            self.contractor.reset_round()
-            raise ResetRound(err)
-
-    def _start_round(self):
-        """Prepare and start calculation of a round."""
-        self.push_log(f'Begin the training of round {self.current_round}.')
-        self.contractor.start_round(round=self.current_round)
-        self.push_log(f'Calculation of round {self.current_round} is started.')
-
-    def _collect_features(self) -> Dict[str, torch.Tensor]:
-        """Collect all input features from all partners."""
-        self.push_log('Waiting for collecting all features from partners ...')
-        self.contractor.notify_ready_for_fusion(self.current_round)
-        feature_map: Dict[str, Dict[str, torch.Tensor]] = {
-            self.id: {self.feature_key: self._local_features}
-        }
-
-        feature_results = self.data_channel.batch_receive_stream(
-            receiver=self.id,
-            source_list=self._partners,
-            timeout=self.calculation_timeout
-        )
-        for _source, _feature_stream in feature_results.items():
-            buffer = io.BytesIO(_feature_stream)
-            features = torch.load(buffer)
-            self._validate_feature_dict(features)
-            feature_map[_source] = features
-            self.push_log(f'Received features from ID: {_source}')
-
-        if len(feature_map) == len(self._partners) + 1:  # plus self
-            self._alpha_map = feature_map
-            features = dict(feature_dict.copy().popitem()
-                            for feature_dict in self._alpha_map.values())
-            self._feature_fusion_map = features
-        else:
-            raise TaskFailed('Failed to collect all features.')
-
-    def _distribute_feature_grad(self):
-        """Distribute feature grad tensors to collaborators."""
-        self.push_log('Distributing features grad tensors ...')
-        for _partner, _feature_dict in self._alpha_map.items():
-            if _partner == self.id:
-                continue
-            _, feature_tensor = _feature_dict.copy().popitem()
-            with TemporaryFile() as tf:
-                torch.save(feature_tensor.grad, tf)
-                tf.seek(0)
-                self.data_channel.send_stream(source=self.id,
-                                              target=_partner,
-                                              data_stream=tf.read())
-        self.push_log('Distributed all features grad tensors to collaborators.')
-
-    def _save_model(self):
-        """Save latest model state."""
-        with open(self._feature_ckpt_file, 'wb') as f:
-            torch.save(self.feature_model.state_dict(), f)
-        with open(self._infer_ckpt_file, 'wb') as f:
-            torch.save(self.infer_model.state_dict(), f)
-        self.push_log('Saved latest parameters locally.')
-
-    def _save_runtime_context(self):
-        """Save runtime context information in case of restoring."""
-        context_info = {
-            'round': self.current_round,
-            'feature_ckpt_file': self._feature_ckpt_file,
-            'infer_ckpt_file': self._infer_ckpt_file
-        }
-        with open(self._context_file, 'w') as f:
-            f.write(json.dumps(context_info, ensure_ascii=False))
-        self.push_log('Saved latest runtime context.')
-
-    @torch.no_grad()
-    def _check_and_run_test(self):
-        """Run test if match configured conditions."""
-        if (
-            self.current_round == 1
-            or (self.log_rounds > 0 and self.current_round % self.log_rounds == 0)
-            or self.current_round == self.max_rounds
-        ):
-            self.push_log('Start a round of test.')
-
-            self.feature_model.eval()
-            self.infer_model.eval()
-
-            self.contractor.start_test_round(round=self.current_round)
-
-            batched_host_features = []
-            batched_labels = []
-            for _feature_batch, _labels in self.iterate_test_feature(
-                self.feature_model, self.test_ids
-            ):
-                batched_host_features.append((self.feature_key, _feature_batch))
-                batched_labels.append(_labels)
-
-            self._switch_status(self._WAITING_FOR_FEATURES)
-            self._wait_for_testing_features()
-            self._batched_test_features.append(batched_host_features)
-            self._switch_status(self._PROJECTING)
-            batched_feature_projections = [dict(_batch)
-                                           for _batch in zip(*self._batched_test_features)]
-            self.push_log('Fused test data features.')
-
-            self.run_test(batched_feature_projections=batched_feature_projections,
-                          batched_labels=batched_labels)
-            self.push_log('Complete a round of test.')
-
-        self.push_log('Skip or close a round of testing.')
-        self.contractor.close_test_round(round=self.current_round)
-
-    def _wait_for_testing_features(self):
-        """Wait for collecting test dataset features."""
-        self.push_log('Waiting for collecting test dataset features ...')
-        self._batched_test_features = []
-
-        test_feature_results = self.data_channel.batch_receive_stream(
-            receiver=self.id,
-            source_list=self._partners,
-            timeout=self.calculation_timeout
-        )
-        for _source, _feature_stream in test_feature_results.items():
-            buffer = io.BytesIO(_feature_stream)
-            batched_features: dict = torch.load(buffer)
-            _key, _feature_list = batched_features.copy().popitem()
-            self._batched_test_features.append([(_key, _feature_batch)
-                                                for _feature_batch in _feature_list])
-            self.push_log(f'Received test dataset features from ID: {_source}.')
-
-        if len(self._batched_test_features) < len(self._partners):
-            raise TaskFailed('Failed to collect all testing features.')
-
-    def _close_round(self):
-        """Close current round when finished."""
-        self.contractor.close_round(round=self.current_round)
-        self.push_log(f'The training of Round {self.current_round} complete.')
-
-    def _close_task(self, is_succ: bool = True):
-        """Close the task.
-
-        Broadcasts the finish task event to all participants,
-        uploads the final parameters and tells L1 task manager the task is complete.
-        """
-        self.push_log(f'Closing task {self.task_id} ...')
-
-        self._switch_status(self._FINISHING)
-        if is_succ:
-            report_file_path, model_file_path = self._prepare_task_output()
-            self.contractor.upload_metric_report(receivers=self.contractor.EVERYONE,
-                                                 report_file=report_file_path)
-            self.contractor.upload_model(receivers=[self.id],
-                                         model_file=model_file_path)
-            self.contractor.finish_task(is_succ=True)
-            self._wait_for_all_complete()
-            self.contractor.notify_task_completion(result=True)
-            self.push_log(f'Task {self.task_id} complete. Byebye!')
-        else:
-            self.contractor.finish_task(is_succ=False)
-            self.push_log(f'Task {self.task_id} failed. Byebye!')
-
-    def _prepare_task_output(self) -> Tuple[str, str]:
-        """Generate final output files of the task.
-
-        :return
-            Local paths of the report file and model file.
-        """
-        self.push_log('Generating task achievement files ...')
-
-        report_file = os.path.join(self._result_dir, 'report.zip')
-        with ZipFile(report_file, 'w') as report_zip:
-            for path, _, filenames in os.walk(self._log_dir):
-                rel_dir = os.path.relpath(path=path, start=self._result_dir)
-                rel_dir = rel_dir.lstrip('.')  # ./file => file
-                for _file in filenames:
-                    rel_path = os.path.join(rel_dir, _file)
-                    report_zip.write(os.path.join(path, _file), rel_path)
-        report_file_path = os.path.abspath(report_file)
-
-        # torch.jit doesn't work with a TemporaryFile
-        feature_model_file = os.path.join(self._result_dir,
-                                          f'feature_model_{self.feature_key}.pt')
-        with open(feature_model_file, 'wb') as f:
-            torch.save(self.feature_model.state_dict(), f)
-        infer_model_file = f'{os.path.join(self._result_dir, "infer_model.pt")}'
-        with open(infer_model_file, 'wb') as f:
-            torch.save(self.infer_model.state_dict(), f)
-        model_file = os.path.join(self._result_dir, 'model.zip')
-        with ZipFile(model_file, 'w') as model_zip:
-            model_zip.write(feature_model_file, os.path.basename(feature_model_file))
-            model_zip.write(infer_model_file, os.path.basename(infer_model_file))
-        model_file_path = os.path.abspath(model_file)
-
-        self.push_log('Task achievement files are ready.')
-        return report_file_path, model_file_path
-
-    def _wait_for_all_complete(self):
-        """Wait for all collaborators complete their tasks."""
-        self.push_log('Waiting for all collaborators complete their tasks ...')
-        results = {_peer_id: False for _peer_id in self._partners}
-        for _event in self.contractor.contract_events():
-            if isinstance(_event, CollaboratorCompleteEvent):
-                results[_event.peer_id] = True
-                if all(results.values()):
-                    break
-        self.push_log('All collaborators have completed their tasks.')
-
-
-class HeteroNNCollaboratorScheduler(HeteroNNScheduler):
-    """Schedule the process of a collaborator in a hetero_nn task."""
-
-    _WAITING_FOR_FEATUE_GRAD = 'wait_4_feature_grad'
-
-    def __init__(self,
-                 feature_key: str,
-                 schedule_timeout: int = 30,
-                 is_feature_trainable: bool = True) -> None:
-        """Init.
-
-        :args
-            :feature_key
-                A unique key of feature used by the host to distinguish features
-                from collaborators.
-            :schedule_timeout
-                Seconds to timeout for process scheduling. Takeing off timeout
-                by setting its value to 0.
-            :is_feature_trainable
-                Decide whether or not train the feature model
-        """
-        super().__init__()
-        self._switch_status(self._INIT)
-
-        self.feature_key = feature_key
-        self.schedule_timeout = schedule_timeout
-        self.is_feature_trainable = is_feature_trainable
-
-        self._validate_config()
-
-        self.current_round = 0
-
-        self.host = None
-
-        self._feature_grad: torch.Tensor = None
-
-    def _validate_config(self):
-        if not self.feature_key or not isinstance(self.feature_key, str):
-            raise ConfigError('Must specify a feature_key of type string.')
-
-    def validate_context(self):
-        """Validate if the local running context is ready.
-
-        For example: check if train and test dataset could be loaded successfully.
-        """
-        if self.feature_model is None:
-            raise ConfigError('Failed to initialize a feature model.')
-        if not isinstance(self.feature_model, nn.Module):
-            err_msg = 'Support feature model of type torch.Module only.'
-            err_msg += f'Got a {type(self.feature_model)} object.'
-            raise ConfigError(err_msg)
-        if self.feature_optimizer is None:
-            raise ConfigError('Failed to initialize a feature optimizer.')
-        if not isinstance(self.feature_optimizer, optim.Optimizer):
-            err_msg = 'Support feature optimizer of type torch.optim.Optimizer only.'
-            err_msg += f'Got a {type(self.feature_optimizer)} object.'
-            raise ConfigError(err_msg)
-
-    @abstractmethod
-    def iterate_train_feature(self,
-                              feature_model: nn.Module,
-                              train_ids: Set[str]) -> torch.Tensor:
-        """Iterate over train dataset and features a batch of data each time.
-
-        :args
-            :feature_model
-                The feature model object to train & test.
-            :train_ids
-                The ID set of train dataset.
-        """
-
-    @abstractmethod
-    def iterate_test_feature(self,
-                             feature_model: nn.Module,
-                             test_ids: Set[str]) -> torch.Tensor:
-        """Iterate over test dataset and features a batch of data each time.
-
-        :args
-            :feature_model
-                The feature model object to train & test.
-            :train_ids
-                The ID set of test dataset.
-        """
-
-    def _setup_context(self, id: str, task_id: str, is_initiator: bool = False):
-        super()._setup_context(id=id, task_id=task_id, is_initiator=is_initiator)
-
-        self._runtime_dir = get_runtime_dir(self.task_id)
-        self._context_file = os.path.join(self._runtime_dir, ".context.json")
-        self._checkpoint_dir = os.path.join(self._runtime_dir, 'checkpoint')
-        self._feature_ckpt_file = os.path.join(self._checkpoint_dir, "feature_model_ckp.pt")
-
-        self.push_log(message='Begin to validate local context.')
-        self.validate_context()
-
-    def _recover_progress(self):
-        if not os.path.isfile(self._context_file):
-            raise TaskFailed('Failed to recover progress: missing cached context.')
-
-        with open(self._context_file, 'r') as f:
-            context_info = json.load(f)
-        feature_ckpt_file = context_info.get('feature_ckpt_file')
-        assert (
-            feature_ckpt_file and isinstance(feature_ckpt_file, str)
-        ), f'Invalid feature_ckpt_file: {feature_ckpt_file} .'
-        if not os.path.isfile(feature_ckpt_file):
-            raise TaskFailed('Failed to recover progress: missing checkpoint parameters.')
-
-        self.current_round = round
-        with open(feature_ckpt_file, 'rb') as f:
-            state_dict = torch.load(f)
-            self.feature_model.load_state_dict(state_dict)
-
-    def _clean_progress(self):
-        """Clean existing progress data."""
-        shutil.rmtree(self._runtime_dir, ignore_errors=True)
-        shutil.rmtree(self._result_dir, ignore_errors=True)
-        os.makedirs(self._runtime_dir, exist_ok=True)
-        os.makedirs(self._checkpoint_dir, exist_ok=True)
-        os.makedirs(self._result_dir, exist_ok=True)
-
-    def _launch_process(self):
-        try:
-            assert self.status == self._INIT, 'must begin from initial status'
-            self.push_log(f'Node {self.id} is up.')
-
-            self._switch_status(self._GETHORING)
-            self._check_in()
-
-            self._switch_status(self._READY)
-            while self.status == self._READY:
-                try:
-                    self._switch_status(self._SYNCHRONIZING)
-                    self._sync_state()
-
-                    if not self._id_intersection:
-                        self._switch_status(self._ID_INTERSECTION)
-                        self._make_id_intersection()
-
-                    self._switch_status(self._IN_A_ROUND)
-                    self._run_a_round()
-                    self._switch_status(self._READY)
-                    delattr(self, '_train_ids')
-                    delattr(self, '_test_ids')
-                except ResetRound:
-                    self.push_log('WARNING: Reset runtime context, there might be an error raised.')
-                    self._switch_status(self._READY)
-                    self._id_intersection = None
-                    delattr(self, '_train_ids')
-                    delattr(self, '_test_ids')
-                    continue
-
-        except TaskComplete:
-            logger.info('Task complete')
-            self._close_task(is_succ=True)
-
-        except TaskFailed as err:
-            logger.exception(err)
-            self._close_task(is_succ=False)
-
-    def _check_in(self):
-        """Check in task."""
-        is_checked_in = False
-        # the host may be in special state so can not response
-        # correctly nor in time, then retry periodically
-        self.push_log('Checking in the task ...')
-        while not is_checked_in:
-            nonce = self.contractor.checkin(peer_id=self.id)
-            logger.debug('_wait_for_check_in_response ...')
-            for _event in self.contractor.contract_events(timeout=self.schedule_timeout):
-                if isinstance(_event, CheckinResponseEvent):
-                    if _event.nonce != nonce:
-                        continue
-                    self.current_round = _event.round
-                    self.host = _event.host
-                    is_checked_in = True
-                    break
-
-                elif isinstance(_event, FailTaskEvent):
-                    raise TaskFailed('Aborted by host.')
-
-        self.push_log(f'Node {self.id} have taken part in the task.')
-
-    def _sync_state(self):
-        """Synchronize state before each round, so it's easier to manage the process.
-
-        As a partner, synchronizes state and gives a response.
-        """
-        self.push_log('Waiting for synchronizing state with the host ...')
-        for _event in self.contractor.contract_events():
-            if isinstance(_event, SyncStateEvent):
-                self.current_round = _event.round
-                self.contractor.respond_sync_state(round=self.current_round,
-                                                   peer_id=self.id,
-                                                   host=_event.host)
-                self.push_log('Successfully synchronized state with the host.')
-                return
-            elif isinstance(_event, FailTaskEvent):
-                raise TaskFailed('Aborted by host.')
-            elif isinstance(_event, CompleteTaskEvent):
-                raise TaskComplete()
-            elif isinstance(_event, ResetRoundEvent):
-                raise ResetRound()
-
-        self.push_log(f'Successfully synchronized state in round {self.current_round}')
-
-    def _make_id_intersection(self) -> List[str]:
-        """Make PSI and get id intersection for training."""
-        local_ids = self.load_local_ids()
-        psi_scheduler = RSAPSICollaboratorScheduler(
-            task_id=self.task_id,
-            collaborator_id=self.id,
-            ids=local_ids,
-            contractor=self.contractor
-        )
-        self._id_intersection = psi_scheduler.collaborate_intersection()
-
-    def _run_a_round(self):
-        self._wait_for_starting_round()
-        self.feature_model.train()
-        for _batch_features in self.iterate_train_feature(self.feature_model, self.train_ids):
-            self.push_log('Featured a batch of data.')
-            self._switch_status(self._PROJECTING)
-            self._local_features = _batch_features
-            self._send_feature()
-
-            self._switch_status(self._WAITING_FOR_FEATUE_GRAD)
-            self._wait_for_feature_grad()
-            self._switch_status(self._UPDATING)
-            self.feature_optimizer.zero_grad()
-            self._local_features.backward(self._feature_grad)
-            self.feature_optimizer.step()
-
-        self._switch_status(self._PERSISTING)
-        self._save_model()
-        self._save_runtime_context()
-
-        self._switch_status(self._TESTING)
-        self._wait_for_testing_round()
-
-        self._switch_status(self._CLOSING_ROUND)
-        self._wait_for_closing_round()
-
-        self.push_log(f'ID: {self.id} finished training task of round {self.current_round}.')
-
-    def _wait_for_starting_round(self):
-        """Wait for starting a new round of training ..."""
-        self.push_log(f'Waiting for training of round {self.current_round} begin ...')
-        for _event in self.contractor.contract_events():
-            if isinstance(_event, StartRoundEvent):
-                assert (
-                    _event.round == self.current_round
-                ), f'Lost synchronization, host: {_event.round}; local: {self.current_round}.'
-                self.push_log(f'Training of round {self.current_round} begins.')
-                return
-            elif isinstance(_event, FailTaskEvent):
-                raise TaskFailed('Aborted by host.')
-            elif isinstance(_event, ResetRoundEvent):
-                raise ResetRound()
-
-    def _send_feature(self):
-        """Send local features of a batch of data to the host."""
-        self.push_log('Waiting for sending features ...')
-        for _event in self.contractor.contract_events():
-            if isinstance(_event, ReadyForFusionEvent):
-                assert (
-                    _event.round == self.current_round
-                ), f'Lost synchronization, host: {_event.round}; local: {self.current_round}.'
-                break
-            elif isinstance(_event, FailTaskEvent):
-                raise TaskFailed('Aborted by host.')
-            elif isinstance(_event, ResetRoundEvent):
-                raise ResetRound()
-
-        self.push_log('Begin to send features.')
-        with TemporaryFile() as tf:
-            torch.save({self.feature_key: self._local_features}, tf)
-            tf.seek(0)
-            self.data_channel.send_stream(source=self.id,
-                                          target=self.host,
-                                          data_stream=tf.read())
-        self.push_log('Sending features complete.')
-
-    def _wait_for_feature_grad(self):
-        """Wait for cipher grad of feature model output."""
-        def reset_handler(event: ContractEvent):
-            if isinstance(event, ResetRoundEvent):
-                raise ResetRound()
-
-        self.push_log('Waiting for cipher grad of feature model output ...')
-        _, stream = self.data_channel.receive_stream(
-            receiver=self.id,
-            complementary_handler=reset_handler,
-            source=self.host
-        )
-        buffer = io.BytesIO(stream)
-        self._feature_grad = torch.load(buffer)
-        self.push_log('Received and decrypted cipher grad of feature model output.')
-
-    def _save_model(self):
-        """Save latest model state."""
-        with open(self._feature_ckpt_file, 'wb') as f:
-            torch.save(self.feature_model.state_dict(), f)
-        self.push_log('Saved latest parameters locally.')
-
-    def _save_runtime_context(self):
-        """Save runtime context information in case of restoring."""
-        context_info = {
-            'feature_ckpt_file': self._feature_ckpt_file
-        }
-        with open(self._context_file, 'w') as f:
-            f.write(json.dumps(context_info, ensure_ascii=False))
-        self.push_log('Saved latest runtime context.')
-
-    def _wait_for_testing_round(self):
-        """Wait for handle a round of testing."""
-        self.push_log('Waiting for start a round of testing ...')
-        for _event in self.contractor.contract_events():
-            if isinstance(_event, StartTestRoundEvent):
-                assert (
-                    _event.round == self.current_round
-                ), f'Lost synchronization, host: {_event.round}; local: {self.current_round}.'
-
-                self.feature_model.eval()
-                features = {
-                    self.feature_key: list(self.iterate_test_feature(self.feature_model,
-                                                                     self.test_ids))
-                }
-                with TemporaryFile() as tf:
-                    torch.save(features, tf)
-                    tf.seek(0)
-                    self.data_channel.send_stream(source=self.id,
-                                                  target=self.host,
-                                                  data_stream=tf.read())
-                self.push_log('Sent all batches of feature to the host.')
-
-            elif isinstance(_event, CloseTestRoundEvent):
-                self.push_log('Skipped or closed a round of testing.')
-                return
-            elif isinstance(_event, FailTaskEvent):
-                raise TaskFailed('Aborted by host.')
-            elif isinstance(_event, ResetRoundEvent):
-                raise ResetRound()
-
-    def _wait_for_closing_round(self):
-        """Wait for closing current round of training."""
-        self.push_log(f'Waiting for closing signal of training round {self.current_round} ...')
-        for _event in self.contractor.contract_events():
-            if isinstance(_event, CloseRoundEvent):
-                if _event.round != self.current_round:
-                    continue
-                return
-            elif isinstance(_event, CompleteTaskEvent):
-                raise TaskComplete()
-            elif isinstance(_event, ResetRoundEvent):
-                raise ResetRound()
-
-    def _close_task(self, is_succ: bool = True):
-        """Close the task and upload the final parameters."""
-        self.push_log(f'Closing task {self.task_id} ...')
-
-        self._switch_status(self._FINISHING)
-        if is_succ:
-            model_file_path = self._prepare_task_output()
-            self.contractor.upload_metric_report(receivers=self.contractor.EVERYONE)
-            self.contractor.upload_model(receivers=[self.id],
-                                         model_file=model_file_path)
-            self.contractor.notify_collaborator_complete(peer_id=self.id, host=self.host)
-            self.push_log(f'Task {self.task_id} complete. Byebye!')
-        else:
-            self.push_log(f'Task {self.task_id} failed. Byebye!')
-
-    def _prepare_task_output(self) -> Tuple[str, str]:
-        """Generate final output files of the task.
-
-        :return
-            Local paths of the model file.
-        """
-        self.push_log('Generating task achievement files ...')
-
-        # torch.jit doesn't work with a TemporaryFile
-        feature_model_file = os.path.join(self._result_dir,
-                                          f'feature_model_{self.feature_key}.pt')
-        with open(feature_model_file, 'wb') as f:
-            torch.save(self.feature_model.state_dict(), f)
-        model_file_path = os.path.abspath(feature_model_file)
-
-        self.push_log('Task achievement files are ready.')
-        return model_file_path
+"""The host of a hetero_nn task.
+
+Reference: https://arxiv.org/pdf/2007.06849.pdf
+"""
+
+import io
+import json
+import os
+import shutil
+import sys
+import traceback
+from abc import ABC, ABCMeta, abstractmethod
+from tempfile import TemporaryFile
+from typing import Dict, List, Set, Tuple, final
+from zipfile import ZipFile
+
+import torch
+import torch.nn as nn
+import torch.optim as optim
+from torch.utils.tensorboard import SummaryWriter
+
+from .. import get_result_dir, get_runtime_dir, logger
+from ..data_channel import SharedFileDataChannel
+from ..scheduler import ConfigError, Scheduler, TaskComplete, TaskFailed
+from .contractor import (CheckinEvent, CheckinResponseEvent, CloseRoundEvent,
+                         CloseTestRoundEvent, CollaboratorCompleteEvent,
+                         CompleteTaskEvent, ContractEvent, FailTaskEvent,
+                         HeteroNNContractor, ReadyForFusionEvent,
+                         ResetRoundEvent, StartRoundEvent, StartTestRoundEvent,
+                         SyncStateEvent, SyncStateResponseEvent)
+from .psi import RSAPSICollaboratorScheduler, RSAPSIInitiatorScheduler
+
+__all__ = ['HeteroNNHostScheduler', 'HeteroNNCollaboratorScheduler']
+
+_FEATURE_KEY = str
+
+
+class ResetRound(Exception):
+    ...
+
+
+class _SimplifiedOptimizer(ABC):
+    """A simplified optimizer tool to facilitate update parameters."""
+
+    @abstractmethod
+    def zero_grad(self):
+        """To clean grad of parameters, as a normal PyTorch Optimizer."""
+
+    @abstractmethod
+    def step(self):
+        """To update parameters, as a normal PyTorch Optimizer."""
+
+
+class HeteroNNScheduler(Scheduler, metaclass=ABCMeta):
+    """Base scheduler for heteto_nn tasks."""
+
+    _INIT = 'init'
+    _GETHORING = 'gethoring'
+    _ID_INTERSECTION = 'id_intersection'
+    _READY = 'ready'
+    _SYNCHRONIZING = 'synchronizing'
+    _IN_A_ROUND = 'in_a_round'
+    _PROJECTING = 'projecting'
+    _FINISHING = 'finishing'
+    _UPDATING = 'updating'
+    _PERSISTING = 'persisting'
+    _TESTING = 'testing'
+    _CLOSING_ROUND = 'closing_round'
+
+    def __init__(self) -> None:
+        super().__init__()
+        self.feature_model
+        self.feature_optimizer
+
+        self._id_intersection = None
+        self._local_features: torch.Tensor = None
+        self._example_feature_inputs = None
+
+    @abstractmethod
+    def _setup_context(self, id: str, task_id: str, is_initiator: bool = False):
+        assert id, 'must specify a unique id for every participant'
+        assert task_id, 'must specify a task_id for every participant'
+
+        self.id = id
+        self.task_id = task_id
+        self.is_host = is_initiator
+        self._result_dir = get_result_dir(self.task_id)
+        self._log_dir = os.path.join(self._result_dir, 'tb_logs')
+        self.tb_writer = SummaryWriter(log_dir=self._log_dir)
+
+        self.contractor = HeteroNNContractor(task_id=task_id)
+        self.data_channel = SharedFileDataChannel(self.contractor)
+
+    @abstractmethod
+    def load_local_ids(self) -> List[str]:
+        """Load all local data IDs for PSI."""
+
+    @abstractmethod
+    def split_dataset(self, id_intersection: Set[str]) -> Tuple[Set[str], Set[str]]:
+        """Split dataset into train set and test set.
+
+        NOTE: Must make sure each node gets the same split results.
+
+        :return
+            A tuple of ID set of training dataset and of testing dataset:
+            (Set[train_ids], Set[test_ids]).
+        """
+
+    @abstractmethod
+    def build_feature_model(self) -> nn.Module:
+        """Return a model object to project input to features.
+
+        The output of feature model MUST be a (str_keyword, torch.Tensor) tuple, where
+        str_keyword is used by the host to distinguish features from collaborators
+        and Tensor is a two dimension (batch, feature_vector) tensor as the input
+        of projection layer.
+        """
+
+    @property
+    def feature_model(self) -> nn.Module:
+        if not hasattr(self, '_feature_model'):
+            self._feature_model = self.build_feature_model()
+        return self._feature_model
+
+    @abstractmethod
+    def build_feature_optimizer(self, feature_model: nn.Module) -> optim.Optimizer:
+        """Return a optimizer object to facilitate training feature model.
+
+        :args
+            :feature_model
+                The feature model object to train & test.
+        """
+
+    @final
+    @property
+    def feature_optimizer(self) -> optim.Optimizer:
+        if not hasattr(self, '_feature_optimizer'):
+            assert self.feature_model, 'Must initialize feature model at first.'
+            self._feature_optimizer = self.build_feature_optimizer(self.feature_model)
+        return self._feature_optimizer
+
+    @final
+    @property
+    def id_intersection(self) -> Set[str]:
+        """Return the intersection of whole dataset IDs."""
+        assert self._id_intersection is not None, 'Have not run ID intersection process.'
+        return self._id_intersection
+
+    @final
+    @property
+    def train_ids(self) -> Set[str]:
+        """Return the ID set of training dataset intersection."""
+        if not hasattr(self, '_train_ids'):
+            assert self.id_intersection, 'Must get the whole ID intersection at first.'
+            self._train_ids, self._test_ids = self.split_dataset(self.id_intersection.copy())
+        return self._train_ids
+
+    @final
+    @property
+    def test_ids(self) -> Set[str]:
+        """Return the ID set of testing dataset intersection."""
+        if not hasattr(self, '_test_ids'):
+            assert self.id_intersection, 'Must get the whole ID intersection at first.'
+            self._train_ids, self._test_ids = self.split_dataset(self.id_intersection.copy())
+        return self._test_ids
+
+    @abstractmethod
+    def _launch_process(self):
+        """Run the main process of the task."""
+
+    @abstractmethod
+    def _recover_progress():
+        """Try to recover progress from last running."""
+
+    @abstractmethod
+    def _clean_progress(self):
+        """Clean existing progress data."""
+
+    def _run(self, id: str, task_id: str, is_initiator: bool = False, recover: bool = False):
+        self._setup_context(id=id, task_id=task_id, is_initiator=is_initiator)
+        self.push_log(message='Local context is ready.')
+        try:
+            if recover:
+                self._recover_progress()
+            else:
+                self._clean_progress()
+            self._launch_process()
+        except Exception:
+            err_stack = '\n'.join(traceback.format_exception(*sys.exc_info()))
+            self.push_log(err_stack)
+
+
+class HeteroNNHostScheduler(HeteroNNScheduler):
+    """Schedule the process of the host in a hetero_nn task."""
+
+    _WAITING_FOR_FEATURES = 'wait_4_feature'
+    _GETTING_GRAD = 'calc_loss'
+    _DISTRIBUTING_FEATURE_GRAD = 'distribute_grad'
+
+    def __init__(self,
+                 feature_key: str,
+                 max_rounds: int = 0,
+                 calculation_timeout: int = 300,
+                 schedule_timeout: int = 30,
+                 log_rounds: int = 0,
+                 is_feature_trainable: bool = True) -> None:
+        r"""Init.
+
+        :args
+            :feature_key
+                A unique key of feature used by the host to distinguish features
+                from collaborators.
+            :max_rounds
+                Maximal number of training rounds.
+            :calculation_timeout
+                Seconds to timeout for calculation in a round. Takeing off timeout
+                by setting its value to 0.
+            :schedule_timeout
+                Seconds to timeout for process scheduling. Takeing off timeout
+                by setting its value to 0.
+            :log_rounds
+                The number of rounds to run testing and log the result. Skip it
+                by setting its value to 0.
+            :is_feature_trainable
+                Decide whether or not train the feature model
+        """
+        super().__init__()
+        self._switch_status(self._INIT)
+
+        self.feature_key = feature_key
+        self.max_rounds = max_rounds
+        self.calculation_timeout = calculation_timeout
+        self.schedule_timeout = schedule_timeout
+        self.log_rounds = log_rounds
+        self.is_feature_trainable = is_feature_trainable  # TODO 暂时不考虑
+
+        self._validate_config()
+
+        self.infer_model
+        self.infer_optimizer
+
+        self.current_round = 1
+        self._partners: List[str] = []
+
+        self._example_project_input = None
+        self._example_infer_input = None
+
+        self._alpha_map: Dict[str, Dict[_FEATURE_KEY, torch.Tensor]] = {}
+        self._feature_fusion_map: Dict[_FEATURE_KEY, torch.Tensor] = {}
+        self._batched_test_features: List[List[Dict[_FEATURE_KEY, torch.Tensor]]] = []
+
+    def _validate_config(self):
+        if not self.feature_key or not isinstance(self.feature_key, str):
+            raise ConfigError('Must specify a feature_key of type string.')
+
+    @abstractmethod
+    def build_infer_model(self) -> nn.Module:
+        """Return a model object to infer business results."""
+
+    @final
+    @property
+    def infer_model(self) -> nn.Module:
+        if not hasattr(self, '_infer_model'):
+            self._infer_model = self.build_infer_model()
+        return self._infer_model
+
+    @abstractmethod
+    def build_infer_optimizer(self, infer_model: nn.Module) -> optim.Optimizer:
+        """Return a optimizer object to facilitate training infer model.
+
+        :args
+            :infer_model
+                The infer model object to train & test.
+        """
+
+    @final
+    @property
+    def infer_optimizer(self) -> optim.Optimizer:
+        if not hasattr(self, '_infer_optimizer'):
+            self._infer_optimizer = self.build_infer_optimizer(self.infer_model)
+        return self._infer_optimizer
+
+    @final
+    @property
+    def optimizer(self) -> _SimplifiedOptimizer:
+        """Return a general optimizer to wrap the 3 (feature, project, infer) optimizers."""
+
+        class _OptimizerImpl(_SimplifiedOptimizer):
+
+            def __init__(self, host_obj: HeteroNNHostScheduler) -> None:
+                super().__init__()
+                self.host_obj = host_obj
+
+            def zero_grad(self):
+                self.host_obj.infer_optimizer.zero_grad()
+                self.host_obj.feature_optimizer.zero_grad()
+
+            def step(self):
+                self.host_obj.infer_optimizer.step()
+                self.host_obj.feature_optimizer.step()
+
+        if not hasattr(self, '_optimizer'):
+            self._optimizer = _OptimizerImpl(host_obj=self)
+        return self._optimizer
+
+    @abstractmethod
+    def iterate_train_feature(self,
+                              feature_model: nn.Module,
+                              train_ids: Set[str]) -> Tuple[torch.Tensor, torch.Tensor]:
+        """Iterate over train dataset and features a batch of data each time.
+
+        :args
+            :feature_model
+                The feature model object to train & test.
+            :train_ids
+                The ID set of train dataset.
+        :return
+            A tuple of a batch of train data and their labels. (train_data, labels)
+        """
+
+    @abstractmethod
+    def iterate_test_feature(self,
+                             feature_model: nn.Module,
+                             test_ids: Set[str]) -> Tuple[torch.Tensor, torch.Tensor]:
+        """Iterate over test dataset and features a batch of data each time.
+
+        :args
+            :feature_model
+                The feature model object to train & test.
+            :train_ids
+                The ID set of test dataset.
+        :return
+            A tuple of a batch of test data and their labels. (test_data, labels)
+        """
+
+    @abstractmethod
+    def train_a_batch(self, feature_projection: Dict[str, torch.Tensor], labels: torch.Tensor):
+        """Train a batch of data in infer model.
+
+        :args
+            :feature_projection
+                A map containing features from all nodes of type feature_key => feature_tensor.
+            :labels
+                Corresponding labels of the batch of data.
+        """
+
+    @abstractmethod
+    def run_test(self,
+                 batched_feature_projection: List[Dict[str, torch.Tensor]],
+                 batched_labels: List[torch.Tensor]):
+        """Define the testing steps.
+
+        If you do not want to do testing after training, simply make it pass.
+
+        :args
+            :batched_feature_projections
+                A list of feature projection grouped by batch of testing data. Each batch
+                is a map containing features from all nodes of type feature_key => feature_tensor.
+            :batched_labels
+                A list of labels grouped by batch of testing data.
+        """
+
+    def validate_context(self):
+        """Validate if the local running context is ready.
+
+        For example: check if train and test dataset could be loaded successfully.
+        """
+        if self.feature_model is None:
+            raise ConfigError('Failed to initialize a feature model.')
+        if not isinstance(self.feature_model, nn.Module):
+            err_msg = 'Support feature model of type torch.Module only.'
+            err_msg += f'Got a {type(self.feature_model)} object.'
+            raise ConfigError(err_msg)
+        if self.feature_optimizer is None:
+            raise ConfigError('Failed to initialize a feature optimizer.')
+        if not isinstance(self.feature_optimizer, optim.Optimizer):
+            err_msg = 'Support feature optimizer of type torch.optim.Optimizer only.'
+            err_msg += f'Got a {type(self.feature_optimizer)} object.'
+            raise ConfigError(err_msg)
+
+        if self.infer_model is None:
+            raise ConfigError('Failed to initialize a infer model.')
+        if not isinstance(self.infer_model, nn.Module):
+            err_msg = 'Support infer model of type torch.Module only.'
+            err_msg += f'Got a {type(self.infer_model)} object.'
+            raise ConfigError(err_msg)
+        if self.infer_optimizer is None:
+            raise ConfigError('Failed to initialize a infer optimizer.')
+        if not isinstance(self.infer_optimizer, optim.Optimizer):
+            err_msg = 'Support infer optimizer of type torch.optim.Optimizer only.'
+            err_msg += f'Got a {type(self.infer_optimizer)} object.'
+            raise ConfigError(err_msg)
+
+        if not self._partners:
+            raise TaskFailed('No partners.')
+
+    def is_task_finished(self) -> bool:
+        """By default true if reach the max rounds configured."""
+        return self._is_reach_max_rounds()
+
+    def _init_partners(self):
+        """Query and set all partners in this task."""
+        self._partners = self.contractor.query_partners()
+        self._partners.remove(self.id)
+
+    def _setup_context(self, id: str, task_id: str, is_initiator: bool = False):
+        super()._setup_context(id=id, task_id=task_id, is_initiator=is_initiator)
+
+        self._init_partners()
+        self._check_in_status = {_partner: False for _partner in self._partners}
+        self._is_gathering_complete = False
+
+        self._runtime_dir = get_runtime_dir(self.task_id)
+        self._context_file = os.path.join(self._runtime_dir, ".context.json")
+        self._checkpoint_dir = os.path.join(self._runtime_dir, 'checkpoint')
+        self._feature_ckpt_file = os.path.join(self._checkpoint_dir, 'feature_model_ckp.pt')
+        self._infer_ckpt_file = os.path.join(self._checkpoint_dir, 'infer_model_ckp.pt')
+
+        self.push_log(message='Begin to validate local context.')
+        self.validate_context()
+
+    def _recover_progress(self):
+        if not os.path.isfile(self._context_file):
+            raise TaskFailed('Failed to recover progress: missing cached context.')
+
+        with open(self._context_file, 'r') as f:
+            context_info = json.load(f)
+        round = context_info.get('round')
+        feature_ckpt_file = context_info.get('feature_ckpt_file')
+        infer_ckpt_file = context_info.get('infer_ckpt_file')
+        assert round and isinstance(round, int) and round > 0, f'Invalid round: {round} .'
+        assert (
+            feature_ckpt_file and isinstance(feature_ckpt_file, str)
+        ), f'Invalid feature_ckpt_file: {feature_ckpt_file} .'
+        assert (
+            infer_ckpt_file and isinstance(infer_ckpt_file, str)
+        ), f'Invalid infer_ckpt_file: {infer_ckpt_file} .'
+        if not os.path.isfile(feature_ckpt_file) or not os.path.isfile(infer_ckpt_file):
+            raise TaskFailed('Failed to recover progress: missing checkpoint parameters.')
+
+        self.current_round = round
+        with open(feature_ckpt_file, 'rb') as f:
+            state_dict = torch.load(f)
+            self.feature_model.load_state_dict(state_dict)
+        with open(infer_ckpt_file, 'rb') as f:
+            state_dict = torch.load(f)
+            self.infer_model.load_state_dict(state_dict)
+
+    def _clean_progress(self):
+        """Clean existing progress data."""
+        shutil.rmtree(self._runtime_dir, ignore_errors=True)
+        shutil.rmtree(self._result_dir, ignore_errors=True)
+        os.makedirs(self._runtime_dir, exist_ok=True)
+        os.makedirs(self._checkpoint_dir, exist_ok=True)
+        os.makedirs(self._result_dir, exist_ok=True)
+        os.makedirs(self._log_dir, exist_ok=True)
+
+    def _is_reach_max_rounds(self) -> bool:
+        """Is the max rounds configuration reached."""
+        return self.current_round >= self.max_rounds
+
+    def _validate_feature_dict(self, features: Dict[str, torch.Tensor]):
+        """Validate feature format."""
+        if not features or not isinstance(features, dict) or len(features) != 1:
+            self.push_log(f'Received invalid features: {features}')
+            err_msg = r'Invalid feature type. It must be a dict of {feature_key: feature tensor}.'
+            raise TaskFailed(err_msg)
+        _key, _val = features.copy().popitem()
+        if not _key or not isinstance(_key, str):
+            self.push_log(f'Received invalid feature key: {_key}')
+            raise TaskFailed('Invalid feature type. It must contain a keyword of string.')
+        if _val is None or not isinstance(_val, torch.Tensor) or _val.dim() != 2:
+            self.push_log(f'Received invalid feature value: {_val}')
+            raise TaskFailed('Invalid feature type. Its value must be a tensor of two dimension.')
+
+    def _launch_process(self):
+        try:
+            assert self.status == self._INIT, 'must begin from initial status'
+            self.push_log(f'Node {self.id} is up.')
+
+            self._switch_status(self._GETHORING)
+            self._check_in()
+
+            self._switch_status(self._READY)
+            while self.status == self._READY:
+                try:
+                    self._switch_status(self._SYNCHRONIZING)
+                    self._sync_state()
+
+                    if not self._id_intersection:
+                        self._switch_status(self._ID_INTERSECTION)
+                        self._make_id_intersection()
+
+                    self._switch_status(self._IN_A_ROUND)
+                    self._run_a_round()
+                    self._switch_status(self._READY)
+                    delattr(self, '_train_ids')
+                    delattr(self, '_test_ids')
+                except ResetRound:
+                    self.push_log('WARNING: Reset runtime context, there might be an error raised.')
+                    self._switch_status(self._READY)
+                    self._id_intersection = None
+                    delattr(self, '_train_ids')
+                    delattr(self, '_test_ids')
+                    continue
+
+                if self.is_task_finished():
+                    self.push_log(f'Obtained the final results of task {self.task_id}')
+                    self._switch_status(self._FINISHING)
+                    self._close_task(is_succ=True)
+
+                self.current_round += 1
+
+        except TaskFailed as err:
+            logger.exception(err)
+            self._close_task(is_succ=False)
+
+    def _check_in(self):
+        """Check in task and connect every partners."""
+        self.push_log('Waiting for participants taking part in ...')
+        for _event in self.contractor.contract_events():
+            if isinstance(_event, CheckinEvent):
+                self._handle_check_in(_event)
+                if all(self._check_in_status.values()):
+                    self._is_gathering_complete = True
+                    break
+        self.push_log('All partners have gethored.')
+
+    def _handle_check_in(self, _event: CheckinEvent):
+        self._check_in_status[_event.peer_id] = True
+        self.push_log(f'Welcome a new partner ID: {_event.peer_id}.')
+        self.push_log(f'There are {sum(self._check_in_status.values())} partners now.')
+        self.contractor.respond_check_in(round=self.current_round,
+                                         host=self.id,
+                                         nonce=_event.nonce,
+                                         requester_id=_event.peer_id)
+        if self._is_gathering_complete:
+            self.contractor.sync_state(round=self.current_round, host=self.id)
+
+    def _sync_state(self):
+        """Synchronize state before each round, so it's easier to manage the process.
+
+        As a host, iterates round, broadcasts and resets context of the new round.
+        """
+        self.push_log(f'Initiate state synchronization of round {self.current_round}.')
+        self.contractor.sync_state(round=self.current_round, host=self.id)
+
+        sync_status = {_partner: False for _partner in self._partners}
+        self.push_log('Waiting for synchronization responses ...')
+        for _event in self.contractor.contract_events(timeout=0):
+            if isinstance(_event, SyncStateResponseEvent):
+                if _event.round != self.current_round:
+                    continue
+                if sync_status.get(_event.peer_id) is False:
+                    sync_status[_event.peer_id] = True
+                    self.push_log(f'Successfully synchronized state with ID: {_event.peer_id}.')
+                if sum(sync_status.values()) == len(self._partners):
+                    break
+            elif isinstance(_event, CheckinEvent):
+                self._handle_check_in(_event)
+
+        self.push_log(f'Successfully synchronized state in round {self.current_round}')
+
+    def _make_id_intersection(self) -> List[str]:
+        """Make PSI and get id intersection for training."""
+        local_ids = self.load_local_ids()
+        psi_scheduler = RSAPSIInitiatorScheduler(
+            task_id=self.task_id,
+            initiator_id=self.id,
+            ids=local_ids,
+            collaborator_ids=self._partners,
+            contractor=self.contractor
+        )
+        self._id_intersection = psi_scheduler.make_intersection()
+
+    def _run_a_round(self):
+        try:
+            self._start_round()
+            self.infer_model.train()
+            self.feature_model.train()
+            for _feature_batch, _labels in self.iterate_train_feature(
+                self.feature_model, self.train_ids
+            ):
+                self.push_log('Featured a batch of data.')
+                self._local_features = _feature_batch
+                self._switch_status(self._WAITING_FOR_FEATURES)
+                self._collect_features()
+                self._switch_status(self._GETTING_GRAD)
+                self.train_a_batch(self._feature_fusion_map, _labels)
+                self._switch_status(self._DISTRIBUTING_FEATURE_GRAD)
+                self._distribute_feature_grad()
+
+            self._switch_status(self._PERSISTING)
+            self._save_model()
+            self._save_runtime_context()
+            self._switch_status(self._TESTING)
+            self._check_and_run_test()
+            self._switch_status(self._CLOSING_ROUND)
+            self._close_round()
+        except TaskFailed as err:
+            err_stack = '\n'.join(traceback.format_exception(*sys.exc_info()))
+            self.push_log(err_stack)
+            self.contractor.reset_round()
+            raise ResetRound(err)
+
+    def _start_round(self):
+        """Prepare and start calculation of a round."""
+        self.push_log(f'Begin the training of round {self.current_round}.')
+        self.contractor.start_round(round=self.current_round)
+        self.push_log(f'Calculation of round {self.current_round} is started.')
+
+    def _collect_features(self) -> Dict[str, torch.Tensor]:
+        """Collect all input features from all partners."""
+        self.push_log('Waiting for collecting all features from partners ...')
+        self.contractor.notify_ready_for_fusion(self.current_round)
+        feature_map: Dict[str, Dict[str, torch.Tensor]] = {
+            self.id: {self.feature_key: self._local_features}
+        }
+
+        feature_results = self.data_channel.batch_receive_stream(
+            receiver=self.id,
+            source_list=self._partners,
+            timeout=self.calculation_timeout
+        )
+        for _source, _feature_stream in feature_results.items():
+            buffer = io.BytesIO(_feature_stream)
+            features = torch.load(buffer)
+            self._validate_feature_dict(features)
+            feature_map[_source] = features
+            self.push_log(f'Received features from ID: {_source}')
+
+        if len(feature_map) == len(self._partners) + 1:  # plus self
+            self._alpha_map = feature_map
+            features = dict(feature_dict.copy().popitem()
+                            for feature_dict in self._alpha_map.values())
+            self._feature_fusion_map = features
+        else:
+            raise TaskFailed('Failed to collect all features.')
+
+    def _distribute_feature_grad(self):
+        """Distribute feature grad tensors to collaborators."""
+        self.push_log('Distributing features grad tensors ...')
+        for _partner, _feature_dict in self._alpha_map.items():
+            if _partner == self.id:
+                continue
+            _, feature_tensor = _feature_dict.copy().popitem()
+            with TemporaryFile() as tf:
+                torch.save(feature_tensor.grad, tf)
+                tf.seek(0)
+                self.data_channel.send_stream(source=self.id,
+                                              target=_partner,
+                                              data_stream=tf.read())
+        self.push_log('Distributed all features grad tensors to collaborators.')
+
+    def _save_model(self):
+        """Save latest model state."""
+        with open(self._feature_ckpt_file, 'wb') as f:
+            torch.save(self.feature_model.state_dict(), f)
+        with open(self._infer_ckpt_file, 'wb') as f:
+            torch.save(self.infer_model.state_dict(), f)
+        self.push_log('Saved latest parameters locally.')
+
+    def _save_runtime_context(self):
+        """Save runtime context information in case of restoring."""
+        context_info = {
+            'round': self.current_round,
+            'feature_ckpt_file': self._feature_ckpt_file,
+            'infer_ckpt_file': self._infer_ckpt_file
+        }
+        with open(self._context_file, 'w') as f:
+            f.write(json.dumps(context_info, ensure_ascii=False))
+        self.push_log('Saved latest runtime context.')
+
+    @torch.no_grad()
+    def _check_and_run_test(self):
+        """Run test if match configured conditions."""
+        if (
+            self.current_round == 1
+            or (self.log_rounds > 0 and self.current_round % self.log_rounds == 0)
+            or self.current_round == self.max_rounds
+        ):
+            self.push_log('Start a round of test.')
+
+            self.feature_model.eval()
+            self.infer_model.eval()
+
+            self.contractor.start_test_round(round=self.current_round)
+
+            batched_host_features = []
+            batched_labels = []
+            for _feature_batch, _labels in self.iterate_test_feature(
+                self.feature_model, self.test_ids
+            ):
+                batched_host_features.append((self.feature_key, _feature_batch))
+                batched_labels.append(_labels)
+
+            self._switch_status(self._WAITING_FOR_FEATURES)
+            self._wait_for_testing_features()
+            self._batched_test_features.append(batched_host_features)
+            self._switch_status(self._PROJECTING)
+            batched_feature_projections = [dict(_batch)
+                                           for _batch in zip(*self._batched_test_features)]
+            self.push_log('Fused test data features.')
+
+            self.run_test(batched_feature_projections=batched_feature_projections,
+                          batched_labels=batched_labels)
+            self.push_log('Complete a round of test.')
+
+        self.push_log('Skip or close a round of testing.')
+        self.contractor.close_test_round(round=self.current_round)
+
+    def _wait_for_testing_features(self):
+        """Wait for collecting test dataset features."""
+        self.push_log('Waiting for collecting test dataset features ...')
+        self._batched_test_features = []
+
+        test_feature_results = self.data_channel.batch_receive_stream(
+            receiver=self.id,
+            source_list=self._partners,
+            timeout=self.calculation_timeout
+        )
+        for _source, _feature_stream in test_feature_results.items():
+            buffer = io.BytesIO(_feature_stream)
+            batched_features: dict = torch.load(buffer)
+            _key, _feature_list = batched_features.copy().popitem()
+            self._batched_test_features.append([(_key, _feature_batch)
+                                                for _feature_batch in _feature_list])
+            self.push_log(f'Received test dataset features from ID: {_source}.')
+
+        if len(self._batched_test_features) < len(self._partners):
+            raise TaskFailed('Failed to collect all testing features.')
+
+    def _close_round(self):
+        """Close current round when finished."""
+        self.contractor.close_round(round=self.current_round)
+        self.push_log(f'The training of Round {self.current_round} complete.')
+
+    def _close_task(self, is_succ: bool = True):
+        """Close the task.
+
+        Broadcasts the finish task event to all participants,
+        uploads the final parameters and tells L1 task manager the task is complete.
+        """
+        self.push_log(f'Closing task {self.task_id} ...')
+
+        self._switch_status(self._FINISHING)
+        if is_succ:
+            report_file_path, model_file_path = self._prepare_task_output()
+            self.contractor.upload_metric_report(receivers=self.contractor.EVERYONE,
+                                                 report_file=report_file_path)
+            self.contractor.upload_model(receivers=[self.id],
+                                         model_file=model_file_path)
+            self.contractor.finish_task(is_succ=True)
+            self._wait_for_all_complete()
+            self.contractor.notify_task_completion(result=True)
+            self.push_log(f'Task {self.task_id} complete. Byebye!')
+        else:
+            self.contractor.finish_task(is_succ=False)
+            self.push_log(f'Task {self.task_id} failed. Byebye!')
+
+    def _prepare_task_output(self) -> Tuple[str, str]:
+        """Generate final output files of the task.
+
+        :return
+            Local paths of the report file and model file.
+        """
+        self.push_log('Generating task achievement files ...')
+
+        report_file = os.path.join(self._result_dir, 'report.zip')
+        with ZipFile(report_file, 'w') as report_zip:
+            for path, _, filenames in os.walk(self._log_dir):
+                rel_dir = os.path.relpath(path=path, start=self._result_dir)
+                rel_dir = rel_dir.lstrip('.')  # ./file => file
+                for _file in filenames:
+                    rel_path = os.path.join(rel_dir, _file)
+                    report_zip.write(os.path.join(path, _file), rel_path)
+        report_file_path = os.path.abspath(report_file)
+
+        # torch.jit doesn't work with a TemporaryFile
+        feature_model_file = os.path.join(self._result_dir,
+                                          f'feature_model_{self.feature_key}.pt')
+        with open(feature_model_file, 'wb') as f:
+            torch.save(self.feature_model.state_dict(), f)
+        infer_model_file = f'{os.path.join(self._result_dir, "infer_model.pt")}'
+        with open(infer_model_file, 'wb') as f:
+            torch.save(self.infer_model.state_dict(), f)
+        model_file = os.path.join(self._result_dir, 'model.zip')
+        with ZipFile(model_file, 'w') as model_zip:
+            model_zip.write(feature_model_file, os.path.basename(feature_model_file))
+            model_zip.write(infer_model_file, os.path.basename(infer_model_file))
+        model_file_path = os.path.abspath(model_file)
+
+        self.push_log('Task achievement files are ready.')
+        return report_file_path, model_file_path
+
+    def _wait_for_all_complete(self):
+        """Wait for all collaborators complete their tasks."""
+        self.push_log('Waiting for all collaborators complete their tasks ...')
+        results = {_peer_id: False for _peer_id in self._partners}
+        for _event in self.contractor.contract_events():
+            if isinstance(_event, CollaboratorCompleteEvent):
+                results[_event.peer_id] = True
+                if all(results.values()):
+                    break
+        self.push_log('All collaborators have completed their tasks.')
+
+
+class HeteroNNCollaboratorScheduler(HeteroNNScheduler):
+    """Schedule the process of a collaborator in a hetero_nn task."""
+
+    _WAITING_FOR_FEATUE_GRAD = 'wait_4_feature_grad'
+
+    def __init__(self,
+                 feature_key: str,
+                 schedule_timeout: int = 30,
+                 is_feature_trainable: bool = True) -> None:
+        """Init.
+
+        :args
+            :feature_key
+                A unique key of feature used by the host to distinguish features
+                from collaborators.
+            :schedule_timeout
+                Seconds to timeout for process scheduling. Takeing off timeout
+                by setting its value to 0.
+            :is_feature_trainable
+                Decide whether or not train the feature model
+        """
+        super().__init__()
+        self._switch_status(self._INIT)
+
+        self.feature_key = feature_key
+        self.schedule_timeout = schedule_timeout
+        self.is_feature_trainable = is_feature_trainable
+
+        self._validate_config()
+
+        self.current_round = 0
+
+        self.host = None
+
+        self._feature_grad: torch.Tensor = None
+
+    def _validate_config(self):
+        if not self.feature_key or not isinstance(self.feature_key, str):
+            raise ConfigError('Must specify a feature_key of type string.')
+
+    def validate_context(self):
+        """Validate if the local running context is ready.
+
+        For example: check if train and test dataset could be loaded successfully.
+        """
+        if self.feature_model is None:
+            raise ConfigError('Failed to initialize a feature model.')
+        if not isinstance(self.feature_model, nn.Module):
+            err_msg = 'Support feature model of type torch.Module only.'
+            err_msg += f'Got a {type(self.feature_model)} object.'
+            raise ConfigError(err_msg)
+        if self.feature_optimizer is None:
+            raise ConfigError('Failed to initialize a feature optimizer.')
+        if not isinstance(self.feature_optimizer, optim.Optimizer):
+            err_msg = 'Support feature optimizer of type torch.optim.Optimizer only.'
+            err_msg += f'Got a {type(self.feature_optimizer)} object.'
+            raise ConfigError(err_msg)
+
+    @abstractmethod
+    def iterate_train_feature(self,
+                              feature_model: nn.Module,
+                              train_ids: Set[str]) -> torch.Tensor:
+        """Iterate over train dataset and features a batch of data each time.
+
+        :args
+            :feature_model
+                The feature model object to train & test.
+            :train_ids
+                The ID set of train dataset.
+        """
+
+    @abstractmethod
+    def iterate_test_feature(self,
+                             feature_model: nn.Module,
+                             test_ids: Set[str]) -> torch.Tensor:
+        """Iterate over test dataset and features a batch of data each time.
+
+        :args
+            :feature_model
+                The feature model object to train & test.
+            :train_ids
+                The ID set of test dataset.
+        """
+
+    def _setup_context(self, id: str, task_id: str, is_initiator: bool = False):
+        super()._setup_context(id=id, task_id=task_id, is_initiator=is_initiator)
+
+        self._runtime_dir = get_runtime_dir(self.task_id)
+        self._context_file = os.path.join(self._runtime_dir, ".context.json")
+        self._checkpoint_dir = os.path.join(self._runtime_dir, 'checkpoint')
+        self._feature_ckpt_file = os.path.join(self._checkpoint_dir, "feature_model_ckp.pt")
+
+        self.push_log(message='Begin to validate local context.')
+        self.validate_context()
+
+    def _recover_progress(self):
+        if not os.path.isfile(self._context_file):
+            raise TaskFailed('Failed to recover progress: missing cached context.')
+
+        with open(self._context_file, 'r') as f:
+            context_info = json.load(f)
+        feature_ckpt_file = context_info.get('feature_ckpt_file')
+        assert (
+            feature_ckpt_file and isinstance(feature_ckpt_file, str)
+        ), f'Invalid feature_ckpt_file: {feature_ckpt_file} .'
+        if not os.path.isfile(feature_ckpt_file):
+            raise TaskFailed('Failed to recover progress: missing checkpoint parameters.')
+
+        self.current_round = round
+        with open(feature_ckpt_file, 'rb') as f:
+            state_dict = torch.load(f)
+            self.feature_model.load_state_dict(state_dict)
+
+    def _clean_progress(self):
+        """Clean existing progress data."""
+        shutil.rmtree(self._runtime_dir, ignore_errors=True)
+        shutil.rmtree(self._result_dir, ignore_errors=True)
+        os.makedirs(self._runtime_dir, exist_ok=True)
+        os.makedirs(self._checkpoint_dir, exist_ok=True)
+        os.makedirs(self._result_dir, exist_ok=True)
+
+    def _launch_process(self):
+        try:
+            assert self.status == self._INIT, 'must begin from initial status'
+            self.push_log(f'Node {self.id} is up.')
+
+            self._switch_status(self._GETHORING)
+            self._check_in()
+
+            self._switch_status(self._READY)
+            while self.status == self._READY:
+                try:
+                    self._switch_status(self._SYNCHRONIZING)
+                    self._sync_state()
+
+                    if not self._id_intersection:
+                        self._switch_status(self._ID_INTERSECTION)
+                        self._make_id_intersection()
+
+                    self._switch_status(self._IN_A_ROUND)
+                    self._run_a_round()
+                    self._switch_status(self._READY)
+                    delattr(self, '_train_ids')
+                    delattr(self, '_test_ids')
+                except ResetRound:
+                    self.push_log('WARNING: Reset runtime context, there might be an error raised.')
+                    self._switch_status(self._READY)
+                    self._id_intersection = None
+                    delattr(self, '_train_ids')
+                    delattr(self, '_test_ids')
+                    continue
+
+        except TaskComplete:
+            logger.info('Task complete')
+            self._close_task(is_succ=True)
+
+        except TaskFailed as err:
+            logger.exception(err)
+            self._close_task(is_succ=False)
+
+    def _check_in(self):
+        """Check in task."""
+        is_checked_in = False
+        # the host may be in special state so can not response
+        # correctly nor in time, then retry periodically
+        self.push_log('Checking in the task ...')
+        while not is_checked_in:
+            nonce = self.contractor.checkin(peer_id=self.id)
+            logger.debug('_wait_for_check_in_response ...')
+            for _event in self.contractor.contract_events(timeout=self.schedule_timeout):
+                if isinstance(_event, CheckinResponseEvent):
+                    if _event.nonce != nonce:
+                        continue
+                    self.current_round = _event.round
+                    self.host = _event.host
+                    is_checked_in = True
+                    break
+
+                elif isinstance(_event, FailTaskEvent):
+                    raise TaskFailed('Aborted by host.')
+
+        self.push_log(f'Node {self.id} have taken part in the task.')
+
+    def _sync_state(self):
+        """Synchronize state before each round, so it's easier to manage the process.
+
+        As a partner, synchronizes state and gives a response.
+        """
+        self.push_log('Waiting for synchronizing state with the host ...')
+        for _event in self.contractor.contract_events():
+            if isinstance(_event, SyncStateEvent):
+                self.current_round = _event.round
+                self.contractor.respond_sync_state(round=self.current_round,
+                                                   peer_id=self.id,
+                                                   host=_event.host)
+                self.push_log('Successfully synchronized state with the host.')
+                return
+            elif isinstance(_event, FailTaskEvent):
+                raise TaskFailed('Aborted by host.')
+            elif isinstance(_event, CompleteTaskEvent):
+                raise TaskComplete()
+            elif isinstance(_event, ResetRoundEvent):
+                raise ResetRound()
+
+        self.push_log(f'Successfully synchronized state in round {self.current_round}')
+
+    def _make_id_intersection(self) -> List[str]:
+        """Make PSI and get id intersection for training."""
+        local_ids = self.load_local_ids()
+        psi_scheduler = RSAPSICollaboratorScheduler(
+            task_id=self.task_id,
+            collaborator_id=self.id,
+            ids=local_ids,
+            contractor=self.contractor
+        )
+        self._id_intersection = psi_scheduler.collaborate_intersection()
+
+    def _run_a_round(self):
+        self._wait_for_starting_round()
+        self.feature_model.train()
+        for _batch_features in self.iterate_train_feature(self.feature_model, self.train_ids):
+            self.push_log('Featured a batch of data.')
+            self._switch_status(self._PROJECTING)
+            self._local_features = _batch_features
+            self._send_feature()
+
+            self._switch_status(self._WAITING_FOR_FEATUE_GRAD)
+            self._wait_for_feature_grad()
+            self._switch_status(self._UPDATING)
+            self.feature_optimizer.zero_grad()
+            self._local_features.backward(self._feature_grad)
+            self.feature_optimizer.step()
+
+        self._switch_status(self._PERSISTING)
+        self._save_model()
+        self._save_runtime_context()
+
+        self._switch_status(self._TESTING)
+        self._wait_for_testing_round()
+
+        self._switch_status(self._CLOSING_ROUND)
+        self._wait_for_closing_round()
+
+        self.push_log(f'ID: {self.id} finished training task of round {self.current_round}.')
+
+    def _wait_for_starting_round(self):
+        """Wait for starting a new round of training ..."""
+        self.push_log(f'Waiting for training of round {self.current_round} begin ...')
+        for _event in self.contractor.contract_events():
+            if isinstance(_event, StartRoundEvent):
+                assert (
+                    _event.round == self.current_round
+                ), f'Lost synchronization, host: {_event.round}; local: {self.current_round}.'
+                self.push_log(f'Training of round {self.current_round} begins.')
+                return
+            elif isinstance(_event, FailTaskEvent):
+                raise TaskFailed('Aborted by host.')
+            elif isinstance(_event, ResetRoundEvent):
+                raise ResetRound()
+
+    def _send_feature(self):
+        """Send local features of a batch of data to the host."""
+        self.push_log('Waiting for sending features ...')
+        for _event in self.contractor.contract_events():
+            if isinstance(_event, ReadyForFusionEvent):
+                assert (
+                    _event.round == self.current_round
+                ), f'Lost synchronization, host: {_event.round}; local: {self.current_round}.'
+                break
+            elif isinstance(_event, FailTaskEvent):
+                raise TaskFailed('Aborted by host.')
+            elif isinstance(_event, ResetRoundEvent):
+                raise ResetRound()
+
+        self.push_log('Begin to send features.')
+        with TemporaryFile() as tf:
+            torch.save({self.feature_key: self._local_features}, tf)
+            tf.seek(0)
+            self.data_channel.send_stream(source=self.id,
+                                          target=self.host,
+                                          data_stream=tf.read())
+        self.push_log('Sending features complete.')
+
+    def _wait_for_feature_grad(self):
+        """Wait for cipher grad of feature model output."""
+        def reset_handler(event: ContractEvent):
+            if isinstance(event, ResetRoundEvent):
+                raise ResetRound()
+
+        self.push_log('Waiting for cipher grad of feature model output ...')
+        _, stream = self.data_channel.receive_stream(
+            receiver=self.id,
+            complementary_handler=reset_handler,
+            source=self.host
+        )
+        buffer = io.BytesIO(stream)
+        self._feature_grad = torch.load(buffer)
+        self.push_log('Received and decrypted cipher grad of feature model output.')
+
+    def _save_model(self):
+        """Save latest model state."""
+        with open(self._feature_ckpt_file, 'wb') as f:
+            torch.save(self.feature_model.state_dict(), f)
+        self.push_log('Saved latest parameters locally.')
+
+    def _save_runtime_context(self):
+        """Save runtime context information in case of restoring."""
+        context_info = {
+            'feature_ckpt_file': self._feature_ckpt_file
+        }
+        with open(self._context_file, 'w') as f:
+            f.write(json.dumps(context_info, ensure_ascii=False))
+        self.push_log('Saved latest runtime context.')
+
+    def _wait_for_testing_round(self):
+        """Wait for handle a round of testing."""
+        self.push_log('Waiting for start a round of testing ...')
+        for _event in self.contractor.contract_events():
+            if isinstance(_event, StartTestRoundEvent):
+                assert (
+                    _event.round == self.current_round
+                ), f'Lost synchronization, host: {_event.round}; local: {self.current_round}.'
+
+                self.feature_model.eval()
+                features = {
+                    self.feature_key: list(self.iterate_test_feature(self.feature_model,
+                                                                     self.test_ids))
+                }
+                with TemporaryFile() as tf:
+                    torch.save(features, tf)
+                    tf.seek(0)
+                    self.data_channel.send_stream(source=self.id,
+                                                  target=self.host,
+                                                  data_stream=tf.read())
+                self.push_log('Sent all batches of feature to the host.')
+
+            elif isinstance(_event, CloseTestRoundEvent):
+                self.push_log('Skipped or closed a round of testing.')
+                return
+            elif isinstance(_event, FailTaskEvent):
+                raise TaskFailed('Aborted by host.')
+            elif isinstance(_event, ResetRoundEvent):
+                raise ResetRound()
+
+    def _wait_for_closing_round(self):
+        """Wait for closing current round of training."""
+        self.push_log(f'Waiting for closing signal of training round {self.current_round} ...')
+        for _event in self.contractor.contract_events():
+            if isinstance(_event, CloseRoundEvent):
+                if _event.round != self.current_round:
+                    continue
+                return
+            elif isinstance(_event, CompleteTaskEvent):
+                raise TaskComplete()
+            elif isinstance(_event, ResetRoundEvent):
+                raise ResetRound()
+
+    def _close_task(self, is_succ: bool = True):
+        """Close the task and upload the final parameters."""
+        self.push_log(f'Closing task {self.task_id} ...')
+
+        self._switch_status(self._FINISHING)
+        if is_succ:
+            model_file_path = self._prepare_task_output()
+            self.contractor.upload_metric_report(receivers=self.contractor.EVERYONE)
+            self.contractor.upload_model(receivers=[self.id],
+                                         model_file=model_file_path)
+            self.contractor.notify_collaborator_complete(peer_id=self.id, host=self.host)
+            self.push_log(f'Task {self.task_id} complete. Byebye!')
+        else:
+            self.push_log(f'Task {self.task_id} failed. Byebye!')
+
+    def _prepare_task_output(self) -> Tuple[str, str]:
+        """Generate final output files of the task.
+
+        :return
+            Local paths of the model file.
+        """
+        self.push_log('Generating task achievement files ...')
+
+        # torch.jit doesn't work with a TemporaryFile
+        feature_model_file = os.path.join(self._result_dir,
+                                          f'feature_model_{self.feature_key}.pt')
+        with open(feature_model_file, 'wb') as f:
+            torch.save(self.feature_model.state_dict(), f)
+        model_file_path = os.path.abspath(feature_model_file)
+
+        self.push_log('Task achievement files are ready.')
+        return model_file_path
```

### Comparing `alphamed-federated-0.4.7/src/alphafed/hetero_nn/psi/psi.py` & `alphamed-federated-0.4.9/src/alphafed/hetero_nn/psi/psi.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/hetero_nn/psi/rsa_intersecter.py` & `alphamed-federated-0.4.9/src/alphafed/hetero_nn/psi/rsa_intersecter.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/hetero_nn/psi/rsa_psi_contractor.py` & `alphamed-federated-0.4.9/src/alphafed/hetero_nn/psi/rsa_psi_contractor.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/hetero_nn/secure_contractor.py` & `alphamed-federated-0.4.9/src/alphafed/hetero_nn/secure_contractor.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/hetero_nn/secure_hetero_nn.py` & `alphamed-federated-0.4.9/src/alphafed/hetero_nn/secure_hetero_nn.py`

 * *Ordering differences only*

 * *Files 20% similar despite different names*

```diff
@@ -1,1671 +1,1671 @@
-"""The host of a hetero_nn task.
-
-Reference: https://arxiv.org/pdf/2007.06849.pdf
-"""
-
-import io
-import json
-import os
-import random
-import shutil
-import sys
-import traceback
-from abc import ABCMeta, abstractmethod
-from dataclasses import dataclass
-from tempfile import TemporaryFile
-from typing import Dict, List, Set, Tuple, Union, final
-from zipfile import ZipFile
-
-import tenseal as ts
-import torch
-import torch.nn as nn
-import torch.optim as optim
-from torch.utils.tensorboard import SummaryWriter
-
-from .. import get_result_dir, get_runtime_dir, logger
-from ..contractor.common import ContractEvent
-from ..data_channel import SharedFileDataChannel
-from ..scheduler import ConfigError, Scheduler, TaskComplete, TaskFailed
-from .hetero_nn import ResetRound, _SimplifiedOptimizer
-from .psi import RSAPSICollaboratorScheduler, RSAPSIInitiatorScheduler
-from .secure_contractor import (CheckinEvent, CheckinResponseEvent,
-                                CloseRoundEvent, CloseTestRoundEvent,
-                                CollaboratorCompleteEvent, CompleteTaskEvent,
-                                FailTaskEvent, HeteroNNContractor,
-                                ReadyForFusionEvent,
-                                ReadyForNoisedProjectionEvent,
-                                ReadyForNoisedWGradEvent, ResetRoundEvent,
-                                StartRoundEvent, StartTestRoundEvent,
-                                SyncStateEvent, SyncStateResponseEvent)
-
-__all__ = ['SecureHeteroNNHostScheduler', 'SecureHeteroNNCollaboratorScheduler']
-
-_HE_Tensor = Union[torch.Tensor, ts.CKKSTensor]
-_FEATURE_KEY = str
-
-_ENCODING = 'utf-8'
-_LEN_BYTES = 4
-_BYTES_ORDER = 'big'
-
-
-@dataclass
-class _CKKSTensorWrapper:
-
-    feature_key: str
-    cipher: bytes
-    context: bytes = None
-
-    def to_bytes(self) -> bytes:
-        """Encode to bytes data."""
-        assert (
-            self.feature_key and isinstance(self.feature_key, str)
-        ), f'Invalid feature key: {self.feature_key}.'
-        assert self.cipher and isinstance(self.cipher, bytes), f'Invalid cipher: {self.cipher}.'
-        assert (
-            not self.context or isinstance(self.context, bytes)
-        ), f'Invalid context: {self.context}.'
-
-        data_stream = b''
-        key_bytes = self.feature_key.encode(encoding=_ENCODING)
-        key_len = len(key_bytes)
-        data_stream += key_len.to_bytes(_LEN_BYTES, _BYTES_ORDER) + key_bytes
-        cipher_len = len(self.cipher)
-        data_stream += cipher_len.to_bytes(_LEN_BYTES, _BYTES_ORDER) + self.cipher
-        data_stream += self.context if self.context else b''
-        return data_stream
-
-    @classmethod
-    def from_bytes(self, data: bytes) -> '_CKKSTensorWrapper':
-        """Initialize a _FeatureCipher object from bytes data."""
-        archor = 0
-        assert len(data) > archor + _LEN_BYTES, 'Invalid feature key length data.'
-        key_len = int.from_bytes(data[archor:(archor + _LEN_BYTES)], _BYTES_ORDER)
-        archor += _LEN_BYTES
-        assert len(data) > archor + key_len, 'Invalid feature key data.'
-        feature_key = data[archor:(archor + key_len)].decode(encoding=_ENCODING)
-        archor += key_len
-        assert len(data) > archor + _LEN_BYTES, 'Invalid cipher length data.'
-        cipher_len = int.from_bytes(data[archor:(archor + _LEN_BYTES)], _BYTES_ORDER)
-        archor += _LEN_BYTES
-        assert len(data) >= archor + cipher_len, 'Invalid cipher data.'
-        cipher = data[archor:(archor + cipher_len)]
-        archor += cipher_len
-        context = data[archor:] or None
-        return _CKKSTensorWrapper(feature_key=feature_key, cipher=cipher, context=context)
-
-
-@dataclass
-class _NoisedWGradWrapper:
-
-    feature_key: str
-    noised_grad: torch.Tensor
-    cipher_epsilon_acc: bytes
-    context: bytes
-
-    def to_bytes(self) -> bytes:
-        """Encode to bytes data."""
-        assert (
-            self.feature_key and isinstance(self.feature_key, str)
-        ), f'Invalid feature key: {self.feature_key}.'
-        assert (
-            self.noised_grad is not None and isinstance(self.noised_grad, torch.Tensor)
-        ), f'Invalid noised grad: {self.noised_grad}.'
-        assert (
-            self.cipher_epsilon_acc and isinstance(self.cipher_epsilon_acc, bytes)
-        ), f'Invalid cipher epsilon acc: {self.cipher_epsilon_acc}.'
-        assert (
-            self.context and isinstance(self.context, bytes)
-        ), f'Invalid context: {self.context}.'
-
-        data_stream = b''
-        key_bytes = self.feature_key.encode(encoding=_ENCODING)
-        key_len = len(key_bytes)
-        data_stream += key_len.to_bytes(_LEN_BYTES, _BYTES_ORDER) + key_bytes
-        with TemporaryFile() as tf:
-            torch.save(self.noised_grad, tf)
-            tf.seek(0)
-            grad_bytes = tf.read()
-            grad_len = len(grad_bytes)
-            data_stream += grad_len.to_bytes(_LEN_BYTES, _BYTES_ORDER) + grad_bytes
-        cipher_len = len(self.cipher_epsilon_acc)
-        data_stream += cipher_len.to_bytes(_LEN_BYTES, _BYTES_ORDER) + self.cipher_epsilon_acc
-        data_stream += self.context
-        return data_stream
-
-    @classmethod
-    def from_bytes(self, data: bytes) -> '_NoisedWGradWrapper':
-        """Initialize a _NoisedWGradWrapper object from bytes data."""
-        archor = 0
-        assert len(data) > archor + _LEN_BYTES, 'Invalid feature key length data.'
-        key_len = int.from_bytes(data[archor:(archor + _LEN_BYTES)], _BYTES_ORDER)
-        archor += _LEN_BYTES
-        assert len(data) > archor + key_len, 'Invalid feature key data.'
-        feature_key = data[archor:(archor + key_len)].decode(encoding=_ENCODING)
-        archor += key_len
-        assert len(data) > archor + _LEN_BYTES, 'Invalid grad length data.'
-        grad_len = int.from_bytes(data[archor:(archor + _LEN_BYTES)], _BYTES_ORDER)
-        archor += _LEN_BYTES
-        assert len(data) >= archor + grad_len, 'Invalid grad data.'
-        grad_bytes = data[archor:(archor + grad_len)]
-        buffer = io.BytesIO(grad_bytes)
-        noised_grad = torch.load(buffer)
-        archor += grad_len
-        assert len(data) > archor + _LEN_BYTES, 'Invalid cipher length data.'
-        cipher_len = int.from_bytes(data[archor:(archor + _LEN_BYTES)], _BYTES_ORDER)
-        archor += _LEN_BYTES
-        assert len(data) >= archor + cipher_len, 'Invalid cipher data.'
-        cipher_epsilon_acc = data[archor:(archor + cipher_len)]
-        archor += cipher_len
-        assert len(data) > archor, 'Invalid context data.'
-        context = data[archor:]
-        return _NoisedWGradWrapper(feature_key=feature_key,
-                                   noised_grad=noised_grad,
-                                   cipher_epsilon_acc=cipher_epsilon_acc,
-                                   context=context)
-
-
-class _ProjectLayer(nn.Module):
-    """An interactive layer used for fusion features with privacy preserving."""
-
-    def __init__(self, project_config: List[Tuple[str, int, int]]) -> None:
-        super().__init__()
-        for _key, _in, _out in project_config:
-            if not _key or not isinstance(_key, str):
-                raise ConfigError(f'Invalid key in project rule: {project_config}')
-            if not _in or not isinstance(_in, int) or _in < 1:
-                raise ConfigError(f'Invalid input dimension in project rule: {project_config}')
-            if not _out or not isinstance(_out, int) or _out < 1:
-                raise ConfigError(f'Invalid output dimension in project rule: {project_config}')
-
-        for _key, _in, _out in project_config:
-            self.add_module(name=_key, module=nn.Linear(_in, _out, bias=False))
-
-    def forward(self, input_map: Dict[str, _HE_Tensor]) -> Dict[str, _HE_Tensor]:
-        output_map = {}
-        for _key, _input in input_map.items():
-            if isinstance(_input, ts.CKKSTensor):
-                W_tensor = self.__getattr__(_key).weight
-                output_map[_key] = _input.mm(W_tensor.T.tolist())
-            else:
-                output_map[_key] = self.__getattr__(_key)(_input)
-        return output_map
-
-
-class SecureHeteroNNScheduler(Scheduler, metaclass=ABCMeta):
-    """Base scheduler for heteto_nn tasks."""
-
-    _INIT = 'init'
-    _GETHORING = 'gethoring'
-    _ID_INTERSECTION = 'id_intersection'
-    _READY = 'ready'
-    _SYNCHRONIZING = 'synchronizing'
-    _IN_A_ROUND = 'in_a_round'
-    _PROJECTING = 'projecting'
-    _FINISHING = 'finishing'
-    _UPDATING = 'updating'
-    _PERSISTING = 'persisting'
-    _TESTING = 'testing'
-    _CLOSING_ROUND = 'closing_round'
-
-    def __init__(self) -> None:
-        super().__init__()
-        self.feature_model
-        self.feature_optimizer
-
-        self._id_intersection = None
-        self._local_features: torch.Tensor = None
-        self._example_feature_inputs = None
-
-        self.transparent_err_count = 0  # TODO make clear the cause
-
-    @abstractmethod
-    def _setup_context(self, id: str, task_id: str, is_initiator: bool = False):
-        assert id, 'must specify a unique id for every participant'
-        assert task_id, 'must specify a task_id for every participant'
-
-        self.id = id
-        self.task_id = task_id
-        self.is_host = is_initiator
-        self._result_dir = get_result_dir(self.task_id)
-        self._log_dir = os.path.join(self._result_dir, 'tb_logs')
-        self.tb_writer = SummaryWriter(log_dir=self._log_dir)
-
-        self.contractor = HeteroNNContractor(task_id=task_id)
-        self.data_channel = SharedFileDataChannel(self.contractor)
-
-    @abstractmethod
-    def _launch_process(self):
-        ...
-
-    @abstractmethod
-    def load_local_ids(self) -> List[str]:
-        """Load all local data IDs for PSI."""
-
-    @abstractmethod
-    def build_feature_model(self) -> nn.Module:
-        """Return a model object to project input to features.
-
-        The output of feature model MUST be a (str_keyword, torch.Tensor) tuple, where
-        str_keyword is used by the host to distinguish features from collaborators
-        and Tensor is a two dimension (batch, feature_vector) tensor as the input
-        of projection layer.
-        """
-
-    @final
-    @property
-    def feature_model(self) -> nn.Module:
-        if not hasattr(self, '_feature_model'):
-            self._feature_model = self.build_feature_model()
-        return self._feature_model
-
-    @abstractmethod
-    def build_feature_optimizer(self, feature_model: nn.Module) -> optim.Optimizer:
-        """Return a optimizer object to facilitate training feature model.
-
-        :args
-            :feature_model
-                The feature model object to train & test.
-        """
-
-    @final
-    @property
-    def feature_optimizer(self) -> optim.Optimizer:
-        if not hasattr(self, '_feature_optimizer'):
-            assert self.feature_model, 'Must initialize feature model at first.'
-            self._feature_optimizer = self.build_feature_optimizer(self.feature_model)
-        return self._feature_optimizer
-
-    @property
-    def id_intersection(self) -> Set[str]:
-        """Return the intersection of whole dataset IDs."""
-        assert self._id_intersection is not None, 'Have not run ID intersection process.'
-        return self._id_intersection
-
-    @abstractmethod
-    def split_dataset(self, id_intersection: Set[str]) -> Tuple[Set[str], Set[str]]:
-        """Split dataset into train set and test set.
-
-        NOTE: Must make sure each node gets the same split results.
-
-        :return
-            A tuple of ID set of training dataset and of testing dataset:
-            (Set[train_ids], Set[test_ids]).
-        """
-
-    @final
-    @property
-    def train_ids(self) -> Set[str]:
-        """Return the ID set of training dataset intersection."""
-        if not hasattr(self, '_train_ids'):
-            assert self.id_intersection, 'Must get the whole ID intersection at first.'
-            self._train_ids, self._test_ids = self.split_dataset(self.id_intersection.copy())
-        return self._train_ids
-
-    @final
-    @property
-    def test_ids(self) -> Set[str]:
-        """Return the ID set of testing dataset intersection."""
-        if not hasattr(self, '_test_ids'):
-            assert self.id_intersection, 'Must get the whole ID intersection at first.'
-            self._train_ids, self._test_ids = self.split_dataset(self.id_intersection.copy())
-        return self._test_ids
-
-    @abstractmethod
-    def _recover_progress():
-        """Try to recover progress from last running."""
-
-    @abstractmethod
-    def _clean_progress(self):
-        """Clean existing progress data."""
-
-    def _run(self, id: str, task_id: str, is_initiator: bool = False, recover: bool = False):
-        self._setup_context(id=id, task_id=task_id, is_initiator=is_initiator)
-        self.push_log(message='Local context is ready.')
-        try:
-            if recover:
-                self._recover_progress()
-            else:
-                self._clean_progress()
-            self._launch_process()
-        except Exception:
-            err_stack = '\n'.join(traceback.format_exception(*sys.exc_info()))
-            self.push_log(err_stack)
-
-
-class SecureHeteroNNHostScheduler(SecureHeteroNNScheduler):
-    """Schedule the process of the host in a hetero_nn task."""
-
-    _WAITING_FOR_FEATURES = 'wait_4_feature'
-    _DISTRIBUTING_CIPHER_PROJECTION = 'distribute_cipher_proj'
-    _COLLECTING_NOISED_PROJECTION = 'collect_proj'
-    _GETTING_GRAD = 'calc_loss'
-    _DISTRIBUTING_CIPHER_W_GRAD = 'distribute_w_grad'
-    _COLLECTING_NOISED_W_GRAD = 'collect_w_grad'
-    _DISTRIBUTING_CIPHER_FEATURE_GRAD = 'distribute_feature_grad'
-
-    def __init__(self,
-                 feature_key: str,
-                 project_layer_config: List[Tuple[str, int, int]],
-                 project_layer_lr: float,
-                 max_rounds: int = 0,
-                 calculation_timeout: int = 300,
-                 schedule_timeout: int = 30,
-                 log_rounds: int = 0,
-                 is_feature_trainable: bool = True) -> None:
-        r"""Init.
-
-        :args
-            :feature_key
-                A unique key of feature used by the host to distinguish features
-                from collaborators.
-            :project_layer_config
-                The input => output rule to define projection matrics which are used
-                to project each node's feature tensor to fuse into the input of infer model.
-                Each record contains three element: keyword, input_dimension, output_dimension.
-                The keyword is used to distinguish features' owner, the input_dimension
-                gives the dimension of the feature, the output_dimension defines the
-                dimension of the projection result.
-            :project_layer_lr
-                The learning rate of project layer.
-            :max_rounds
-                Maximal number of training rounds.
-            :calculation_timeout
-                Seconds to timeout for calculation in a round. Takeing off timeout
-                by setting its value to 0.
-            :schedule_timeout
-                Seconds to timeout for process scheduling. Takeing off timeout
-                by setting its value to 0.
-            :log_rounds
-                The number of rounds to run testing and log the result. Skip it
-                by setting its value to 0.
-            :is_feature_trainable
-                Decide whether or not train the feature model
-        """
-        super().__init__()
-        self._switch_status(self._INIT)
-
-        self.feature_key = feature_key
-        self.project_layer_config = project_layer_config
-        self.project_layer_lr = project_layer_lr
-        self.max_rounds = max_rounds
-        self.calculation_timeout = calculation_timeout
-        self.schedule_timeout = schedule_timeout
-        self.log_rounds = log_rounds
-        self.is_feature_trainable = is_feature_trainable  # TODO 暂时不考虑
-
-        self._validate_config()
-
-        self.project_layer
-        self.infer_model
-        self.infer_optimizer
-
-        self.current_round = 1
-        self._partners: List[str] = []
-
-        self._example_project_input = None
-        self._example_infer_input = None
-
-        self._alpha_map: Dict[str, Dict[_FEATURE_KEY, _HE_Tensor]] = {}
-        self._feature_projection_map: Dict[_FEATURE_KEY, _HE_Tensor] = {}
-        self._feature_fusion_map: Dict[_FEATURE_KEY, torch.Tensor] = {}
-        self._noised_w_grad_map: Dict[_FEATURE_KEY, _NoisedWGradWrapper] = {}
-        self._batched_test_features: List[List[Dict[_FEATURE_KEY, _HE_Tensor]]] = []
-        self._epsilon_host = None
-
-    def _validate_config(self):
-        if not self.feature_key or not isinstance(self.feature_key, str):
-            raise ConfigError('Must specify a feature_key of type string.')
-        if not self.project_layer_config or not isinstance(self.project_layer_config, list):
-            raise ConfigError(f'Invalid project layer config: {self.project_layer_config}.')
-        for _config in self.project_layer_config:
-            if not _config or not isinstance(_config, tuple) or len(_config) != 3:
-                raise ConfigError(f'Invalid project layer config items: {_config}.')
-            _key, _in_dim, _out_dim = _config
-            if (
-                not _key or not isinstance(_key, str)
-                or not _in_dim or not isinstance(_in_dim, int) or _in_dim < 1
-                or not _out_dim or not isinstance(_out_dim, int) or _out_dim < 1
-            ):
-                raise ConfigError(f'Invalid project layer config items: {_config}.')
-        if (
-            not self.project_layer_lr
-            or not isinstance(self.project_layer_lr, float)
-            or self.project_layer_lr <= 0
-        ):
-            raise ConfigError(f'Invalid project layer learning rate: {self.project_layer_lr}.')
-
-    @final
-    @property
-    def project_layer(self) -> nn.Module:
-        """Return a model object to project features."""
-        if not hasattr(self, '_project_layer'):
-            self._project_layer = _ProjectLayer(project_config=self.project_layer_config)
-        return self._project_layer
-
-    @final
-    @property
-    def project_optimizer(self) -> _SimplifiedOptimizer:
-        """Return a proxy optimizer to facilitate updating parameters of the project layer."""
-
-        class _ProjectOptimizerImpl(_SimplifiedOptimizer):
-
-            def __init__(self, host_obj: SecureHeteroNNHostScheduler) -> None:
-                super().__init__()
-                self.host_obj = host_obj
-
-            def zero_grad(self):
-                if self.host_obj.project_layer is not None:
-                    for _param in self.host_obj.project_layer.parameters():
-                        if _param.grad is not None:
-                            _param.grad.zero_()
-                if self.host_obj._feature_fusion_map is not None:
-                    for _proj in self.host_obj._feature_fusion_map.values():
-                        if _proj.grad is not None:
-                            _proj.grad.zero_()
-
-            def step(self):
-                self.host_obj._switch_status(self.host_obj._DISTRIBUTING_CIPHER_W_GRAD)
-                self.host_obj._distribute_cipher_w_grad()
-                self.host_obj._switch_status(self.host_obj._COLLECTING_NOISED_W_GRAD)
-                self.host_obj._collect_noised_w_grad()
-                self.host_obj._switch_status(self.host_obj._DISTRIBUTING_CIPHER_FEATURE_GRAD)
-                self.host_obj._distribute_cipher_feature_grad()
-                self.host_obj._switch_status(self.host_obj._UPDATING)
-                self.host_obj._update_project_layer_weight()
-
-        if not hasattr(self, '_project_optimizer'):
-            self._project_optimizer = _ProjectOptimizerImpl(host_obj=self)
-        return self._project_optimizer
-
-    @abstractmethod
-    def build_infer_model(self) -> nn.Module:
-        """Return a model object to infer business results."""
-
-    @final
-    @property
-    def infer_model(self) -> nn.Module:
-        if not hasattr(self, '_infer_model'):
-            self._infer_model = self.build_infer_model()
-        return self._infer_model
-
-    @abstractmethod
-    def build_infer_optimizer(self, infer_model: nn.Module) -> optim.Optimizer:
-        """Return a optimizer object to facilitate training infer model.
-
-        :args
-            :infer_model
-                The infer model object to train & test.
-        """
-
-    @final
-    @property
-    def infer_optimizer(self) -> optim.Optimizer:
-        if not hasattr(self, '_infer_optimizer'):
-            self._infer_optimizer = self.build_infer_optimizer(self.infer_model)
-        return self._infer_optimizer
-
-    @final
-    @property
-    def optimizer(self) -> _SimplifiedOptimizer:
-        """Return a general optimizer to wrap the 3 (feature, project, infer) optimizers."""
-
-        class _OptimizerImpl(_SimplifiedOptimizer):
-
-            def __init__(self, host_obj: SecureHeteroNNHostScheduler) -> None:
-                super().__init__()
-                self.host_obj = host_obj
-
-            def zero_grad(self):
-                self.host_obj.infer_optimizer.zero_grad()
-                self.host_obj.project_optimizer.zero_grad()
-                self.host_obj.feature_optimizer.zero_grad()
-
-            def step(self):
-                self.host_obj.infer_optimizer.step()
-                self.host_obj.project_optimizer.step()
-                self.host_obj.feature_optimizer.step()
-
-        if not hasattr(self, '_optimizer'):
-            self._optimizer = _OptimizerImpl(host_obj=self)
-        return self._optimizer
-
-    @abstractmethod
-    def iterate_train_feature(self,
-                              feature_model: nn.Module,
-                              train_ids: Set[str]) -> Tuple[torch.Tensor, torch.Tensor]:
-        """Iterate over train dataset and features a batch of data each time.
-
-        :args
-            :feature_model
-                The feature model object to train & test.
-            :train_ids
-                The ID set of train dataset.
-        :return
-            A tuple of a batch of train data and their labels. (train_data, labels)
-        """
-
-    @abstractmethod
-    def iterate_test_feature(self,
-                             feature_model: nn.Module,
-                             test_ids: Set[str]) -> Tuple[torch.Tensor, torch.Tensor]:
-        """Iterate over test dataset and features a batch of data each time.
-
-        :args
-            :feature_model
-                The feature model object to train & test.
-            :train_ids
-                The ID set of test dataset.
-        :return
-            A tuple of a batch of test data and their labels. (test_data, labels)
-        """
-
-    @abstractmethod
-    def train_a_batch(self, feature_projection: Dict[str, torch.Tensor], labels: torch.Tensor):
-        """Train a batch of data in infer model.
-
-        :args
-            :feature_projection
-                A map containing features from all nodes of type feature_key => feature_tensor.
-            :labels
-                Corresponding labels of the batch of data.
-        """
-
-    @abstractmethod
-    def run_test(self,
-                 batched_feature_projection: List[Dict[str, torch.Tensor]],
-                 batched_labels: List[torch.Tensor]):
-        """Define the testing steps.
-
-        If you do not want to do testing after training, simply make it pass.
-
-        :args
-            :batched_feature_projections
-                A list of feature projection grouped by batch of testing data. Each batch
-                is a map containing features from all nodes of type feature_key => feature_tensor.
-            :batched_labels
-                A list of labels grouped by batch of testing data.
-        """
-
-    def validate_context(self):
-        """Validate if the local running context is ready.
-
-        For example: check if train and test dataset could be loaded successfully.
-        """
-        if self.feature_model is None:
-            raise ConfigError('Failed to initialize a feature model.')
-        if not isinstance(self.feature_model, nn.Module):
-            err_msg = 'Support feature model of type torch.Module only.'
-            err_msg += f'Got a {type(self.feature_model)} object.'
-            raise ConfigError(err_msg)
-        if self.feature_optimizer is None:
-            raise ConfigError('Failed to initialize a feature optimizer.')
-        if not isinstance(self.feature_optimizer, optim.Optimizer):
-            err_msg = 'Support feature optimizer of type torch.optim.Optimizer only.'
-            err_msg += f'Got a {type(self.feature_optimizer)} object.'
-            raise ConfigError(err_msg)
-
-        if self.infer_model is None:
-            raise ConfigError('Failed to initialize a infer model.')
-        if not isinstance(self.infer_model, nn.Module):
-            err_msg = 'Support infer model of type torch.Module only.'
-            err_msg += f'Got a {type(self.infer_model)} object.'
-            raise ConfigError(err_msg)
-        if self.infer_optimizer is None:
-            raise ConfigError('Failed to initialize a infer optimizer.')
-        if not isinstance(self.infer_optimizer, optim.Optimizer):
-            err_msg = 'Support infer optimizer of type torch.optim.Optimizer only.'
-            err_msg += f'Got a {type(self.infer_optimizer)} object.'
-            raise ConfigError(err_msg)
-
-        if self.project_layer is None:
-            raise TaskFailed('Failed to initialize the project layer.')
-
-        if not self._partners:
-            raise TaskFailed('No partners.')
-
-    def is_task_finished(self) -> bool:
-        """By default true if reach the max rounds configured."""
-        return self._is_reach_max_rounds()
-
-    def _init_partners(self):
-        """Query and set all partners in this task."""
-        self._partners = self.contractor.query_partners()
-        self._partners.remove(self.id)
-
-    def _setup_context(self, id: str, task_id: str, is_initiator: bool = False):
-        super()._setup_context(id=id, task_id=task_id, is_initiator=is_initiator)
-
-        self._init_partners()
-        self._check_in_status = {_partner: False for _partner in self._partners}
-        self._is_gathering_complete = False
-
-        self._runtime_dir = get_runtime_dir(self.task_id)
-        self._context_file = os.path.join(self._runtime_dir, ".context.json")
-        self._checkpoint_dir = os.path.join(self._runtime_dir, 'checkpoint')
-        self._feature_ckpt_file = os.path.join(self._checkpoint_dir, "feature_model_ckp.pt")
-        self._project_ckpt_file = os.path.join(self._checkpoint_dir, "project_layer_ckp.pt")
-        self._infer_ckpt_file = os.path.join(self._checkpoint_dir, "infer_model_ckp.pt")
-
-        self.push_log(message='Begin to validate local context.')
-        self.validate_context()
-
-    def _recover_progress(self):
-        if not os.path.isfile(self._context_file):
-            raise TaskFailed('Failed to recover progress: missing cached context.')
-
-        with open(self._context_file, 'r') as f:
-            context_info = json.load(f)
-        round = context_info.get('round')
-        feature_ckpt_file = context_info.get('feature_ckpt_file')
-        project_ckpt_file = context_info.get('project_ckpt_file')
-        infer_ckpt_file = context_info.get('infer_ckpt_file')
-        assert round and isinstance(round, int) and round > 0, f'Invalid round: {round} .'
-        assert (
-            feature_ckpt_file and isinstance(feature_ckpt_file, str)
-        ), f'Invalid feature_ckpt_file: {feature_ckpt_file} .'
-        assert (
-            project_ckpt_file and isinstance(project_ckpt_file, str)
-        ), f'Invalid project_ckpt_file: {project_ckpt_file} .'
-        assert (
-            infer_ckpt_file and isinstance(infer_ckpt_file, str)
-        ), f'Invalid infer_ckpt_file: {infer_ckpt_file} .'
-        if (
-            not os.path.isfile(feature_ckpt_file)
-            or not os.path.isfile(project_ckpt_file)
-            or not os.path.isfile(infer_ckpt_file)
-        ):
-            raise TaskFailed('Failed to recover progress: missing checkpoint parameters.')
-
-        self.current_round = round
-        with open(feature_ckpt_file, 'rb') as f:
-            state_dict = torch.load(f)
-            self.feature_model.load_state_dict(state_dict)
-        with open(project_ckpt_file, 'rb') as f:
-            state_dict = torch.load(f)
-            self.project_layer.load_state_dict(state_dict)
-        with open(infer_ckpt_file, 'rb') as f:
-            state_dict = torch.load(f)
-            self.infer_model.load_state_dict(state_dict)
-
-    def _clean_progress(self):
-        """Clean existing progress data."""
-        shutil.rmtree(self._runtime_dir, ignore_errors=True)
-        shutil.rmtree(self._result_dir, ignore_errors=True)
-        os.makedirs(self._runtime_dir, exist_ok=True)
-        os.makedirs(self._checkpoint_dir, exist_ok=True)
-        os.makedirs(self._result_dir, exist_ok=True)
-        os.makedirs(self._log_dir, exist_ok=True)
-
-    def _is_reach_max_rounds(self) -> bool:
-        """Is the max rounds configuration reached."""
-        return self.current_round >= self.max_rounds
-
-    def _validate_feature_dict(self, features: Dict[str, ts.CKKSTensor]):
-        """Validate feature format."""
-        if not features or not isinstance(features, dict) or len(features) != 1:
-            self.push_log(f'Received invalid features: {features}')
-            err_msg = r'Invalid feature type. It must be a dict of {feature_key: feature tensor}.'
-            raise TaskFailed(err_msg)
-        _key, _val = features.copy().popitem()
-        if not _key or not isinstance(_key, str):
-            self.push_log(f'Received invalid feature key: {_key}')
-            raise TaskFailed('Invalid feature type. It must contain a keyword of string.')
-        if _val is None or not isinstance(_val, ts.CKKSTensor) or len(_val.shape) != 2:
-            self.push_log(f'Received invalid feature value: {_val}')
-            raise TaskFailed('Invalid feature type. Its value must be a tensor of two dimension.')
-
-    def _launch_process(self):
-        try:
-            assert self.status == self._INIT, 'must begin from initial status'
-            self.push_log(f'Node {self.id} is up.')
-
-            self._switch_status(self._GETHORING)
-            self._check_in()
-
-            self._switch_status(self._READY)
-            while self.status == self._READY:
-                try:
-                    self._switch_status(self._SYNCHRONIZING)
-                    self._sync_state()
-
-                    if not self._id_intersection:
-                        self._switch_status(self._ID_INTERSECTION)
-                        self._make_id_intersection()
-
-                    self._switch_status(self._IN_A_ROUND)
-                    self._run_a_round()
-                    self._switch_status(self._READY)
-                    delattr(self, '_train_ids')
-                    delattr(self, '_test_ids')
-                except ResetRound:
-                    self.push_log('WARNING: Reset runtime context, there might be an error raised.')
-                    self._switch_status(self._READY)
-                    self._id_intersection = None
-                    delattr(self, '_train_ids')
-                    delattr(self, '_test_ids')
-                    continue
-
-                if self.is_task_finished():
-                    self.push_log(f'Obtained the final results of task {self.task_id}')
-                    self._switch_status(self._FINISHING)
-                    self._close_task(is_succ=True)
-
-                self.current_round += 1
-
-        except TaskFailed as err:
-            logger.exception(err)
-            self._close_task(is_succ=False)
-
-    def _check_in(self):
-        """Check in task and connect every partners."""
-        self.push_log('Waiting for participants taking part in ...')
-        for _event in self.contractor.contract_events():
-            if isinstance(_event, CheckinEvent):
-                self._handle_check_in(_event)
-                if all(self._check_in_status.values()):
-                    self._is_gathering_complete = True
-                    break
-        self.push_log('All partners have gethored.')
-
-    def _handle_check_in(self, _event: CheckinEvent):
-        self._check_in_status[_event.peer_id] = True
-        self.push_log(f'Welcome a new partner ID: {_event.peer_id}.')
-        self.push_log(f'There are {sum(self._check_in_status.values())} partners now.')
-        self.contractor.respond_check_in(round=self.current_round,
-                                         host=self.id,
-                                         nonce=_event.nonce,
-                                         requester_id=_event.peer_id)
-        if self._is_gathering_complete:
-            self.contractor.sync_state(round=self.current_round, host=self.id)
-
-    def _sync_state(self):
-        """Synchronize state before each round, so it's easier to manage the process.
-
-        As a host, iterates round, broadcasts and resets context of the new round.
-        """
-        self.push_log(f'Initiate state synchronization of round {self.current_round}.')
-        self.contractor.sync_state(round=self.current_round, host=self.id)
-
-        sync_status = {_partner: False for _partner in self._partners}
-        self.push_log('Waiting for synchronization responses ...')
-        for _event in self.contractor.contract_events(timeout=0):
-            if isinstance(_event, SyncStateResponseEvent):
-                if _event.round != self.current_round:
-                    continue
-                if sync_status.get(_event.peer_id) is False:
-                    sync_status[_event.peer_id] = True
-                    self.push_log(f'Successfully synchronized state with ID: {_event.peer_id}.')
-                if sum(sync_status.values()) == len(self._partners):
-                    break
-            elif isinstance(_event, CheckinEvent):
-                self._handle_check_in(_event)
-
-        self.push_log(f'Successfully synchronized state in round {self.current_round}')
-
-    def _make_id_intersection(self) -> List[str]:
-        """Make PSI and get id intersection for training."""
-        local_ids = self.load_local_ids()
-        psi_scheduler = RSAPSIInitiatorScheduler(
-            task_id=self.task_id,
-            initiator_id=self.id,
-            ids=local_ids,
-            collaborator_ids=self._partners,
-            contractor=self.contractor
-        )
-        self._id_intersection = psi_scheduler.make_intersection()
-
-    def _run_a_round(self):
-        try:
-            self._start_round()
-            self.infer_model.train()
-            self.project_layer.train()
-            self.feature_model.train()
-            for _feature_batch, _labels in self.iterate_train_feature(
-                self.feature_model, self.train_ids
-            ):
-                self.push_log('Featured a batch of data.')
-                self._local_features = _feature_batch
-                self._switch_status(self._WAITING_FOR_FEATURES)
-                self._collect_features()
-                self._switch_status(self._PROJECTING)
-                self._make_projection()
-                self._switch_status(self._DISTRIBUTING_CIPHER_PROJECTION)
-                self._distribute_cipher_projection()
-                self._switch_status(self._COLLECTING_NOISED_PROJECTION)
-                self._collect_noised_projection()
-
-                self._switch_status(self._GETTING_GRAD)
-                self.train_a_batch(self._feature_fusion_map, _labels)
-
-            self._switch_status(self._PERSISTING)
-            self._save_model()
-            self._save_runtime_context()
-            self._switch_status(self._TESTING)
-            self._check_and_run_test()
-            self._switch_status(self._CLOSING_ROUND)
-            self._close_round()
-        except TaskFailed as err:
-            err_stack = '\n'.join(traceback.format_exception(*sys.exc_info()))
-            self.push_log(err_stack)
-            self.contractor.reset_round()
-            raise ResetRound(err)
-
-    def _start_round(self):
-        """Prepare and start calculation of a round."""
-        self.push_log(f'Begin the training of round {self.current_round}.')
-        self.contractor.start_round(round=self.current_round)
-        self.push_log(f'Calculation of round {self.current_round} is started.')
-
-    def _collect_features(self) -> Dict[str, _HE_Tensor]:
-        """Collect all input features from all partners."""
-        self.push_log('Waiting for collecting all features from partners ...')
-        self.contractor.notify_ready_for_fusion(self.current_round)
-        feature_map: Dict[str, Dict[str, _HE_Tensor]] = {
-            self.id: {self.feature_key: self._local_features}
-        }
-
-        feature_results = self.data_channel.batch_receive_stream(
-            receiver=self.id,
-            source_list=self._partners,
-            timeout=self.calculation_timeout
-        )
-        for _source, _feature_stream in feature_results.items():
-            cipher_feature = _CKKSTensorWrapper.from_bytes(_feature_stream)
-            cipher_context = ts.context_from(cipher_feature.context)
-            cipher_tensor = ts.ckks_tensor_from(cipher_context, cipher_feature.cipher)
-            features = {cipher_feature.feature_key: cipher_tensor}
-            self._validate_feature_dict(features)
-            feature_map[_source] = features
-            self.push_log(f'Received dataset features from ID: {_source}.')
-
-        if len(feature_map) == len(self._partners) + 1:  # plus self
-            self._alpha_map = feature_map
-        else:
-            raise TaskFailed('Failed to collect all features.')
-
-    def _make_projection(self):
-        """Fuse features and get cipher feature projection."""
-        self.push_log('Calculating features projection ...')
-        features = dict(feature_dict.copy().popitem()
-                        for feature_dict in self._alpha_map.values())
-        self._feature_projection_map = self.project_layer(features)
-
-    def _distribute_cipher_projection(self):
-        """Distribute cipher feature projection to collaborators."""
-        self.push_log('Distributing cipher projection to collaborators ...')
-        self._epsilon_host = random.randint(1, 2**10)
-        for _partner, _cipher_feature in self._alpha_map.items():
-            if _partner == self.id:
-                continue
-            feature_key, _ = _cipher_feature.copy().popitem()
-            cipher_tensor: ts.CKKSTensor = self._feature_projection_map[feature_key]
-            cipher_tensor.add_(self._epsilon_host)
-            cipher_projection = _CKKSTensorWrapper(feature_key=feature_key,
-                                                   cipher=cipher_tensor.serialize())
-            self.data_channel.send_stream(source=self.id,
-                                          target=_partner,
-                                          data_stream=cipher_projection.to_bytes())
-            self.push_log(f'Distributed cipher projection to collaborator ID: {_partner}')
-
-    @torch.no_grad()
-    def _collect_noised_projection(self):
-        """Collect noised but plain projection from collaborators."""
-        self.push_log('Collecting noised but plain projection from collaborators ...')
-        self.contractor.notify_ready_for_noised_projection(round=self.current_round)
-        self._feature_fusion_map = {
-            self.feature_key: self._feature_projection_map[self.feature_key]
-        }
-
-        proj_results = self.data_channel.batch_receive_stream(
-            receiver=self.id,
-            source_list=self._partners,
-            timeout=self.calculation_timeout
-        )
-        for _source, _proj_stream in proj_results.items():
-            buffer = io.BytesIO(_proj_stream)
-            proj_dict: Dict[str, torch.Tensor] = torch.load(buffer)
-            feature_key, proj_tensor = proj_dict.copy().popitem()
-            proj_tensor.sub_(self._epsilon_host)
-            proj_tensor.requires_grad_()
-            self._feature_fusion_map[feature_key] = proj_tensor
-            self.push_log(f'Received noised projection from ID: {_source}.')
-
-        if len(self._feature_fusion_map) == len(self._partners) + 1:  # and self
-            self.push_log('Received all copies of noised projection.')
-        else:
-            raise TaskFailed('Failed to collect all noised projection.')
-
-    def _distribute_cipher_w_grad(self):
-        self._epsilon_host = random.randint(1, 2**10)
-        self.push_log('Distributing cipher W grad to collaborators ...')
-        for _partner, feature_dict in self._alpha_map.items():
-            if _partner == self.id:
-                continue
-            feature_key, feature_tensor = feature_dict.copy().popitem()
-            feature_tensor: ts.CKKSTensor
-            proj = self._feature_fusion_map[feature_key]
-            cipher_W_grad: ts.CKKSTensor = feature_tensor.transpose()
-            try:
-                cipher_W_grad.mm_(proj.grad).add_(self._epsilon_host)
-            except ValueError:
-                logger.error(f'{proj.grad=}')
-                raise
-            self.data_channel.send_stream(source=self.id,
-                                          target=_partner,
-                                          data_stream=cipher_W_grad.serialize())
-            self.push_log(f'Sent cipher W grad to ID: {_partner}.')
-        self.push_log('Distributed all cipher W grad to collaborators.')
-
-    def _collect_noised_w_grad(self):
-        """Collect decrypted but noised W grad of project layer from collaborators."""
-        self.contractor.notify_ready_for_noised_w_grad(round=self.current_round)
-        self.push_log('Collecting noised W grad from collaborators ...')
-        self._noised_w_grad_map.clear()
-
-        noised_w_grad_results = self.data_channel.batch_receive_stream(
-            receiver=self.id,
-            source_list=self._partners,
-            timeout=self.calculation_timeout
-        )
-        for _source, _stream in noised_w_grad_results.items():
-            noised_grad = _NoisedWGradWrapper.from_bytes(_stream)
-            self._noised_w_grad_map[noised_grad.feature_key] = noised_grad
-            self.push_log(f'Received noised W grad from parter ID: {_source}.')
-
-        if len(self._noised_w_grad_map) == len(self._partners):
-            self.push_log('Received all copies of noised W grad.')
-        else:
-            raise TaskFailed('Failed to collect all noised w grad.')
-
-    def _distribute_cipher_feature_grad(self):
-        """Send cipher feature grad to collaborators."""
-        self.push_log('Distributing cipher feature grad to collaborators ...')
-        for _partner, feature_dict in self._alpha_map.items():
-            if _partner == self.id:
-                continue
-            feature_key, _ = feature_dict.copy().popitem()
-            noised_w_grad = self._noised_w_grad_map[feature_key]
-            he_context = ts.context_from(noised_w_grad.context)
-            cipher_acc = ts.ckks_tensor_from(he_context, noised_w_grad.cipher_epsilon_acc)
-            partner_linear: nn.Linear = self.project_layer.__getattr__(feature_key)
-            partner_W = partner_linear.weight
-            proj_grad = self._feature_fusion_map[feature_key].grad
-            cipher_grad = cipher_acc.broadcast_(partner_W.shape).add_(partner_W.tolist())
-            try:
-                cipher_grad.mm_(proj_grad.T).transpose_()
-                data_stream = cipher_grad.serialize()
-            except ValueError:
-                # deal with "result ciphertext is transparent" error
-                logger.warn('"ValueError: result ciphertext is transparent" presents.')
-                self.transparent_err_count += 1
-                logger.warn(f'proj_grad={proj_grad.tolist()}')
-                data_stream = b'ValueError: result ciphertext is transparent'
-            self.data_channel.send_stream(source=self.id,
-                                          target=_partner,
-                                          data_stream=data_stream)
-            self.push_log(f'Sent cipher feature grad to ID {_partner}.')
-        self.push_log('Distributed all cipher feature grad to collaborators.')
-
-    @torch.no_grad()
-    def _update_project_layer_weight(self):
-        """Update parameters of project layer."""
-        self.push_log('Updating parameters of project layer ...')
-
-        # update self owned project linear layer
-        proj_linear: nn.Linear = self.project_layer.__getattr__(self.feature_key)
-        proj_linear.weight.sub_(self.project_layer_lr * proj_linear.weight.grad)
-
-        # update partners' project linear layer
-        for _feature_key, _noised_w_grad in self._noised_w_grad_map.items():
-            proj_linear: nn.Linear = self.project_layer.__getattr__(_feature_key)
-            _noised_tensor = _noised_w_grad.noised_grad
-            _noised_tensor.sub_(self._epsilon_host)
-            proj_linear.weight.sub_(self.project_layer_lr * _noised_tensor)
-
-        self.push_log('Updated parameters of project layer.')
-
-    def _save_model(self):
-        """Save latest model state."""
-        with open(self._feature_ckpt_file, 'wb') as f:
-            torch.save(self.feature_model.state_dict(), f)
-        with open(self._project_ckpt_file, 'wb') as f:
-            torch.save(self.project_layer.state_dict(), f)
-        with open(self._infer_ckpt_file, 'wb') as f:
-            torch.save(self.infer_model.state_dict(), f)
-        self.push_log('Saved latest parameters locally.')
-
-    def _save_runtime_context(self):
-        """Save runtime context information in case of restoring."""
-        context_info = {
-            'round': self.current_round,
-            'feature_ckpt_file': self._feature_ckpt_file,
-            'project_ckpt_file': self._project_ckpt_file,
-            'infer_ckpt_file': self._infer_ckpt_file
-        }
-        with open(self._context_file, 'w') as f:
-            f.write(json.dumps(context_info, ensure_ascii=False))
-        self.push_log('Saved latest runtime context.')
-
-    @torch.no_grad()
-    def _check_and_run_test(self):
-        """Run test if match configured conditions."""
-        if (
-            self.current_round == 1
-            or (self.log_rounds > 0 and self.current_round % self.log_rounds == 0)
-            or self.current_round == self.max_rounds
-        ):
-            self.push_log('Start a round of test.')
-
-            self.feature_model.eval()
-            self.project_layer.eval()
-            self.infer_model.eval()
-
-            self.contractor.start_test_round(round=self.current_round)
-
-            batched_feature_projections = []
-            batched_labels = []
-            for _feature_batch, _labels in self.iterate_test_feature(
-                self.feature_model, self.test_ids
-            ):
-                self._local_features = _feature_batch
-                self._switch_status(self._WAITING_FOR_FEATURES)
-                self._collect_features()
-                self._switch_status(self._PROJECTING)
-                self._make_projection()
-                self._switch_status(self._DISTRIBUTING_CIPHER_PROJECTION)
-                self._distribute_cipher_projection()
-                self._switch_status(self._COLLECTING_NOISED_PROJECTION)
-                self._collect_noised_projection()
-                batched_labels.append(_labels)
-                batched_feature_projections.append(self._feature_fusion_map)
-                self.push_log('Fused a batch of test data features.')
-
-            self.run_test(batched_feature_projections=batched_feature_projections,
-                          batched_labels=batched_labels)
-            self.push_log('Complete a round of test.')
-
-        self.push_log('Skip or close a round of testing.')
-        self.contractor.close_test_round(round=self.current_round)
-
-    def _close_round(self):
-        """Close current round when finished."""
-        self.contractor.close_round(round=self.current_round)
-        self.push_log(f'The training of Round {self.current_round} complete.')
-
-    def _close_task(self, is_succ: bool = True):
-        """Close the task.
-
-        Broadcasts the finish task event to all participants,
-        uploads the final parameters and tells L1 task manager the task is complete.
-        """
-        self.push_log(f'Closing task {self.task_id} ...')
-
-        logger.info(f'"ValueError: result ciphertext is transparent" present for {self.transparent_err_count} times.')
-
-        self._switch_status(self._FINISHING)
-        if is_succ:
-            report_file_path, model_file_path = self._prepare_task_output()
-            self.contractor.upload_metric_report(receivers=[self.id],
-                                                 report_file=report_file_path)
-            self.contractor.upload_model(receivers=[self.id],
-                                         model_file=model_file_path)
-            self.contractor.finish_task(is_succ=True)
-            self._wait_for_all_complete()
-            self.contractor.notify_task_completion(result=True)
-            self.push_log(f'Task {self.task_id} complete. Byebye!')
-        else:
-            self.contractor.finish_task(is_succ=False)
-            self.push_log(f'Task {self.task_id} failed. Byebye!')
-
-    def _prepare_task_output(self) -> Tuple[str, str]:
-        """Generate final output files of the task.
-
-        :return
-            Local paths of the report file and model file.
-        """
-        self.push_log('Generating task achievement files ...')
-
-        report_file = os.path.join(self._result_dir, 'report.zip')
-        with ZipFile(report_file, 'w') as report_zip:
-            for path, _, filenames in os.walk(self._log_dir):
-                rel_dir = os.path.relpath(path=path, start=self._result_dir)
-                rel_dir = rel_dir.lstrip('.')  # ./file => file
-                for _file in filenames:
-                    rel_path = os.path.join(rel_dir, _file)
-                    report_zip.write(os.path.join(path, _file), rel_path)
-        report_file_path = os.path.abspath(report_file)
-
-        # torch.jit doesn't work with a TemporaryFile
-        feature_model_file = os.path.join(self._result_dir,
-                                          f'feature_model_{self.feature_key}.pt')
-        with open(feature_model_file, 'wb') as f:
-            torch.save(self.feature_model.state_dict(), f)
-        project_layer_file = os.path.join(self._result_dir, 'project_layer.pt')
-        with open(project_layer_file, 'wb') as f:
-            torch.save(self.project_layer.state_dict(), f)
-        infer_model_file = f'{os.path.join(self._result_dir, "infer_model.pt")}'
-        with open(infer_model_file, 'wb') as f:
-            torch.save(self.infer_model.state_dict(), f)
-        model_file = os.path.join(self._result_dir, 'model.zip')
-        with ZipFile(model_file, 'w') as model_zip:
-            model_zip.write(feature_model_file, os.path.basename(feature_model_file))
-            model_zip.write(project_layer_file, os.path.basename(project_layer_file))
-            model_zip.write(infer_model_file, os.path.basename(infer_model_file))
-        model_file_path = os.path.abspath(model_file)
-
-        self.push_log('Task achievement files are ready.')
-        return report_file_path, model_file_path
-
-    def _wait_for_all_complete(self):
-        """Wait for all collaborators complete their tasks."""
-        self.push_log('Waiting for all collaborators complete their tasks ...')
-        results = {_peer_id: False for _peer_id in self._partners}
-        for _event in self.contractor.contract_events():
-            if isinstance(_event, CollaboratorCompleteEvent):
-                results[_event.peer_id] = True
-                if all(results.values()):
-                    break
-        self.push_log('All collaborators have completed their tasks.')
-
-
-class SecureHeteroNNCollaboratorScheduler(SecureHeteroNNScheduler):
-    """Schedule the process of a collaborator in a hetero_nn task."""
-
-    _WAITING_FOR_CIPHER_PROJECTION = 'wait_4_proj'
-    _SENDING_NOISED_PROJECTION = 'send_proj'
-    _WAITING_FOR_W_GRAD = 'wait_4_w_grad'
-    _SENDING_NOISED_W_GRAD = 'send_w_grad'
-    _WAITING_FOR_FEATUE_GRAD = 'wait_4_feature_grad'
-
-    def __init__(self,
-                 feature_key: str,
-                 project_layer_lr: int,
-                 schedule_timeout: int = 30,
-                 is_feature_trainable: bool = True) -> None:
-        """Init.
-
-        :args
-            :feature_key
-                A unique key of feature used by the host to distinguish features
-                from collaborators.
-            :project_layer_lr
-                The learning rate of project layer.
-            :schedule_timeout
-                Seconds to timeout for process scheduling. Takeing off timeout
-                by setting its value to 0.
-            :is_feature_trainable
-                Decide whether or not train the feature model
-        """
-        super().__init__()
-        self._switch_status(self._INIT)
-
-        self.feature_key = feature_key
-        self.project_layer_lr = project_layer_lr
-        self.schedule_timeout = schedule_timeout
-        self.is_feature_trainable = is_feature_trainable
-
-        self._validate_config()
-
-        self.current_round = 0
-
-        self.host = None
-
-        self._he_context: ts.Context = None
-        self._he_context_serialize: bytes = None
-        self._epsilon_acc: float = None
-        self._proj_tensor: torch.Tensor = None
-        self._noised_w_grad: torch.Tensor = None
-        self._feature_grad: torch.Tensor = None
-
-    def _validate_config(self):
-        if not self.feature_key or not isinstance(self.feature_key, str):
-            raise ConfigError('Must specify a feature_key of type string.')
-        if (
-            not self.project_layer_lr
-            or not isinstance(self.project_layer_lr, float)
-            or self.project_layer_lr <= 0
-        ):
-            raise ConfigError(f'Invalid project layer learning rate: {self.project_layer_lr}.')
-
-    def validate_context(self):
-        """Validate if the local running context is ready.
-
-        For example: check if train and test dataset could be loaded successfully.
-        """
-        if self.feature_model is None:
-            raise ConfigError('Failed to initialize a feature model.')
-        if not isinstance(self.feature_model, nn.Module):
-            err_msg = 'Support feature model of type torch.Module only.'
-            err_msg += f'Got a {type(self.feature_model)} object.'
-            raise ConfigError(err_msg)
-        if self.feature_optimizer is None:
-            raise ConfigError('Failed to initialize a feature optimizer.')
-        if not isinstance(self.feature_optimizer, optim.Optimizer):
-            err_msg = 'Support feature optimizer of type torch.optim.Optimizer only.'
-            err_msg += f'Got a {type(self.feature_optimizer)} object.'
-            raise ConfigError(err_msg)
-
-    @abstractmethod
-    def iterate_train_feature(self,
-                              feature_model: nn.Module,
-                              train_ids: Set[str]) -> torch.Tensor:
-        """Iterate over train dataset and features a batch of data each time.
-
-        :args
-            :feature_model
-                The feature model object to train & test.
-            :train_ids
-                The ID set of train dataset.
-        """
-
-    @abstractmethod
-    def iterate_test_feature(self,
-                             feature_model: nn.Module,
-                             test_ids: Set[str]) -> torch.Tensor:
-        """Iterate over test dataset and features a batch of data each time.
-
-        :args
-            :feature_model
-                The feature model object to train & test.
-            :train_ids
-                The ID set of test dataset.
-        """
-
-    def _setup_context(self, id: str, task_id: str, is_initiator: bool = False):
-        super()._setup_context(id=id, task_id=task_id, is_initiator=is_initiator)
-
-        self._he_context = ts.context(ts.SCHEME_TYPE.CKKS,
-                                      poly_modulus_degree=2**12,
-                                      coeff_mod_bit_sizes=[21, 20, 20, 21])
-        self._he_context.global_scale = 2**20
-        self._he_context_serialize = self._he_context.serialize()
-        self._epsilon_acc = random.gauss(0, 0.1)
-
-        self._runtime_dir = get_runtime_dir(self.task_id)
-        self._context_file = os.path.join(self._runtime_dir, ".context.json")
-        self._checkpoint_dir = os.path.join(self._runtime_dir, 'checkpoint')
-        self._feature_ckpt_file = os.path.join(self._checkpoint_dir, "feature_model_ckp.pt")
-
-        self.push_log(message='Begin to validate local context.')
-        self.validate_context()
-
-    def _recover_progress(self):
-        if not os.path.isfile(self._context_file):
-            raise TaskFailed('Failed to recover progress: missing cached context.')
-
-        with open(self._context_file, 'r') as f:
-            context_info = json.load(f)
-        feature_ckpt_file = context_info.get('feature_ckpt_file')
-        assert (
-            feature_ckpt_file and isinstance(feature_ckpt_file, str)
-        ), f'Invalid feature_ckpt_file: {feature_ckpt_file} .'
-        if not os.path.isfile(feature_ckpt_file):
-            raise TaskFailed('Failed to recover progress: missing checkpoint parameters.')
-
-        self.current_round = round
-        with open(feature_ckpt_file, 'rb') as f:
-            state_dict = torch.load(f)
-            self.feature_model.load_state_dict(state_dict)
-
-    def _clean_progress(self):
-        """Clean existing progress data."""
-        shutil.rmtree(self._runtime_dir, ignore_errors=True)
-        shutil.rmtree(self._result_dir, ignore_errors=True)
-        os.makedirs(self._runtime_dir, exist_ok=True)
-        os.makedirs(self._checkpoint_dir, exist_ok=True)
-        os.makedirs(self._result_dir, exist_ok=True)
-
-    def _launch_process(self):
-        try:
-            assert self.status == self._INIT, 'must begin from initial status'
-            self.push_log(f'Node {self.id} is up.')
-
-            self._switch_status(self._GETHORING)
-            self._check_in()
-
-            self._switch_status(self._READY)
-            while self.status == self._READY:
-                try:
-                    self._switch_status(self._SYNCHRONIZING)
-                    self._sync_state()
-
-                    if not self._id_intersection:
-                        self._switch_status(self._ID_INTERSECTION)
-                        self._make_id_intersection()
-
-                    self._switch_status(self._IN_A_ROUND)
-                    self._run_a_round()
-                    self._switch_status(self._READY)
-                    delattr(self, '_train_ids')
-                    delattr(self, '_test_ids')
-                except ResetRound:
-                    self.push_log('WARNING: Reset runtime context, there might be an error raised.')
-                    self._switch_status(self._READY)
-                    self._id_intersection = None
-                    delattr(self, '_train_ids')
-                    delattr(self, '_test_ids')
-                    continue
-
-        except TaskComplete:
-            logger.info('Task complete')
-            self._close_task(is_succ=True)
-
-        except TaskFailed as err:
-            logger.exception(err)
-            self._close_task(is_succ=False)
-
-    def _check_in(self):
-        """Check in task."""
-        is_checked_in = False
-        # the host may be in special state so can not response
-        # correctly nor in time, then retry periodically
-        self.push_log('Checking in the task ...')
-        while not is_checked_in:
-            nonce = self.contractor.checkin(peer_id=self.id)
-            logger.debug('_wait_for_check_in_response ...')
-            for _event in self.contractor.contract_events(timeout=self.schedule_timeout):
-                if isinstance(_event, CheckinResponseEvent):
-                    if _event.nonce != nonce:
-                        continue
-                    self.current_round = _event.round
-                    self.host = _event.host
-                    is_checked_in = True
-                    break
-
-                elif isinstance(_event, FailTaskEvent):
-                    raise TaskFailed('Aborted by host.')
-
-        self.push_log(f'Node {self.id} have taken part in the task.')
-
-    def _sync_state(self):
-        """Synchronize state before each round, so it's easier to manage the process.
-
-        As a partner, synchronizes state and gives a response.
-        """
-        self.push_log('Waiting for synchronizing state with the host ...')
-        for _event in self.contractor.contract_events():
-            if isinstance(_event, SyncStateEvent):
-                self.current_round = _event.round
-                self.contractor.respond_sync_state(round=self.current_round,
-                                                   peer_id=self.id,
-                                                   host=_event.host)
-                self.push_log('Successfully synchronized state with the host.')
-                return
-            elif isinstance(_event, FailTaskEvent):
-                raise TaskFailed('Aborted by host.')
-            elif isinstance(_event, CompleteTaskEvent):
-                raise TaskComplete()
-            elif isinstance(_event, ResetRoundEvent):
-                raise ResetRound()
-
-        self.push_log(f'Successfully synchronized state in round {self.current_round}')
-
-    def _make_id_intersection(self) -> List[str]:
-        """Make PSI and get id intersection for training."""
-        local_ids = self.load_local_ids()
-        psi_scheduler = RSAPSICollaboratorScheduler(
-            task_id=self.task_id,
-            collaborator_id=self.id,
-            ids=local_ids,
-            contractor=self.contractor
-        )
-        self._id_intersection = psi_scheduler.collaborate_intersection()
-
-    def _run_a_round(self):
-        self._wait_for_starting_round()
-        self.feature_model.train()
-        for _batch_features in self.iterate_train_feature(self.feature_model, self.train_ids):
-            self.push_log('Featured a batch of data.')
-            self._switch_status(self._PROJECTING)
-            self._local_features = _batch_features
-            self._send_feature_cipher()
-            self._switch_status(self._WAITING_FOR_CIPHER_PROJECTION)
-            self._wait_for_cipher_projection()
-            self._switch_status(self._SENDING_NOISED_PROJECTION)
-            self._send_noised_projection()
-
-            self._switch_status(self._WAITING_FOR_W_GRAD)
-            self._wait_for_w_grad()
-            self._switch_status(self._SENDING_NOISED_W_GRAD)
-            self._send_noised_w_grad()
-            self._switch_status(self._WAITING_FOR_FEATUE_GRAD)
-            self._wait_for_feature_grad()
-            self._switch_status(self._UPDATING)
-            if self._feature_grad is not None:
-                self.feature_optimizer.zero_grad()
-                self._local_features.backward(self._feature_grad)
-                self.feature_optimizer.step()
-
-        self._switch_status(self._PERSISTING)
-        self._save_model()
-        self._save_runtime_context()
-
-        self._switch_status(self._TESTING)
-        self._wait_for_testing_round()
-
-        self._switch_status(self._CLOSING_ROUND)
-        self._wait_for_closing_round()
-
-        self.push_log(f'ID: {self.id} finished training task of round {self.current_round}.')
-
-    def _wait_for_starting_round(self):
-        """Wait for starting a new round of training ..."""
-        self.push_log(f'Waiting for training of round {self.current_round} begin ...')
-        for _event in self.contractor.contract_events():
-            if isinstance(_event, StartRoundEvent):
-                assert (
-                    _event.round == self.current_round
-                ), f'Lost synchronization, host: {_event.round}; local: {self.current_round}.'
-                self.push_log(f'Training of round {self.current_round} begins.')
-                return
-            elif isinstance(_event, FailTaskEvent):
-                raise TaskFailed('Aborted by host.')
-            elif isinstance(_event, ResetRoundEvent):
-                raise ResetRound()
-
-    def _send_feature_cipher(self):
-        """Send local features of a batch of data to the host."""
-        self.push_log('Waiting for sending features ...')
-        for _event in self.contractor.contract_events():
-            if isinstance(_event, ReadyForFusionEvent):
-                assert (
-                    _event.round == self.current_round
-                ), f'Lost synchronization, host: {_event.round}; local: {self.current_round}.'
-                break
-            elif isinstance(_event, FailTaskEvent):
-                raise TaskFailed('Aborted by host.')
-            elif isinstance(_event, ResetRoundEvent):
-                raise ResetRound()
-
-        self.push_log('Begin to send features.')
-        cipher_tensor = ts.ckks_tensor(self._he_context, self._local_features.detach())
-        cipher_feature = _CKKSTensorWrapper(feature_key=self.feature_key,
-                                            cipher=cipher_tensor.serialize(),
-                                            context=self._he_context_serialize)
-        self.data_channel.send_stream(source=self.id,
-                                      target=self.host,
-                                      data_stream=cipher_feature.to_bytes())
-        self.push_log('Sending features complete.')
-
-    def _abnormal_handler(self, event: ContractEvent):
-        if isinstance(event, FailTaskEvent):
-            raise TaskFailed('Aborted by host.')
-        elif isinstance(event, ResetRoundEvent):
-            raise ResetRound()
-
-    def _wait_for_cipher_projection(self):
-        """Wait for receiving cipher projection of the self owned features."""
-        self.push_log('Waiting for receiving cipher projection ...')
-        _, stream = self.data_channel.receive_stream(
-            receiver=self.id,
-            complementary_handler=self._abnormal_handler,
-            source=self.host
-        )
-        cipher_projection = _CKKSTensorWrapper.from_bytes(stream)
-        cipher_tensor = ts.ckks_tensor_from(context=self._he_context,
-                                            data=cipher_projection.cipher)
-        projection = cipher_tensor.decrypt()
-        self._proj_tensor = torch.tensor(projection.tolist())
-        self._proj_tensor.add_(self._local_features * self._epsilon_acc)
-        self.push_log('Received cipher projection.')
-
-    def _send_noised_projection(self):
-        """Send noised projection to the host for fusion."""
-        self.push_log('Waiting for sending noised projection ...')
-        for _event in self.contractor.contract_events():
-            if isinstance(_event, ReadyForNoisedProjectionEvent):
-                with TemporaryFile() as tf:
-                    torch.save({self.feature_key: self._proj_tensor}, tf)
-                    tf.seek(0)
-                    self.data_channel.send_stream(source=self.id,
-                                                  target=self.host,
-                                                  data_stream=tf.read())
-                return
-            elif isinstance(_event, FailTaskEvent):
-                raise TaskFailed('Aborted by host.')
-            elif isinstance(_event, ResetRoundEvent):
-                raise ResetRound()
-
-    def _wait_for_w_grad(self):
-        """Wait for cipher grad of project layer W to decrypt."""
-        self.push_log('Waiting for cipher grad of project layer W ...')
-        _, stream = self.data_channel.receive_stream(
-            receiver=self.id,
-            complementary_handler=self._abnormal_handler,
-            source=self.host
-        )
-        cipher_grad = ts.ckks_tensor_from(self._he_context, stream)
-        # sample from (-0.005, 0.015) to decrease the overrall speed of
-        # accumulation, thus facilitate convergence
-        epsilon_collab = random.uniform(-0.005, 0.015)
-        self._noised_w_grad = torch.tensor(cipher_grad.decrypt().tolist())
-        self._noised_w_grad.add_(epsilon_collab / self.project_layer_lr)
-        self._epsilon_acc += epsilon_collab
-        self.push_log('Received and decrypted cipher grad of project layer W.')
-
-    def _send_noised_w_grad(self):
-        """Send decrypted grad of project layer W to the host."""
-        self.push_log('Sending noised grad of project layer W to host ...')
-        for _event in self.contractor.contract_events():
-            cipher_acc = ts.ckks_tensor(self._he_context, [self._epsilon_acc])
-            if isinstance(_event, ReadyForNoisedWGradEvent):
-                noised_w_grad = _NoisedWGradWrapper(feature_key=self.feature_key,
-                                                    noised_grad=self._noised_w_grad,
-                                                    cipher_epsilon_acc=cipher_acc.serialize(),
-                                                    context=self._he_context_serialize)
-                self.data_channel.send_stream(source=self.id,
-                                              target=self.host,
-                                              data_stream=noised_w_grad.to_bytes())
-                break
-            elif isinstance(_event, ResetRoundEvent):
-                raise ResetRound()
-        self.push_log('Sent noised grad of project layer W to host.')
-
-    def _wait_for_feature_grad(self):
-        """Wait for cipher grad of feature model output."""
-        self.push_log('Waiting for cipher grad of feature model output ...')
-        _, stream = self.data_channel.receive_stream(
-            receiver=self.id,
-            complementary_handler=self._abnormal_handler,
-            source=self.host
-        )
-        # TODO make clear the cause of 'ValueError: result ciphertext is transparent'
-        if stream == b'ValueError: result ciphertext is transparent':
-            self._feature_grad = None
-            logger.warn(f'noised_w_grad={self._noised_w_grad.tolist()}')
-            logger.warn(f'epsilon_acc={self._epsilon_acc}')
-            logger.warn(f'context={self._he_context.serialize(save_secret_key=True)}')
-        else:
-            cipher_grad = ts.ckks_tensor_from(self._he_context, stream)
-            self._feature_grad = torch.tensor(cipher_grad.decrypt().tolist())
-        self.push_log('Received and decrypted cipher grad of feature model output.')
-
-    def _save_model(self):
-        """Save latest model state."""
-        with open(self._feature_ckpt_file, 'wb') as f:
-            torch.save(self.feature_model.state_dict(), f)
-        self.push_log('Saved latest parameters locally.')
-
-    def _save_runtime_context(self):
-        """Save runtime context information in case of restoring."""
-        context_info = {
-            'feature_ckpt_file': self._feature_ckpt_file
-        }
-        with open(self._context_file, 'w') as f:
-            f.write(json.dumps(context_info, ensure_ascii=False))
-        self.push_log('Saved latest runtime context.')
-
-    def _wait_for_testing_round(self):
-        """Wait for handle a round of testing."""
-        self.push_log('Waiting for start a round of testing ...')
-        for _event in self.contractor.contract_events():
-            if isinstance(_event, StartTestRoundEvent):
-                assert (
-                    _event.round == self.current_round
-                ), f'Lost synchronization, host: {_event.round}; local: {self.current_round}.'
-
-                self.feature_model.eval()
-                for _batch_features in self.iterate_test_feature(self.feature_model,
-                                                                 self.test_ids):
-                    self._switch_status(self._PROJECTING)
-                    self._local_features = _batch_features
-                    self._send_feature_cipher()
-                    self._switch_status(self._WAITING_FOR_CIPHER_PROJECTION)
-                    self._wait_for_cipher_projection()
-                    self._switch_status(self._SENDING_NOISED_PROJECTION)
-                    self._send_noised_projection()
-                    self.push_log('Fused a batch of test data features.')
-
-            elif isinstance(_event, CloseTestRoundEvent):
-                self.push_log('Skipped or closed a round of testing.')
-                return
-            elif isinstance(_event, FailTaskEvent):
-                raise TaskFailed('Aborted by host.')
-            elif isinstance(_event, ResetRoundEvent):
-                raise ResetRound()
-
-    def _wait_for_closing_round(self):
-        """Wait for closing current round of training."""
-        self.push_log(f'Waiting for closing signal of training round {self.current_round} ...')
-        for _event in self.contractor.contract_events():
-            if isinstance(_event, CloseRoundEvent):
-                if _event.round != self.current_round:
-                    continue
-                return
-            elif isinstance(_event, CompleteTaskEvent):
-                raise TaskComplete()
-            elif isinstance(_event, ResetRoundEvent):
-                raise ResetRound()
-
-    def _close_task(self, is_succ: bool = True):
-        """Close the task and upload the final parameters."""
-        self.push_log(f'Closing task {self.task_id} ...')
-
-        self._switch_status(self._FINISHING)
-        if is_succ:
-            model_file_path = self._prepare_task_output()
-            self.contractor.upload_metric_report(receivers=self.contractor.EVERYONE)
-            self.contractor.upload_model(receivers=[self.id],
-                                         model_file=model_file_path)
-            self.contractor.notify_collaborator_complete(peer_id=self.id, host=self.host)
-            self.push_log(f'Task {self.task_id} complete. Byebye!')
-        else:
-            self.push_log(f'Task {self.task_id} failed. Byebye!')
-
-    def _prepare_task_output(self) -> Tuple[str, str]:
-        """Generate final output files of the task.
-
-        :return
-            Local paths of the model file.
-        """
-        self.push_log('Generating task achievement files ...')
-
-        # torch.jit doesn't work with a TemporaryFile
-        feature_model_file = os.path.join(self._result_dir,
-                                          f'feature_model_{self.feature_key}.pt')
-        with open(feature_model_file, 'wb') as f:
-            torch.save(self.feature_model.state_dict(), f)
-        model_file_path = os.path.abspath(feature_model_file)
-
-        self.push_log('Task achievement files are ready.')
-        return model_file_path
+"""The host of a hetero_nn task.
+
+Reference: https://arxiv.org/pdf/2007.06849.pdf
+"""
+
+import io
+import json
+import os
+import random
+import shutil
+import sys
+import traceback
+from abc import ABCMeta, abstractmethod
+from dataclasses import dataclass
+from tempfile import TemporaryFile
+from typing import Dict, List, Set, Tuple, Union, final
+from zipfile import ZipFile
+
+import tenseal as ts
+import torch
+import torch.nn as nn
+import torch.optim as optim
+from torch.utils.tensorboard import SummaryWriter
+
+from .. import get_result_dir, get_runtime_dir, logger
+from ..contractor.common import ContractEvent
+from ..data_channel import SharedFileDataChannel
+from ..scheduler import ConfigError, Scheduler, TaskComplete, TaskFailed
+from .hetero_nn import ResetRound, _SimplifiedOptimizer
+from .psi import RSAPSICollaboratorScheduler, RSAPSIInitiatorScheduler
+from .secure_contractor import (CheckinEvent, CheckinResponseEvent,
+                                CloseRoundEvent, CloseTestRoundEvent,
+                                CollaboratorCompleteEvent, CompleteTaskEvent,
+                                FailTaskEvent, HeteroNNContractor,
+                                ReadyForFusionEvent,
+                                ReadyForNoisedProjectionEvent,
+                                ReadyForNoisedWGradEvent, ResetRoundEvent,
+                                StartRoundEvent, StartTestRoundEvent,
+                                SyncStateEvent, SyncStateResponseEvent)
+
+__all__ = ['SecureHeteroNNHostScheduler', 'SecureHeteroNNCollaboratorScheduler']
+
+_HE_Tensor = Union[torch.Tensor, ts.CKKSTensor]
+_FEATURE_KEY = str
+
+_ENCODING = 'utf-8'
+_LEN_BYTES = 4
+_BYTES_ORDER = 'big'
+
+
+@dataclass
+class _CKKSTensorWrapper:
+
+    feature_key: str
+    cipher: bytes
+    context: bytes = None
+
+    def to_bytes(self) -> bytes:
+        """Encode to bytes data."""
+        assert (
+            self.feature_key and isinstance(self.feature_key, str)
+        ), f'Invalid feature key: {self.feature_key}.'
+        assert self.cipher and isinstance(self.cipher, bytes), f'Invalid cipher: {self.cipher}.'
+        assert (
+            not self.context or isinstance(self.context, bytes)
+        ), f'Invalid context: {self.context}.'
+
+        data_stream = b''
+        key_bytes = self.feature_key.encode(encoding=_ENCODING)
+        key_len = len(key_bytes)
+        data_stream += key_len.to_bytes(_LEN_BYTES, _BYTES_ORDER) + key_bytes
+        cipher_len = len(self.cipher)
+        data_stream += cipher_len.to_bytes(_LEN_BYTES, _BYTES_ORDER) + self.cipher
+        data_stream += self.context if self.context else b''
+        return data_stream
+
+    @classmethod
+    def from_bytes(self, data: bytes) -> '_CKKSTensorWrapper':
+        """Initialize a _FeatureCipher object from bytes data."""
+        archor = 0
+        assert len(data) > archor + _LEN_BYTES, 'Invalid feature key length data.'
+        key_len = int.from_bytes(data[archor:(archor + _LEN_BYTES)], _BYTES_ORDER)
+        archor += _LEN_BYTES
+        assert len(data) > archor + key_len, 'Invalid feature key data.'
+        feature_key = data[archor:(archor + key_len)].decode(encoding=_ENCODING)
+        archor += key_len
+        assert len(data) > archor + _LEN_BYTES, 'Invalid cipher length data.'
+        cipher_len = int.from_bytes(data[archor:(archor + _LEN_BYTES)], _BYTES_ORDER)
+        archor += _LEN_BYTES
+        assert len(data) >= archor + cipher_len, 'Invalid cipher data.'
+        cipher = data[archor:(archor + cipher_len)]
+        archor += cipher_len
+        context = data[archor:] or None
+        return _CKKSTensorWrapper(feature_key=feature_key, cipher=cipher, context=context)
+
+
+@dataclass
+class _NoisedWGradWrapper:
+
+    feature_key: str
+    noised_grad: torch.Tensor
+    cipher_epsilon_acc: bytes
+    context: bytes
+
+    def to_bytes(self) -> bytes:
+        """Encode to bytes data."""
+        assert (
+            self.feature_key and isinstance(self.feature_key, str)
+        ), f'Invalid feature key: {self.feature_key}.'
+        assert (
+            self.noised_grad is not None and isinstance(self.noised_grad, torch.Tensor)
+        ), f'Invalid noised grad: {self.noised_grad}.'
+        assert (
+            self.cipher_epsilon_acc and isinstance(self.cipher_epsilon_acc, bytes)
+        ), f'Invalid cipher epsilon acc: {self.cipher_epsilon_acc}.'
+        assert (
+            self.context and isinstance(self.context, bytes)
+        ), f'Invalid context: {self.context}.'
+
+        data_stream = b''
+        key_bytes = self.feature_key.encode(encoding=_ENCODING)
+        key_len = len(key_bytes)
+        data_stream += key_len.to_bytes(_LEN_BYTES, _BYTES_ORDER) + key_bytes
+        with TemporaryFile() as tf:
+            torch.save(self.noised_grad, tf)
+            tf.seek(0)
+            grad_bytes = tf.read()
+            grad_len = len(grad_bytes)
+            data_stream += grad_len.to_bytes(_LEN_BYTES, _BYTES_ORDER) + grad_bytes
+        cipher_len = len(self.cipher_epsilon_acc)
+        data_stream += cipher_len.to_bytes(_LEN_BYTES, _BYTES_ORDER) + self.cipher_epsilon_acc
+        data_stream += self.context
+        return data_stream
+
+    @classmethod
+    def from_bytes(self, data: bytes) -> '_NoisedWGradWrapper':
+        """Initialize a _NoisedWGradWrapper object from bytes data."""
+        archor = 0
+        assert len(data) > archor + _LEN_BYTES, 'Invalid feature key length data.'
+        key_len = int.from_bytes(data[archor:(archor + _LEN_BYTES)], _BYTES_ORDER)
+        archor += _LEN_BYTES
+        assert len(data) > archor + key_len, 'Invalid feature key data.'
+        feature_key = data[archor:(archor + key_len)].decode(encoding=_ENCODING)
+        archor += key_len
+        assert len(data) > archor + _LEN_BYTES, 'Invalid grad length data.'
+        grad_len = int.from_bytes(data[archor:(archor + _LEN_BYTES)], _BYTES_ORDER)
+        archor += _LEN_BYTES
+        assert len(data) >= archor + grad_len, 'Invalid grad data.'
+        grad_bytes = data[archor:(archor + grad_len)]
+        buffer = io.BytesIO(grad_bytes)
+        noised_grad = torch.load(buffer)
+        archor += grad_len
+        assert len(data) > archor + _LEN_BYTES, 'Invalid cipher length data.'
+        cipher_len = int.from_bytes(data[archor:(archor + _LEN_BYTES)], _BYTES_ORDER)
+        archor += _LEN_BYTES
+        assert len(data) >= archor + cipher_len, 'Invalid cipher data.'
+        cipher_epsilon_acc = data[archor:(archor + cipher_len)]
+        archor += cipher_len
+        assert len(data) > archor, 'Invalid context data.'
+        context = data[archor:]
+        return _NoisedWGradWrapper(feature_key=feature_key,
+                                   noised_grad=noised_grad,
+                                   cipher_epsilon_acc=cipher_epsilon_acc,
+                                   context=context)
+
+
+class _ProjectLayer(nn.Module):
+    """An interactive layer used for fusion features with privacy preserving."""
+
+    def __init__(self, project_config: List[Tuple[str, int, int]]) -> None:
+        super().__init__()
+        for _key, _in, _out in project_config:
+            if not _key or not isinstance(_key, str):
+                raise ConfigError(f'Invalid key in project rule: {project_config}')
+            if not _in or not isinstance(_in, int) or _in < 1:
+                raise ConfigError(f'Invalid input dimension in project rule: {project_config}')
+            if not _out or not isinstance(_out, int) or _out < 1:
+                raise ConfigError(f'Invalid output dimension in project rule: {project_config}')
+
+        for _key, _in, _out in project_config:
+            self.add_module(name=_key, module=nn.Linear(_in, _out, bias=False))
+
+    def forward(self, input_map: Dict[str, _HE_Tensor]) -> Dict[str, _HE_Tensor]:
+        output_map = {}
+        for _key, _input in input_map.items():
+            if isinstance(_input, ts.CKKSTensor):
+                W_tensor = self.__getattr__(_key).weight
+                output_map[_key] = _input.mm(W_tensor.T.tolist())
+            else:
+                output_map[_key] = self.__getattr__(_key)(_input)
+        return output_map
+
+
+class SecureHeteroNNScheduler(Scheduler, metaclass=ABCMeta):
+    """Base scheduler for heteto_nn tasks."""
+
+    _INIT = 'init'
+    _GETHORING = 'gethoring'
+    _ID_INTERSECTION = 'id_intersection'
+    _READY = 'ready'
+    _SYNCHRONIZING = 'synchronizing'
+    _IN_A_ROUND = 'in_a_round'
+    _PROJECTING = 'projecting'
+    _FINISHING = 'finishing'
+    _UPDATING = 'updating'
+    _PERSISTING = 'persisting'
+    _TESTING = 'testing'
+    _CLOSING_ROUND = 'closing_round'
+
+    def __init__(self) -> None:
+        super().__init__()
+        self.feature_model
+        self.feature_optimizer
+
+        self._id_intersection = None
+        self._local_features: torch.Tensor = None
+        self._example_feature_inputs = None
+
+        self.transparent_err_count = 0  # TODO make clear the cause
+
+    @abstractmethod
+    def _setup_context(self, id: str, task_id: str, is_initiator: bool = False):
+        assert id, 'must specify a unique id for every participant'
+        assert task_id, 'must specify a task_id for every participant'
+
+        self.id = id
+        self.task_id = task_id
+        self.is_host = is_initiator
+        self._result_dir = get_result_dir(self.task_id)
+        self._log_dir = os.path.join(self._result_dir, 'tb_logs')
+        self.tb_writer = SummaryWriter(log_dir=self._log_dir)
+
+        self.contractor = HeteroNNContractor(task_id=task_id)
+        self.data_channel = SharedFileDataChannel(self.contractor)
+
+    @abstractmethod
+    def _launch_process(self):
+        ...
+
+    @abstractmethod
+    def load_local_ids(self) -> List[str]:
+        """Load all local data IDs for PSI."""
+
+    @abstractmethod
+    def build_feature_model(self) -> nn.Module:
+        """Return a model object to project input to features.
+
+        The output of feature model MUST be a (str_keyword, torch.Tensor) tuple, where
+        str_keyword is used by the host to distinguish features from collaborators
+        and Tensor is a two dimension (batch, feature_vector) tensor as the input
+        of projection layer.
+        """
+
+    @final
+    @property
+    def feature_model(self) -> nn.Module:
+        if not hasattr(self, '_feature_model'):
+            self._feature_model = self.build_feature_model()
+        return self._feature_model
+
+    @abstractmethod
+    def build_feature_optimizer(self, feature_model: nn.Module) -> optim.Optimizer:
+        """Return a optimizer object to facilitate training feature model.
+
+        :args
+            :feature_model
+                The feature model object to train & test.
+        """
+
+    @final
+    @property
+    def feature_optimizer(self) -> optim.Optimizer:
+        if not hasattr(self, '_feature_optimizer'):
+            assert self.feature_model, 'Must initialize feature model at first.'
+            self._feature_optimizer = self.build_feature_optimizer(self.feature_model)
+        return self._feature_optimizer
+
+    @property
+    def id_intersection(self) -> Set[str]:
+        """Return the intersection of whole dataset IDs."""
+        assert self._id_intersection is not None, 'Have not run ID intersection process.'
+        return self._id_intersection
+
+    @abstractmethod
+    def split_dataset(self, id_intersection: Set[str]) -> Tuple[Set[str], Set[str]]:
+        """Split dataset into train set and test set.
+
+        NOTE: Must make sure each node gets the same split results.
+
+        :return
+            A tuple of ID set of training dataset and of testing dataset:
+            (Set[train_ids], Set[test_ids]).
+        """
+
+    @final
+    @property
+    def train_ids(self) -> Set[str]:
+        """Return the ID set of training dataset intersection."""
+        if not hasattr(self, '_train_ids'):
+            assert self.id_intersection, 'Must get the whole ID intersection at first.'
+            self._train_ids, self._test_ids = self.split_dataset(self.id_intersection.copy())
+        return self._train_ids
+
+    @final
+    @property
+    def test_ids(self) -> Set[str]:
+        """Return the ID set of testing dataset intersection."""
+        if not hasattr(self, '_test_ids'):
+            assert self.id_intersection, 'Must get the whole ID intersection at first.'
+            self._train_ids, self._test_ids = self.split_dataset(self.id_intersection.copy())
+        return self._test_ids
+
+    @abstractmethod
+    def _recover_progress():
+        """Try to recover progress from last running."""
+
+    @abstractmethod
+    def _clean_progress(self):
+        """Clean existing progress data."""
+
+    def _run(self, id: str, task_id: str, is_initiator: bool = False, recover: bool = False):
+        self._setup_context(id=id, task_id=task_id, is_initiator=is_initiator)
+        self.push_log(message='Local context is ready.')
+        try:
+            if recover:
+                self._recover_progress()
+            else:
+                self._clean_progress()
+            self._launch_process()
+        except Exception:
+            err_stack = '\n'.join(traceback.format_exception(*sys.exc_info()))
+            self.push_log(err_stack)
+
+
+class SecureHeteroNNHostScheduler(SecureHeteroNNScheduler):
+    """Schedule the process of the host in a hetero_nn task."""
+
+    _WAITING_FOR_FEATURES = 'wait_4_feature'
+    _DISTRIBUTING_CIPHER_PROJECTION = 'distribute_cipher_proj'
+    _COLLECTING_NOISED_PROJECTION = 'collect_proj'
+    _GETTING_GRAD = 'calc_loss'
+    _DISTRIBUTING_CIPHER_W_GRAD = 'distribute_w_grad'
+    _COLLECTING_NOISED_W_GRAD = 'collect_w_grad'
+    _DISTRIBUTING_CIPHER_FEATURE_GRAD = 'distribute_feature_grad'
+
+    def __init__(self,
+                 feature_key: str,
+                 project_layer_config: List[Tuple[str, int, int]],
+                 project_layer_lr: float,
+                 max_rounds: int = 0,
+                 calculation_timeout: int = 300,
+                 schedule_timeout: int = 30,
+                 log_rounds: int = 0,
+                 is_feature_trainable: bool = True) -> None:
+        r"""Init.
+
+        :args
+            :feature_key
+                A unique key of feature used by the host to distinguish features
+                from collaborators.
+            :project_layer_config
+                The input => output rule to define projection matrics which are used
+                to project each node's feature tensor to fuse into the input of infer model.
+                Each record contains three element: keyword, input_dimension, output_dimension.
+                The keyword is used to distinguish features' owner, the input_dimension
+                gives the dimension of the feature, the output_dimension defines the
+                dimension of the projection result.
+            :project_layer_lr
+                The learning rate of project layer.
+            :max_rounds
+                Maximal number of training rounds.
+            :calculation_timeout
+                Seconds to timeout for calculation in a round. Takeing off timeout
+                by setting its value to 0.
+            :schedule_timeout
+                Seconds to timeout for process scheduling. Takeing off timeout
+                by setting its value to 0.
+            :log_rounds
+                The number of rounds to run testing and log the result. Skip it
+                by setting its value to 0.
+            :is_feature_trainable
+                Decide whether or not train the feature model
+        """
+        super().__init__()
+        self._switch_status(self._INIT)
+
+        self.feature_key = feature_key
+        self.project_layer_config = project_layer_config
+        self.project_layer_lr = project_layer_lr
+        self.max_rounds = max_rounds
+        self.calculation_timeout = calculation_timeout
+        self.schedule_timeout = schedule_timeout
+        self.log_rounds = log_rounds
+        self.is_feature_trainable = is_feature_trainable  # TODO 暂时不考虑
+
+        self._validate_config()
+
+        self.project_layer
+        self.infer_model
+        self.infer_optimizer
+
+        self.current_round = 1
+        self._partners: List[str] = []
+
+        self._example_project_input = None
+        self._example_infer_input = None
+
+        self._alpha_map: Dict[str, Dict[_FEATURE_KEY, _HE_Tensor]] = {}
+        self._feature_projection_map: Dict[_FEATURE_KEY, _HE_Tensor] = {}
+        self._feature_fusion_map: Dict[_FEATURE_KEY, torch.Tensor] = {}
+        self._noised_w_grad_map: Dict[_FEATURE_KEY, _NoisedWGradWrapper] = {}
+        self._batched_test_features: List[List[Dict[_FEATURE_KEY, _HE_Tensor]]] = []
+        self._epsilon_host = None
+
+    def _validate_config(self):
+        if not self.feature_key or not isinstance(self.feature_key, str):
+            raise ConfigError('Must specify a feature_key of type string.')
+        if not self.project_layer_config or not isinstance(self.project_layer_config, list):
+            raise ConfigError(f'Invalid project layer config: {self.project_layer_config}.')
+        for _config in self.project_layer_config:
+            if not _config or not isinstance(_config, tuple) or len(_config) != 3:
+                raise ConfigError(f'Invalid project layer config items: {_config}.')
+            _key, _in_dim, _out_dim = _config
+            if (
+                not _key or not isinstance(_key, str)
+                or not _in_dim or not isinstance(_in_dim, int) or _in_dim < 1
+                or not _out_dim or not isinstance(_out_dim, int) or _out_dim < 1
+            ):
+                raise ConfigError(f'Invalid project layer config items: {_config}.')
+        if (
+            not self.project_layer_lr
+            or not isinstance(self.project_layer_lr, float)
+            or self.project_layer_lr <= 0
+        ):
+            raise ConfigError(f'Invalid project layer learning rate: {self.project_layer_lr}.')
+
+    @final
+    @property
+    def project_layer(self) -> nn.Module:
+        """Return a model object to project features."""
+        if not hasattr(self, '_project_layer'):
+            self._project_layer = _ProjectLayer(project_config=self.project_layer_config)
+        return self._project_layer
+
+    @final
+    @property
+    def project_optimizer(self) -> _SimplifiedOptimizer:
+        """Return a proxy optimizer to facilitate updating parameters of the project layer."""
+
+        class _ProjectOptimizerImpl(_SimplifiedOptimizer):
+
+            def __init__(self, host_obj: SecureHeteroNNHostScheduler) -> None:
+                super().__init__()
+                self.host_obj = host_obj
+
+            def zero_grad(self):
+                if self.host_obj.project_layer is not None:
+                    for _param in self.host_obj.project_layer.parameters():
+                        if _param.grad is not None:
+                            _param.grad.zero_()
+                if self.host_obj._feature_fusion_map is not None:
+                    for _proj in self.host_obj._feature_fusion_map.values():
+                        if _proj.grad is not None:
+                            _proj.grad.zero_()
+
+            def step(self):
+                self.host_obj._switch_status(self.host_obj._DISTRIBUTING_CIPHER_W_GRAD)
+                self.host_obj._distribute_cipher_w_grad()
+                self.host_obj._switch_status(self.host_obj._COLLECTING_NOISED_W_GRAD)
+                self.host_obj._collect_noised_w_grad()
+                self.host_obj._switch_status(self.host_obj._DISTRIBUTING_CIPHER_FEATURE_GRAD)
+                self.host_obj._distribute_cipher_feature_grad()
+                self.host_obj._switch_status(self.host_obj._UPDATING)
+                self.host_obj._update_project_layer_weight()
+
+        if not hasattr(self, '_project_optimizer'):
+            self._project_optimizer = _ProjectOptimizerImpl(host_obj=self)
+        return self._project_optimizer
+
+    @abstractmethod
+    def build_infer_model(self) -> nn.Module:
+        """Return a model object to infer business results."""
+
+    @final
+    @property
+    def infer_model(self) -> nn.Module:
+        if not hasattr(self, '_infer_model'):
+            self._infer_model = self.build_infer_model()
+        return self._infer_model
+
+    @abstractmethod
+    def build_infer_optimizer(self, infer_model: nn.Module) -> optim.Optimizer:
+        """Return a optimizer object to facilitate training infer model.
+
+        :args
+            :infer_model
+                The infer model object to train & test.
+        """
+
+    @final
+    @property
+    def infer_optimizer(self) -> optim.Optimizer:
+        if not hasattr(self, '_infer_optimizer'):
+            self._infer_optimizer = self.build_infer_optimizer(self.infer_model)
+        return self._infer_optimizer
+
+    @final
+    @property
+    def optimizer(self) -> _SimplifiedOptimizer:
+        """Return a general optimizer to wrap the 3 (feature, project, infer) optimizers."""
+
+        class _OptimizerImpl(_SimplifiedOptimizer):
+
+            def __init__(self, host_obj: SecureHeteroNNHostScheduler) -> None:
+                super().__init__()
+                self.host_obj = host_obj
+
+            def zero_grad(self):
+                self.host_obj.infer_optimizer.zero_grad()
+                self.host_obj.project_optimizer.zero_grad()
+                self.host_obj.feature_optimizer.zero_grad()
+
+            def step(self):
+                self.host_obj.infer_optimizer.step()
+                self.host_obj.project_optimizer.step()
+                self.host_obj.feature_optimizer.step()
+
+        if not hasattr(self, '_optimizer'):
+            self._optimizer = _OptimizerImpl(host_obj=self)
+        return self._optimizer
+
+    @abstractmethod
+    def iterate_train_feature(self,
+                              feature_model: nn.Module,
+                              train_ids: Set[str]) -> Tuple[torch.Tensor, torch.Tensor]:
+        """Iterate over train dataset and features a batch of data each time.
+
+        :args
+            :feature_model
+                The feature model object to train & test.
+            :train_ids
+                The ID set of train dataset.
+        :return
+            A tuple of a batch of train data and their labels. (train_data, labels)
+        """
+
+    @abstractmethod
+    def iterate_test_feature(self,
+                             feature_model: nn.Module,
+                             test_ids: Set[str]) -> Tuple[torch.Tensor, torch.Tensor]:
+        """Iterate over test dataset and features a batch of data each time.
+
+        :args
+            :feature_model
+                The feature model object to train & test.
+            :train_ids
+                The ID set of test dataset.
+        :return
+            A tuple of a batch of test data and their labels. (test_data, labels)
+        """
+
+    @abstractmethod
+    def train_a_batch(self, feature_projection: Dict[str, torch.Tensor], labels: torch.Tensor):
+        """Train a batch of data in infer model.
+
+        :args
+            :feature_projection
+                A map containing features from all nodes of type feature_key => feature_tensor.
+            :labels
+                Corresponding labels of the batch of data.
+        """
+
+    @abstractmethod
+    def run_test(self,
+                 batched_feature_projection: List[Dict[str, torch.Tensor]],
+                 batched_labels: List[torch.Tensor]):
+        """Define the testing steps.
+
+        If you do not want to do testing after training, simply make it pass.
+
+        :args
+            :batched_feature_projections
+                A list of feature projection grouped by batch of testing data. Each batch
+                is a map containing features from all nodes of type feature_key => feature_tensor.
+            :batched_labels
+                A list of labels grouped by batch of testing data.
+        """
+
+    def validate_context(self):
+        """Validate if the local running context is ready.
+
+        For example: check if train and test dataset could be loaded successfully.
+        """
+        if self.feature_model is None:
+            raise ConfigError('Failed to initialize a feature model.')
+        if not isinstance(self.feature_model, nn.Module):
+            err_msg = 'Support feature model of type torch.Module only.'
+            err_msg += f'Got a {type(self.feature_model)} object.'
+            raise ConfigError(err_msg)
+        if self.feature_optimizer is None:
+            raise ConfigError('Failed to initialize a feature optimizer.')
+        if not isinstance(self.feature_optimizer, optim.Optimizer):
+            err_msg = 'Support feature optimizer of type torch.optim.Optimizer only.'
+            err_msg += f'Got a {type(self.feature_optimizer)} object.'
+            raise ConfigError(err_msg)
+
+        if self.infer_model is None:
+            raise ConfigError('Failed to initialize a infer model.')
+        if not isinstance(self.infer_model, nn.Module):
+            err_msg = 'Support infer model of type torch.Module only.'
+            err_msg += f'Got a {type(self.infer_model)} object.'
+            raise ConfigError(err_msg)
+        if self.infer_optimizer is None:
+            raise ConfigError('Failed to initialize a infer optimizer.')
+        if not isinstance(self.infer_optimizer, optim.Optimizer):
+            err_msg = 'Support infer optimizer of type torch.optim.Optimizer only.'
+            err_msg += f'Got a {type(self.infer_optimizer)} object.'
+            raise ConfigError(err_msg)
+
+        if self.project_layer is None:
+            raise TaskFailed('Failed to initialize the project layer.')
+
+        if not self._partners:
+            raise TaskFailed('No partners.')
+
+    def is_task_finished(self) -> bool:
+        """By default true if reach the max rounds configured."""
+        return self._is_reach_max_rounds()
+
+    def _init_partners(self):
+        """Query and set all partners in this task."""
+        self._partners = self.contractor.query_partners()
+        self._partners.remove(self.id)
+
+    def _setup_context(self, id: str, task_id: str, is_initiator: bool = False):
+        super()._setup_context(id=id, task_id=task_id, is_initiator=is_initiator)
+
+        self._init_partners()
+        self._check_in_status = {_partner: False for _partner in self._partners}
+        self._is_gathering_complete = False
+
+        self._runtime_dir = get_runtime_dir(self.task_id)
+        self._context_file = os.path.join(self._runtime_dir, ".context.json")
+        self._checkpoint_dir = os.path.join(self._runtime_dir, 'checkpoint')
+        self._feature_ckpt_file = os.path.join(self._checkpoint_dir, "feature_model_ckp.pt")
+        self._project_ckpt_file = os.path.join(self._checkpoint_dir, "project_layer_ckp.pt")
+        self._infer_ckpt_file = os.path.join(self._checkpoint_dir, "infer_model_ckp.pt")
+
+        self.push_log(message='Begin to validate local context.')
+        self.validate_context()
+
+    def _recover_progress(self):
+        if not os.path.isfile(self._context_file):
+            raise TaskFailed('Failed to recover progress: missing cached context.')
+
+        with open(self._context_file, 'r') as f:
+            context_info = json.load(f)
+        round = context_info.get('round')
+        feature_ckpt_file = context_info.get('feature_ckpt_file')
+        project_ckpt_file = context_info.get('project_ckpt_file')
+        infer_ckpt_file = context_info.get('infer_ckpt_file')
+        assert round and isinstance(round, int) and round > 0, f'Invalid round: {round} .'
+        assert (
+            feature_ckpt_file and isinstance(feature_ckpt_file, str)
+        ), f'Invalid feature_ckpt_file: {feature_ckpt_file} .'
+        assert (
+            project_ckpt_file and isinstance(project_ckpt_file, str)
+        ), f'Invalid project_ckpt_file: {project_ckpt_file} .'
+        assert (
+            infer_ckpt_file and isinstance(infer_ckpt_file, str)
+        ), f'Invalid infer_ckpt_file: {infer_ckpt_file} .'
+        if (
+            not os.path.isfile(feature_ckpt_file)
+            or not os.path.isfile(project_ckpt_file)
+            or not os.path.isfile(infer_ckpt_file)
+        ):
+            raise TaskFailed('Failed to recover progress: missing checkpoint parameters.')
+
+        self.current_round = round
+        with open(feature_ckpt_file, 'rb') as f:
+            state_dict = torch.load(f)
+            self.feature_model.load_state_dict(state_dict)
+        with open(project_ckpt_file, 'rb') as f:
+            state_dict = torch.load(f)
+            self.project_layer.load_state_dict(state_dict)
+        with open(infer_ckpt_file, 'rb') as f:
+            state_dict = torch.load(f)
+            self.infer_model.load_state_dict(state_dict)
+
+    def _clean_progress(self):
+        """Clean existing progress data."""
+        shutil.rmtree(self._runtime_dir, ignore_errors=True)
+        shutil.rmtree(self._result_dir, ignore_errors=True)
+        os.makedirs(self._runtime_dir, exist_ok=True)
+        os.makedirs(self._checkpoint_dir, exist_ok=True)
+        os.makedirs(self._result_dir, exist_ok=True)
+        os.makedirs(self._log_dir, exist_ok=True)
+
+    def _is_reach_max_rounds(self) -> bool:
+        """Is the max rounds configuration reached."""
+        return self.current_round >= self.max_rounds
+
+    def _validate_feature_dict(self, features: Dict[str, ts.CKKSTensor]):
+        """Validate feature format."""
+        if not features or not isinstance(features, dict) or len(features) != 1:
+            self.push_log(f'Received invalid features: {features}')
+            err_msg = r'Invalid feature type. It must be a dict of {feature_key: feature tensor}.'
+            raise TaskFailed(err_msg)
+        _key, _val = features.copy().popitem()
+        if not _key or not isinstance(_key, str):
+            self.push_log(f'Received invalid feature key: {_key}')
+            raise TaskFailed('Invalid feature type. It must contain a keyword of string.')
+        if _val is None or not isinstance(_val, ts.CKKSTensor) or len(_val.shape) != 2:
+            self.push_log(f'Received invalid feature value: {_val}')
+            raise TaskFailed('Invalid feature type. Its value must be a tensor of two dimension.')
+
+    def _launch_process(self):
+        try:
+            assert self.status == self._INIT, 'must begin from initial status'
+            self.push_log(f'Node {self.id} is up.')
+
+            self._switch_status(self._GETHORING)
+            self._check_in()
+
+            self._switch_status(self._READY)
+            while self.status == self._READY:
+                try:
+                    self._switch_status(self._SYNCHRONIZING)
+                    self._sync_state()
+
+                    if not self._id_intersection:
+                        self._switch_status(self._ID_INTERSECTION)
+                        self._make_id_intersection()
+
+                    self._switch_status(self._IN_A_ROUND)
+                    self._run_a_round()
+                    self._switch_status(self._READY)
+                    delattr(self, '_train_ids')
+                    delattr(self, '_test_ids')
+                except ResetRound:
+                    self.push_log('WARNING: Reset runtime context, there might be an error raised.')
+                    self._switch_status(self._READY)
+                    self._id_intersection = None
+                    delattr(self, '_train_ids')
+                    delattr(self, '_test_ids')
+                    continue
+
+                if self.is_task_finished():
+                    self.push_log(f'Obtained the final results of task {self.task_id}')
+                    self._switch_status(self._FINISHING)
+                    self._close_task(is_succ=True)
+
+                self.current_round += 1
+
+        except TaskFailed as err:
+            logger.exception(err)
+            self._close_task(is_succ=False)
+
+    def _check_in(self):
+        """Check in task and connect every partners."""
+        self.push_log('Waiting for participants taking part in ...')
+        for _event in self.contractor.contract_events():
+            if isinstance(_event, CheckinEvent):
+                self._handle_check_in(_event)
+                if all(self._check_in_status.values()):
+                    self._is_gathering_complete = True
+                    break
+        self.push_log('All partners have gethored.')
+
+    def _handle_check_in(self, _event: CheckinEvent):
+        self._check_in_status[_event.peer_id] = True
+        self.push_log(f'Welcome a new partner ID: {_event.peer_id}.')
+        self.push_log(f'There are {sum(self._check_in_status.values())} partners now.')
+        self.contractor.respond_check_in(round=self.current_round,
+                                         host=self.id,
+                                         nonce=_event.nonce,
+                                         requester_id=_event.peer_id)
+        if self._is_gathering_complete:
+            self.contractor.sync_state(round=self.current_round, host=self.id)
+
+    def _sync_state(self):
+        """Synchronize state before each round, so it's easier to manage the process.
+
+        As a host, iterates round, broadcasts and resets context of the new round.
+        """
+        self.push_log(f'Initiate state synchronization of round {self.current_round}.')
+        self.contractor.sync_state(round=self.current_round, host=self.id)
+
+        sync_status = {_partner: False for _partner in self._partners}
+        self.push_log('Waiting for synchronization responses ...')
+        for _event in self.contractor.contract_events(timeout=0):
+            if isinstance(_event, SyncStateResponseEvent):
+                if _event.round != self.current_round:
+                    continue
+                if sync_status.get(_event.peer_id) is False:
+                    sync_status[_event.peer_id] = True
+                    self.push_log(f'Successfully synchronized state with ID: {_event.peer_id}.')
+                if sum(sync_status.values()) == len(self._partners):
+                    break
+            elif isinstance(_event, CheckinEvent):
+                self._handle_check_in(_event)
+
+        self.push_log(f'Successfully synchronized state in round {self.current_round}')
+
+    def _make_id_intersection(self) -> List[str]:
+        """Make PSI and get id intersection for training."""
+        local_ids = self.load_local_ids()
+        psi_scheduler = RSAPSIInitiatorScheduler(
+            task_id=self.task_id,
+            initiator_id=self.id,
+            ids=local_ids,
+            collaborator_ids=self._partners,
+            contractor=self.contractor
+        )
+        self._id_intersection = psi_scheduler.make_intersection()
+
+    def _run_a_round(self):
+        try:
+            self._start_round()
+            self.infer_model.train()
+            self.project_layer.train()
+            self.feature_model.train()
+            for _feature_batch, _labels in self.iterate_train_feature(
+                self.feature_model, self.train_ids
+            ):
+                self.push_log('Featured a batch of data.')
+                self._local_features = _feature_batch
+                self._switch_status(self._WAITING_FOR_FEATURES)
+                self._collect_features()
+                self._switch_status(self._PROJECTING)
+                self._make_projection()
+                self._switch_status(self._DISTRIBUTING_CIPHER_PROJECTION)
+                self._distribute_cipher_projection()
+                self._switch_status(self._COLLECTING_NOISED_PROJECTION)
+                self._collect_noised_projection()
+
+                self._switch_status(self._GETTING_GRAD)
+                self.train_a_batch(self._feature_fusion_map, _labels)
+
+            self._switch_status(self._PERSISTING)
+            self._save_model()
+            self._save_runtime_context()
+            self._switch_status(self._TESTING)
+            self._check_and_run_test()
+            self._switch_status(self._CLOSING_ROUND)
+            self._close_round()
+        except TaskFailed as err:
+            err_stack = '\n'.join(traceback.format_exception(*sys.exc_info()))
+            self.push_log(err_stack)
+            self.contractor.reset_round()
+            raise ResetRound(err)
+
+    def _start_round(self):
+        """Prepare and start calculation of a round."""
+        self.push_log(f'Begin the training of round {self.current_round}.')
+        self.contractor.start_round(round=self.current_round)
+        self.push_log(f'Calculation of round {self.current_round} is started.')
+
+    def _collect_features(self) -> Dict[str, _HE_Tensor]:
+        """Collect all input features from all partners."""
+        self.push_log('Waiting for collecting all features from partners ...')
+        self.contractor.notify_ready_for_fusion(self.current_round)
+        feature_map: Dict[str, Dict[str, _HE_Tensor]] = {
+            self.id: {self.feature_key: self._local_features}
+        }
+
+        feature_results = self.data_channel.batch_receive_stream(
+            receiver=self.id,
+            source_list=self._partners,
+            timeout=self.calculation_timeout
+        )
+        for _source, _feature_stream in feature_results.items():
+            cipher_feature = _CKKSTensorWrapper.from_bytes(_feature_stream)
+            cipher_context = ts.context_from(cipher_feature.context)
+            cipher_tensor = ts.ckks_tensor_from(cipher_context, cipher_feature.cipher)
+            features = {cipher_feature.feature_key: cipher_tensor}
+            self._validate_feature_dict(features)
+            feature_map[_source] = features
+            self.push_log(f'Received dataset features from ID: {_source}.')
+
+        if len(feature_map) == len(self._partners) + 1:  # plus self
+            self._alpha_map = feature_map
+        else:
+            raise TaskFailed('Failed to collect all features.')
+
+    def _make_projection(self):
+        """Fuse features and get cipher feature projection."""
+        self.push_log('Calculating features projection ...')
+        features = dict(feature_dict.copy().popitem()
+                        for feature_dict in self._alpha_map.values())
+        self._feature_projection_map = self.project_layer(features)
+
+    def _distribute_cipher_projection(self):
+        """Distribute cipher feature projection to collaborators."""
+        self.push_log('Distributing cipher projection to collaborators ...')
+        self._epsilon_host = random.randint(1, 2**10)
+        for _partner, _cipher_feature in self._alpha_map.items():
+            if _partner == self.id:
+                continue
+            feature_key, _ = _cipher_feature.copy().popitem()
+            cipher_tensor: ts.CKKSTensor = self._feature_projection_map[feature_key]
+            cipher_tensor.add_(self._epsilon_host)
+            cipher_projection = _CKKSTensorWrapper(feature_key=feature_key,
+                                                   cipher=cipher_tensor.serialize())
+            self.data_channel.send_stream(source=self.id,
+                                          target=_partner,
+                                          data_stream=cipher_projection.to_bytes())
+            self.push_log(f'Distributed cipher projection to collaborator ID: {_partner}')
+
+    @torch.no_grad()
+    def _collect_noised_projection(self):
+        """Collect noised but plain projection from collaborators."""
+        self.push_log('Collecting noised but plain projection from collaborators ...')
+        self.contractor.notify_ready_for_noised_projection(round=self.current_round)
+        self._feature_fusion_map = {
+            self.feature_key: self._feature_projection_map[self.feature_key]
+        }
+
+        proj_results = self.data_channel.batch_receive_stream(
+            receiver=self.id,
+            source_list=self._partners,
+            timeout=self.calculation_timeout
+        )
+        for _source, _proj_stream in proj_results.items():
+            buffer = io.BytesIO(_proj_stream)
+            proj_dict: Dict[str, torch.Tensor] = torch.load(buffer)
+            feature_key, proj_tensor = proj_dict.copy().popitem()
+            proj_tensor.sub_(self._epsilon_host)
+            proj_tensor.requires_grad_()
+            self._feature_fusion_map[feature_key] = proj_tensor
+            self.push_log(f'Received noised projection from ID: {_source}.')
+
+        if len(self._feature_fusion_map) == len(self._partners) + 1:  # and self
+            self.push_log('Received all copies of noised projection.')
+        else:
+            raise TaskFailed('Failed to collect all noised projection.')
+
+    def _distribute_cipher_w_grad(self):
+        self._epsilon_host = random.randint(1, 2**10)
+        self.push_log('Distributing cipher W grad to collaborators ...')
+        for _partner, feature_dict in self._alpha_map.items():
+            if _partner == self.id:
+                continue
+            feature_key, feature_tensor = feature_dict.copy().popitem()
+            feature_tensor: ts.CKKSTensor
+            proj = self._feature_fusion_map[feature_key]
+            cipher_W_grad: ts.CKKSTensor = feature_tensor.transpose()
+            try:
+                cipher_W_grad.mm_(proj.grad).add_(self._epsilon_host)
+            except ValueError:
+                logger.error(f'{proj.grad=}')
+                raise
+            self.data_channel.send_stream(source=self.id,
+                                          target=_partner,
+                                          data_stream=cipher_W_grad.serialize())
+            self.push_log(f'Sent cipher W grad to ID: {_partner}.')
+        self.push_log('Distributed all cipher W grad to collaborators.')
+
+    def _collect_noised_w_grad(self):
+        """Collect decrypted but noised W grad of project layer from collaborators."""
+        self.contractor.notify_ready_for_noised_w_grad(round=self.current_round)
+        self.push_log('Collecting noised W grad from collaborators ...')
+        self._noised_w_grad_map.clear()
+
+        noised_w_grad_results = self.data_channel.batch_receive_stream(
+            receiver=self.id,
+            source_list=self._partners,
+            timeout=self.calculation_timeout
+        )
+        for _source, _stream in noised_w_grad_results.items():
+            noised_grad = _NoisedWGradWrapper.from_bytes(_stream)
+            self._noised_w_grad_map[noised_grad.feature_key] = noised_grad
+            self.push_log(f'Received noised W grad from parter ID: {_source}.')
+
+        if len(self._noised_w_grad_map) == len(self._partners):
+            self.push_log('Received all copies of noised W grad.')
+        else:
+            raise TaskFailed('Failed to collect all noised w grad.')
+
+    def _distribute_cipher_feature_grad(self):
+        """Send cipher feature grad to collaborators."""
+        self.push_log('Distributing cipher feature grad to collaborators ...')
+        for _partner, feature_dict in self._alpha_map.items():
+            if _partner == self.id:
+                continue
+            feature_key, _ = feature_dict.copy().popitem()
+            noised_w_grad = self._noised_w_grad_map[feature_key]
+            he_context = ts.context_from(noised_w_grad.context)
+            cipher_acc = ts.ckks_tensor_from(he_context, noised_w_grad.cipher_epsilon_acc)
+            partner_linear: nn.Linear = self.project_layer.__getattr__(feature_key)
+            partner_W = partner_linear.weight
+            proj_grad = self._feature_fusion_map[feature_key].grad
+            cipher_grad = cipher_acc.broadcast_(partner_W.shape).add_(partner_W.tolist())
+            try:
+                cipher_grad.mm_(proj_grad.T).transpose_()
+                data_stream = cipher_grad.serialize()
+            except ValueError:
+                # deal with "result ciphertext is transparent" error
+                logger.warn('"ValueError: result ciphertext is transparent" presents.')
+                self.transparent_err_count += 1
+                logger.warn(f'proj_grad={proj_grad.tolist()}')
+                data_stream = b'ValueError: result ciphertext is transparent'
+            self.data_channel.send_stream(source=self.id,
+                                          target=_partner,
+                                          data_stream=data_stream)
+            self.push_log(f'Sent cipher feature grad to ID {_partner}.')
+        self.push_log('Distributed all cipher feature grad to collaborators.')
+
+    @torch.no_grad()
+    def _update_project_layer_weight(self):
+        """Update parameters of project layer."""
+        self.push_log('Updating parameters of project layer ...')
+
+        # update self owned project linear layer
+        proj_linear: nn.Linear = self.project_layer.__getattr__(self.feature_key)
+        proj_linear.weight.sub_(self.project_layer_lr * proj_linear.weight.grad)
+
+        # update partners' project linear layer
+        for _feature_key, _noised_w_grad in self._noised_w_grad_map.items():
+            proj_linear: nn.Linear = self.project_layer.__getattr__(_feature_key)
+            _noised_tensor = _noised_w_grad.noised_grad
+            _noised_tensor.sub_(self._epsilon_host)
+            proj_linear.weight.sub_(self.project_layer_lr * _noised_tensor)
+
+        self.push_log('Updated parameters of project layer.')
+
+    def _save_model(self):
+        """Save latest model state."""
+        with open(self._feature_ckpt_file, 'wb') as f:
+            torch.save(self.feature_model.state_dict(), f)
+        with open(self._project_ckpt_file, 'wb') as f:
+            torch.save(self.project_layer.state_dict(), f)
+        with open(self._infer_ckpt_file, 'wb') as f:
+            torch.save(self.infer_model.state_dict(), f)
+        self.push_log('Saved latest parameters locally.')
+
+    def _save_runtime_context(self):
+        """Save runtime context information in case of restoring."""
+        context_info = {
+            'round': self.current_round,
+            'feature_ckpt_file': self._feature_ckpt_file,
+            'project_ckpt_file': self._project_ckpt_file,
+            'infer_ckpt_file': self._infer_ckpt_file
+        }
+        with open(self._context_file, 'w') as f:
+            f.write(json.dumps(context_info, ensure_ascii=False))
+        self.push_log('Saved latest runtime context.')
+
+    @torch.no_grad()
+    def _check_and_run_test(self):
+        """Run test if match configured conditions."""
+        if (
+            self.current_round == 1
+            or (self.log_rounds > 0 and self.current_round % self.log_rounds == 0)
+            or self.current_round == self.max_rounds
+        ):
+            self.push_log('Start a round of test.')
+
+            self.feature_model.eval()
+            self.project_layer.eval()
+            self.infer_model.eval()
+
+            self.contractor.start_test_round(round=self.current_round)
+
+            batched_feature_projections = []
+            batched_labels = []
+            for _feature_batch, _labels in self.iterate_test_feature(
+                self.feature_model, self.test_ids
+            ):
+                self._local_features = _feature_batch
+                self._switch_status(self._WAITING_FOR_FEATURES)
+                self._collect_features()
+                self._switch_status(self._PROJECTING)
+                self._make_projection()
+                self._switch_status(self._DISTRIBUTING_CIPHER_PROJECTION)
+                self._distribute_cipher_projection()
+                self._switch_status(self._COLLECTING_NOISED_PROJECTION)
+                self._collect_noised_projection()
+                batched_labels.append(_labels)
+                batched_feature_projections.append(self._feature_fusion_map)
+                self.push_log('Fused a batch of test data features.')
+
+            self.run_test(batched_feature_projections=batched_feature_projections,
+                          batched_labels=batched_labels)
+            self.push_log('Complete a round of test.')
+
+        self.push_log('Skip or close a round of testing.')
+        self.contractor.close_test_round(round=self.current_round)
+
+    def _close_round(self):
+        """Close current round when finished."""
+        self.contractor.close_round(round=self.current_round)
+        self.push_log(f'The training of Round {self.current_round} complete.')
+
+    def _close_task(self, is_succ: bool = True):
+        """Close the task.
+
+        Broadcasts the finish task event to all participants,
+        uploads the final parameters and tells L1 task manager the task is complete.
+        """
+        self.push_log(f'Closing task {self.task_id} ...')
+
+        logger.info(f'"ValueError: result ciphertext is transparent" present for {self.transparent_err_count} times.')
+
+        self._switch_status(self._FINISHING)
+        if is_succ:
+            report_file_path, model_file_path = self._prepare_task_output()
+            self.contractor.upload_metric_report(receivers=[self.id],
+                                                 report_file=report_file_path)
+            self.contractor.upload_model(receivers=[self.id],
+                                         model_file=model_file_path)
+            self.contractor.finish_task(is_succ=True)
+            self._wait_for_all_complete()
+            self.contractor.notify_task_completion(result=True)
+            self.push_log(f'Task {self.task_id} complete. Byebye!')
+        else:
+            self.contractor.finish_task(is_succ=False)
+            self.push_log(f'Task {self.task_id} failed. Byebye!')
+
+    def _prepare_task_output(self) -> Tuple[str, str]:
+        """Generate final output files of the task.
+
+        :return
+            Local paths of the report file and model file.
+        """
+        self.push_log('Generating task achievement files ...')
+
+        report_file = os.path.join(self._result_dir, 'report.zip')
+        with ZipFile(report_file, 'w') as report_zip:
+            for path, _, filenames in os.walk(self._log_dir):
+                rel_dir = os.path.relpath(path=path, start=self._result_dir)
+                rel_dir = rel_dir.lstrip('.')  # ./file => file
+                for _file in filenames:
+                    rel_path = os.path.join(rel_dir, _file)
+                    report_zip.write(os.path.join(path, _file), rel_path)
+        report_file_path = os.path.abspath(report_file)
+
+        # torch.jit doesn't work with a TemporaryFile
+        feature_model_file = os.path.join(self._result_dir,
+                                          f'feature_model_{self.feature_key}.pt')
+        with open(feature_model_file, 'wb') as f:
+            torch.save(self.feature_model.state_dict(), f)
+        project_layer_file = os.path.join(self._result_dir, 'project_layer.pt')
+        with open(project_layer_file, 'wb') as f:
+            torch.save(self.project_layer.state_dict(), f)
+        infer_model_file = f'{os.path.join(self._result_dir, "infer_model.pt")}'
+        with open(infer_model_file, 'wb') as f:
+            torch.save(self.infer_model.state_dict(), f)
+        model_file = os.path.join(self._result_dir, 'model.zip')
+        with ZipFile(model_file, 'w') as model_zip:
+            model_zip.write(feature_model_file, os.path.basename(feature_model_file))
+            model_zip.write(project_layer_file, os.path.basename(project_layer_file))
+            model_zip.write(infer_model_file, os.path.basename(infer_model_file))
+        model_file_path = os.path.abspath(model_file)
+
+        self.push_log('Task achievement files are ready.')
+        return report_file_path, model_file_path
+
+    def _wait_for_all_complete(self):
+        """Wait for all collaborators complete their tasks."""
+        self.push_log('Waiting for all collaborators complete their tasks ...')
+        results = {_peer_id: False for _peer_id in self._partners}
+        for _event in self.contractor.contract_events():
+            if isinstance(_event, CollaboratorCompleteEvent):
+                results[_event.peer_id] = True
+                if all(results.values()):
+                    break
+        self.push_log('All collaborators have completed their tasks.')
+
+
+class SecureHeteroNNCollaboratorScheduler(SecureHeteroNNScheduler):
+    """Schedule the process of a collaborator in a hetero_nn task."""
+
+    _WAITING_FOR_CIPHER_PROJECTION = 'wait_4_proj'
+    _SENDING_NOISED_PROJECTION = 'send_proj'
+    _WAITING_FOR_W_GRAD = 'wait_4_w_grad'
+    _SENDING_NOISED_W_GRAD = 'send_w_grad'
+    _WAITING_FOR_FEATUE_GRAD = 'wait_4_feature_grad'
+
+    def __init__(self,
+                 feature_key: str,
+                 project_layer_lr: int,
+                 schedule_timeout: int = 30,
+                 is_feature_trainable: bool = True) -> None:
+        """Init.
+
+        :args
+            :feature_key
+                A unique key of feature used by the host to distinguish features
+                from collaborators.
+            :project_layer_lr
+                The learning rate of project layer.
+            :schedule_timeout
+                Seconds to timeout for process scheduling. Takeing off timeout
+                by setting its value to 0.
+            :is_feature_trainable
+                Decide whether or not train the feature model
+        """
+        super().__init__()
+        self._switch_status(self._INIT)
+
+        self.feature_key = feature_key
+        self.project_layer_lr = project_layer_lr
+        self.schedule_timeout = schedule_timeout
+        self.is_feature_trainable = is_feature_trainable
+
+        self._validate_config()
+
+        self.current_round = 0
+
+        self.host = None
+
+        self._he_context: ts.Context = None
+        self._he_context_serialize: bytes = None
+        self._epsilon_acc: float = None
+        self._proj_tensor: torch.Tensor = None
+        self._noised_w_grad: torch.Tensor = None
+        self._feature_grad: torch.Tensor = None
+
+    def _validate_config(self):
+        if not self.feature_key or not isinstance(self.feature_key, str):
+            raise ConfigError('Must specify a feature_key of type string.')
+        if (
+            not self.project_layer_lr
+            or not isinstance(self.project_layer_lr, float)
+            or self.project_layer_lr <= 0
+        ):
+            raise ConfigError(f'Invalid project layer learning rate: {self.project_layer_lr}.')
+
+    def validate_context(self):
+        """Validate if the local running context is ready.
+
+        For example: check if train and test dataset could be loaded successfully.
+        """
+        if self.feature_model is None:
+            raise ConfigError('Failed to initialize a feature model.')
+        if not isinstance(self.feature_model, nn.Module):
+            err_msg = 'Support feature model of type torch.Module only.'
+            err_msg += f'Got a {type(self.feature_model)} object.'
+            raise ConfigError(err_msg)
+        if self.feature_optimizer is None:
+            raise ConfigError('Failed to initialize a feature optimizer.')
+        if not isinstance(self.feature_optimizer, optim.Optimizer):
+            err_msg = 'Support feature optimizer of type torch.optim.Optimizer only.'
+            err_msg += f'Got a {type(self.feature_optimizer)} object.'
+            raise ConfigError(err_msg)
+
+    @abstractmethod
+    def iterate_train_feature(self,
+                              feature_model: nn.Module,
+                              train_ids: Set[str]) -> torch.Tensor:
+        """Iterate over train dataset and features a batch of data each time.
+
+        :args
+            :feature_model
+                The feature model object to train & test.
+            :train_ids
+                The ID set of train dataset.
+        """
+
+    @abstractmethod
+    def iterate_test_feature(self,
+                             feature_model: nn.Module,
+                             test_ids: Set[str]) -> torch.Tensor:
+        """Iterate over test dataset and features a batch of data each time.
+
+        :args
+            :feature_model
+                The feature model object to train & test.
+            :train_ids
+                The ID set of test dataset.
+        """
+
+    def _setup_context(self, id: str, task_id: str, is_initiator: bool = False):
+        super()._setup_context(id=id, task_id=task_id, is_initiator=is_initiator)
+
+        self._he_context = ts.context(ts.SCHEME_TYPE.CKKS,
+                                      poly_modulus_degree=2**12,
+                                      coeff_mod_bit_sizes=[21, 20, 20, 21])
+        self._he_context.global_scale = 2**20
+        self._he_context_serialize = self._he_context.serialize()
+        self._epsilon_acc = random.gauss(0, 0.1)
+
+        self._runtime_dir = get_runtime_dir(self.task_id)
+        self._context_file = os.path.join(self._runtime_dir, ".context.json")
+        self._checkpoint_dir = os.path.join(self._runtime_dir, 'checkpoint')
+        self._feature_ckpt_file = os.path.join(self._checkpoint_dir, "feature_model_ckp.pt")
+
+        self.push_log(message='Begin to validate local context.')
+        self.validate_context()
+
+    def _recover_progress(self):
+        if not os.path.isfile(self._context_file):
+            raise TaskFailed('Failed to recover progress: missing cached context.')
+
+        with open(self._context_file, 'r') as f:
+            context_info = json.load(f)
+        feature_ckpt_file = context_info.get('feature_ckpt_file')
+        assert (
+            feature_ckpt_file and isinstance(feature_ckpt_file, str)
+        ), f'Invalid feature_ckpt_file: {feature_ckpt_file} .'
+        if not os.path.isfile(feature_ckpt_file):
+            raise TaskFailed('Failed to recover progress: missing checkpoint parameters.')
+
+        self.current_round = round
+        with open(feature_ckpt_file, 'rb') as f:
+            state_dict = torch.load(f)
+            self.feature_model.load_state_dict(state_dict)
+
+    def _clean_progress(self):
+        """Clean existing progress data."""
+        shutil.rmtree(self._runtime_dir, ignore_errors=True)
+        shutil.rmtree(self._result_dir, ignore_errors=True)
+        os.makedirs(self._runtime_dir, exist_ok=True)
+        os.makedirs(self._checkpoint_dir, exist_ok=True)
+        os.makedirs(self._result_dir, exist_ok=True)
+
+    def _launch_process(self):
+        try:
+            assert self.status == self._INIT, 'must begin from initial status'
+            self.push_log(f'Node {self.id} is up.')
+
+            self._switch_status(self._GETHORING)
+            self._check_in()
+
+            self._switch_status(self._READY)
+            while self.status == self._READY:
+                try:
+                    self._switch_status(self._SYNCHRONIZING)
+                    self._sync_state()
+
+                    if not self._id_intersection:
+                        self._switch_status(self._ID_INTERSECTION)
+                        self._make_id_intersection()
+
+                    self._switch_status(self._IN_A_ROUND)
+                    self._run_a_round()
+                    self._switch_status(self._READY)
+                    delattr(self, '_train_ids')
+                    delattr(self, '_test_ids')
+                except ResetRound:
+                    self.push_log('WARNING: Reset runtime context, there might be an error raised.')
+                    self._switch_status(self._READY)
+                    self._id_intersection = None
+                    delattr(self, '_train_ids')
+                    delattr(self, '_test_ids')
+                    continue
+
+        except TaskComplete:
+            logger.info('Task complete')
+            self._close_task(is_succ=True)
+
+        except TaskFailed as err:
+            logger.exception(err)
+            self._close_task(is_succ=False)
+
+    def _check_in(self):
+        """Check in task."""
+        is_checked_in = False
+        # the host may be in special state so can not response
+        # correctly nor in time, then retry periodically
+        self.push_log('Checking in the task ...')
+        while not is_checked_in:
+            nonce = self.contractor.checkin(peer_id=self.id)
+            logger.debug('_wait_for_check_in_response ...')
+            for _event in self.contractor.contract_events(timeout=self.schedule_timeout):
+                if isinstance(_event, CheckinResponseEvent):
+                    if _event.nonce != nonce:
+                        continue
+                    self.current_round = _event.round
+                    self.host = _event.host
+                    is_checked_in = True
+                    break
+
+                elif isinstance(_event, FailTaskEvent):
+                    raise TaskFailed('Aborted by host.')
+
+        self.push_log(f'Node {self.id} have taken part in the task.')
+
+    def _sync_state(self):
+        """Synchronize state before each round, so it's easier to manage the process.
+
+        As a partner, synchronizes state and gives a response.
+        """
+        self.push_log('Waiting for synchronizing state with the host ...')
+        for _event in self.contractor.contract_events():
+            if isinstance(_event, SyncStateEvent):
+                self.current_round = _event.round
+                self.contractor.respond_sync_state(round=self.current_round,
+                                                   peer_id=self.id,
+                                                   host=_event.host)
+                self.push_log('Successfully synchronized state with the host.')
+                return
+            elif isinstance(_event, FailTaskEvent):
+                raise TaskFailed('Aborted by host.')
+            elif isinstance(_event, CompleteTaskEvent):
+                raise TaskComplete()
+            elif isinstance(_event, ResetRoundEvent):
+                raise ResetRound()
+
+        self.push_log(f'Successfully synchronized state in round {self.current_round}')
+
+    def _make_id_intersection(self) -> List[str]:
+        """Make PSI and get id intersection for training."""
+        local_ids = self.load_local_ids()
+        psi_scheduler = RSAPSICollaboratorScheduler(
+            task_id=self.task_id,
+            collaborator_id=self.id,
+            ids=local_ids,
+            contractor=self.contractor
+        )
+        self._id_intersection = psi_scheduler.collaborate_intersection()
+
+    def _run_a_round(self):
+        self._wait_for_starting_round()
+        self.feature_model.train()
+        for _batch_features in self.iterate_train_feature(self.feature_model, self.train_ids):
+            self.push_log('Featured a batch of data.')
+            self._switch_status(self._PROJECTING)
+            self._local_features = _batch_features
+            self._send_feature_cipher()
+            self._switch_status(self._WAITING_FOR_CIPHER_PROJECTION)
+            self._wait_for_cipher_projection()
+            self._switch_status(self._SENDING_NOISED_PROJECTION)
+            self._send_noised_projection()
+
+            self._switch_status(self._WAITING_FOR_W_GRAD)
+            self._wait_for_w_grad()
+            self._switch_status(self._SENDING_NOISED_W_GRAD)
+            self._send_noised_w_grad()
+            self._switch_status(self._WAITING_FOR_FEATUE_GRAD)
+            self._wait_for_feature_grad()
+            self._switch_status(self._UPDATING)
+            if self._feature_grad is not None:
+                self.feature_optimizer.zero_grad()
+                self._local_features.backward(self._feature_grad)
+                self.feature_optimizer.step()
+
+        self._switch_status(self._PERSISTING)
+        self._save_model()
+        self._save_runtime_context()
+
+        self._switch_status(self._TESTING)
+        self._wait_for_testing_round()
+
+        self._switch_status(self._CLOSING_ROUND)
+        self._wait_for_closing_round()
+
+        self.push_log(f'ID: {self.id} finished training task of round {self.current_round}.')
+
+    def _wait_for_starting_round(self):
+        """Wait for starting a new round of training ..."""
+        self.push_log(f'Waiting for training of round {self.current_round} begin ...')
+        for _event in self.contractor.contract_events():
+            if isinstance(_event, StartRoundEvent):
+                assert (
+                    _event.round == self.current_round
+                ), f'Lost synchronization, host: {_event.round}; local: {self.current_round}.'
+                self.push_log(f'Training of round {self.current_round} begins.')
+                return
+            elif isinstance(_event, FailTaskEvent):
+                raise TaskFailed('Aborted by host.')
+            elif isinstance(_event, ResetRoundEvent):
+                raise ResetRound()
+
+    def _send_feature_cipher(self):
+        """Send local features of a batch of data to the host."""
+        self.push_log('Waiting for sending features ...')
+        for _event in self.contractor.contract_events():
+            if isinstance(_event, ReadyForFusionEvent):
+                assert (
+                    _event.round == self.current_round
+                ), f'Lost synchronization, host: {_event.round}; local: {self.current_round}.'
+                break
+            elif isinstance(_event, FailTaskEvent):
+                raise TaskFailed('Aborted by host.')
+            elif isinstance(_event, ResetRoundEvent):
+                raise ResetRound()
+
+        self.push_log('Begin to send features.')
+        cipher_tensor = ts.ckks_tensor(self._he_context, self._local_features.detach())
+        cipher_feature = _CKKSTensorWrapper(feature_key=self.feature_key,
+                                            cipher=cipher_tensor.serialize(),
+                                            context=self._he_context_serialize)
+        self.data_channel.send_stream(source=self.id,
+                                      target=self.host,
+                                      data_stream=cipher_feature.to_bytes())
+        self.push_log('Sending features complete.')
+
+    def _abnormal_handler(self, event: ContractEvent):
+        if isinstance(event, FailTaskEvent):
+            raise TaskFailed('Aborted by host.')
+        elif isinstance(event, ResetRoundEvent):
+            raise ResetRound()
+
+    def _wait_for_cipher_projection(self):
+        """Wait for receiving cipher projection of the self owned features."""
+        self.push_log('Waiting for receiving cipher projection ...')
+        _, stream = self.data_channel.receive_stream(
+            receiver=self.id,
+            complementary_handler=self._abnormal_handler,
+            source=self.host
+        )
+        cipher_projection = _CKKSTensorWrapper.from_bytes(stream)
+        cipher_tensor = ts.ckks_tensor_from(context=self._he_context,
+                                            data=cipher_projection.cipher)
+        projection = cipher_tensor.decrypt()
+        self._proj_tensor = torch.tensor(projection.tolist())
+        self._proj_tensor.add_(self._local_features * self._epsilon_acc)
+        self.push_log('Received cipher projection.')
+
+    def _send_noised_projection(self):
+        """Send noised projection to the host for fusion."""
+        self.push_log('Waiting for sending noised projection ...')
+        for _event in self.contractor.contract_events():
+            if isinstance(_event, ReadyForNoisedProjectionEvent):
+                with TemporaryFile() as tf:
+                    torch.save({self.feature_key: self._proj_tensor}, tf)
+                    tf.seek(0)
+                    self.data_channel.send_stream(source=self.id,
+                                                  target=self.host,
+                                                  data_stream=tf.read())
+                return
+            elif isinstance(_event, FailTaskEvent):
+                raise TaskFailed('Aborted by host.')
+            elif isinstance(_event, ResetRoundEvent):
+                raise ResetRound()
+
+    def _wait_for_w_grad(self):
+        """Wait for cipher grad of project layer W to decrypt."""
+        self.push_log('Waiting for cipher grad of project layer W ...')
+        _, stream = self.data_channel.receive_stream(
+            receiver=self.id,
+            complementary_handler=self._abnormal_handler,
+            source=self.host
+        )
+        cipher_grad = ts.ckks_tensor_from(self._he_context, stream)
+        # sample from (-0.005, 0.015) to decrease the overrall speed of
+        # accumulation, thus facilitate convergence
+        epsilon_collab = random.uniform(-0.005, 0.015)
+        self._noised_w_grad = torch.tensor(cipher_grad.decrypt().tolist())
+        self._noised_w_grad.add_(epsilon_collab / self.project_layer_lr)
+        self._epsilon_acc += epsilon_collab
+        self.push_log('Received and decrypted cipher grad of project layer W.')
+
+    def _send_noised_w_grad(self):
+        """Send decrypted grad of project layer W to the host."""
+        self.push_log('Sending noised grad of project layer W to host ...')
+        for _event in self.contractor.contract_events():
+            cipher_acc = ts.ckks_tensor(self._he_context, [self._epsilon_acc])
+            if isinstance(_event, ReadyForNoisedWGradEvent):
+                noised_w_grad = _NoisedWGradWrapper(feature_key=self.feature_key,
+                                                    noised_grad=self._noised_w_grad,
+                                                    cipher_epsilon_acc=cipher_acc.serialize(),
+                                                    context=self._he_context_serialize)
+                self.data_channel.send_stream(source=self.id,
+                                              target=self.host,
+                                              data_stream=noised_w_grad.to_bytes())
+                break
+            elif isinstance(_event, ResetRoundEvent):
+                raise ResetRound()
+        self.push_log('Sent noised grad of project layer W to host.')
+
+    def _wait_for_feature_grad(self):
+        """Wait for cipher grad of feature model output."""
+        self.push_log('Waiting for cipher grad of feature model output ...')
+        _, stream = self.data_channel.receive_stream(
+            receiver=self.id,
+            complementary_handler=self._abnormal_handler,
+            source=self.host
+        )
+        # TODO make clear the cause of 'ValueError: result ciphertext is transparent'
+        if stream == b'ValueError: result ciphertext is transparent':
+            self._feature_grad = None
+            logger.warn(f'noised_w_grad={self._noised_w_grad.tolist()}')
+            logger.warn(f'epsilon_acc={self._epsilon_acc}')
+            logger.warn(f'context={self._he_context.serialize(save_secret_key=True)}')
+        else:
+            cipher_grad = ts.ckks_tensor_from(self._he_context, stream)
+            self._feature_grad = torch.tensor(cipher_grad.decrypt().tolist())
+        self.push_log('Received and decrypted cipher grad of feature model output.')
+
+    def _save_model(self):
+        """Save latest model state."""
+        with open(self._feature_ckpt_file, 'wb') as f:
+            torch.save(self.feature_model.state_dict(), f)
+        self.push_log('Saved latest parameters locally.')
+
+    def _save_runtime_context(self):
+        """Save runtime context information in case of restoring."""
+        context_info = {
+            'feature_ckpt_file': self._feature_ckpt_file
+        }
+        with open(self._context_file, 'w') as f:
+            f.write(json.dumps(context_info, ensure_ascii=False))
+        self.push_log('Saved latest runtime context.')
+
+    def _wait_for_testing_round(self):
+        """Wait for handle a round of testing."""
+        self.push_log('Waiting for start a round of testing ...')
+        for _event in self.contractor.contract_events():
+            if isinstance(_event, StartTestRoundEvent):
+                assert (
+                    _event.round == self.current_round
+                ), f'Lost synchronization, host: {_event.round}; local: {self.current_round}.'
+
+                self.feature_model.eval()
+                for _batch_features in self.iterate_test_feature(self.feature_model,
+                                                                 self.test_ids):
+                    self._switch_status(self._PROJECTING)
+                    self._local_features = _batch_features
+                    self._send_feature_cipher()
+                    self._switch_status(self._WAITING_FOR_CIPHER_PROJECTION)
+                    self._wait_for_cipher_projection()
+                    self._switch_status(self._SENDING_NOISED_PROJECTION)
+                    self._send_noised_projection()
+                    self.push_log('Fused a batch of test data features.')
+
+            elif isinstance(_event, CloseTestRoundEvent):
+                self.push_log('Skipped or closed a round of testing.')
+                return
+            elif isinstance(_event, FailTaskEvent):
+                raise TaskFailed('Aborted by host.')
+            elif isinstance(_event, ResetRoundEvent):
+                raise ResetRound()
+
+    def _wait_for_closing_round(self):
+        """Wait for closing current round of training."""
+        self.push_log(f'Waiting for closing signal of training round {self.current_round} ...')
+        for _event in self.contractor.contract_events():
+            if isinstance(_event, CloseRoundEvent):
+                if _event.round != self.current_round:
+                    continue
+                return
+            elif isinstance(_event, CompleteTaskEvent):
+                raise TaskComplete()
+            elif isinstance(_event, ResetRoundEvent):
+                raise ResetRound()
+
+    def _close_task(self, is_succ: bool = True):
+        """Close the task and upload the final parameters."""
+        self.push_log(f'Closing task {self.task_id} ...')
+
+        self._switch_status(self._FINISHING)
+        if is_succ:
+            model_file_path = self._prepare_task_output()
+            self.contractor.upload_metric_report(receivers=self.contractor.EVERYONE)
+            self.contractor.upload_model(receivers=[self.id],
+                                         model_file=model_file_path)
+            self.contractor.notify_collaborator_complete(peer_id=self.id, host=self.host)
+            self.push_log(f'Task {self.task_id} complete. Byebye!')
+        else:
+            self.push_log(f'Task {self.task_id} failed. Byebye!')
+
+    def _prepare_task_output(self) -> Tuple[str, str]:
+        """Generate final output files of the task.
+
+        :return
+            Local paths of the model file.
+        """
+        self.push_log('Generating task achievement files ...')
+
+        # torch.jit doesn't work with a TemporaryFile
+        feature_model_file = os.path.join(self._result_dir,
+                                          f'feature_model_{self.feature_key}.pt')
+        with open(feature_model_file, 'wb') as f:
+            torch.save(self.feature_model.state_dict(), f)
+        model_file_path = os.path.abspath(feature_model_file)
+
+        self.push_log('Task achievement files are ready.')
+        return model_file_path
```

### Comparing `alphamed-federated-0.4.7/src/alphafed/loggers.py` & `alphamed-federated-0.4.9/src/alphafed/loggers.py`

 * *Ordering differences only*

 * *Files 10% similar despite different names*

```diff
@@ -1,23 +1,23 @@
-import logging
-
-
-__all__ = ['logger', 'task_logger']
-
-if 'alphafed' in logging.Logger.manager.loggerDict.keys():
-    logger = logging.getLogger('alphafed')
-
-else:
-    format = '%(asctime)s|%(levelname)s|%(module)s|%(funcName)s|%(lineno)d:\n%(message)s'
-    logging.basicConfig(level=logging.DEBUG,
-                        filename='alphafed.log',
-                        filemode='w',
-                        format=format)
-    logger = logging.getLogger(__name__)
-    console_handler = logging.StreamHandler()
-    console_handler.setFormatter(logging.Formatter(format))
-    logger.addHandler(console_handler)
-
-if 'task' in logging.Logger.manager.loggerDict.keys():
-    task_logger = logging.getLogger('task')
-else:
-    task_logger = logger
+import logging
+
+
+__all__ = ['logger', 'task_logger']
+
+if 'alphafed' in logging.Logger.manager.loggerDict.keys():
+    logger = logging.getLogger('alphafed')
+
+else:
+    format = '%(asctime)s|%(levelname)s|%(module)s|%(funcName)s|%(lineno)d:\n%(message)s'
+    logging.basicConfig(level=logging.DEBUG,
+                        filename='alphafed.log',
+                        filemode='w',
+                        format=format)
+    logger = logging.getLogger(__name__)
+    console_handler = logging.StreamHandler()
+    console_handler.setFormatter(logging.Formatter(format))
+    logger.addHandler(console_handler)
+
+if 'task' in logging.Logger.manager.loggerDict.keys():
+    task_logger = logging.getLogger('task')
+else:
+    task_logger = logger
```

### Comparing `alphamed-federated-0.4.7/src/alphafed/mock.py` & `alphamed-federated-0.4.9/src/alphafed/mock.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,200 +1,202 @@
-from functools import wraps
-import sqlite3
-from hashlib import sha1
-import threading
-from typing import Callable, List, Optional
-from uuid import uuid4
-
-from .loggers import logger
-
-__all__ = ['mock_context', 'is_mock_mode', 'mock_node_id', 'mock_nodes']
-
-
-_VERSION = 'v1'
-_MOCK_DB = f'.mock_{_VERSION}.db'
-_mock_conn: sqlite3.Connection = None
-_mock_cur: sqlite3.Cursor = None
-
-_lock = threading.Lock()
-
-
-def _init_mock_db():
-    _mock_cur.execute(
-        '''
-        CREATE TABLE IF NOT EXISTS contracts (
-            contract_id    INTEGER   PRIMARY KEY  AUTOINCREMENT,
-            target         CHAR(50)  NOT NULL,
-            message_title  CHAR(50)  NOT NULL,
-            content        TEXT      NOT NULL,
-            message_time   INT       NOT NULL,
-            channel        CHAR(20)  NOT NULL,
-            task_id        CHAR(50)  NOT NULL
-        )
-        '''
-    )
-    _mock_cur.execute('CREATE INDEX IF NOT EXISTS contract_task_id ON contracts (task_id);')
-    _mock_cur.execute(
-        '''
-        CREATE TABLE IF NOT EXISTS contract_consume_cursors (
-            cursor_id    INT       PRIMARY KEY,
-            node_id      CHAR(50)  NOT NULL,
-            cursor       INT       NOT NULL
-        )
-        '''
-    )
-    _mock_cur.execute('CREATE INDEX IF NOT EXISTS cursor_node_id ON contract_consume_cursors (node_id);')
-    _mock_cur.connection.commit()
-
-
-class mock_context:
-
-    __mock_mode = False
-    __nodes = []
-    __node_id = None
-
-    def __init__(self,
-                 clean: bool = False,
-                 id: str = None,
-                 nodes: List[str] = None) -> None:
-        """Set running context into mock mode.
-
-        Args:
-            clean:
-                Whether to clean all historical data, and begin from a very clean.
-            id:
-                A unique ID of the node this process mocks. If not specified, a random
-                one will be assigned each time.
-            nodes:
-                The ID list of ALL node which take part in this mock task. If specified,
-                query_nodes returns this list, otherwise it returns an empty list.
-                It's all right to use all FAKE ID values but they must not be duplicate.
-        """
-        assert isinstance(clean, bool), f'clean must be a bool value instead of `{clean}`.'
-        assert id is None or isinstance(id, str), f'id must be a str value instead of `{id}`.'
-        assert (
-            nodes is None or (isinstance(nodes, list)
-                              and all(isinstance(_node, str) for _node in nodes))
-        ), f'nodes must be a str list instead of `{nodes}`.'
-
-        self.clean = clean
-        self.id = id or str(uuid4())
-        self.nodes = nodes
-
-    def __enter__(self):
-        mock_context._mock_context__mock_mode = True
-        if self.nodes:
-            mock_context._mock_context__nodes = self.nodes
-        else:
-            logger.warn('Without specifying nodes, query_nodes returns an empty list.')
-        mock_context._mock_context__node_id = self.id
-
-        global _mock_conn
-        global _mock_cur
-        _mock_conn = sqlite3.connect(_MOCK_DB, check_same_thread=False)
-        _mock_conn.row_factory = sqlite3.Row
-        _mock_cur = _mock_conn.cursor()
-        _init_mock_db()
-
-        if self.clean:
-            _mock_cur.execute('DELETE FROM contract_consume_cursors WHERE 1=1')
-            _mock_cur.execute('DELETE FROM contracts WHERE 1=1')
-            _mock_cur.connection.commit()
-        self._init_contract_cursor(node_id=self.id)
-
-    def _init_contract_cursor(self, node_id: str):
-        is_exist = _mock_cur.execute(
-            'SELECT 1 FROM contract_consume_cursors WHERE node_id=?',
-            (node_id,)
-        ).fetchone()
-        if is_exist is None:
-            _mock_cur.execute(
-                '''
-                INSERT INTO contract_consume_cursors (node_id, cursor)
-                VALUES (?, ?)
-                ''',
-                (node_id, 0)
-            )
-            _mock_cur.connection.commit()
-
-    def __exit__(self, *exc):
-        mock_context._mock_context__mock_mode = False
-        mock_context._mock_context__nodes = []
-        mock_context._mock_context__node_id = None
-
-        global _mock_conn
-        global _mock_cur
-        _mock_conn = None
-        _mock_cur = None
-
-
-def is_mock_mode():
-    return mock_context._mock_context__mock_mode
-
-
-def mock_nodes():
-    return mock_context._mock_context__nodes
-
-
-def mock_node_id():
-    return mock_context._mock_context__node_id
-
-
-def _lock_thread(func: Callable):
-    @wraps(func)
-    def wrapper(*args, **kwargs):
-        try:
-            _lock.acquire(True)
-            return func(*args, **kwargs)
-        finally:
-            _lock.release()
-    return wrapper
-
-
-@_lock_thread
-def _put_mock_contract(targets: List[str],
-                       message_title: str,
-                       content: str,
-                       message_time: int,
-                       channel: str,
-                       task_id: str) -> str:
-    _mock_cur.executemany(
-        '''
-        INSERT INTO contracts (target, message_title, content, message_time, channel, task_id)
-        VALUES (?, ?, ?, ?, ?, ?)
-        ''',
-        [(_target, message_title, content, message_time, channel, task_id) for _target in targets]
-    )
-    _mock_cur.connection.commit()
-    max_id = _mock_cur.execute(
-        'SELECT MAX(contract_id) FROM contracts'
-    ).fetchone()['MAX(contract_id)']
-    return sha1(str(max_id).encode()).hexdigest()
-
-
-@_lock_thread
-def _get_mock_contract(node_id: str, channel: str, task_id: str) -> Optional[str]:
-    cursor = _mock_cur.execute(
-        'SELECT cursor FROM contract_consume_cursors WHERE node_id=?', (node_id,)
-    ).fetchone()['cursor']
-    contract = _mock_cur.execute(
-        '''
-        SELECT contract_id, content
-        FROM contracts
-        WHERE contract_id>:cursor
-        AND task_id=:task_id
-        AND target=:node_id
-        AND channel=:channel
-        ORDER BY contract_id
-        ''',
-        {'cursor': cursor, 'node_id': node_id, 'channel': channel, 'task_id': task_id}
-    ).fetchone()
-    if contract is None:
-        return None
-
-    new_cursor = contract['contract_id']
-    _mock_cur.execute(
-        'UPDATE contract_consume_cursors SET cursor=:new_cursor WHERE node_id=:node_id',
-        {'new_cursor': new_cursor, 'node_id': node_id}
-    )
-    _mock_cur.connection.commit()
-    return contract['content']
+import fcntl
+from functools import wraps
+import sqlite3
+from hashlib import sha1
+from typing import Callable, List, Optional
+from uuid import uuid4
+
+from .loggers import logger
+
+__all__ = ['mock_context', 'is_mock_mode', 'mock_node_id', 'mock_nodes']
+
+
+_VERSION = 'v1'
+_MOCK_DB = f'.mock_{_VERSION}.db'
+_FILE_LOCK = '.alphamed.lock'
+_mock_conn: sqlite3.Connection = None
+_mock_cur: sqlite3.Cursor = None
+
+
+def _lock_execute(func: Callable):
+    @wraps(func)
+    def wrapper(*args, **kwargs):
+        with open(_FILE_LOCK, 'w') as fl:
+            try:
+                fcntl.flock(fl, fcntl.LOCK_EX)
+                return func(*args, **kwargs)
+            finally:
+                fcntl.flock(fl, fcntl.LOCK_UN)
+    return wrapper
+
+
+@_lock_execute
+def _init_mock_db():
+    _mock_cur.execute(
+        '''
+        CREATE TABLE IF NOT EXISTS contracts (
+            contract_id    INTEGER   PRIMARY KEY  AUTOINCREMENT,
+            target         CHAR(50)  NOT NULL,
+            message_title  CHAR(50)  NOT NULL,
+            content        TEXT      NOT NULL,
+            message_time   INT       NOT NULL,
+            channel        CHAR(20)  NOT NULL,
+            task_id        CHAR(50)  NOT NULL
+        )
+        '''
+    )
+    _mock_cur.execute('CREATE INDEX IF NOT EXISTS contract_task_id ON contracts (task_id);')
+    _mock_cur.execute(
+        '''
+        CREATE TABLE IF NOT EXISTS contract_consume_cursors (
+            cursor_id    INT       PRIMARY KEY,
+            node_id      CHAR(50)  NOT NULL,
+            cursor       INT       NOT NULL
+        )
+        '''
+    )
+    _mock_cur.execute('CREATE INDEX IF NOT EXISTS cursor_node_id ON contract_consume_cursors (node_id);')
+    _mock_cur.connection.commit()
+
+
+class mock_context:
+
+    __mock_mode = False
+    __nodes = []
+    __node_id = None
+
+    def __init__(self,
+                 clean: bool = False,
+                 id: str = None,
+                 nodes: List[str] = None) -> None:
+        """Set running context into mock mode.
+
+        Args:
+            clean:
+                Whether to clean all historical data, and begin from a very clean.
+            id:
+                A unique ID of the node this process mocks. If not specified, a random
+                one will be assigned each time.
+            nodes:
+                The ID list of ALL node which take part in this mock task. If specified,
+                query_nodes returns this list, otherwise it returns an empty list.
+                It's all right to use all FAKE ID values but they must not be duplicate.
+        """
+        assert isinstance(clean, bool), f'clean must be a bool value instead of `{clean}`.'
+        assert id is None or isinstance(id, str), f'id must be a str value instead of `{id}`.'
+        assert (
+            nodes is None or (isinstance(nodes, list)
+                              and all(isinstance(_node, str) for _node in nodes))
+        ), f'nodes must be a str list instead of `{nodes}`.'
+
+        self.clean = clean
+        self.id = id or str(uuid4())
+        self.nodes = nodes
+
+    def __enter__(self):
+        mock_context._mock_context__mock_mode = True
+        if self.nodes:
+            mock_context._mock_context__nodes = self.nodes
+        else:
+            logger.warn('Without specifying nodes, query_nodes returns an empty list.')
+        mock_context._mock_context__node_id = self.id
+
+        global _mock_conn
+        global _mock_cur
+        _mock_conn = sqlite3.connect(_MOCK_DB, check_same_thread=False)
+        _mock_conn.row_factory = sqlite3.Row
+        _mock_cur = _mock_conn.cursor()
+        _init_mock_db()
+
+        if self.clean:
+            _mock_cur.execute('DELETE FROM contract_consume_cursors WHERE 1=1')
+            _mock_cur.execute('DELETE FROM contracts WHERE 1=1')
+            _mock_cur.connection.commit()
+        self._init_contract_cursor(node_id=self.id)
+
+    @_lock_execute
+    def _init_contract_cursor(self, node_id: str):
+        is_exist = _mock_cur.execute(
+            'SELECT 1 FROM contract_consume_cursors WHERE node_id=?',
+            (node_id,)
+        ).fetchone()
+        if is_exist is None:
+            _mock_cur.execute(
+                '''
+                INSERT INTO contract_consume_cursors (node_id, cursor)
+                VALUES (?, ?)
+                ''',
+                (node_id, 0)
+            )
+            _mock_cur.connection.commit()
+
+    def __exit__(self, *exc):
+        mock_context._mock_context__mock_mode = False
+        mock_context._mock_context__nodes = []
+        mock_context._mock_context__node_id = None
+
+        global _mock_conn
+        global _mock_cur
+        _mock_conn = None
+        _mock_cur = None
+
+
+def is_mock_mode():
+    return mock_context._mock_context__mock_mode
+
+
+def mock_nodes():
+    return mock_context._mock_context__nodes
+
+
+def mock_node_id():
+    return mock_context._mock_context__node_id
+
+
+@_lock_execute
+def _put_mock_contract(targets: List[str],
+                       message_title: str,
+                       content: str,
+                       message_time: int,
+                       channel: str,
+                       task_id: str) -> str:
+    _mock_cur.executemany(
+        '''
+        INSERT INTO contracts (target, message_title, content, message_time, channel, task_id)
+        VALUES (?, ?, ?, ?, ?, ?)
+        ''',
+        [(_target, message_title, content, message_time, channel, task_id) for _target in targets]
+    )
+    _mock_cur.connection.commit()
+    max_id = _mock_cur.execute(
+        'SELECT MAX(contract_id) FROM contracts'
+    ).fetchone()['MAX(contract_id)']
+    return sha1(str(max_id).encode()).hexdigest()
+
+
+@_lock_execute
+def _get_mock_contract(node_id: str, channel: str, task_id: str) -> Optional[str]:
+    cursor = _mock_cur.execute(
+        'SELECT cursor FROM contract_consume_cursors WHERE node_id=?', (node_id,)
+    ).fetchone()['cursor']
+    contract = _mock_cur.execute(
+        '''
+        SELECT contract_id, content
+        FROM contracts
+        WHERE contract_id>:cursor
+        AND task_id=:task_id
+        AND target=:node_id
+        AND channel=:channel
+        ORDER BY contract_id
+        ''',
+        {'cursor': cursor, 'node_id': node_id, 'channel': channel, 'task_id': task_id}
+    ).fetchone()
+    if contract is None:
+        return None
+
+    new_cursor = contract['contract_id']
+    _mock_cur.execute(
+        'UPDATE contract_consume_cursors SET cursor=:new_cursor WHERE node_id=:node_id',
+        {'new_cursor': new_cursor, 'node_id': node_id}
+    )
+    _mock_cur.connection.commit()
+    return contract['content']
```

### Comparing `alphamed-federated-0.4.7/src/alphafed/perf_bench.py` & `alphamed-federated-0.4.9/src/alphafed/perf_bench.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/scheduler.py` & `alphamed-federated-0.4.9/src/alphafed/scheduler.py`

 * *Ordering differences only*

 * *Files 16% similar despite different names*

```diff
@@ -1,166 +1,166 @@
-"""Algorithm scheduler."""
-
-import inspect
-import os
-import sys
-from abc import ABC, abstractmethod
-from typing import Set, Tuple
-from zipfile import ZipFile
-
-import cloudpickle as pickle
-
-from . import is_mock_mode, logger, task_logger
-from .contractor import TaskContractor
-
-
-class ConfigError(Exception):
-    ...
-
-
-class TaskFailed(Exception):
-    ...
-
-
-class TaskComplete(Exception):
-    ...
-
-
-class DataChecker(ABC):
-    """To verify local data state."""
-
-    @abstractmethod
-    def verify_data(self) -> Tuple[bool, str]:
-        """Verify if local data is ready or not.
-
-        Return:
-            Tuple[verification result, explanation of the cause of the failure]
-        """
-
-    def submit(self, task_id: str):
-        """Submit the data checker of the task to the task manager.
-
-        `Only for platform developers`:
-        This method is running in `notebook` context, so it cannot access the common
-        local directory shared by federated-service. Thus it have to upload files in a stream.
-        """
-        assert task_id and isinstance(task_id, str), 'Must specify task ID.'
-
-        save_dir = os.path.join('/tmp', task_id)
-        os.makedirs(save_dir, exist_ok=True)
-        pickle_file = os.path.join(save_dir, 'entry.pickle')
-        with open(pickle_file, 'wb') as f:
-            pickle.dump(self, f)
-
-        current_dir = os.path.abspath('.')
-        dependencies: Set[str] = set()
-        # sys.modules could change in the iteration.
-        for _module in dict(sys.modules).values():
-            try:
-                _module_file = inspect.getabsfile(_module)
-                if _module_file.startswith(current_dir):
-                    dependencies.add(_module_file)
-            except (TypeError, ModuleNotFoundError):
-                pass
-
-        zip_file = os.path.join(save_dir, 'src.zip')
-        offset = len(current_dir)
-        with ZipFile(zip_file, 'w') as src_zip:
-            # include pickle of code in notebook cell
-            src_zip.write(pickle_file, os.path.basename(pickle_file))
-            # include dependent python files under same directory
-            for _file in dependencies:
-                src_zip.write(_file, _file[offset:])
-            # include requirements.txt if exists
-            requirements_file = os.path.join(current_dir, 'requirements.txt')
-            if os.path.exists(requirements_file):
-                src_zip.write(requirements_file, os.path.basename(requirements_file))
-
-        with open(zip_file, 'rb') as src_zip:
-            task_contractor = TaskContractor(task_id=task_id)
-            file_url = task_contractor.upload_file(upload_name='src.zip',
-                                                   fp=src_zip,
-                                                   persistent=True)
-        task_contractor._submit_data_checker(resource_url=file_url,
-                                             entry_type=TaskContractor._ENTRY_PICKLE)
-        logger.info('Submit the data checker complete.')
-
-
-class Scheduler(ABC):
-
-    def submit(self, task_id: str):
-        """Submit the task scheduler to the task manager.
-
-        `Only for platform developers`:
-        This method is running in `notebook` context, so it cannot access the common
-        local directory shared by federated-service. Thus it have to upload files in a stream.
-        """
-        assert task_id and isinstance(task_id, str), f'invalid task ID: {task_id}'
-
-        save_dir = os.path.join('/tmp', task_id)
-        os.makedirs(save_dir, exist_ok=True)
-        pickle_file = os.path.join(save_dir, 'entry.pickle')
-        with open(pickle_file, 'wb') as f:
-            pickle.dump(self, f)
-
-        current_dir = os.path.abspath('.')
-        dependencies: Set[str] = set()
-        # sys.modules could change in the iteration.
-        for _module in dict(sys.modules).values():
-            try:
-                _module_file = inspect.getabsfile(_module)
-                if _module_file.startswith(current_dir):
-                    dependencies.add(_module_file)
-            except (TypeError, ModuleNotFoundError):
-                pass
-
-        zip_file = os.path.join(save_dir, 'src.zip')
-        offset = len(current_dir)
-        with ZipFile(zip_file, 'w') as src_zip:
-            # include pickle of code in notebook cell
-            src_zip.write(pickle_file, os.path.basename(pickle_file))
-            # include dependent python files under same directory
-            for _file in dependencies:
-                src_zip.write(_file, _file[offset:])
-            # include requirements.txt if exists
-            requirements_file = os.path.join(current_dir, 'requirements.txt')
-            if os.path.exists(requirements_file):
-                src_zip.write(requirements_file, os.path.basename(requirements_file))
-
-        with open(zip_file, 'rb') as src_zip:
-            task_contractor = TaskContractor(task_id=task_id)
-            file_url = task_contractor.upload_file(upload_name='src.zip',
-                                                   fp=src_zip,
-                                                   persistent=True)
-        task_contractor._submit_scheduler(resource_url=file_url,
-                                          entry_type=TaskContractor._ENTRY_PICKLE)
-        logger.info('Submit the scheduler complete.')
-
-    def push_log(self, message: str):
-        """Push a running log message to the task manager."""
-        assert message and isinstance(message, str), f'invalid log message: {message}'
-        if not is_mock_mode() and hasattr(self, 'task_id') and self.task_id:
-            task_logger.info(message, extra={"task_id": self.task_id})
-        logger.info(message)
-
-    def _switch_status(self, _status: str):
-        """Switch to a new status and leave a log."""
-        self.status = _status
-        logger.debug(f'{self.status=}')
-
-    @abstractmethod
-    def _run(self, id: str, task_id: str, is_initiator: bool = False, recover: bool = False):
-        """Run the scheduler.
-
-        This function is used by the context manager, DO NOT modify it, otherwize
-        there would be strange errors raised.
-
-        Args:
-            id:
-                the node id of the running context
-            task_id:
-                the id of the task to be scheduled
-            is_initiator:
-                is this scheduler the initiator of the task
-            recover:
-                whether to try recovering from last failed running
-        """
+"""Algorithm scheduler."""
+
+import inspect
+import os
+import sys
+from abc import ABC, abstractmethod
+from typing import Set, Tuple
+from zipfile import ZipFile
+
+import cloudpickle as pickle
+
+from . import is_mock_mode, logger, task_logger
+from .contractor import TaskContractor
+
+
+class ConfigError(Exception):
+    ...
+
+
+class TaskFailed(Exception):
+    ...
+
+
+class TaskComplete(Exception):
+    ...
+
+
+class DataChecker(ABC):
+    """To verify local data state."""
+
+    @abstractmethod
+    def verify_data(self) -> Tuple[bool, str]:
+        """Verify if local data is ready or not.
+
+        Return:
+            Tuple[verification result, explanation of the cause of the failure]
+        """
+
+    def submit(self, task_id: str):
+        """Submit the data checker of the task to the task manager.
+
+        `Only for platform developers`:
+        This method is running in `notebook` context, so it cannot access the common
+        local directory shared by federated-service. Thus it have to upload files in a stream.
+        """
+        assert task_id and isinstance(task_id, str), 'Must specify task ID.'
+
+        save_dir = os.path.join('/tmp', task_id)
+        os.makedirs(save_dir, exist_ok=True)
+        pickle_file = os.path.join(save_dir, 'entry.pickle')
+        with open(pickle_file, 'wb') as f:
+            pickle.dump(self, f)
+
+        current_dir = os.path.abspath('.')
+        dependencies: Set[str] = set()
+        # sys.modules could change in the iteration.
+        for _module in dict(sys.modules).values():
+            try:
+                _module_file = inspect.getabsfile(_module)
+                if _module_file.startswith(current_dir):
+                    dependencies.add(_module_file)
+            except (TypeError, ModuleNotFoundError):
+                pass
+
+        zip_file = os.path.join(save_dir, 'src.zip')
+        offset = len(current_dir)
+        with ZipFile(zip_file, 'w') as src_zip:
+            # include pickle of code in notebook cell
+            src_zip.write(pickle_file, os.path.basename(pickle_file))
+            # include dependent python files under same directory
+            for _file in dependencies:
+                src_zip.write(_file, _file[offset:])
+            # include requirements.txt if exists
+            requirements_file = os.path.join(current_dir, 'requirements.txt')
+            if os.path.exists(requirements_file):
+                src_zip.write(requirements_file, os.path.basename(requirements_file))
+
+        with open(zip_file, 'rb') as src_zip:
+            task_contractor = TaskContractor(task_id=task_id)
+            file_url = task_contractor.upload_file(upload_name='src.zip',
+                                                   fp=src_zip,
+                                                   persistent=True)
+        task_contractor._submit_data_checker(resource_url=file_url,
+                                             entry_type=TaskContractor._ENTRY_PICKLE)
+        logger.info('Submit the data checker complete.')
+
+
+class Scheduler(ABC):
+
+    def submit(self, task_id: str):
+        """Submit the task scheduler to the task manager.
+
+        `Only for platform developers`:
+        This method is running in `notebook` context, so it cannot access the common
+        local directory shared by federated-service. Thus it have to upload files in a stream.
+        """
+        assert task_id and isinstance(task_id, str), f'invalid task ID: {task_id}'
+
+        save_dir = os.path.join('/tmp', task_id)
+        os.makedirs(save_dir, exist_ok=True)
+        pickle_file = os.path.join(save_dir, 'entry.pickle')
+        with open(pickle_file, 'wb') as f:
+            pickle.dump(self, f)
+
+        current_dir = os.path.abspath('.')
+        dependencies: Set[str] = set()
+        # sys.modules could change in the iteration.
+        for _module in dict(sys.modules).values():
+            try:
+                _module_file = inspect.getabsfile(_module)
+                if _module_file.startswith(current_dir):
+                    dependencies.add(_module_file)
+            except (TypeError, ModuleNotFoundError):
+                pass
+
+        zip_file = os.path.join(save_dir, 'src.zip')
+        offset = len(current_dir)
+        with ZipFile(zip_file, 'w') as src_zip:
+            # include pickle of code in notebook cell
+            src_zip.write(pickle_file, os.path.basename(pickle_file))
+            # include dependent python files under same directory
+            for _file in dependencies:
+                src_zip.write(_file, _file[offset:])
+            # include requirements.txt if exists
+            requirements_file = os.path.join(current_dir, 'requirements.txt')
+            if os.path.exists(requirements_file):
+                src_zip.write(requirements_file, os.path.basename(requirements_file))
+
+        with open(zip_file, 'rb') as src_zip:
+            task_contractor = TaskContractor(task_id=task_id)
+            file_url = task_contractor.upload_file(upload_name='src.zip',
+                                                   fp=src_zip,
+                                                   persistent=True)
+        task_contractor._submit_scheduler(resource_url=file_url,
+                                          entry_type=TaskContractor._ENTRY_PICKLE)
+        logger.info('Submit the scheduler complete.')
+
+    def push_log(self, message: str):
+        """Push a running log message to the task manager."""
+        assert message and isinstance(message, str), f'invalid log message: {message}'
+        if not is_mock_mode() and hasattr(self, 'task_id') and self.task_id:
+            task_logger.info(message, extra={"task_id": self.task_id})
+        logger.info(message)
+
+    def _switch_status(self, _status: str):
+        """Switch to a new status and leave a log."""
+        self.status = _status
+        logger.debug(f'{self.status=}')
+
+    @abstractmethod
+    def _run(self, id: str, task_id: str, is_initiator: bool = False, recover: bool = False):
+        """Run the scheduler.
+
+        This function is used by the context manager, DO NOT modify it, otherwize
+        there would be strange errors raised.
+
+        Args:
+            id:
+                the node id of the running context
+            task_id:
+                the id of the task to be scheduled
+            is_initiator:
+                is this scheduler the initiator of the task
+            recover:
+                whether to try recovering from last failed running
+        """
```

### Comparing `alphamed-federated-0.4.7/src/alphafed/secure/aes.py` & `alphamed-federated-0.4.9/src/alphafed/secure/aes.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/secure/ecdhe.py` & `alphamed-federated-0.4.9/src/alphafed/secure/ecdhe.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/secure/shamir.py` & `alphamed-federated-0.4.9/src/alphafed/secure/shamir.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/secure/tools.py` & `alphamed-federated-0.4.9/src/alphafed/secure/tools.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphafed/utils.py` & `alphamed-federated-0.4.9/src/alphafed/utils.py`

 * *Files identical despite different names*

### Comparing `alphamed-federated-0.4.7/src/alphamed_federated.egg-info/PKG-INFO` & `alphamed-federated-0.4.9/src/alphamed_federated.egg-info/PKG-INFO`

 * *Files 0% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: alphamed-federated
-Version: 0.4.7
+Version: 0.4.9
 Summary: AlphaMed Federated Learning Module
 Author-email: Huang Yi Chun <huangyichun@jinghang.ai>
 License:                                  Apache License
                                    Version 2.0, January 2004
                                 http://www.apache.org/licenses/
         
            TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
```

### Comparing `alphamed-federated-0.4.7/src/alphamed_federated.egg-info/SOURCES.txt` & `alphamed-federated-0.4.9/src/alphamed_federated.egg-info/SOURCES.txt`

 * *Files 1% similar despite different names*

```diff
@@ -1,10 +1,11 @@
 LICENSE
 README.md
 pyproject.toml
+src/fcntl.py
 src/alphafed/__init__.py
 src/alphafed/fs.py
 src/alphafed/loggers.py
 src/alphafed/mock.py
 src/alphafed/perf_bench.py
 src/alphafed/scheduler.py
 src/alphafed/utils.py
@@ -20,14 +21,16 @@
 src/alphafed/contractor/task_message_contractor.py
 src/alphafed/data_channel/__init__.py
 src/alphafed/data_channel/data_channel.py
 src/alphafed/data_channel/data_channel_pb2.py
 src/alphafed/data_channel/data_channel_pb2_grpc.py
 src/alphafed/data_channel/grpc_data_channel.py
 src/alphafed/data_channel/shared_file_data_channel.py
+src/alphafed/dataset/__init__.py
+src/alphafed/dataset/mnist.py
 src/alphafed/docs/auto_ml/res/auto.py
 src/alphafed/docs/auto_ml/res/res_net.py
 src/alphafed/docs/customized_scheduler/contractor.py
 src/alphafed/docs/customized_scheduler/scheduler.py
 src/alphafed/docs/customized_scheduler/simple_task.py
 src/alphafed/docs/fed_avg/net.py
 src/alphafed/docs/mock/net.py
@@ -75,23 +78,27 @@
 src/alphafed/examples/auto_ml/skin_lesion_diagnosis/run_data_owner_2.py
 src/alphafed/examples/auto_ml/skin_lesion_diagnosis/run_data_owner_4.py
 src/alphafed/examples/auto_ml/skin_lesion_diagnosis/run_local.py
 src/alphafed/examples/auto_ml/skin_lesion_diagnosis/res_fed_avg/auto.py
 src/alphafed/examples/auto_ml/skin_lesion_diagnosis/res_fed_avg/res_net.py
 src/alphafed/examples/auto_ml/skin_lesion_diagnosis/res_local/auto.py
 src/alphafed/examples/auto_ml/skin_lesion_diagnosis/res_local/res_net.py
+src/alphafed/examples/benchmark/fed_avg_schd.py
+src/alphafed/examples/benchmark/fed_prox_schd.py
+src/alphafed/examples/benchmark/train_res.py
 src/alphafed/examples/data_channel/__init__.py
 src/alphafed/examples/data_channel/clean_history_msg.py
 src/alphafed/examples/data_channel/run_receiver_2.py
 src/alphafed/examples/data_channel/run_receiver_4.py
 src/alphafed/examples/data_channel/run_sender.py
 src/alphafed/examples/fed_avg/__init__.py
 src/alphafed/examples/fed_avg/clean_history_msg.py
 src/alphafed/examples/fed_avg/demo_FedIRM.py
 src/alphafed/examples/fed_avg/demos.py
+src/alphafed/examples/fed_avg/res_net.py
 src/alphafed/examples/fed_avg/run_aggregator.py
 src/alphafed/examples/fed_avg/run_data_owner_2.py
 src/alphafed/examples/fed_avg/run_data_owner_3.py
 src/alphafed/examples/fed_avg/run_data_owner_4.py
 src/alphafed/examples/fed_avg/run_data_owner_5.py
 src/alphafed/examples/fed_avg/model/my_scheduler.py
 src/alphafed/examples/fed_avg/model/net.py
@@ -143,14 +150,16 @@
 src/alphafed/fed_avg/__init__.py
 src/alphafed/fed_avg/contractor.py
 src/alphafed/fed_avg/dp_contractor.py
 src/alphafed/fed_avg/dp_fed_avg.py
 src/alphafed/fed_avg/fed_avg.py
 src/alphafed/fed_avg/secure_contractor.py
 src/alphafed/fed_avg/secure_fed_avg.py
+src/alphafed/fed_prox/__init__.py
+src/alphafed/fed_prox/scheduler.py
 src/alphafed/hetero_nn/__init__.py
 src/alphafed/hetero_nn/contractor.py
 src/alphafed/hetero_nn/hetero_nn.py
 src/alphafed/hetero_nn/secure_contractor.py
 src/alphafed/hetero_nn/secure_hetero_nn.py
 src/alphafed/hetero_nn/psi/__init__.py
 src/alphafed/hetero_nn/psi/psi.py
```

